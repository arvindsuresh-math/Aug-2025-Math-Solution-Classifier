{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef72f69",
   "metadata": {},
   "source": [
    "### Cell 1: Setup and Validator Code\n",
    "\n",
    "This first cell contains all the necessary imports and the full code for the validator. It also defines the configuration variables (`BASE_DIR`, `PROBLEM_INDEX`, `GOLD_ANSWER`) that will be used by the subsequent testing cells.\n",
    "\n",
    "**Action:**\n",
    "1.  Paste the entire content of your `gsm8k_validator.py` script into the marked section below.\n",
    "2.  Set the `PROBLEM_INDEX` and `GOLD_ANSWER` for the problem you want to test.\n",
    "3.  Run this cell once to set up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5affe16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "gsm8k_validator_v2.py\n",
    "======================\n",
    "\n",
    "Performs a flexible, score-based validation of multiple LLM-generated `solve()`\n",
    "functions for a given GSM8K problem. Instead of a rigid filter, this script\n",
    "analyzes all pairs of models to find the most robust and comprehensive consensus.\n",
    "\n",
    "The final output is a confidence score (0.0-1.0+) that reflects:\n",
    "1.  The completeness of parameter alignment between models.\n",
    "2.  The semantic clarity of the aligned parameters.\n",
    "3.  The level of consensus (number of models in agreement).\n",
    "\n",
    "Core Logic:\n",
    "-----------\n",
    "1.  **Parse & Pre-filter (UT-0):** All generated Python files for a problem are\n",
    "    parsed and filtered, keeping only those that produce the correct answer\n",
    "    for the default values.\n",
    "\n",
    "2.  **Pairwise Alignment (UT-2):** For every pair of surviving models, find the\n",
    "    best possible alignment between their function arguments based on semantic\n",
    "    similarity (SBERT) and matching default values. Order is ignored.\n",
    "\n",
    "3.  **Pairwise Fuzzing (UT-3):** For each aligned pair, fuzz-test for functional\n",
    "    equivalence using the \"Fuzz Aligned, Freeze Unaligned\" strategy. This\n",
    "    ensures logical soundness even with partially matching signatures.\n",
    "\n",
    "4.  **Scoring & Consensus:**\n",
    "    - Each successfully validated pair receives a `PairwiseQualityScore` based\n",
    "      on its Alignment Ratio and Semantic Strength.\n",
    "    - The script identifies the largest \"clique\" of models that are all\n",
    "      mutually validated.\n",
    "    - A final `ConfidenceScore` is computed from the clique's average quality,\n",
    "      boosted by a bonus for the size of the consensus.\n",
    "\n",
    "Dependencies\n",
    "------------\n",
    "black                – whitespace-stable formatting\n",
    "libcst               – reliable CST traversal with comment access\n",
    "hypothesis           – property-based fuzzing\n",
    "sentence-transformers (mpnet-base) – SBERT cosine for comment semantics\n",
    "numpy                - for fast vector operations\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "# --- (inside gsm8k_validator.py) ---\n",
    "\n",
    "import importlib.util\n",
    "import inspect\n",
    "import itertools\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import List, Any, Tuple, Dict\n",
    "\n",
    "import black\n",
    "import hypothesis.strategies as st\n",
    "import libcst as cst  # <--- ADD THIS LINE\n",
    "import numpy as np\n",
    "from hypothesis import given, settings, HealthCheck\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import pprint\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---------------------------------------------------------------------- #\n",
    "#  Global constants & Configuration\n",
    "# ---------------------------------------------------------------------- #\n",
    "\n",
    "BASE_DIR = Path(\"code_generation_outputs_cleaned\")\n",
    "\n",
    "_MODEL = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "_COS_THRESHOLD = 0.70  # SBERT cosine ≥ 0.7 ⇒ semantic match\n",
    "_FUZZ_EXAMPLES = 50  # Hypothesis draws\n",
    "_MIN_ALIGNMENT_FOR_FUZZ = 1 # A pair must align on at least one arg to be fuzzed\n",
    "\n",
    "# --- Scoring Weights --- #\n",
    "W_ALIGNMENT = 0.7\n",
    "W_SEMANTIC = 0.3\n",
    "\n",
    "# --- Consensus Bonus Multipliers --- #\n",
    "CONSENSUS_BONUS = {\n",
    "    2: 1.0,  # Baseline for a pair\n",
    "    3: 1.1,  # 10% bonus for a 3-way consensus\n",
    "    4: 1.2,  # 20% bonus for a 4-way consensus\n",
    "    5: 1.3,\n",
    "}\n",
    "\n",
    "_TRACE_RE = re.compile(r\"^#: L(\\d+)\\b\")\n",
    "_DOC_INDEX_RE = re.compile(r\"^Index:\\s*(\\d+)\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------- #\n",
    "#  Dataclasses for Structured Data\n",
    "# ---------------------------------------------------------------------- #\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Argument:\n",
    "    \"\"\"Represents a single argument from a function signature.\"\"\"\n",
    "    name: str\n",
    "    arg_type: str  # <--- ADD THIS LINE\n",
    "    default: Any\n",
    "    comment: str\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ParsedFile:\n",
    "    \"\"\"Normalised representation of a generated code file.\"\"\"\n",
    "    path: Path\n",
    "    module_code: str\n",
    "    func: Any\n",
    "    args: List[Argument] = field(default_factory=list)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class AlignmentResult:\n",
    "    \"\"\"Stores the result of aligning two ParsedFiles.\"\"\"\n",
    "    aligned_pairs: List[Tuple[Argument, Argument]]\n",
    "    unaligned_A: List[Argument]\n",
    "    unaligned_B: List[Argument]\n",
    "    semantic_scores: List[float]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PairwiseValidation:\n",
    "    \"\"\"Stores the full result of a successful pairwise validation.\"\"\"\n",
    "    file_A: ParsedFile\n",
    "    file_B: ParsedFile\n",
    "    alignment: AlignmentResult\n",
    "    quality_score: float\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------- #\n",
    "#  Core Logic Implementation\n",
    "# ---------------------------------------------------------------------- #\n",
    "\n",
    "# In your validator script, find and replace the parse_file function\n",
    "\n",
    "def parse_file(path: Path) -> ParsedFile | None:\n",
    "    \"\"\"\n",
    "    Parse one generated .py file into a structured ParsedFile object using\n",
    "    a direct, regex-based approach.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        src_raw = path.read_text(encoding=\"utf-8\")\n",
    "        src_fmt = black.format_str(src_raw, mode=black.FileMode())\n",
    "\n",
    "        signature_match = re.search(r\"def solve\\s*\\((.*?)\\):\", src_fmt, re.DOTALL)\n",
    "        if not signature_match:\n",
    "            raise ValueError(\"Could not find a 'def solve(...):' signature.\")\n",
    "        \n",
    "        signature_content = signature_match.group(1)\n",
    "\n",
    "        args = []\n",
    "        # --- MODIFIED REGEX: Now captures the type hint in group(2) ---\n",
    "        arg_pattern = re.compile(\n",
    "            r\"^\\s*([a-zA-Z_]\\w*)\\s*:\\s*(\\w+)\\s*=\\s*(.*?)\\s*,?\\s*(?:#\\s*(.*))?$\"\n",
    "        )\n",
    "\n",
    "        for line in signature_content.splitlines():\n",
    "            if not line.strip(): continue\n",
    "            match = arg_pattern.match(line)\n",
    "            if match:\n",
    "                name = match.group(1)\n",
    "                arg_type = match.group(2) # <--- CAPTURE TYPE\n",
    "                default_str = match.group(3).strip()\n",
    "                default_val = eval(default_str)\n",
    "                comment = match.group(4).strip() if match.group(4) else \"\"\n",
    "                \n",
    "                args.append(Argument(\n",
    "                    name=name,\n",
    "                    arg_type=arg_type, # <--- STORE TYPE\n",
    "                    default=default_val,\n",
    "                    comment=comment\n",
    "                ))\n",
    "\n",
    "        spec = importlib.util.spec_from_loader(f\"gsm8k_{path.stem}_{hash(path)}\", loader=None)\n",
    "        mod_dyn = importlib.util.module_from_spec(spec)\n",
    "        exec(src_fmt, mod_dyn.__dict__)\n",
    "\n",
    "        return ParsedFile(\n",
    "            path=path,\n",
    "            module_code=src_fmt,\n",
    "            func=mod_dyn.solve,\n",
    "            args=args\n",
    "        )\n",
    "    except (FileNotFoundError, StopIteration, SyntaxError, Exception) as e:\n",
    "        print(f\"[Parser Error] Skipping {path.name}: {e!r}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "\n",
    "def ut0_answer_match(files: List[ParsedFile], gold: float) -> List[ParsedFile]:\n",
    "    \"\"\"Keep only files whose solve() returns the official answer with default args.\"\"\"\n",
    "    ok_files = []\n",
    "    for pf in files:\n",
    "        try:\n",
    "            if np.isclose(pf.func(), gold):\n",
    "                ok_files.append(pf)\n",
    "        except Exception as e:\n",
    "            print(f\"[UT-0 Fail] {pf.path.name} raised {e!r}\", file=sys.stderr)\n",
    "    return ok_files\n",
    "\n",
    "def find_best_alignment(file_A: ParsedFile, file_B: ParsedFile) -> AlignmentResult:\n",
    "    \"\"\"\n",
    "    Finds the best argument alignment using a 'bucket and match' strategy.\n",
    "    1. Groups args from each file into buckets by (type, default_value).\n",
    "    2. Only performs semantic comparison on args within matching buckets.\n",
    "    \"\"\"\n",
    "    # --- 1. Create buckets for each file's arguments ---\n",
    "    buckets_A = defaultdict(list)\n",
    "    for arg in file_A.args:\n",
    "        buckets_A[(arg.arg_type, arg.default)].append(arg)\n",
    "        \n",
    "    buckets_B = defaultdict(list)\n",
    "    for arg in file_B.args:\n",
    "        buckets_B[(arg.arg_type, arg.default)].append(arg)\n",
    "\n",
    "    aligned_pairs = []\n",
    "    semantic_scores = []\n",
    "    \n",
    "    # --- 2. Iterate through buckets that exist in BOTH files ---\n",
    "    common_keys = set(buckets_A.keys()) & set(buckets_B.keys())\n",
    "    \n",
    "    for key in common_keys:\n",
    "        args_in_bucket_A = buckets_A[key]\n",
    "        args_in_bucket_B = buckets_B[key]\n",
    "        \n",
    "        # --- 3. Perform semantic alignment ONLY within the current bucket ---\n",
    "        texts_A = [arg.name.replace(\"_\", \" \") + \" | \" + arg.comment for arg in args_in_bucket_A]\n",
    "        texts_B = [arg.name.replace(\"_\", \" \") + \" | \" + arg.comment for arg in args_in_bucket_B]\n",
    "        \n",
    "        embeddings_A = _MODEL.encode(texts_A, normalize_embeddings=True)\n",
    "        embeddings_B = _MODEL.encode(texts_B, normalize_embeddings=True)\n",
    "        similarity_matrix = embeddings_A @ embeddings_B.T\n",
    "\n",
    "        # Use a greedy matching strategy within the bucket\n",
    "        sorted_indices = np.argsort(similarity_matrix, axis=None)[::-1]\n",
    "        flat_indices = np.atleast_1d(sorted_indices)\n",
    "        rows, cols = np.unravel_index(flat_indices, similarity_matrix.shape)\n",
    "\n",
    "        used_in_bucket_A = set()\n",
    "        used_in_bucket_B = set()\n",
    "\n",
    "        for i, j in zip(rows, cols):\n",
    "            if i in used_in_bucket_A or j in used_in_bucket_B:\n",
    "                continue\n",
    "\n",
    "            similarity_score = similarity_matrix[i, j]\n",
    "            if similarity_score >= _COS_THRESHOLD:\n",
    "                aligned_pairs.append((args_in_bucket_A[i], args_in_bucket_B[j]))\n",
    "                semantic_scores.append(similarity_score)\n",
    "                used_in_bucket_A.add(i)\n",
    "                used_in_bucket_B.add(j)\n",
    "\n",
    "    # --- 4. Calculate the final unaligned sets ---\n",
    "    final_aligned_A = {p[0] for p in aligned_pairs}\n",
    "    final_aligned_B = {p[1] for p in aligned_pairs}\n",
    "    unaligned_A = [arg for arg in file_A.args if arg not in final_aligned_A]\n",
    "    unaligned_B = [arg for arg in file_B.args if arg not in final_aligned_B]\n",
    "\n",
    "    return AlignmentResult(aligned_pairs, unaligned_A, unaligned_B, semantic_scores)\n",
    "\n",
    "\n",
    "def fuzz_aligned_pair(alignment: AlignmentResult, func_A: callable, func_B: callable) -> bool:\n",
    "    \"\"\"Fuzz-test an aligned pair using the 'Fuzz Aligned, Freeze Unaligned' strategy.\"\"\"\n",
    "    if len(alignment.aligned_pairs) < _MIN_ALIGNMENT_FOR_FUZZ:\n",
    "        return False\n",
    "\n",
    "    strat_map = {}\n",
    "    for i, (arg_A, _) in enumerate(alignment.aligned_pairs):\n",
    "        literal = arg_A.default\n",
    "        strat = st.floats if isinstance(literal, float) else st.integers\n",
    "        strat_map[f\"pair_{i}\"] = strat(min_value=1, max_value=50)\n",
    "\n",
    "    # Freeze unaligned args to their defaults\n",
    "    frozen_kwargs_A = {arg.name: arg.default for arg in alignment.unaligned_A}\n",
    "    frozen_kwargs_B = {arg.name: arg.default for arg in alignment.unaligned_B}\n",
    "\n",
    "    @settings(max_examples=_FUZZ_EXAMPLES, deadline=None, suppress_health_check=[HealthCheck.too_slow])\n",
    "    @given(st.fixed_dictionaries(strat_map))\n",
    "    def _check(fuzzed_values):\n",
    "        kwargs_A = frozen_kwargs_A.copy()\n",
    "        kwargs_B = frozen_kwargs_B.copy()\n",
    "\n",
    "        for i, (arg_A, arg_B) in enumerate(alignment.aligned_pairs):\n",
    "            fuzzed_val = fuzzed_values[f\"pair_{i}\"]\n",
    "            kwargs_A[arg_A.name] = fuzzed_val\n",
    "            kwargs_B[arg_B.name] = fuzzed_val\n",
    "\n",
    "        assert np.isclose(func_A(**kwargs_A), func_B(**kwargs_B))\n",
    "\n",
    "    try:\n",
    "        _check()\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def calculate_pairwise_score(alignment: AlignmentResult, file_A: ParsedFile, file_B: ParsedFile) -> float:\n",
    "    \"\"\"Calculate the quality score for a single validated pair.\"\"\"\n",
    "    num_aligned = len(alignment.aligned_pairs)\n",
    "    \n",
    "    # --- MODIFIED: A more robust Alignment Ratio calculation ---\n",
    "    total_unique_args = num_aligned + len(alignment.unaligned_A) + len(alignment.unaligned_B)\n",
    "    alignment_ratio = num_aligned / total_unique_args if total_unique_args > 0 else 1.0\n",
    "\n",
    "    # Semantic Strength (no change needed here)\n",
    "    semantic_strength = np.mean(alignment.semantic_scores) if alignment.semantic_scores else 1.0\n",
    "\n",
    "    return (W_ALIGNMENT * alignment_ratio) + (W_SEMANTIC * semantic_strength)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------- #\n",
    "#  Orchestration and Reporting\n",
    "# ---------------------------------------------------------------------- #\n",
    "\n",
    "def analyze_problem_outputs(problem_dir: Path, gold_answer: float):\n",
    "    \"\"\"Main orchestrator to analyze all model outputs for a single problem.\"\"\"\n",
    "    print(f\"\\n{'='*20} Analyzing Problem: {problem_dir.name} {'='*20}\")\n",
    "    \n",
    "    all_files = list(problem_dir.glob(\"*.py\"))\n",
    "    if not all_files:\n",
    "        print(\"No Python files found in this directory.\")\n",
    "        return\n",
    "\n",
    "    parsed_files = [pf for pf in [parse_file(p) for p in all_files] if pf is not None]\n",
    "    print(f\"Found and parsed {len(parsed_files)} files.\")\n",
    "\n",
    "    survivors_ut0 = ut0_answer_match(parsed_files, gold_answer)\n",
    "    print(f\"{len(survivors_ut0)} files passed UT-0 (correct default answer).\")\n",
    "    if len(survivors_ut0) < 2:\n",
    "        print(\"Not enough models passed UT-0 to find a pair. Aborting.\")\n",
    "        return\n",
    "\n",
    "    # --- Pairwise Validation ---\n",
    "    validated_pairs: List[PairwiseValidation] = []\n",
    "    for file_A, file_B in itertools.combinations(survivors_ut0, 2):\n",
    "        alignment = find_best_alignment(file_A, file_B)\n",
    "        \n",
    "        if fuzz_aligned_pair(alignment, file_A.func, file_B.func):\n",
    "            score = calculate_pairwise_score(alignment, file_A, file_B)\n",
    "            validated_pairs.append(PairwiseValidation(file_A, file_B, alignment, score))\n",
    "            print(f\"  ✓ Validated Pair: ({file_A.path.name}, {file_B.path.name}), Score: {score:.3f}\")\n",
    "\n",
    "    if not validated_pairs:\n",
    "        print(\"\\nNo functionally equivalent pairs found after fuzzing.\")\n",
    "        return\n",
    "\n",
    "    # --- Find Best Consensus Clique ---\n",
    "    nodes = survivors_ut0\n",
    "    adj = {pf.path.name: set() for pf in nodes}\n",
    "    for vp in validated_pairs:\n",
    "        adj[vp.file_A.path.name].add(vp.file_B.path.name)\n",
    "        adj[vp.file_B.path.name].add(vp.file_A.path.name)\n",
    "\n",
    "    best_clique_names = []\n",
    "    # Check for cliques of decreasing size\n",
    "    for size in range(len(nodes), 1, -1):\n",
    "        # Use a list of names for combinations, not the ParsedFile objects\n",
    "        node_names = [pf.path.name for pf in nodes]\n",
    "        for combo_names in itertools.combinations(node_names, size):\n",
    "            is_clique = all(\n",
    "                combo_names[j] in adj[combo_names[i]] for i in range(size) for j in range(i + 1, size)\n",
    "            )\n",
    "            if is_clique:\n",
    "                best_clique_names = list(combo_names)\n",
    "                break\n",
    "        if best_clique_names:\n",
    "            break\n",
    "    \n",
    "    # --- Calculate Final Score and Report ---\n",
    "    # This block now correctly handles the case where no clique is found\n",
    "    if not best_clique_names and validated_pairs:\n",
    "        # If no clique > 2 found, find the single best pair\n",
    "        print(\"\\nNo consensus clique found. Reporting score for the single best pair.\")\n",
    "        best_pair = max(validated_pairs, key=lambda vp: vp.quality_score)\n",
    "        final_score = best_pair.quality_score\n",
    "        clique_size = 2\n",
    "        best_clique_names = sorted([best_pair.file_A.path.name, best_pair.file_B.path.name])\n",
    "        avg_quality = final_score\n",
    "        bonus = CONSENSUS_BONUS.get(clique_size, 1.0)\n",
    "    elif best_clique_names:\n",
    "        # A clique was found\n",
    "        clique_size = len(best_clique_names)\n",
    "        clique_pairs_scores = [\n",
    "            vp.quality_score for vp in validated_pairs \n",
    "            if vp.file_A.path.name in best_clique_names and vp.file_B.path.name in best_clique_names\n",
    "        ]\n",
    "        avg_quality = np.mean(clique_pairs_scores) if clique_pairs_scores else 0\n",
    "        bonus = CONSENSUS_BONUS.get(clique_size, max(CONSENSUS_BONUS.values()))\n",
    "        final_score = avg_quality * bonus\n",
    "    else:\n",
    "        # This case handles when there are no validated pairs at all\n",
    "        clique_size = 0\n",
    "        avg_quality = 0\n",
    "        bonus = 0\n",
    "        final_score = 0\n",
    "\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"                 VALIDATION SUMMARY\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Best Consensus Found: {clique_size}-way agreement\")\n",
    "    if best_clique_names:\n",
    "        print(f\"Models in Best Clique:\")\n",
    "        for name in sorted(best_clique_names):\n",
    "            print(f\"  - {name}\")\n",
    "    else:\n",
    "        print(\"Models in Best Clique: None\")\n",
    "\n",
    "    print(f\"\\nAverage Pairwise Quality in Clique: {avg_quality:.4f}\")\n",
    "    print(f\"Consensus Bonus Multiplier: x{bonus}\")\n",
    "    print(f\"FINAL CONFIDENCE SCORE: {final_score:.4f}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82fa680",
   "metadata": {},
   "source": [
    "### Cell 2: Test File Parsing\n",
    "\n",
    "This cell finds all `.py` files in the directory for the configured `PROBLEM_INDEX` and runs the `parse_file` function on each one. It reports the total number of files found and how many were parsed successfully, listing their names. The result is stored in `all_parsed_files` for the next cell to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e076b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_parsing_test(base_dir_str: str, problem_index: int) -> list[ParsedFile]:\n",
    "    \"\"\"Finds and parses all source files for a given problem index.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*20 + \" Test 1: File Parsing \" + \"=\"*20)\n",
    "    problem_dir = Path(base_dir_str) / str(problem_index)\n",
    "    if not problem_dir.is_dir():\n",
    "        print(f\"Error: Directory not found at {problem_dir}\")\n",
    "        return []\n",
    "    \n",
    "    all_source_files = list(problem_dir.glob(\"*.py\"))\n",
    "    print(f\"Found {len(all_source_files)} files in '{problem_dir}'.\")\n",
    "    \n",
    "    all_parsed_files = [pf for pf in [parse_file(p) for p in all_source_files] if pf]\n",
    "    print(f\"\\nSuccessfully parsed {len(all_parsed_files)} files:\")\n",
    "    for pf in all_parsed_files:\n",
    "        print(f\"  - {pf.path.name}\")\n",
    "    return all_parsed_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ac3b3",
   "metadata": {},
   "source": [
    "### Cell 3: Test UT-0 (Answer Match)\n",
    "\n",
    "This cell takes the list of successfully parsed files from the previous step and runs the `ut0_answer_match` function. It filters the list, keeping only the files whose `solve()` function returns the correct `GOLD_ANSWER`. The result is stored in `survivors_ut0` for the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "577291af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ut0_test(parsed_files: list[ParsedFile], gold_answer: float) -> list[ParsedFile]:\n",
    "    \"\"\"Runs UT-0 (Answer Match) on a list of parsed files.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*20 + \" Test 2: UT-0 (Answer Match) \" + \"=\"*20)\n",
    "    if not parsed_files:\n",
    "        print(\"No parsed files to test. Skipping.\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"--- Running UT-0 against Gold Answer: {gold_answer} ---\")\n",
    "    survivors = ut0_answer_match(parsed_files, gold_answer)\n",
    "    print(f\"\\n{len(survivors)} files passed UT-0:\")\n",
    "    for pf in survivors:\n",
    "        print(f\"  - {pf.path.name}\")\n",
    "    return survivors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94975616",
   "metadata": {},
   "source": [
    "### Cell 4: Note on UT-1 (Trace Lists)\n",
    "\n",
    "Our new flexible validation strategy does not use the `UT-1` (Trace List comparison) as a hard filter. The new philosophy prioritizes *functional equivalence* (proven by fuzzing) over the exact sequence of intermediate steps. Therefore, there is no dedicated test cell for UT-1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c60e53a",
   "metadata": {},
   "source": [
    "### Cell 5: Test UT-2 (Argument Alignment)\n",
    "\n",
    "This cell tests the core alignment logic (`find_best_alignment`) on the files that passed UT-0. It iterates through every possible pair, running the \"bucket and match\" strategy, and prints a detailed debug report showing which pairs were aligned and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb991f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Test case functions are defined.\n"
     ]
    }
   ],
   "source": [
    "def run_ut2_alignment_test(survivors_ut0: list[ParsedFile]):\n",
    "    \"\"\"Runs UT-2 (Argument Alignment) on all pairs of UT-0 survivors.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*20 + \" Test 3: UT-2 (Argument Alignment) \" + \"=\"*20)\n",
    "    if not survivors_ut0 or len(survivors_ut0) < 2:\n",
    "        print(\"Fewer than 2 survivors from UT-0. Cannot perform alignment.\")\n",
    "        return\n",
    "\n",
    "    print(f\"--- Running alignment report on {len(survivors_ut0)} files ---\")\n",
    "    pp = pprint.PrettyPrinter(indent=2)\n",
    "    \n",
    "    for file_A, file_B in itertools.combinations(survivors_ut0, 2):\n",
    "        print(\"\\n\" + \"#\"*60)\n",
    "        print(f\"### Aligning: {file_A.path.name} (A) vs. {file_B.path.name} (B)\")\n",
    "        print(\"#\"*60)\n",
    "\n",
    "        alignment_result = find_best_alignment(file_A, file_B)\n",
    "        \n",
    "        print(\"\\n--- Summary of Alignment ---\")\n",
    "        print(f\"Found {len(alignment_result.aligned_pairs)} aligned pairs:\")\n",
    "        pp.pprint(sorted([(p[0].name, p[1].name) for p in alignment_result.aligned_pairs]))\n",
    "        \n",
    "        print(\"\\n--- Unaligned Arguments ---\")\n",
    "        print(\"Unaligned in A:\", sorted([arg.name for arg in alignment_result.unaligned_A]))\n",
    "        print(\"Unaligned in B:\", sorted([arg.name for arg in alignment_result.unaligned_B]))\n",
    "\n",
    "print(\"Setup complete. Test case functions are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30d9aa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Test 1: File Parsing ====================\n",
      "Found 9 files in 'code_generation_outputs_cleaned/4483'.\n",
      "\n",
      "Successfully parsed 9 files:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - google_gemini-2.5-flash-lite-preview-06-17.py\n",
      "  - openai_o3-mini.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - openai_o4-mini.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - google_gemini-2.5-pro.py\n",
      "\n",
      "==================== Test 2: UT-0 (Answer Match) ====================\n",
      "--- Running UT-0 against Gold Answer: 100.0 ---\n",
      "\n",
      "9 files passed UT-0:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - google_gemini-2.5-flash-lite-preview-06-17.py\n",
      "  - openai_o3-mini.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - openai_o4-mini.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - google_gemini-2.5-pro.py\n",
      "\n",
      "==================== Test 3: UT-2 (Argument Alignment) ====================\n",
      "--- Running alignment report on 9 files ---\n",
      "\n",
      "############################################################\n",
      "### Aligning: anthropic_claude-3-5-haiku-20241022.py (A) vs. google_gemini-2.5-flash.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('bryan_high_price_per_record', 'bryan_price_interested'),\n",
      "  ('bryan_low_price_per_record', 'bryan_price_not_interested'),\n",
      "  ('sammy_price_per_record', 'sammy_price_per_record'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: ['bryan_fraction_interested']\n",
      "\n",
      "############################################################\n",
      "### Aligning: anthropic_claude-3-5-haiku-20241022.py (A) vs. google_gemini-2.5-flash-lite-preview-06-17.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('bryan_high_price_per_record', 'bryan_offer_interested_half'),\n",
      "  ('sammy_price_per_record', 'sammy_offer_per_record'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_low_price_per_record']\n",
      "Unaligned in B: ['bryan_offer_uninterested_half']\n",
      "\n",
      "############################################################\n",
      "### Aligning: anthropic_claude-3-5-haiku-20241022.py (A) vs. openai_o3-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('bryan_low_price_per_record', 'bryan_other_price'),\n",
      "  ('sammy_price_per_record', 'sammy_price'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_high_price_per_record']\n",
      "Unaligned in B: ['bryan_interest_price']\n",
      "\n",
      "############################################################\n",
      "### Aligning: anthropic_claude-3-5-haiku-20241022.py (A) vs. openai_gpt-4.1.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('bryan_high_price_per_record', 'price_per_record_bryan_interested'),\n",
      "  ('bryan_low_price_per_record', 'price_per_record_bryan_not_interested'),\n",
      "  ('sammy_price_per_record', 'price_per_record_sammy'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: anthropic_claude-3-5-haiku-20241022.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('bryan_high_price_per_record', 'bryan_price_interested'),\n",
      "  ('bryan_low_price_per_record', 'bryan_price_not_interested'),\n",
      "  ('sammy_price_per_record', 'sammy_price_per_record'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: ['bryan_fraction_interested']\n",
      "\n",
      "############################################################\n",
      "### Aligning: anthropic_claude-3-5-haiku-20241022.py (A) vs. openai_o4-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 2 aligned pairs:\n",
      "[('sammy_price_per_record', 'price_sammy'), ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_high_price_per_record', 'bryan_low_price_per_record']\n",
      "Unaligned in B: ['fraction_records_bryan', 'price_interested', 'price_not_interested']\n",
      "\n",
      "############################################################\n",
      "### Aligning: anthropic_claude-3-5-haiku-20241022.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 1 aligned pairs:\n",
      "[('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_high_price_per_record', 'bryan_low_price_per_record', 'sammy_price_per_record']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: anthropic_claude-3-5-haiku-20241022.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('bryan_high_price_per_record', 'bryan_price_per_record_interested'),\n",
      "  ('bryan_low_price_per_record', 'bryan_price_per_record_not_interested'),\n",
      "  ('sammy_price_per_record', 'sammy_price_per_record'),\n",
      "  ('total_records', 'num_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash.py (A) vs. google_gemini-2.5-flash-lite-preview-06-17.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('bryan_price_interested', 'bryan_offer_interested_half'),\n",
      "  ('bryan_price_not_interested', 'bryan_offer_uninterested_half'),\n",
      "  ('sammy_price_per_record', 'sammy_offer_per_record'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_fraction_interested']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash.py (A) vs. openai_o3-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('bryan_price_interested', 'bryan_interest_price'),\n",
      "  ('bryan_price_not_interested', 'bryan_other_price'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_fraction_interested', 'sammy_price_per_record']\n",
      "Unaligned in B: ['sammy_price']\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash.py (A) vs. openai_gpt-4.1.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('bryan_price_interested', 'price_per_record_bryan_interested'),\n",
      "  ('bryan_price_not_interested', 'price_per_record_bryan_not_interested'),\n",
      "  ('sammy_price_per_record', 'price_per_record_sammy'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_fraction_interested']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 5 aligned pairs:\n",
      "[ ('bryan_fraction_interested', 'bryan_fraction_interested'),\n",
      "  ('bryan_price_interested', 'bryan_price_interested'),\n",
      "  ('bryan_price_not_interested', 'bryan_price_not_interested'),\n",
      "  ('sammy_price_per_record', 'sammy_price_per_record'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash.py (A) vs. openai_o4-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('bryan_price_interested', 'price_interested'),\n",
      "  ('bryan_price_not_interested', 'price_not_interested'),\n",
      "  ('sammy_price_per_record', 'price_sammy'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_fraction_interested']\n",
      "Unaligned in B: ['fraction_records_bryan']\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 1 aligned pairs:\n",
      "[('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_fraction_interested', 'bryan_price_interested', 'bryan_price_not_interested', 'sammy_price_per_record']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('bryan_price_interested', 'bryan_price_per_record_interested'),\n",
      "  ('bryan_price_not_interested', 'bryan_price_per_record_not_interested'),\n",
      "  ('sammy_price_per_record', 'sammy_price_per_record'),\n",
      "  ('total_records', 'num_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_fraction_interested']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. openai_o3-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('bryan_offer_interested_half', 'bryan_interest_price'),\n",
      "  ('bryan_offer_uninterested_half', 'bryan_other_price'),\n",
      "  ('sammy_offer_per_record', 'sammy_price'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. openai_gpt-4.1.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('bryan_offer_interested_half', 'price_per_record_bryan_interested'),\n",
      "  ('bryan_offer_uninterested_half', 'price_per_record_bryan_not_interested'),\n",
      "  ('sammy_offer_per_record', 'price_per_record_sammy'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('bryan_offer_interested_half', 'bryan_price_interested'),\n",
      "  ('bryan_offer_uninterested_half', 'bryan_price_not_interested'),\n",
      "  ('sammy_offer_per_record', 'sammy_price_per_record'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: ['bryan_fraction_interested']\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. openai_o4-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('bryan_offer_interested_half', 'price_interested'),\n",
      "  ('bryan_offer_uninterested_half', 'price_not_interested'),\n",
      "  ('sammy_offer_per_record', 'price_sammy'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: ['fraction_records_bryan']\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 1 aligned pairs:\n",
      "[('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_offer_interested_half', 'bryan_offer_uninterested_half', 'sammy_offer_per_record']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('bryan_offer_interested_half', 'bryan_price_per_record_interested'),\n",
      "  ('sammy_offer_per_record', 'sammy_price_per_record'),\n",
      "  ('total_records', 'num_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_offer_uninterested_half']\n",
      "Unaligned in B: ['bryan_price_per_record_not_interested']\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_o3-mini.py (A) vs. openai_gpt-4.1.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('bryan_interest_price', 'price_per_record_bryan_interested'),\n",
      "  ('bryan_other_price', 'price_per_record_bryan_not_interested'),\n",
      "  ('sammy_price', 'price_per_record_sammy'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_o3-mini.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('bryan_interest_price', 'bryan_price_interested'),\n",
      "  ('bryan_other_price', 'bryan_price_not_interested'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['sammy_price']\n",
      "Unaligned in B: ['bryan_fraction_interested', 'sammy_price_per_record']\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_o3-mini.py (A) vs. openai_o4-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('bryan_interest_price', 'price_interested'),\n",
      "  ('sammy_price', 'price_sammy'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_other_price']\n",
      "Unaligned in B: ['fraction_records_bryan', 'price_not_interested']\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_o3-mini.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 1 aligned pairs:\n",
      "[('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_interest_price', 'bryan_other_price', 'sammy_price']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_o3-mini.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('bryan_interest_price', 'bryan_price_per_record_interested'),\n",
      "  ('bryan_other_price', 'bryan_price_per_record_not_interested'),\n",
      "  ('sammy_price', 'sammy_price_per_record'),\n",
      "  ('total_records', 'num_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_gpt-4.1.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('price_per_record_bryan_interested', 'bryan_price_interested'),\n",
      "  ('price_per_record_bryan_not_interested', 'bryan_price_not_interested'),\n",
      "  ('price_per_record_sammy', 'sammy_price_per_record'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: ['bryan_fraction_interested']\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_gpt-4.1.py (A) vs. openai_o4-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('price_per_record_bryan_not_interested', 'price_not_interested'),\n",
      "  ('price_per_record_sammy', 'price_sammy'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['price_per_record_bryan_interested']\n",
      "Unaligned in B: ['fraction_records_bryan', 'price_interested']\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_gpt-4.1.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 1 aligned pairs:\n",
      "[('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['price_per_record_bryan_interested', 'price_per_record_bryan_not_interested', 'price_per_record_sammy']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_gpt-4.1.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('price_per_record_bryan_interested', 'bryan_price_per_record_interested'),\n",
      "  ( 'price_per_record_bryan_not_interested',\n",
      "    'bryan_price_per_record_not_interested'),\n",
      "  ('price_per_record_sammy', 'sammy_price_per_record'),\n",
      "  ('total_records', 'num_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.0-flash-thinking-exp.py (A) vs. openai_o4-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('bryan_price_interested', 'price_interested'),\n",
      "  ('bryan_price_not_interested', 'price_not_interested'),\n",
      "  ('sammy_price_per_record', 'price_sammy'),\n",
      "  ('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_fraction_interested']\n",
      "Unaligned in B: ['fraction_records_bryan']\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.0-flash-thinking-exp.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 1 aligned pairs:\n",
      "[('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_fraction_interested', 'bryan_price_interested', 'bryan_price_not_interested', 'sammy_price_per_record']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.0-flash-thinking-exp.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('bryan_price_interested', 'bryan_price_per_record_interested'),\n",
      "  ('bryan_price_not_interested', 'bryan_price_per_record_not_interested'),\n",
      "  ('sammy_price_per_record', 'sammy_price_per_record'),\n",
      "  ('total_records', 'num_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['bryan_fraction_interested']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_o4-mini.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 1 aligned pairs:\n",
      "[('total_records', 'total_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['fraction_records_bryan', 'price_interested', 'price_not_interested', 'price_sammy']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_o4-mini.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('price_interested', 'bryan_price_per_record_interested'),\n",
      "  ('price_sammy', 'sammy_price_per_record'),\n",
      "  ('total_records', 'num_records')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['fraction_records_bryan', 'price_not_interested']\n",
      "Unaligned in B: ['bryan_price_per_record_not_interested']\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_gpt-4.1-mini.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 0 aligned pairs:\n",
      "[]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['total_records']\n",
      "Unaligned in B: ['bryan_price_per_record_interested', 'bryan_price_per_record_not_interested', 'num_records', 'sammy_price_per_record']\n"
     ]
    }
   ],
   "source": [
    "PROBLEM_INDEX = 4483\n",
    "GOLD_ANSWER = 100.0\n",
    "\n",
    "# --- Execute Tests in Sequence ---\n",
    "# 1. Parsing\n",
    "parsed_files = run_parsing_test(BASE_DIR, PROBLEM_INDEX)\n",
    "\n",
    "# 2. UT-0\n",
    "ut0_survivors_4483 = run_ut0_test(parsed_files, GOLD_ANSWER)\n",
    "\n",
    "# 3. UT-2\n",
    "run_ut2_alignment_test(ut0_survivors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6f4b8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Test 1: File Parsing ====================\n",
      "Found 8 files in 'code_generation_outputs_cleaned/636'.\n",
      "\n",
      "Successfully parsed 8 files:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - google_gemini-2.5-flash-lite-preview-06-17.py\n",
      "  - openai_o3-mini.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - google_gemini-2.5-pro.py\n",
      "\n",
      "==================== Test 2: UT-0 (Answer Match) ====================\n",
      "--- Running UT-0 against Gold Answer: 52.0 ---\n",
      "\n",
      "8 files passed UT-0:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - google_gemini-2.5-flash-lite-preview-06-17.py\n",
      "  - openai_o3-mini.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - google_gemini-2.5-pro.py\n",
      "\n",
      "==================== Test 3: UT-2 (Argument Alignment) ====================\n",
      "--- Running alignment report on 8 files ---\n",
      "\n",
      "############################################################\n",
      "### Aligning: anthropic_claude-3-5-haiku-20241022.py (A) vs. google_gemini-2.5-flash.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('homework_time', 'assignment_time'),\n",
      "  ('keys_sticky', 'total_sticky_keys'),\n",
      "  ('time_per_key', 'time_per_key')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['keys_cleaned']\n",
      "Unaligned in B: ['keys_left_to_clean']\n",
      "\n",
      "############################################################\n",
      "### Aligning: anthropic_claude-3-5-haiku-20241022.py (A) vs. google_gemini-2.5-flash-lite-preview-06-17.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('homework_time', 'assignment_time'),\n",
      "  ('keys_sticky', 'keys_to_fix_initially'),\n",
      "  ('time_per_key', 'time_per_key')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['keys_cleaned']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: anthropic_claude-3-5-haiku-20241022.py (A) vs. openai_o3-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('homework_time', 'assignment_time'),\n",
      "  ('keys_cleaned', 'keys_cleaned'),\n",
      "  ('keys_sticky', 'sticky_keys'),\n",
      "  ('time_per_key', 'cleaning_time_per_key')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: ['dinner_time', 'keys_remaining']\n",
      "\n",
      "############################################################\n",
      "### Aligning: anthropic_claude-3-5-haiku-20241022.py (A) vs. openai_gpt-4.1.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('homework_time', 'assignment_time'),\n",
      "  ('keys_sticky', 'total_sticky_keys'),\n",
      "  ('time_per_key', 'time_per_key')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['keys_cleaned']\n",
      "Unaligned in B: ['dinner_time', 'keys_left_after_one']\n",
      "\n",
      "############################################################\n",
      "### Aligning: anthropic_claude-3-5-haiku-20241022.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('homework_time', 'assignment_time'),\n",
      "  ('keys_sticky', 'total_sticky_keys'),\n",
      "  ('time_per_key', 'time_per_key')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['keys_cleaned']\n",
      "Unaligned in B: ['keys_left_after_one']\n",
      "\n",
      "############################################################\n",
      "### Aligning: anthropic_claude-3-5-haiku-20241022.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('homework_time', 'time_assignment'),\n",
      "  ('keys_sticky', 'total_keys'),\n",
      "  ('time_per_key', 'time_per_key')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['keys_cleaned']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: anthropic_claude-3-5-haiku-20241022.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('homework_time', 'assignment_time'),\n",
      "  ('keys_sticky', 'sticky_keys_total'),\n",
      "  ('time_per_key', 'time_to_clean_one_key')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['keys_cleaned']\n",
      "Unaligned in B: ['dinner_hour', 'dinner_minute', 'keys_left_to_clean']\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash.py (A) vs. google_gemini-2.5-flash-lite-preview-06-17.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('assignment_time', 'assignment_time'),\n",
      "  ('time_per_key', 'time_per_key'),\n",
      "  ('total_sticky_keys', 'keys_to_fix_initially')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['keys_left_to_clean']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash.py (A) vs. openai_o3-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('assignment_time', 'assignment_time'),\n",
      "  ('keys_left_to_clean', 'keys_remaining'),\n",
      "  ('time_per_key', 'cleaning_time_per_key'),\n",
      "  ('total_sticky_keys', 'sticky_keys')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: ['dinner_time', 'keys_cleaned']\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash.py (A) vs. openai_gpt-4.1.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('assignment_time', 'assignment_time'),\n",
      "  ('keys_left_to_clean', 'keys_left_after_one'),\n",
      "  ('time_per_key', 'time_per_key'),\n",
      "  ('total_sticky_keys', 'total_sticky_keys')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: ['dinner_time']\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('assignment_time', 'assignment_time'),\n",
      "  ('keys_left_to_clean', 'keys_left_after_one'),\n",
      "  ('time_per_key', 'time_per_key'),\n",
      "  ('total_sticky_keys', 'total_sticky_keys')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('assignment_time', 'time_assignment'),\n",
      "  ('time_per_key', 'time_per_key'),\n",
      "  ('total_sticky_keys', 'total_keys')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['keys_left_to_clean']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('assignment_time', 'assignment_time'),\n",
      "  ('keys_left_to_clean', 'keys_left_to_clean'),\n",
      "  ('time_per_key', 'time_to_clean_one_key'),\n",
      "  ('total_sticky_keys', 'sticky_keys_total')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: ['dinner_hour', 'dinner_minute']\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. openai_o3-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('assignment_time', 'assignment_time'),\n",
      "  ('keys_to_fix_initially', 'sticky_keys'),\n",
      "  ('time_per_key', 'cleaning_time_per_key')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: ['dinner_time', 'keys_cleaned', 'keys_remaining']\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. openai_gpt-4.1.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('assignment_time', 'assignment_time'),\n",
      "  ('keys_to_fix_initially', 'total_sticky_keys'),\n",
      "  ('time_per_key', 'time_per_key')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: ['dinner_time', 'keys_left_after_one']\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('assignment_time', 'assignment_time'),\n",
      "  ('keys_to_fix_initially', 'total_sticky_keys'),\n",
      "  ('time_per_key', 'time_per_key')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: ['keys_left_after_one']\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('assignment_time', 'time_assignment'),\n",
      "  ('keys_to_fix_initially', 'total_keys'),\n",
      "  ('time_per_key', 'time_per_key')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('assignment_time', 'assignment_time'),\n",
      "  ('keys_to_fix_initially', 'sticky_keys_total'),\n",
      "  ('time_per_key', 'time_to_clean_one_key')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: ['dinner_hour', 'dinner_minute', 'keys_left_to_clean']\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_o3-mini.py (A) vs. openai_gpt-4.1.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('assignment_time', 'assignment_time'),\n",
      "  ('cleaning_time_per_key', 'time_per_key'),\n",
      "  ('keys_remaining', 'keys_left_after_one'),\n",
      "  ('sticky_keys', 'total_sticky_keys')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['dinner_time', 'keys_cleaned']\n",
      "Unaligned in B: ['dinner_time']\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_o3-mini.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('assignment_time', 'assignment_time'),\n",
      "  ('cleaning_time_per_key', 'time_per_key'),\n",
      "  ('keys_remaining', 'keys_left_after_one'),\n",
      "  ('sticky_keys', 'total_sticky_keys')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['dinner_time', 'keys_cleaned']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_o3-mini.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('assignment_time', 'time_assignment'),\n",
      "  ('cleaning_time_per_key', 'time_per_key'),\n",
      "  ('sticky_keys', 'total_keys')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['dinner_time', 'keys_cleaned', 'keys_remaining']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_o3-mini.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('assignment_time', 'assignment_time'),\n",
      "  ('cleaning_time_per_key', 'time_to_clean_one_key'),\n",
      "  ('keys_remaining', 'keys_left_to_clean'),\n",
      "  ('sticky_keys', 'sticky_keys_total')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['dinner_time', 'keys_cleaned']\n",
      "Unaligned in B: ['dinner_hour', 'dinner_minute']\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_gpt-4.1.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('assignment_time', 'assignment_time'),\n",
      "  ('keys_left_after_one', 'keys_left_after_one'),\n",
      "  ('time_per_key', 'time_per_key'),\n",
      "  ('total_sticky_keys', 'total_sticky_keys')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['dinner_time']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_gpt-4.1.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('assignment_time', 'time_assignment'),\n",
      "  ('time_per_key', 'time_per_key'),\n",
      "  ('total_sticky_keys', 'total_keys')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['dinner_time', 'keys_left_after_one']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_gpt-4.1.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('assignment_time', 'assignment_time'),\n",
      "  ('keys_left_after_one', 'keys_left_to_clean'),\n",
      "  ('time_per_key', 'time_to_clean_one_key'),\n",
      "  ('total_sticky_keys', 'sticky_keys_total')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['dinner_time']\n",
      "Unaligned in B: ['dinner_hour', 'dinner_minute']\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.0-flash-thinking-exp.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('assignment_time', 'time_assignment'),\n",
      "  ('time_per_key', 'time_per_key'),\n",
      "  ('total_sticky_keys', 'total_keys')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: ['keys_left_after_one']\n",
      "Unaligned in B: []\n",
      "\n",
      "############################################################\n",
      "### Aligning: google_gemini-2.0-flash-thinking-exp.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 4 aligned pairs:\n",
      "[ ('assignment_time', 'assignment_time'),\n",
      "  ('keys_left_after_one', 'keys_left_to_clean'),\n",
      "  ('time_per_key', 'time_to_clean_one_key'),\n",
      "  ('total_sticky_keys', 'sticky_keys_total')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: ['dinner_hour', 'dinner_minute']\n",
      "\n",
      "############################################################\n",
      "### Aligning: openai_gpt-4.1-mini.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "\n",
      "--- Summary of Alignment ---\n",
      "Found 3 aligned pairs:\n",
      "[ ('time_assignment', 'assignment_time'),\n",
      "  ('time_per_key', 'time_to_clean_one_key'),\n",
      "  ('total_keys', 'sticky_keys_total')]\n",
      "\n",
      "--- Unaligned Arguments ---\n",
      "Unaligned in A: []\n",
      "Unaligned in B: ['dinner_hour', 'dinner_minute', 'keys_left_to_clean']\n"
     ]
    }
   ],
   "source": [
    "PROBLEM_INDEX = 636\n",
    "GOLD_ANSWER = 52.0\n",
    "\n",
    "# --- Execute Tests in Sequence ---\n",
    "# 1. Parsing\n",
    "parsed_files_636 = run_parsing_test(BASE_DIR, PROBLEM_INDEX)\n",
    "\n",
    "# 2. UT-0\n",
    "ut0_survivors_636 = run_ut0_test(parsed_files_636, GOLD_ANSWER)\n",
    "\n",
    "# 3. UT-2\n",
    "run_ut2_alignment_test(ut0_survivors_636)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb2e1f6",
   "metadata": {},
   "source": [
    "### Cell: Test UT-3 (Fuzzing Equivalence)\n",
    "\n",
    "This cell tests the `fuzz_aligned_pair` function. It defines two test cases:\n",
    "\n",
    "1.  **A \"Passing\" Case:** Two functions (`equivalent_A`, `equivalent_B`) that are mathematically identical but use different variable names. This pair should pass the fuzz test.\n",
    "2.  **A \"Failing\" Case:** Two functions (`different_A`, `different_B`) that produce the same result for their default values but have different underlying logic. This pair should fail the fuzz test.\n",
    "\n",
    "This will confirm that the fuzzer can correctly distinguish between truly equivalent and merely coincidentally correct functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee8996d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Test Case 1: Equivalent Functions ====================\n",
      "\n",
      "############################################################\n",
      "### Fuzz-Testing: mock_equivalent_A.py vs. mock_equivalent_B.py\n",
      "############################################################\n",
      "Alignment successful. Found 1 pairs to fuzz.\n",
      "\n",
      "✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "==================== Test Case 2: Different Functions ====================\n",
      "\n",
      "############################################################\n",
      "### Fuzz-Testing: mock_different_A.py vs. mock_different_C.py\n",
      "############################################################\n",
      "Alignment successful. Found 2 pairs to fuzz.\n",
      "\n",
      "❌ RESULT: FAILED. The functions have different logic.\n"
     ]
    }
   ],
   "source": [
    "# Cell for testing UT-3\n",
    "\n",
    "def run_ut3_fuzzing_test(file_A: ParsedFile, file_B: ParsedFile):\n",
    "    \"\"\"\n",
    "    A dedicated function to test the fuzzing logic on a given pair of ParsedFile objects.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"#\"*60)\n",
    "    print(f\"### Fuzz-Testing: {file_A.path.name} vs. {file_B.path.name}\")\n",
    "    print(\"#\"*60)\n",
    "\n",
    "    # Step 1: Align the pair first, as this is a prerequisite for fuzzing.\n",
    "    alignment = find_best_alignment(file_A, file_B)\n",
    "    \n",
    "    if len(alignment.aligned_pairs) < _MIN_ALIGNMENT_FOR_FUZZ:\n",
    "        print(\"Alignment failed or found too few common arguments. Skipping fuzz test.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Alignment successful. Found {len(alignment.aligned_pairs)} pairs to fuzz.\")\n",
    "    \n",
    "    # Step 2: Run the fuzz test.\n",
    "    is_equivalent = fuzz_aligned_pair(alignment, file_A.func, file_B.func)\n",
    "    \n",
    "    # Step 3: Report the result.\n",
    "    if is_equivalent:\n",
    "        print(\"\\n✅ RESULT: PASSED. The functions are functionally equivalent.\")\n",
    "    else:\n",
    "        print(\"\\n❌ RESULT: FAILED. The functions have different logic.\")\n",
    "\n",
    "# --- Test Case 1: Functionally EQUIVALENT Pair (Should PASS) ---\n",
    "print(\"=\"*20 + \" Test Case 1: Equivalent Functions \" + \"=\"*20)\n",
    "\n",
    "# Define two functions that are identical in logic but have different arg names\n",
    "def equivalent_A(price: int = 10, num_items: int = 5, tax: int = 2):\n",
    "    return price * num_items + tax\n",
    "\n",
    "def equivalent_B(unit_cost: int = 10, quantity: int = 5, flat_fee: int = 2):\n",
    "    return unit_cost * quantity + flat_fee\n",
    "\n",
    "# Create mock ParsedFile objects for them\n",
    "mock_file_A = ParsedFile(\n",
    "    path=Path(\"mock_equivalent_A.py\"), module_code=\"\", func=equivalent_A,\n",
    "    args=[\n",
    "        Argument(\"price\", \"int\", 10, \"item price\"),\n",
    "        Argument(\"num_items\", \"int\", 5, \"number of items\"),\n",
    "        Argument(\"tax\", \"int\", 2, \"sales tax\")\n",
    "    ]\n",
    ")\n",
    "mock_file_B = ParsedFile(\n",
    "    path=Path(\"mock_equivalent_B.py\"), module_code=\"\", func=equivalent_B,\n",
    "    args=[\n",
    "        Argument(\"unit_cost\", \"int\", 10, \"cost per unit\"),\n",
    "        Argument(\"quantity\", \"int\", 5, \"amount of items\"),\n",
    "        Argument(\"flat_fee\", \"int\", 2, \"service fee\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Run the test on the equivalent pair\n",
    "run_ut3_fuzzing_test(mock_file_A, mock_file_B)\n",
    "\n",
    "\n",
    "# --- Test Case 2: Functionally DIFFERENT Pair (Should FAIL) ---\n",
    "print(\"\\n\" + \"=\"*20 + \" Test Case 2: Different Functions \" + \"=\"*20)\n",
    "\n",
    "# These functions produce the same result (20) with defaults, but have different logic.\n",
    "def different_A(price: int = 10, quantity: int = 2):\n",
    "    # Logic is price * quantity\n",
    "    return price * quantity\n",
    "\n",
    "def different_B(price: int = 10, quantity: int = 2):\n",
    "    # Logic is price + price + ... (quantity times)\n",
    "    # A different way to write price * 2\n",
    "    return sum([price for _ in range(quantity)])\n",
    "\n",
    "# Create mock ParsedFile objects\n",
    "mock_file_C = ParsedFile(\n",
    "    path=Path(\"mock_different_A.py\"), module_code=\"\", func=different_A,\n",
    "    args=[\n",
    "        Argument(\"price\", \"int\", 10, \"item price\"),\n",
    "        Argument(\"quantity\", \"int\", 2, \"number of items\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# This is a subtle logical error. When we fuzz quantity, it will fail.\n",
    "# For example, if quantity=3, different_A returns 30, different_B returns 30.\n",
    "# Let's make it more obvious.\n",
    "def different_C(price: int = 10, quantity: int = 2):\n",
    "    # This is price * 2, it IGNORES the quantity when quantity > 2\n",
    "    return price * 2\n",
    "\n",
    "mock_file_D = ParsedFile(\n",
    "    path=Path(\"mock_different_C.py\"), module_code=\"\", func=different_C,\n",
    "    args=[\n",
    "        Argument(\"price\", \"int\", 10, \"item price\"),\n",
    "        Argument(\"quantity\", \"int\", 2, \"number of items\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Run the test on the different pair\n",
    "run_ut3_fuzzing_test(mock_file_C, mock_file_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd64d9a",
   "metadata": {},
   "source": [
    "### Test 4: UT-3 (Fuzzing for Functional Equivalence)\n",
    "\n",
    "This cell defines and runs the final validation test. The `run_ut3_fuzzing_test` function takes the list of UT-0 survivors, tests every possible pair for functional equivalence, and returns a list of the pairs that passed all checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f273ee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for UT-3 Fuzzing Test\n",
    "\n",
    "def run_ut3_fuzzing_test(survivors_ut0: list[ParsedFile]) -> list[tuple[ParsedFile, ParsedFile]]:\n",
    "    \"\"\"\n",
    "    Takes UT-0 survivors, finds all aligned pairs, and runs UT-3 fuzzing on them.\n",
    "    Returns a list of all pairs that passed the fuzzing test.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*20 + \" Test 4: UT-3 (Fuzzing Equivalence) \" + \"=\"*20)\n",
    "    if not survivors_ut0 or len(survivors_ut0) < 2:\n",
    "        print(\"Fewer than 2 survivors from UT-0. Cannot perform fuzzing.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"--- Running fuzzing on all possible pairs from {len(survivors_ut0)} files ---\")\n",
    "    \n",
    "    validated_pairs = []\n",
    "\n",
    "    for file_A, file_B in itertools.combinations(survivors_ut0, 2):\n",
    "        print(\"\\n\" + \"#\"*60)\n",
    "        print(f\"### Testing: {file_A.path.name} (A) vs. {file_B.path.name} (B)\")\n",
    "        print(\"#\"*60)\n",
    "\n",
    "        # 1. Align the pair\n",
    "        alignment = find_best_alignment(file_A, file_B)\n",
    "        if len(alignment.aligned_pairs) < _MIN_ALIGNMENT_FOR_FUZZ:\n",
    "            print(\"  - SKIPPED: Alignment found too few common arguments.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  - Alignment found {len(alignment.aligned_pairs)} pairs. Proceeding to fuzz.\")\n",
    "\n",
    "        # 2. Run the fuzz test\n",
    "        is_equivalent = fuzz_aligned_pair(alignment, file_A.func, file_B.func)\n",
    "        \n",
    "        # 3. Report result and store successful pairs\n",
    "        if is_equivalent:\n",
    "            print(\"  - ✅ RESULT: PASSED. The functions are functionally equivalent.\")\n",
    "            validated_pairs.append((file_A, file_B))\n",
    "        else:\n",
    "            print(\"  - ❌ RESULT: FAILED. The functions have different logic.\")\n",
    "            \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Fuzzing complete. Found {len(validated_pairs)} functionally equivalent pairs.\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return validated_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8b76bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Test 4: UT-3 (Fuzzing Equivalence) ====================\n",
      "--- Running fuzzing on all possible pairs from 9 files ---\n",
      "\n",
      "############################################################\n",
      "### Testing: anthropic_claude-3-5-haiku-20241022.py (A) vs. google_gemini-2.5-flash.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: anthropic_claude-3-5-haiku-20241022.py (A) vs. google_gemini-2.5-flash-lite-preview-06-17.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: anthropic_claude-3-5-haiku-20241022.py (A) vs. openai_o3-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: anthropic_claude-3-5-haiku-20241022.py (A) vs. openai_gpt-4.1.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: anthropic_claude-3-5-haiku-20241022.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: anthropic_claude-3-5-haiku-20241022.py (A) vs. openai_o4-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 2 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: anthropic_claude-3-5-haiku-20241022.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 1 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: anthropic_claude-3-5-haiku-20241022.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash.py (A) vs. google_gemini-2.5-flash-lite-preview-06-17.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash.py (A) vs. openai_o3-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash.py (A) vs. openai_gpt-4.1.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "  - Alignment found 5 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash.py (A) vs. openai_o4-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 1 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. openai_o3-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. openai_gpt-4.1.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. openai_o4-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 1 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_o3-mini.py (A) vs. openai_gpt-4.1.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_o3-mini.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_o3-mini.py (A) vs. openai_o4-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_o3-mini.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 1 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_o3-mini.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_gpt-4.1.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_gpt-4.1.py (A) vs. openai_o4-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_gpt-4.1.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 1 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_gpt-4.1.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.0-flash-thinking-exp.py (A) vs. openai_o4-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.0-flash-thinking-exp.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 1 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.0-flash-thinking-exp.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_o4-mini.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 1 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_o4-mini.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_gpt-4.1-mini.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "  - SKIPPED: Alignment found too few common arguments.\n",
      "\n",
      "============================================================\n",
      "Fuzzing complete. Found 27 functionally equivalent pairs.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Execute the Fuzzing Test ---\n",
    "# This uses the `ut0_survivors` variable created by the previous test cells.\n",
    "if 'ut0_survivors' in locals() and ut0_survivors_4483:\n",
    "    # This will run the fuzz test on all pairs from the currently configured problem\n",
    "    # It might take a minute or two depending on the number of files and pairs.\n",
    "    fully_validated_pairs = run_ut3_fuzzing_test(ut0_survivors_4483)\n",
    "else:\n",
    "    print(\"Variable 'ut0_survivors' not found. Please run the preceding test cells for a problem first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d24a288d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Test 4: UT-3 (Fuzzing Equivalence) ====================\n",
      "--- Running fuzzing on all possible pairs from 8 files ---\n",
      "\n",
      "############################################################\n",
      "### Testing: anthropic_claude-3-5-haiku-20241022.py (A) vs. google_gemini-2.5-flash.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: anthropic_claude-3-5-haiku-20241022.py (A) vs. google_gemini-2.5-flash-lite-preview-06-17.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: anthropic_claude-3-5-haiku-20241022.py (A) vs. openai_o3-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: anthropic_claude-3-5-haiku-20241022.py (A) vs. openai_gpt-4.1.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: anthropic_claude-3-5-haiku-20241022.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: anthropic_claude-3-5-haiku-20241022.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: anthropic_claude-3-5-haiku-20241022.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash.py (A) vs. google_gemini-2.5-flash-lite-preview-06-17.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash.py (A) vs. openai_o3-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash.py (A) vs. openai_gpt-4.1.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. openai_o3-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. openai_gpt-4.1.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.5-flash-lite-preview-06-17.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_o3-mini.py (A) vs. openai_gpt-4.1.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_o3-mini.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_o3-mini.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_o3-mini.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_gpt-4.1.py (A) vs. google_gemini-2.0-flash-thinking-exp.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_gpt-4.1.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_gpt-4.1.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.0-flash-thinking-exp.py (A) vs. openai_gpt-4.1-mini.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "############################################################\n",
      "### Testing: google_gemini-2.0-flash-thinking-exp.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "  - Alignment found 4 pairs. Proceeding to fuzz.\n",
      "  - ✅ RESULT: PASSED. The functions are functionally equivalent.\n",
      "\n",
      "############################################################\n",
      "### Testing: openai_gpt-4.1-mini.py (A) vs. google_gemini-2.5-pro.py (B)\n",
      "############################################################\n",
      "  - Alignment found 3 pairs. Proceeding to fuzz.\n",
      "  - ❌ RESULT: FAILED. The functions have different logic.\n",
      "\n",
      "============================================================\n",
      "Fuzzing complete. Found 13 functionally equivalent pairs.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Execute the Fuzzing Test ---\n",
    "# This uses the `ut0_survivors` variable created by the previous test cells.\n",
    "if 'ut0_survivors' in locals() and ut0_survivors_636:\n",
    "    # This will run the fuzz test on all pairs from the currently configured problem\n",
    "    # It might take a minute or two depending on the number of files and pairs.\n",
    "    fully_validated_pairs = run_ut3_fuzzing_test(ut0_survivors_636)\n",
    "else:\n",
    "    print(\"Variable 'ut0_survivors' not found. Please run the preceding test cells for a problem first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9b1482",
   "metadata": {},
   "source": [
    "### Final Test: Run End-to-End Analysis and Scoring\n",
    "\n",
    "This cell executes the entire validation pipeline for a single problem by calling the main `analyze_problem_outputs` function. It performs all steps automatically:\n",
    "\n",
    "1.  Parses all files for the given problem index.\n",
    "2.  Filters them with the UT-0 answer check.\n",
    "3.  Tests every possible pair for alignment (UT-2) and functional equivalence (UT-3).\n",
    "4.  Calculates a `PairwiseQualityScore` for every successfully validated pair.\n",
    "5.  Finds the best consensus clique among the models.\n",
    "6.  Computes and prints the final `ConfidenceScore` in a summary report.\n",
    "\n",
    "To test a new problem, you only need to change the `PROBLEM_INDEX` and `GOLD_ANSWER` variables in this cell and re-run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0a7d2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Analyzing Problem: 4483 ====================\n",
      "Found and parsed 9 files.\n",
      "9 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash.py), Score: 0.817\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.678\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_o3-mini.py), Score: 0.656\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1.py), Score: 0.970\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.817\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1-mini.py), Score: 0.391\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-pro.py), Score: 0.958\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.838\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_o3-mini.py), Score: 0.609\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1.py), Score: 0.832\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.999\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1-mini.py), Score: 0.356\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-pro.py), Score: 0.819\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_o3-mini.py), Score: 0.955\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1.py), Score: 0.969\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.838\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1-mini.py), Score: 0.391\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.5-pro.py), Score: 0.689\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1.py), Score: 0.937\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.609\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1-mini.py), Score: 0.404\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.5-pro.py), Score: 0.935\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.832\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, openai_gpt-4.1-mini.py), Score: 0.391\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.5-pro.py), Score: 0.977\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, openai_gpt-4.1-mini.py), Score: 0.356\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, google_gemini-2.5-pro.py), Score: 0.819\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 7-way agreement\n",
      "Models in Best Clique:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash-lite-preview-06-17.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - openai_o3-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.6973\n",
      "Consensus Bonus Multiplier: x1.3\n",
      "FINAL CONFIDENCE SCORE: 0.9065\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "PROBLEM_INDEX = 4483\n",
    "GOLD_ANSWER = 100.0\n",
    "\n",
    "# --- Execute the Full Pipeline ---\n",
    "problem_dir = BASE_DIR / str(PROBLEM_INDEX)\n",
    "if not problem_dir.is_dir():\n",
    "    print(f\"Error: Directory not found at {problem_dir}\")\n",
    "else:\n",
    "    # This single function call runs the entire validation and scoring process\n",
    "    analyze_problem_outputs(problem_dir, GOLD_ANSWER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66db645f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Analyzing Problem: 636 ====================\n",
      "Found and parsed 8 files.\n",
      "8 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.784\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1-mini.py), Score: 0.784\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_o3-mini.py), Score: 0.726\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1.py), Score: 0.820\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.963\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-pro.py), Score: 0.743\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1-mini.py), Score: 0.953\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1.py), Score: 0.660\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.736\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.5-pro.py), Score: 0.621\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.847\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.5-pro.py), Score: 0.660\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, google_gemini-2.5-pro.py), Score: 0.737\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 5-way agreement\n",
      "Models in Best Clique:\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - google_gemini-2.5-pro.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - openai_o3-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.7513\n",
      "Consensus Bonus Multiplier: x1.3\n",
      "FINAL CONFIDENCE SCORE: 0.9767\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "PROBLEM_INDEX = 636\n",
    "GOLD_ANSWER = 52.0\n",
    "\n",
    "# --- Execute the Full Pipeline ---\n",
    "problem_dir = BASE_DIR / str(PROBLEM_INDEX)\n",
    "if not problem_dir.is_dir():\n",
    "    print(f\"Error: Directory not found at {problem_dir}\")\n",
    "else:\n",
    "    # This single function call runs the entire validation and scoring process\n",
    "    analyze_problem_outputs(problem_dir, GOLD_ANSWER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00a21667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the GSM8K dataset (train split)\n",
    "gsm8k_train = load_dataset(\"gsm8k\", \"main\", split=\"train\")\n",
    "\n",
    "def extract_gsm8k_answer(gsm8k_data, index):\n",
    "    \"\"\"\n",
    "    Extracts the final numerical answer from a GSM8K sample.\n",
    "    Args:\n",
    "        gsm8k_data: The loaded GSM8K dataset (e.g., gsm8k_train).\n",
    "        index: The integer index of the sample.\n",
    "    Returns:\n",
    "        The answer as a float if possible, else as a string.\n",
    "    \"\"\"\n",
    "    answer_text = gsm8k_data[index]['answer']\n",
    "    # The answer is after the last '####'\n",
    "    if '####' in answer_text:\n",
    "        answer = answer_text.split('####')[-1].strip()\n",
    "    else:\n",
    "        answer = answer_text.strip()\n",
    "    # Try to convert to float or int\n",
    "    try:\n",
    "        return float(answer.replace(',', ''))\n",
    "    except ValueError:\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a39b7ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "ans = extract_gsm8k_answer(gsm8k_train, 4483)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6115aa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Problem Index: 399, Gold Answer: 30.0\n",
      "\n",
      "==================== Analyzing Problem: 399 ====================\n",
      "Found and parsed 8 files.\n",
      "6 files passed UT-0 (correct default answer).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[UT-0 Fail] google_gemini-2.5-flash-lite-preview-06-17.py raised ZeroDivisionError('float division by zero')\n",
      "[UT-0 Fail] openai_gpt-4.1.py raised ZeroDivisionError('float division by zero')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash.py), Score: 0.721\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_o3-mini.py), Score: 0.866\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.722\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1-mini.py), Score: 0.868\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-pro.py), Score: 0.730\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.682\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1-mini.py), Score: 0.659\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-pro.py), Score: 0.671\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.779\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1-mini.py), Score: 0.779\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.5-pro.py), Score: 0.790\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, openai_gpt-4.1-mini.py), Score: 0.966\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, google_gemini-2.5-pro.py), Score: 0.671\n",
      "  ✓ Validated Pair: (openai_gpt-4.1-mini.py, google_gemini-2.5-pro.py), Score: 0.658\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 5-way agreement\n",
      "Models in Best Clique:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - google_gemini-2.5-pro.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.7348\n",
      "Consensus Bonus Multiplier: x1.3\n",
      "FINAL CONFIDENCE SCORE: 0.9552\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing Problem Index: 636, Gold Answer: 52.0\n",
      "\n",
      "==================== Analyzing Problem: 636 ====================\n",
      "Found and parsed 8 files.\n",
      "8 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.784\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1-mini.py), Score: 0.784\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_o3-mini.py), Score: 0.726\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1.py), Score: 0.820\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.963\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-pro.py), Score: 0.743\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1-mini.py), Score: 0.953\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1.py), Score: 0.660\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.736\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.5-pro.py), Score: 0.621\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.847\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.5-pro.py), Score: 0.660\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, google_gemini-2.5-pro.py), Score: 0.737\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 5-way agreement\n",
      "Models in Best Clique:\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - google_gemini-2.5-pro.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - openai_o3-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.7513\n",
      "Consensus Bonus Multiplier: x1.3\n",
      "FINAL CONFIDENCE SCORE: 0.9767\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing Problem Index: 1202, Gold Answer: 76.0\n",
      "\n",
      "==================== Analyzing Problem: 1202 ====================\n",
      "Found and parsed 9 files.\n",
      "9 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash.py), Score: 0.787\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.665\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_o3-mini.py), Score: 0.946\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1.py), Score: 0.958\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.788\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1-mini.py), Score: 0.956\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.813\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_o3-mini.py), Score: 0.789\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1.py), Score: 0.806\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.985\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1-mini.py), Score: 0.795\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_o3-mini.py), Score: 0.977\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1.py), Score: 0.967\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.823\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1-mini.py), Score: 0.581\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1.py), Score: 0.982\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.587\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1-mini.py), Score: 0.807\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.809\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, openai_gpt-4.1-mini.py), Score: 0.804\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, openai_gpt-4.1-mini.py), Score: 0.576\n",
      "  ✓ Validated Pair: (openai_o4-mini.py, google_gemini-2.5-pro.py), Score: 0.692\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 7-way agreement\n",
      "Models in Best Clique:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash-lite-preview-06-17.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - openai_o3-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.8191\n",
      "Consensus Bonus Multiplier: x1.3\n",
      "FINAL CONFIDENCE SCORE: 1.0648\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing Problem Index: 1205, Gold Answer: 375.0\n",
      "\n",
      "==================== Analyzing Problem: 1205 ====================\n",
      "Found and parsed 8 files.\n",
      "8 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash.py), Score: 0.843\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.807\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_o3-mini.py), Score: 0.818\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.807\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1-mini.py), Score: 0.807\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-pro.py), Score: 0.804\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.709\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_o3-mini.py), Score: 0.965\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.705\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1-mini.py), Score: 0.693\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-pro.py), Score: 0.706\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_o3-mini.py), Score: 0.685\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.982\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1-mini.py), Score: 0.972\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.5-pro.py), Score: 0.979\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.683\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1-mini.py), Score: 0.677\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.5-pro.py), Score: 0.686\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, openai_gpt-4.1-mini.py), Score: 0.980\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, google_gemini-2.5-pro.py), Score: 0.985\n",
      "  ✓ Validated Pair: (openai_gpt-4.1-mini.py, google_gemini-2.5-pro.py), Score: 0.968\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 7-way agreement\n",
      "Models in Best Clique:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash-lite-preview-06-17.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - google_gemini-2.5-pro.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - openai_o3-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.8220\n",
      "Consensus Bonus Multiplier: x1.3\n",
      "FINAL CONFIDENCE SCORE: 1.0686\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing Problem Index: 1531, Gold Answer: 12.0\n",
      "\n",
      "==================== Analyzing Problem: 1531 ====================\n",
      "Found and parsed 8 files.\n",
      "8 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash.py), Score: 0.837\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.838\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_o3-mini.py), Score: 0.951\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1.py), Score: 0.960\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.836\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1-mini.py), Score: 0.950\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-pro.py), Score: 0.829\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.990\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_o3-mini.py), Score: 0.672\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1.py), Score: 0.873\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.999\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1-mini.py), Score: 0.854\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-pro.py), Score: 0.988\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_o3-mini.py), Score: 0.845\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1.py), Score: 0.870\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.989\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1-mini.py), Score: 0.848\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.5-pro.py), Score: 0.983\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1.py), Score: 0.770\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.672\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1-mini.py), Score: 0.759\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.5-pro.py), Score: 0.837\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.872\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, openai_gpt-4.1-mini.py), Score: 0.960\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.5-pro.py), Score: 0.862\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, openai_gpt-4.1-mini.py), Score: 0.853\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, google_gemini-2.5-pro.py), Score: 0.987\n",
      "  ✓ Validated Pair: (openai_gpt-4.1-mini.py, google_gemini-2.5-pro.py), Score: 0.687\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 8-way agreement\n",
      "Models in Best Clique:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash-lite-preview-06-17.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - google_gemini-2.5-pro.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - openai_o3-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.8704\n",
      "Consensus Bonus Multiplier: x1.3\n",
      "FINAL CONFIDENCE SCORE: 1.1315\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing Problem Index: 1647, Gold Answer: 88.0\n",
      "\n",
      "==================== Analyzing Problem: 1647 ====================\n",
      "Found and parsed 8 files.\n",
      "8 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash.py), Score: 0.984\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.990\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_o3-mini.py), Score: 0.957\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1.py), Score: 0.991\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.988\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1-mini.py), Score: 0.987\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-pro.py), Score: 0.976\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.983\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_o3-mini.py), Score: 0.959\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1.py), Score: 0.989\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.992\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1-mini.py), Score: 0.987\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-pro.py), Score: 0.994\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_o3-mini.py), Score: 0.959\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1.py), Score: 0.989\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.990\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1-mini.py), Score: 0.987\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.5-pro.py), Score: 0.974\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1.py), Score: 0.959\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.961\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1-mini.py), Score: 0.962\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.5-pro.py), Score: 0.960\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.987\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, openai_gpt-4.1-mini.py), Score: 0.992\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.5-pro.py), Score: 0.986\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, openai_gpt-4.1-mini.py), Score: 0.984\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, google_gemini-2.5-pro.py), Score: 0.986\n",
      "  ✓ Validated Pair: (openai_gpt-4.1-mini.py, google_gemini-2.5-pro.py), Score: 0.983\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 8-way agreement\n",
      "Models in Best Clique:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash-lite-preview-06-17.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - google_gemini-2.5-pro.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - openai_o3-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.9798\n",
      "Consensus Bonus Multiplier: x1.3\n",
      "FINAL CONFIDENCE SCORE: 1.2738\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing Problem Index: 2345, Gold Answer: 40.0\n",
      "\n",
      "==================== Analyzing Problem: 2345 ====================\n",
      "Found and parsed 9 files.\n",
      "9 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash.py), Score: 0.973\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_o3-mini.py), Score: 0.950\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1.py), Score: 0.963\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.957\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_o4-mini.py), Score: 0.976\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1-mini.py), Score: 0.958\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-pro.py), Score: 0.979\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_o3-mini.py), Score: 0.959\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1.py), Score: 0.966\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.980\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_o4-mini.py), Score: 0.982\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-pro.py), Score: 0.969\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1.py), Score: 0.959\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.967\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_o4-mini.py), Score: 0.964\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1-mini.py), Score: 0.957\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.5-pro.py), Score: 0.954\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.965\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, openai_o4-mini.py), Score: 0.982\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, openai_gpt-4.1-mini.py), Score: 0.964\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.5-pro.py), Score: 0.957\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, openai_gpt-4.1-mini.py), Score: 0.976\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, google_gemini-2.5-pro.py), Score: 0.962\n",
      "  ✓ Validated Pair: (openai_o4-mini.py, openai_gpt-4.1-mini.py), Score: 0.973\n",
      "  ✓ Validated Pair: (openai_o4-mini.py, google_gemini-2.5-pro.py), Score: 0.968\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 6-way agreement\n",
      "Models in Best Clique:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - google_gemini-2.5-pro.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - openai_o3-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.9640\n",
      "Consensus Bonus Multiplier: x1.3\n",
      "FINAL CONFIDENCE SCORE: 1.2532\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing Problem Index: 3331, Gold Answer: 6.0\n",
      "\n",
      "==================== Analyzing Problem: 3331 ====================\n",
      "Found and parsed 8 files.\n",
      "8 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_o3-mini.py), Score: 0.961\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1-mini.py), Score: 0.980\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.812\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.999\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-pro.py), Score: 0.995\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.812\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.5-pro.py), Score: 0.811\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1-mini.py), Score: 0.955\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, google_gemini-2.5-pro.py), Score: 0.996\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 4-way agreement\n",
      "Models in Best Clique:\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash-lite-preview-06-17.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - google_gemini-2.5-pro.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.9042\n",
      "Consensus Bonus Multiplier: x1.2\n",
      "FINAL CONFIDENCE SCORE: 1.0851\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing Problem Index: 3518, Gold Answer: 42.0\n",
      "\n",
      "==================== Analyzing Problem: 3518 ====================\n",
      "Found and parsed 8 files.\n",
      "8 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash.py), Score: 0.983\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.977\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_o3-mini.py), Score: 0.727\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1.py), Score: 0.955\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.641\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1-mini.py), Score: 0.486\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-pro.py), Score: 0.953\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.969\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_o3-mini.py), Score: 0.739\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1.py), Score: 0.954\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.647\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1-mini.py), Score: 0.602\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-pro.py), Score: 0.951\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_o3-mini.py), Score: 0.551\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1.py), Score: 0.974\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.635\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1-mini.py), Score: 0.609\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.5-pro.py), Score: 0.968\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1.py), Score: 0.426\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.448\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1-mini.py), Score: 0.711\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.5-pro.py), Score: 0.437\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.618\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, openai_gpt-4.1-mini.py), Score: 0.619\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.5-pro.py), Score: 0.972\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, openai_gpt-4.1-mini.py), Score: 0.407\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, google_gemini-2.5-pro.py), Score: 0.611\n",
      "  ✓ Validated Pair: (openai_gpt-4.1-mini.py, google_gemini-2.5-pro.py), Score: 0.610\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 8-way agreement\n",
      "Models in Best Clique:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash-lite-preview-06-17.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - google_gemini-2.5-pro.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - openai_o3-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.7208\n",
      "Consensus Bonus Multiplier: x1.3\n",
      "FINAL CONFIDENCE SCORE: 0.9370\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing Problem Index: 3779, Gold Answer: 742.0\n",
      "\n",
      "==================== Analyzing Problem: 3779 ====================\n",
      "Found and parsed 9 files.\n",
      "9 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash.py), Score: 0.981\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1.py), Score: 0.991\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-pro.py), Score: 0.976\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1.py), Score: 0.981\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-pro.py), Score: 0.995\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_o3-mini.py), Score: 0.977\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.992\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_o4-mini.py), Score: 0.965\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1-mini.py), Score: 0.876\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.977\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_o4-mini.py), Score: 0.958\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1-mini.py), Score: 0.866\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.5-pro.py), Score: 0.976\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, openai_o4-mini.py), Score: 0.970\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, openai_gpt-4.1-mini.py), Score: 0.876\n",
      "  ✓ Validated Pair: (openai_o4-mini.py, openai_gpt-4.1-mini.py), Score: 0.879\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 5-way agreement\n",
      "Models in Best Clique:\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash-lite-preview-06-17.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - openai_o3-mini.py\n",
      "  - openai_o4-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.9334\n",
      "Consensus Bonus Multiplier: x1.3\n",
      "FINAL CONFIDENCE SCORE: 1.2134\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing Problem Index: 4483, Gold Answer: 100.0\n",
      "\n",
      "==================== Analyzing Problem: 4483 ====================\n",
      "Found and parsed 9 files.\n",
      "9 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash.py), Score: 0.817\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.678\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_o3-mini.py), Score: 0.656\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1.py), Score: 0.970\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.817\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1-mini.py), Score: 0.391\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-pro.py), Score: 0.958\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.838\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_o3-mini.py), Score: 0.609\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1.py), Score: 0.832\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.999\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1-mini.py), Score: 0.356\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-pro.py), Score: 0.819\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_o3-mini.py), Score: 0.955\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1.py), Score: 0.969\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.838\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1-mini.py), Score: 0.391\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.5-pro.py), Score: 0.689\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1.py), Score: 0.937\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.609\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1-mini.py), Score: 0.404\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.5-pro.py), Score: 0.935\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.832\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, openai_gpt-4.1-mini.py), Score: 0.391\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.5-pro.py), Score: 0.977\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, openai_gpt-4.1-mini.py), Score: 0.356\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, google_gemini-2.5-pro.py), Score: 0.819\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 7-way agreement\n",
      "Models in Best Clique:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash-lite-preview-06-17.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - openai_o3-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.6973\n",
      "Consensus Bonus Multiplier: x1.3\n",
      "FINAL CONFIDENCE SCORE: 0.9065\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing Problem Index: 4670, Gold Answer: 180.0\n",
      "\n",
      "==================== Analyzing Problem: 4670 ====================\n",
      "Found and parsed 8 files.\n",
      "8 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash.py), Score: 0.986\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1.py), Score: 0.986\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.986\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1-mini.py), Score: 0.986\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-pro.py), Score: 0.935\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1.py), Score: 1.000\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.0-flash-thinking-exp.py), Score: 1.000\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1-mini.py), Score: 1.000\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-pro.py), Score: 0.953\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.0-flash-thinking-exp.py), Score: 1.000\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, openai_gpt-4.1-mini.py), Score: 1.000\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.5-pro.py), Score: 0.953\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, openai_gpt-4.1-mini.py), Score: 1.000\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, google_gemini-2.5-pro.py), Score: 0.953\n",
      "  ✓ Validated Pair: (openai_gpt-4.1-mini.py, google_gemini-2.5-pro.py), Score: 0.953\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 6-way agreement\n",
      "Models in Best Clique:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - google_gemini-2.5-pro.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - openai_gpt-4.1.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.9793\n",
      "Consensus Bonus Multiplier: x1.3\n",
      "FINAL CONFIDENCE SCORE: 1.2730\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing Problem Index: 5464, Gold Answer: 41.0\n",
      "\n",
      "==================== Analyzing Problem: 5464 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parser Error] Skipping google_gemini-2.5-pro.py: InvalidInput('Cannot parse: 1:9: ```python')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and parsed 6 files.\n",
      "5 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1.py), Score: 0.970\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.970\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1-mini.py), Score: 0.974\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.992\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, openai_gpt-4.1-mini.py), Score: 0.993\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, openai_gpt-4.1-mini.py), Score: 0.986\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 4-way agreement\n",
      "Models in Best Clique:\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - openai_o3-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.9808\n",
      "Consensus Bonus Multiplier: x1.2\n",
      "FINAL CONFIDENCE SCORE: 1.1769\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing Problem Index: 5918, Gold Answer: 1400.0\n",
      "\n",
      "==================== Analyzing Problem: 5918 ====================\n",
      "Found and parsed 8 files.\n",
      "8 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash.py), Score: 0.548\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.423\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_o3-mini.py), Score: 0.947\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1.py), Score: 0.407\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.552\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1-mini.py), Score: 0.749\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-pro.py), Score: 0.552\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.969\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_o3-mini.py), Score: 0.937\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1.py), Score: 0.944\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.985\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1-mini.py), Score: 0.533\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-pro.py), Score: 0.986\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_o3-mini.py), Score: 0.721\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1.py), Score: 0.939\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.975\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1-mini.py), Score: 0.403\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.5-pro.py), Score: 0.977\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1.py), Score: 0.706\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.946\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1-mini.py), Score: 0.544\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.5-pro.py), Score: 0.944\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.952\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, openai_gpt-4.1-mini.py), Score: 0.320\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.5-pro.py), Score: 0.954\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, openai_gpt-4.1-mini.py), Score: 0.424\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, google_gemini-2.5-pro.py), Score: 0.998\n",
      "  ✓ Validated Pair: (openai_gpt-4.1-mini.py, google_gemini-2.5-pro.py), Score: 0.424\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 8-way agreement\n",
      "Models in Best Clique:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash-lite-preview-06-17.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - google_gemini-2.5-pro.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - openai_o3-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.7414\n",
      "Consensus Bonus Multiplier: x1.3\n",
      "FINAL CONFIDENCE SCORE: 0.9638\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing Problem Index: 6237, Gold Answer: 56.0\n",
      "\n",
      "==================== Analyzing Problem: 6237 ====================\n",
      "Found and parsed 9 files.\n",
      "9 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.480\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_o4-mini.py), Score: 0.536\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1-mini.py), Score: 0.817\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.902\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_o4-mini.py), Score: 0.890\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1.py), Score: 0.675\n",
      "  ✓ Validated Pair: (openai_gpt-4.1-mini.py, google_gemini-2.5-pro.py), Score: 0.797\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 3-way agreement\n",
      "Models in Best Clique:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.5-flash-lite-preview-06-17.py\n",
      "  - openai_o4-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.6353\n",
      "Consensus Bonus Multiplier: x1.1\n",
      "FINAL CONFIDENCE SCORE: 0.6988\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing Problem Index: 6732, Gold Answer: 69000.0\n",
      "\n",
      "==================== Analyzing Problem: 6732 ====================\n",
      "Found and parsed 8 files.\n",
      "8 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash.py), Score: 0.620\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.973\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_o3-mini.py), Score: 0.502\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1.py), Score: 0.971\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.981\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_gpt-4.1-mini.py), Score: 0.674\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-pro.py), Score: 0.780\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-flash-lite-preview-06-17.py), Score: 0.610\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_o3-mini.py), Score: 0.474\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1.py), Score: 0.603\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.631\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1-mini.py), Score: 0.511\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.5-pro.py), Score: 0.753\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_o3-mini.py), Score: 0.506\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1.py), Score: 0.975\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.963\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, openai_gpt-4.1-mini.py), Score: 0.668\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash-lite-preview-06-17.py, google_gemini-2.5-pro.py), Score: 0.753\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1.py), Score: 0.519\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.491\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1-mini.py), Score: 0.667\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.5-pro.py), Score: 0.609\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.977\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, openai_gpt-4.1-mini.py), Score: 0.684\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.5-pro.py), Score: 0.759\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, openai_gpt-4.1-mini.py), Score: 0.676\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, google_gemini-2.5-pro.py), Score: 0.764\n",
      "  ✓ Validated Pair: (openai_gpt-4.1-mini.py, google_gemini-2.5-pro.py), Score: 0.533\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 8-way agreement\n",
      "Models in Best Clique:\n",
      "  - anthropic_claude-3-5-haiku-20241022.py\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash-lite-preview-06-17.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - google_gemini-2.5-pro.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - openai_o3-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.7010\n",
      "Consensus Bonus Multiplier: x1.3\n",
      "FINAL CONFIDENCE SCORE: 0.9113\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing Problem Index: 7364, Gold Answer: 4.0\n",
      "\n",
      "==================== Analyzing Problem: 7364 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parser Error] Skipping google_gemini-2.5-pro.py: InvalidInput('Cannot parse: 1:9: ```python')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and parsed 7 files.\n",
      "6 files passed UT-0 (correct default answer).\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.5-flash.py), Score: 0.748\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, openai_o3-mini.py), Score: 0.793\n",
      "  ✓ Validated Pair: (anthropic_claude-3-5-haiku-20241022.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.571\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_o3-mini.py), Score: 0.658\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1.py), Score: 0.837\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.967\n",
      "  ✓ Validated Pair: (google_gemini-2.5-flash.py, openai_gpt-4.1-mini.py), Score: 0.831\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1.py), Score: 0.756\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.641\n",
      "  ✓ Validated Pair: (openai_o3-mini.py, openai_gpt-4.1-mini.py), Score: 0.747\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, google_gemini-2.0-flash-thinking-exp.py), Score: 0.828\n",
      "  ✓ Validated Pair: (openai_gpt-4.1.py, openai_gpt-4.1-mini.py), Score: 0.988\n",
      "  ✓ Validated Pair: (google_gemini-2.0-flash-thinking-exp.py, openai_gpt-4.1-mini.py), Score: 0.718\n",
      "\n",
      "--------------------------------------------------\n",
      "                 VALIDATION SUMMARY\n",
      "--------------------------------------------------\n",
      "Best Consensus Found: 5-way agreement\n",
      "Models in Best Clique:\n",
      "  - google_gemini-2.0-flash-thinking-exp.py\n",
      "  - google_gemini-2.5-flash.py\n",
      "  - openai_gpt-4.1-mini.py\n",
      "  - openai_gpt-4.1.py\n",
      "  - openai_o3-mini.py\n",
      "\n",
      "Average Pairwise Quality in Clique: 0.7971\n",
      "Consensus Bonus Multiplier: x1.3\n",
      "FINAL CONFIDENCE SCORE: 1.0362\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "output_indices = sorted([3331, 1647, 636, 399, 4670, 5918, 1531, 7364, 5464, 1205, 3518, 6732, 3779, 4483, 6237, 1202, 2345])\n",
    "\n",
    "# --- Execute the Full Pipeline for all samples---\n",
    "\n",
    "for PROBLEM_INDEX in output_indices:\n",
    "    GOLD_ANSWER = extract_gsm8k_answer(gsm8k_train, PROBLEM_INDEX)\n",
    "    print(f\"\\nProcessing Problem Index: {PROBLEM_INDEX}, Gold Answer: {GOLD_ANSWER}\")\n",
    "\n",
    "    problem_dir = BASE_DIR / str(PROBLEM_INDEX)\n",
    "    if not problem_dir.is_dir():\n",
    "        print(f\"Error: Directory not found at {problem_dir}\")\n",
    "    else:\n",
    "        # This single function call runs the entire validation and scoring process\n",
    "        analyze_problem_outputs(problem_dir, GOLD_ANSWER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4583791e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
