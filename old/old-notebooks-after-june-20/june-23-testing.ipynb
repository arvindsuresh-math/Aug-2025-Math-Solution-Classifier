{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b6e3bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # REFACTOR: Standard imports + asyncio and nest_asyncio for Jupyter compatibility.\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import time\n",
    "# import datetime\n",
    "# import importlib\n",
    "# import inspect\n",
    "# import os\n",
    "# import re\n",
    "# import json\n",
    "# import random\n",
    "# import openai\n",
    "# import google.generativeai as genai\n",
    "# import anthropic\n",
    "# import asyncio\n",
    "# import nest_asyncio\n",
    "# from openai import AsyncOpenAI # REFACTOR: Import async client\n",
    "# from anthropic import AsyncClient # REFACTOR: Import async client\n",
    "# from datasets import load_dataset\n",
    "# from tqdm.notebook import tqdm # REFACTOR: Use notebook-friendly tqdm\n",
    "# from dotenv import load_dotenv\n",
    "# from typing import List, Dict, Any\n",
    "# from pathlib import Path\n",
    "\n",
    "# def find_project_root():\n",
    "#     \"\"\"Traverse upwards to find the project root, marked by the .git folder.\"\"\"\n",
    "#     current_path = Path.cwd()\n",
    "#     while current_path != current_path.parent:\n",
    "#         if (current_path / \".git\").is_dir():\n",
    "#             return current_path\n",
    "#         current_path = current_path.parent\n",
    "#     raise FileNotFoundError(\"Could not find project root. Is this a git repository?\")\n",
    "\n",
    "# # REFACTOR: Apply nest_asyncio to allow asyncio to run in a Jupyter notebook.\n",
    "# # This must be done once per kernel.\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "# # --- 1. Client and Model Configuration ---\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# # REFACTOR: Initialize asynchronous clients.\n",
    "# # The synchronous clients are no longer needed for the generation script.\n",
    "# openai_client_async = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "# anthropic_client_async = AsyncClient(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "# genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# # Define the project root as a global constant\n",
    "# PROJECT_ROOT = find_project_root()\n",
    "# print(f\"Project root identified: {PROJECT_ROOT}\")\n",
    "# BASE_OUTPUT_DIR = PROJECT_ROOT / 'data' / 'code_gen_outputs_raw'\n",
    "\n",
    "# # REFACTOR: Define rate limits here.\n",
    "# # These values are placeholders. You MUST replace them with the actual\n",
    "# # requests-per-minute (RPM) limits for your API keys to avoid errors.\n",
    "# # A safe starting point is slightly below the documented RPM.\n",
    "# API_CONCURRENCY_LIMITS = {\n",
    "#     \"openai\": 10,    # e.g., limit to 10 concurrent requests for OpenAI\n",
    "#     \"anthropic\": 10, # e.g., limit to 10 concurrent requests for Anthropic\n",
    "#     \"google\": 10,    # e.g., limit to 10 concurrent requests for Google\n",
    "# }\n",
    "\n",
    "# # --- 2. System Prompt and Helper Functions (no changes needed) ---\n",
    "\n",
    "# SYSTEM_PROMPT = \"You are an expert Python programmer specializing in data formalization. Your role is to meticulously convert natural language math problems and their step-by-step solutions into a single, well-structured Python function. You will be presented with examples of the required format followed by a final task to complete.\"\n",
    "\n",
    "\n",
    "# PROMPT_GUIDELINES = \"\"\"### Guidelines\n",
    "\n",
    "# 0. **Output wrapping**\n",
    "#    Return the code inside a single ```python … ``` block, and nothing else.\n",
    "\n",
    "# 1.  **Function Naming & Docstring:** The function must be named `solve`. It must begin with a docstring that has exactly two lines:\n",
    "#     *   The first line must be: \"Index: [Index].\" using the index from the task header.\n",
    "#     *   The second line must be a succinct, one-sentence description of what the function returns (e.g., \"Returns: the total cost of wages and taxes.\").\n",
    "\n",
    "# 2.  **Function Arguments:** The function arguments must be derived from the 'Question' text. \n",
    "#     *   Create a distinct argument for every numerical value that is directly stated in the text.\n",
    "#     *   The arguments should be created **in the same order in which they appear in the question**.\n",
    "#     *   **Note:** Some of these arguments may end up not being used in the function body. This is expected. Do not worry about this and leave the unused arguments in the function signature.\n",
    "\n",
    "# 3.  **Argument Formatting:** Each argument must include a type-hint (e.g., `int`, `float`) and a default value equal to its value in the 'Question'. You must also add a comment (`#`) next to each argument that quotes or refers to the phrase in the 'Question' it comes from. \n",
    "\n",
    "# 4.  **Function Body:** The body of the function should follow the logic of the provided 'Solution' dict, which contains the step-by-step solution to the problem. The keys of this dict are strings (e.g. `\"L1\"`, `\"L2\"`) which refer to the line number, and the values of the dict are the corresponding steps in the solution. \n",
    "#     * For every relevant line in the 'Solution', you must include a comment in the Python code that indicates the line number (key) from the 'Solution' dict.\n",
    "#     * These comments should be formatted as `#: L<n>`, where `<n>` is the line number from the 'Solution' dict.\n",
    "#     * Immediately follow the comment with the Python statement that performs the calculation.\n",
    "#     * Steps in the solution should result in the creation of new, intermediate variables, which should be named descriptively based on the context of the calculation.\n",
    "#     * Wherever possible, in your code try to use only the variables from the function arguments and the intermediate variables you created before, and try to avoid using hard-coded numbers in the calculations.\n",
    "\n",
    "# 5.  **Calculator Annotations:** Pay close attention to the calculator annotations (e.g., `[[25*8=200]]`) in the 'Solution' as they reveal the precise mathematical operations to implement. **Note**: Some lines in the solution may not contain calculator annotations, but you should still pay attention to the logic and calculations described in those lines.\n",
    "\n",
    "# 6.  **Final Answer:** Store the final answer in a variable named 'answer', and on the same line, add the comment `# FINAL ANSWER`. In the next line, return the 'answer' variable.\n",
    "\n",
    "# 7. **No extra output:** Your output should end with the ``` closing the code block. Do not include any additional text, explanations, or comments outside of the code block.\"\"\"\n",
    "\n",
    "# gsm8k_train = load_dataset(\"gsm8k\", \"main\", split=\"train\")\n",
    "\n",
    "# def build_solution_mapping(\n",
    "#     index: int,\n",
    "#     dataset: Any,\n",
    "#     convert_brackets: bool = True,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     index : int\n",
    "#         Position of the sample in the loaded dataset.\n",
    "#     dataset : iterable / HuggingFace Dataset\n",
    "#     convert_brackets : bool, default ``True``\n",
    "#         If ``True`` replace every ``<< … >>`` calculator annotation with\n",
    "#         the canonical ``[[ … ]]`` form so downstream code sees a single\n",
    "#         bracket style.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     Dict[str, str]\n",
    "#         Mapping ``{\"L1\": <first non-empty line>, \"L2\": <second>, …}``.\n",
    "\n",
    "#     Notes\n",
    "#     -----\n",
    "#     * Blank lines in ``sample[\"answer\"]`` are ignored.\n",
    "#     * The line numbering reflects the *order* in the original solution\n",
    "#       string; there is no semantic grouping beyond that.\n",
    "#     \"\"\"\n",
    "#     # extract & split solution text\n",
    "#     solution_text = dataset[index][\"answer\"]\n",
    "#     lines = [ln.strip() for ln in solution_text.splitlines() if ln.strip()]\n",
    "\n",
    "#     # Remove the last line if it matches the '####' answer pattern\n",
    "#     if lines and re.match(r\"^####\\s*\\d+(\\.\\d+)?$\", lines[-1]):\n",
    "#         lines = lines[:-1]\n",
    "\n",
    "#     # optional bracket normalisation\n",
    "#     if convert_brackets:\n",
    "#         angle = re.compile(r\"<<([^>]+)>>\")\n",
    "#         lines = [angle.sub(r\"[[\\1]]\", ln) for ln in lines]\n",
    "#     # build mapping\n",
    "#     return {f\"L{i}\": line for i, line in enumerate(lines, 1)}\n",
    "\n",
    "# def get_code_strings(indices: List[int], savepath: Path = PROJECT_ROOT / 'data' / 'code_examples'):\n",
    "#     \"\"\"\n",
    "#     Reads code examples directly from .py files instead of importing them.\n",
    "#     This is more robust and avoids Python's complex import path mechanics.\n",
    "#     \"\"\"\n",
    "#     code_strings = {}\n",
    "#     for idx in indices:\n",
    "#         # Construct the full file path\n",
    "#         filepath = os.path.join(savepath, f\"_{idx}.py\")\n",
    "#         try:\n",
    "#             # Read the entire content of the file\n",
    "#             with open(filepath, 'r', encoding='utf-8') as f:\n",
    "#                 code_strings[idx] = f.read()\n",
    "#         except FileNotFoundError:\n",
    "#             print(f\"Error: Could not find example file for index {idx} at: {filepath}\")\n",
    "#             code_strings[idx] = f\"# Error: Code for example {idx} not found.\"\n",
    "#     return code_strings\n",
    "\n",
    "# def format_prompt_query(index: int, code_strings: dict, with_code: bool = False):\n",
    "#     sample = gsm8k_train[index]\n",
    "#     question = sample[\"question\"]\n",
    "#     solution_mapping = build_solution_mapping(index, gsm8k_train)\n",
    "#     solution = json.dumps(solution_mapping)\n",
    "#     out = f\"\"\"*Index*: \n",
    "# {index}\n",
    "\n",
    "# *Question*: \n",
    "# {question}\n",
    "\n",
    "# *Solution*: \n",
    "# {solution}\n",
    "\n",
    "# *Code*:\"\"\"\n",
    "#     if with_code:\n",
    "#         out += f\"\"\"\\n```python\n",
    "# {code_strings.get(index, \"# Code not found\")}\n",
    "# ```\"\"\"\n",
    "#     return out\n",
    "\n",
    "# def craft_user_prompt(index: int, example_indices: List[int], code_examples: Dict[int, str]):\n",
    "#     example_prompts = [\n",
    "#         format_prompt_query(index=idx, code_strings=code_examples, with_code=True)\n",
    "#         for idx in example_indices\n",
    "#     ]\n",
    "#     task_prompt = format_prompt_query(index=index, code_strings=code_examples)\n",
    "#     full_prompt = \"\\n\".join([\n",
    "#         PROMPT_GUIDELINES,\n",
    "#         \"\\n--- EXAMPLES ---\\n\",\n",
    "#         \"\\n\".join(example_prompts),\n",
    "#         \"--- TASK ---\\n\",\n",
    "#         task_prompt\n",
    "#     ])\n",
    "#     return full_prompt\n",
    "\n",
    "\n",
    "# # --- 3. Asynchronous API Calling Function ---\n",
    "\n",
    "# # REFACTOR: This new async function replaces the original `call_model_api`.\n",
    "# async def call_model_api_async(\n",
    "#     provider: str,\n",
    "#     model: str,\n",
    "#     system_prompt: str,\n",
    "#     user_prompt: str,\n",
    "#     semaphore: asyncio.Semaphore\n",
    "# ) -> str | None:\n",
    "#     \"\"\"\n",
    "#     Asynchronously calls the appropriate LLM API using a semaphore for rate limiting.\n",
    "#     \"\"\"\n",
    "#     async with semaphore: # Wait for an open slot to respect rate limits\n",
    "#         try:\n",
    "#             if provider == \"google\":\n",
    "#                 gemini = genai.GenerativeModel(\n",
    "#                     model_name=model,\n",
    "#                     system_instruction=system_prompt\n",
    "#                 )\n",
    "#                 generation_config = genai.types.GenerationConfig(\n",
    "#                     temperature=0.1,\n",
    "#                     max_output_tokens=4000\n",
    "#                 )\n",
    "#                 # Use the async method for the Google SDK\n",
    "#                 response = await gemini.generate_content_async(\n",
    "#                     user_prompt,\n",
    "#                     generation_config=generation_config\n",
    "#                 )\n",
    "#                 return response.text\n",
    "\n",
    "#             elif provider == \"anthropic\":\n",
    "#                 # Use the async client for Anthropic\n",
    "#                 response = await anthropic_client_async.messages.create(\n",
    "#                     model=model,\n",
    "#                     max_tokens=4000,\n",
    "#                     temperature=0.1,\n",
    "#                     system=system_prompt,\n",
    "#                     messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
    "#                 )\n",
    "#                 return response.content[0].text\n",
    "\n",
    "#             elif provider == \"openai\":\n",
    "#                 kwargs = {\n",
    "#                     \"model\": model,\n",
    "#                     \"messages\": [\n",
    "#                         {\"role\": \"system\", \"content\": system_prompt},\n",
    "#                         {\"role\": \"user\", \"content\": user_prompt}\n",
    "#                     ]\n",
    "#                 }\n",
    "#                 if model not in [\"o3-mini\", \"o4-mini\"]:\n",
    "#                     kwargs[\"temperature\"] = 0.1\n",
    "#                     kwargs[\"max_tokens\"] = 4000\n",
    "#                 # Use the async client for OpenAI\n",
    "#                 response = await openai_client_async.chat.completions.create(**kwargs)\n",
    "#                 return response.choices[0].message.content\n",
    "            \n",
    "#             else:\n",
    "#                 print(f\"Unknown provider: {provider}\")\n",
    "#                 return None\n",
    "\n",
    "#         except Exception as e:\n",
    "#             # Important to print the error to know why a call failed\n",
    "#             print(f\"An API error occurred for {provider} model {model}: {e}\")\n",
    "#             # Return the exception itself to be handled by the orchestrator\n",
    "#             return e\n",
    "\n",
    "# # --- 4. Parallel Orchestration Function ---\n",
    "\n",
    "# # REFACTOR: This is the new main orchestrator.\n",
    "# async def generate_GSM8K_code_parallel(\n",
    "#     model_dict: Dict[str, List[str]],\n",
    "#     indices_to_generate: List[int],\n",
    "#     example_indices: List[int],\n",
    "#     system_prompt: str = SYSTEM_PROMPT,\n",
    "#     output_dir: str = BASE_OUTPUT_DIR  # Add this argument\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Calls multiple LLM APIs in parallel for each problem index, saves the\n",
    "#     raw output, and logs performance.\n",
    "#     \"\"\"\n",
    "#     performance_data = []\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#     # REFACTOR: Create a dictionary of semaphores based on the defined limits.\n",
    "#     semaphores = {\n",
    "#         provider: asyncio.Semaphore(limit)\n",
    "#         for provider, limit in API_CONCURRENCY_LIMITS.items()\n",
    "#     }\n",
    "\n",
    "#     # Use tqdm for the outer loop to track progress over problem indices\n",
    "#     for index in tqdm(indices_to_generate, desc=\"Processing Problems\"):\n",
    "#         problem_dir = os.path.join(output_dir, str(index))\n",
    "#         os.makedirs(problem_dir, exist_ok=True)\n",
    "\n",
    "#         # Craft prompt once per problem\n",
    "#         user_prompt = craft_user_prompt(\n",
    "#             index=index,\n",
    "#             example_indices=example_indices,\n",
    "#             code_examples=get_code_strings(example_indices)\n",
    "#         )\n",
    "\n",
    "#         # REFACTOR: Create a list of async tasks for all models for the current index.\n",
    "#         tasks = []\n",
    "#         for provider, models in model_dict.items():\n",
    "#             for model_name in models:\n",
    "#                 task = asyncio.create_task(\n",
    "#                     call_model_api_async(\n",
    "#                         provider,\n",
    "#                         model_name,\n",
    "#                         system_prompt,\n",
    "#                         user_prompt,\n",
    "#                         semaphores[provider]\n",
    "#                     )\n",
    "#                 )\n",
    "#                 # Store metadata with the task for later processing\n",
    "#                 task.meta = {'provider': provider, 'model': model_name, 'index': index, 'start_time': time.time()}\n",
    "#                 tasks.append(task)\n",
    "        \n",
    "#         # REFACTOR: Run all tasks concurrently and wait for them to complete.\n",
    "#         # `return_exceptions=True` ensures that one failed API call doesn't stop others.\n",
    "#         print(f\"Index {index}: Launching {len(tasks)} API calls in parallel...\")\n",
    "#         results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "#         print(f\"Index {index}: All API calls completed.\")\n",
    "\n",
    "#         # REFACTOR: Process the results.\n",
    "#         for task, result in zip(tasks, results):\n",
    "#             meta = task.meta\n",
    "#             time_taken = time.time() - meta['start_time']\n",
    "            \n",
    "#             # Check if the result is an exception\n",
    "#             if isinstance(result, Exception):\n",
    "#                 raw_response = None\n",
    "#                 print(f\"  -> Failed: {meta['provider']}_{meta['model']} ({time_taken:.2f}s). Error: {result}\")\n",
    "#             else:\n",
    "#                 raw_response = result\n",
    "#                 print(f\"  -> Success: {meta['provider']}_{meta['model']} ({time_taken:.2f}s).\")\n",
    "\n",
    "#             performance_data.append({\n",
    "#                 'provider': meta['provider'],\n",
    "#                 'model': meta['model'],\n",
    "#                 'index': meta['index'],\n",
    "#                 'time_taken': time_taken,\n",
    "#                 'status': 'Failed' if raw_response is None else 'Success'\n",
    "#             })\n",
    "            \n",
    "#             if raw_response:\n",
    "#                 output_filename = f\"{meta['provider']}_{meta['model']}.txt\"\n",
    "#                 output_path = os.path.join(problem_dir, output_filename)\n",
    "#                 try:\n",
    "#                     with open(output_path, 'w', encoding='utf-8') as f:\n",
    "#                         f.write(raw_response)\n",
    "#                 except IOError as e:\n",
    "#                     print(f\"    Error: Failed to write file. Reason: {e}\")\n",
    "\n",
    "#     # Save performance data to CSV at the end\n",
    "#     df = pd.DataFrame(performance_data)\n",
    "#     csv_path = os.path.join(output_dir, 'generation_performance.csv')\n",
    "#     df.to_csv(csv_path, index=False)\n",
    "#     print(f\"\\nGeneration complete. Performance data saved to {csv_path}.\")\n",
    "#     return df\n",
    "\n",
    "# # # Add any problem indices you have generated outputs for.\n",
    "# # problem_indices_to_test = sorted([3331, 1647, 636, 399, 4670, 5918, 1531, 7364, 5464, 1205, 3518, 6732, 3779, 4483, 6237, 1202, 2345])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95761ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_and_print_sample_prompt(target_index: int, example_indices: List[int]):\n",
    "#     \"\"\"\n",
    "#     Generates and prints the full user prompt for a single target index\n",
    "#     for debugging and inspection.\n",
    "\n",
    "#     Args:\n",
    "#         target_index: The GSM8K index for the final task in the prompt.\n",
    "#         example_indices: A list of GSM8K indices to use as few-shot examples.\n",
    "#     \"\"\"\n",
    "#     print(f\"--- Generating sample prompt for target index: {target_index} ---\")\n",
    "\n",
    "#     # 1. Load the code strings for the few-shot examples using the same\n",
    "#     #    function as the main pipeline. This tests if the examples are loading correctly.\n",
    "#     code_examples = get_code_strings(indices=example_indices)\n",
    "\n",
    "#     # 2. Craft the full user prompt.\n",
    "#     full_prompt = craft_user_prompt(\n",
    "#         index=target_index,\n",
    "#         example_indices=example_indices,\n",
    "#         code_examples=code_examples\n",
    "#     )\n",
    "#     print(full_prompt)\n",
    "\n",
    "# generate_and_print_sample_prompt(\n",
    "#     target_index=6237,\n",
    "#     example_indices=[310, 3822, 7371]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3cbcb22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 5. Execution ---\n",
    "\n",
    "# # Define your parameters here\n",
    "# indices = [310, 3822, 7371] # Use the indices of your few-shot examples\n",
    "# indices_to_generate = list(range(10))\n",
    "\n",
    "# model_dict = {\n",
    "#   \"anthropic\": [\"claude-3-5-haiku-20241022\"], \n",
    "#   \"openai\": [\"gpt-4.1-mini\"],\n",
    "#   \"google\": [\"gemini-2.0-flash-thinking-exp\", \n",
    "#              \"gemini-2.5-flash-lite-preview-06-17\"]\n",
    "# }\n",
    "\n",
    "# # REFACTOR: To run the async function, you must `await` it.\n",
    "# # This will execute the entire parallel generation process.\n",
    "# # The result (a pandas DataFrame with performance logs) will be stored in `perf_df`.\n",
    "\n",
    "# perf_df = await generate_GSM8K_code_parallel(\n",
    "#     model_dict=model_dict,\n",
    "#     indices_to_generate=indices_to_generate,\n",
    "#     example_indices=indices\n",
    "# )\n",
    "\n",
    "# # print(\"\\nFinal Performance Summary:\")\n",
    "# # print(perf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ac1169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root identified: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math\n"
     ]
    }
   ],
   "source": [
    "# REFACTOR: Standard imports + asyncio and nest_asyncio for Jupyter compatibility.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import importlib\n",
    "import inspect\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import openai\n",
    "import google.generativeai as genai\n",
    "import anthropic\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from openai import AsyncOpenAI # REFACTOR: Import async client\n",
    "from anthropic import AsyncClient # REFACTOR: Import async client\n",
    "from datasets import load_dataset\n",
    "from tqdm.notebook import tqdm # REFACTOR: Use notebook-friendly tqdm\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Any\n",
    "from pathlib import Path\n",
    "\n",
    "def find_project_root():\n",
    "    \"\"\"Traverse upwards to find the project root, marked by the .git folder.\"\"\"\n",
    "    current_path = Path.cwd()\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / \".git\").is_dir():\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    raise FileNotFoundError(\"Could not find project root. Is this a git repository?\")\n",
    "\n",
    "# REFACTOR: Apply nest_asyncio to allow asyncio to run in a Jupyter notebook.\n",
    "# This must be done once per kernel.\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- 1. Client and Model Configuration ---\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# REFACTOR: Initialize asynchronous clients.\n",
    "# The synchronous clients are no longer needed for the generation script.\n",
    "openai_client_async = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "anthropic_client_async = AsyncClient(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Define the project root as a global constant\n",
    "PROJECT_ROOT = find_project_root()\n",
    "print(f\"Project root identified: {PROJECT_ROOT}\")\n",
    "BASE_OUTPUT_DIR = PROJECT_ROOT / 'data' / 'code_gen_outputs_raw'\n",
    "\n",
    "# REFACTOR: Define rate limits here.\n",
    "# These values are placeholders. You MUST replace them with the actual\n",
    "# requests-per-minute (RPM) limits for your API keys to avoid errors.\n",
    "# A safe starting point is slightly below the documented RPM.\n",
    "API_CONCURRENCY_LIMITS = {\n",
    "    \"openai\": 10,    # e.g., limit to 10 concurrent requests for OpenAI\n",
    "    \"anthropic\": 10, # e.g., limit to 10 concurrent requests for Anthropic\n",
    "    \"google\": 10,    # e.g., limit to 10 concurrent requests for Google\n",
    "}\n",
    "\n",
    "# --- 2. System Prompt and Helper Functions (no changes needed) ---\n",
    "\n",
    "SYSTEM_PROMPT = \"You are an expert Python programmer specializing in data formalization. Your role is to meticulously convert natural language math problems and their step-by-step solutions into a single, well-structured Python function. You will be presented with examples of the required format followed by a final task to complete.\"\n",
    "\n",
    "\n",
    "PROMPT_GUIDELINES = \"\"\"### Guidelines\n",
    "\n",
    "0. **Output wrapping**\n",
    "   Return the code inside a single ```python … ``` block, and nothing else.\n",
    "\n",
    "1.  **Function Naming & Docstring:** The function must be named `solve`. It must begin with a docstring that has exactly two lines:\n",
    "    *   The first line must be: \"Index: [Index].\" using the index from the task header.\n",
    "    *   The second line must be a succinct, one-sentence description of what the function returns (e.g., \"Returns: the total cost of wages and taxes.\").\n",
    "\n",
    "2.  **Function Arguments:** The function arguments must be derived from the 'Question' text. \n",
    "    *   Create a distinct argument for every numerical value that is directly stated in the text.\n",
    "    *   The arguments should be created **in the same order in which they appear in the question**.\n",
    "    *   **Note:** Some of these arguments may end up not being used in the function body. This is expected. Do not worry about this and leave the unused arguments in the function signature.\n",
    "\n",
    "3.  **Argument Formatting:** Each argument must include a type-hint (e.g., `int`, `float`) and a default value equal to its value in the 'Question'. You must also add a comment (`#`) next to each argument that quotes or refers to the phrase in the 'Question' it comes from. \n",
    "\n",
    "4.  **Function Body:** The body of the function should follow the logic of the provided 'Solution' dict, which contains the step-by-step solution to the problem. The keys of this dict are strings (e.g. `\"L1\"`, `\"L2\"`) which refer to the line number, and the values of the dict are the corresponding steps in the solution. \n",
    "    * For every relevant line in the 'Solution', you must include a comment in the Python code that indicates the line number (key) from the 'Solution' dict.\n",
    "    * These comments should be formatted as `#: L<n>`, where `<n>` is the line number from the 'Solution' dict.\n",
    "    * Immediately follow the comment with the Python statement that performs the calculation.\n",
    "    * Steps in the solution should result in the creation of new, intermediate variables, which should be named descriptively based on the context of the calculation.\n",
    "    * Wherever possible, in your code try to use only the variables from the function arguments and the intermediate variables you created before, and try to avoid using hard-coded numbers in the calculations.\n",
    "\n",
    "5.  **Calculator Annotations:** Pay close attention to the calculator annotations (e.g., `[[25*8=200]]`) in the 'Solution' as they reveal the precise mathematical operations to implement. **Note**: Some lines in the solution may not contain calculator annotations, but you should still pay attention to the logic and calculations described in those lines.\n",
    "\n",
    "6.  **Final Answer:** Store the final answer in a variable named 'answer', and on the same line, add the comment `# FINAL ANSWER`. In the next line, return the 'answer' variable.\n",
    "\n",
    "7. **No extra output:** Your output should end with the ``` closing the code block. Do not include any additional text, explanations, or comments outside of the code block.\"\"\"\n",
    "\n",
    "gsm8k_train = load_dataset(\"gsm8k\", \"main\", split=\"train\")\n",
    "\n",
    "def build_solution_mapping(\n",
    "    index: int,\n",
    "    dataset: Any,\n",
    "    convert_brackets: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    index : int\n",
    "        Position of the sample in the loaded dataset.\n",
    "    dataset : iterable / HuggingFace Dataset\n",
    "    convert_brackets : bool, default ``True``\n",
    "        If ``True`` replace every ``<< … >>`` calculator annotation with\n",
    "        the canonical ``[[ … ]]`` form so downstream code sees a single\n",
    "        bracket style.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, str]\n",
    "        Mapping ``{\"L1\": <first non-empty line>, \"L2\": <second>, …}``.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    * Blank lines in ``sample[\"answer\"]`` are ignored.\n",
    "    * The line numbering reflects the *order* in the original solution\n",
    "      string; there is no semantic grouping beyond that.\n",
    "    \"\"\"\n",
    "    # extract & split solution text\n",
    "    solution_text = dataset[index][\"answer\"]\n",
    "    lines = [ln.strip() for ln in solution_text.splitlines() if ln.strip()]\n",
    "\n",
    "    # Remove the last line if it matches the '####' answer pattern\n",
    "    if lines and re.match(r\"^####\\s*\\d+(\\.\\d+)?$\", lines[-1]):\n",
    "        lines = lines[:-1]\n",
    "\n",
    "    # optional bracket normalisation\n",
    "    if convert_brackets:\n",
    "        angle = re.compile(r\"<<([^>]+)>>\")\n",
    "        lines = [angle.sub(r\"[[\\1]]\", ln) for ln in lines]\n",
    "    # build mapping\n",
    "    return {f\"L{i}\": line for i, line in enumerate(lines, 1)}\n",
    "\n",
    "def get_code_strings(indices: List[int], savepath: Path = PROJECT_ROOT / 'data' / 'code_examples'):\n",
    "    \"\"\"\n",
    "    Reads code examples directly from .py files instead of importing them.\n",
    "    This is more robust and avoids Python's complex import path mechanics.\n",
    "    \"\"\"\n",
    "    code_strings = {}\n",
    "    for idx in indices:\n",
    "        # Construct the full file path\n",
    "        filepath = os.path.join(savepath, f\"_{idx}.py\")\n",
    "        try:\n",
    "            # Read the entire content of the file\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                code_strings[idx] = f.read()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Could not find example file for index {idx} at: {filepath}\")\n",
    "            code_strings[idx] = f\"# Error: Code for example {idx} not found.\"\n",
    "    return code_strings\n",
    "\n",
    "def format_prompt_query(index: int, code_strings: dict, with_code: bool = False):\n",
    "    sample = gsm8k_train[index]\n",
    "    question = sample[\"question\"]\n",
    "    solution_mapping = build_solution_mapping(index, gsm8k_train)\n",
    "    solution = json.dumps(solution_mapping)\n",
    "    out = f\"\"\"*Index*: \n",
    "{index}\n",
    "\n",
    "*Question*: \n",
    "{question}\n",
    "\n",
    "*Solution*: \n",
    "{solution}\n",
    "\n",
    "*Code*:\"\"\"\n",
    "    if with_code:\n",
    "        out += f\"\"\"\\n```python\n",
    "{code_strings.get(index, \"# Code not found\")}\n",
    "```\"\"\"\n",
    "    return out\n",
    "\n",
    "def craft_user_prompt(index: int, example_indices: List[int], code_examples: Dict[int, str]):\n",
    "    example_prompts = [\n",
    "        format_prompt_query(index=idx, code_strings=code_examples, with_code=True)\n",
    "        for idx in example_indices\n",
    "    ]\n",
    "    task_prompt = format_prompt_query(index=index, code_strings=code_examples)\n",
    "    full_prompt = \"\\n\".join([\n",
    "        PROMPT_GUIDELINES,\n",
    "        \"\\n--- EXAMPLES ---\\n\",\n",
    "        \"\\n\".join(example_prompts),\n",
    "        \"--- TASK ---\\n\",\n",
    "        task_prompt\n",
    "    ])\n",
    "    return full_prompt\n",
    "\n",
    "\n",
    "# --- 3. Asynchronous API Calling Function ---\n",
    "\n",
    "# REFACTOR: Simplified function that removes the internal try/except block.\n",
    "# It now lets exceptions propagate to be caught by asyncio.gather.\n",
    "async def call_model_api_async(\n",
    "    provider: str,\n",
    "    model: str,\n",
    "    system_prompt: str,\n",
    "    user_prompt: str,\n",
    "    semaphore: asyncio.Semaphore\n",
    ") -> tuple[str, dict]:\n",
    "    \"\"\"\n",
    "    Asynchronously calls the appropriate LLM API and returns the text response\n",
    "    and a dictionary of token usage statistics.\n",
    "    Raises an exception on API failure.\n",
    "    \"\"\"\n",
    "    async with semaphore:\n",
    "        token_usage = {\"input_tokens\": 0, \"output_tokens\": 0}\n",
    "\n",
    "        if provider == \"google\":\n",
    "            gemini = genai.GenerativeModel(model_name=model, system_instruction=system_prompt)\n",
    "            generation_config = genai.types.GenerationConfig(temperature=0.1, max_output_tokens=4000)\n",
    "            response = await gemini.generate_content_async(user_prompt, generation_config=generation_config)\n",
    "            text = response.text\n",
    "            if response.usage_metadata:\n",
    "                token_usage[\"input_tokens\"] = response.usage_metadata.prompt_token_count\n",
    "                token_usage[\"output_tokens\"] = response.usage_metadata.candidates_token_count\n",
    "            return text, token_usage\n",
    "\n",
    "        elif provider == \"anthropic\":\n",
    "            response = await anthropic_client_async.messages.create(\n",
    "                model=model, max_tokens=4000, temperature=0.1,\n",
    "                system=system_prompt,\n",
    "                messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
    "            )\n",
    "            text = response.content[0].text\n",
    "            if response.usage:\n",
    "                token_usage[\"input_tokens\"] = response.usage.input_tokens\n",
    "                token_usage[\"output_tokens\"] = response.usage.output_tokens\n",
    "            return text, token_usage\n",
    "\n",
    "        elif provider == \"openai\":\n",
    "            kwargs = {\n",
    "                \"model\": model,\n",
    "                \"messages\": [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}]\n",
    "            }\n",
    "            if model not in [\"o3-mini\", \"o4-mini\"]:\n",
    "                kwargs[\"temperature\"] = 0.1\n",
    "                kwargs[\"max_tokens\"] = 4000\n",
    "            response = await openai_client_async.chat.completions.create(**kwargs)\n",
    "            text = response.choices[0].message.content\n",
    "            if response.usage:\n",
    "                token_usage[\"input_tokens\"] = response.usage.prompt_tokens\n",
    "                token_usage[\"output_tokens\"] = response.usage.completion_tokens\n",
    "            return text, token_usage\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown provider: {provider}\")\n",
    "\n",
    "# --- 4. Parallel Orchestration Function ---\n",
    "\n",
    "# REFACTOR: Updated orchestrator with correct exception handling logic.\n",
    "async def generate_GSM8K_code_parallel(\n",
    "    model_dict: Dict[str, List[str]],\n",
    "    indices_to_generate: List[int],\n",
    "    example_indices: List[int],\n",
    "    system_prompt: str = SYSTEM_PROMPT,\n",
    "    output_dir: Path = BASE_OUTPUT_DIR\n",
    "):\n",
    "    \"\"\"\n",
    "    Calls multiple LLM APIs in parallel, saves the raw output, and logs\n",
    "    performance including token usage and timestamps.\n",
    "    \"\"\"\n",
    "    performance_data = []\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    semaphores = {\n",
    "        provider: asyncio.Semaphore(limit)\n",
    "        for provider, limit in API_CONCURRENCY_LIMITS.items()\n",
    "    }\n",
    "\n",
    "    for index in tqdm(indices_to_generate, desc=\"Processing Problems\"):\n",
    "        problem_dir = output_dir / str(index)\n",
    "        os.makedirs(problem_dir, exist_ok=True)\n",
    "\n",
    "        user_prompt = craft_user_prompt(\n",
    "            index=index,\n",
    "            example_indices=example_indices,\n",
    "            code_examples=get_code_strings(indices=example_indices)\n",
    "        )\n",
    "\n",
    "        tasks = []\n",
    "        for provider, models in model_dict.items():\n",
    "            for model_name in models:\n",
    "                task = asyncio.create_task(\n",
    "                    call_model_api_async(\n",
    "                        provider, model_name, system_prompt, user_prompt, semaphores[provider]\n",
    "                    )\n",
    "                )\n",
    "                task.meta = {'provider': provider, 'model': model_name, 'index': index, 'start_time': time.time()}\n",
    "                tasks.append(task)\n",
    "        \n",
    "        print(f\"Index {index}: Launching {len(tasks)} API calls in parallel...\")\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        print(f\"Index {index}: All API calls completed.\")\n",
    "\n",
    "        # This loop now correctly handles exceptions caught by asyncio.gather.\n",
    "        for task, result in zip(tasks, results):\n",
    "            meta = task.meta\n",
    "            time_taken = time.time() - meta['start_time']\n",
    "            completion_timestamp = datetime.datetime.now(datetime.timezone.utc).isoformat()\n",
    "            \n",
    "            raw_response = None\n",
    "            token_usage = {\"input_tokens\": 0, \"output_tokens\": 0}\n",
    "            status = \"Failed\" # Default to Failed\n",
    "\n",
    "            # Correctly check if the result is an exception object.\n",
    "            if isinstance(result, Exception):\n",
    "                print(f\"  -> Failed: {meta['provider']}_{meta['model']} ({time_taken:.2f}s). Error: {result}\")\n",
    "                # We do not unpack 'result' here because it is an exception.\n",
    "            \n",
    "            else:\n",
    "                # If it's not an exception, it must be the (text, usage) tuple.\n",
    "                raw_response, token_usage = result # This unpacking is now safe.\n",
    "                status = \"Success\"\n",
    "                print(f\"  -> Success: {meta['provider']}_{meta['model']} ({time_taken:.2f}s).\")\n",
    "\n",
    "            performance_data.append({\n",
    "                'provider': meta['provider'],\n",
    "                'model': meta['model'],\n",
    "                'index': meta['index'],\n",
    "                'time_taken': time_taken,\n",
    "                'status': status,\n",
    "                'completion_timestamp_utc': completion_timestamp,\n",
    "                'input_tokens': token_usage.get('input_tokens', 0),\n",
    "                'output_tokens': token_usage.get('output_tokens', 0),\n",
    "            })\n",
    "            \n",
    "            if raw_response:\n",
    "                output_filename = f\"{meta['provider']}_{meta['model']}.txt\"\n",
    "                output_path = problem_dir / output_filename\n",
    "                try:\n",
    "                    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                        f.write(raw_response)\n",
    "                except IOError as e:\n",
    "                    print(f\"    Error: Failed to write file. Reason: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(performance_data)\n",
    "    csv_path = output_dir / 'generation_performance.csv'\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nGeneration complete. Performance data saved to {csv_path}.\")\n",
    "    return df\n",
    "\n",
    "# # Add any problem indices you have generated outputs for.\n",
    "# problem_indices_to_test = sorted([3331, 1647, 636, 399, 4670, 5918, 1531, 7364, 5464, 1205, 3518, 6732, 3779, 4483, 6237, 1202, 2345])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "488bd2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd642b522684d94ae8f5f11d388c40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Problems:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: Launching 4 API calls in parallel...\n",
      "Index 0: All API calls completed.\n",
      "  -> Success: anthropic_claude-3-5-haiku-20241022 (4.32s).\n",
      "  -> Success: openai_gpt-4.1-mini (4.32s).\n",
      "  -> Success: google_gemini-2.0-flash-thinking-exp (4.32s).\n",
      "  -> Success: google_gemini-2.5-flash-lite-preview-06-17 (4.32s).\n",
      "Index 1: Launching 4 API calls in parallel...\n",
      "Index 1: All API calls completed.\n",
      "  -> Success: anthropic_claude-3-5-haiku-20241022 (2.60s).\n",
      "  -> Success: openai_gpt-4.1-mini (2.60s).\n",
      "  -> Success: google_gemini-2.0-flash-thinking-exp (2.60s).\n",
      "  -> Success: google_gemini-2.5-flash-lite-preview-06-17 (2.60s).\n",
      "Index 2: Launching 4 API calls in parallel...\n",
      "Index 2: All API calls completed.\n",
      "  -> Success: anthropic_claude-3-5-haiku-20241022 (3.74s).\n",
      "  -> Success: openai_gpt-4.1-mini (3.74s).\n",
      "  -> Success: google_gemini-2.0-flash-thinking-exp (3.74s).\n",
      "  -> Success: google_gemini-2.5-flash-lite-preview-06-17 (3.74s).\n",
      "Index 3: Launching 4 API calls in parallel...\n",
      "Index 3: All API calls completed.\n",
      "  -> Success: anthropic_claude-3-5-haiku-20241022 (4.61s).\n",
      "  -> Success: openai_gpt-4.1-mini (4.61s).\n",
      "  -> Success: google_gemini-2.0-flash-thinking-exp (4.61s).\n",
      "  -> Success: google_gemini-2.5-flash-lite-preview-06-17 (4.61s).\n",
      "Index 4: Launching 4 API calls in parallel...\n",
      "Index 4: All API calls completed.\n",
      "  -> Success: anthropic_claude-3-5-haiku-20241022 (3.98s).\n",
      "  -> Success: openai_gpt-4.1-mini (3.98s).\n",
      "  -> Success: google_gemini-2.0-flash-thinking-exp (3.98s).\n",
      "  -> Success: google_gemini-2.5-flash-lite-preview-06-17 (3.98s).\n",
      "\n",
      "Generation complete. Performance data saved to /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/code_gen_outputs_raw/generation_performance.csv.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Execution ---\n",
    "\n",
    "# Define your parameters here\n",
    "indices = [310, 3822, 7371] # Use the indices of your few-shot examples\n",
    "indices_to_generate = list(range(5))\n",
    "\n",
    "model_dict = {\n",
    "  \"anthropic\": [\"claude-3-5-haiku-20241022\"], \n",
    "  \"openai\": [\"gpt-4.1-mini\"],\n",
    "  \"google\": [\"gemini-2.0-flash-thinking-exp\", \n",
    "             \"gemini-2.5-flash-lite-preview-06-17\"]\n",
    "}\n",
    "\n",
    "# REFACTOR: To run the async function, you must `await` it.\n",
    "# This will execute the entire parallel generation process.\n",
    "# The result (a pandas DataFrame with performance logs) will be stored in `perf_df`.\n",
    "\n",
    "perf_df = await generate_GSM8K_code_parallel(\n",
    "    model_dict=model_dict,\n",
    "    indices_to_generate=indices_to_generate,\n",
    "    example_indices=indices\n",
    ")\n",
    "\n",
    "# print(\"\\nFinal Performance Summary:\")\n",
    "# print(perf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "405e3d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating sample prompt for target index: 6237 ---\n",
      "### Guidelines\n",
      "\n",
      "0. **Output wrapping**\n",
      "   Return the code inside a single ```python … ``` block, and nothing else.\n",
      "\n",
      "1.  **Function Naming & Docstring:** The function must be named `solve`. It must begin with a docstring that has exactly two lines:\n",
      "    *   The first line must be: \"Index: [Index].\" using the index from the task header.\n",
      "    *   The second line must be a succinct, one-sentence description of what the function returns (e.g., \"Returns: the total cost of wages and taxes.\").\n",
      "\n",
      "2.  **Function Arguments:** The function arguments must be derived from the 'Question' text. \n",
      "    *   Create a distinct argument for every numerical value that is directly stated in the text.\n",
      "    *   The arguments should be created **in the same order in which they appear in the question**.\n",
      "    *   **Note:** Some of these arguments may end up not being used in the function body. This is expected. Do not worry about this and leave the unused arguments in the function signature.\n",
      "\n",
      "3.  **Argument Formatting:** Each argument must include a type-hint (e.g., `int`, `float`) and a default value equal to its value in the 'Question'. You must also add a comment (`#`) next to each argument that quotes or refers to the phrase in the 'Question' it comes from. \n",
      "\n",
      "4.  **Function Body:** The body of the function should follow the logic of the provided 'Solution' dict, which contains the step-by-step solution to the problem. The keys of this dict are strings (e.g. `\"L1\"`, `\"L2\"`) which refer to the line number, and the values of the dict are the corresponding steps in the solution. \n",
      "    * For every relevant line in the 'Solution', you must include a comment in the Python code that indicates the line number (key) from the 'Solution' dict.\n",
      "    * These comments should be formatted as `#: L<n>`, where `<n>` is the line number from the 'Solution' dict.\n",
      "    * Immediately follow the comment with the Python statement that performs the calculation.\n",
      "    * Steps in the solution should result in the creation of new, intermediate variables, which should be named descriptively based on the context of the calculation.\n",
      "    * Wherever possible, in your code try to use only the variables from the function arguments and the intermediate variables you created before, and try to avoid using hard-coded numbers in the calculations.\n",
      "\n",
      "5.  **Calculator Annotations:** Pay close attention to the calculator annotations (e.g., `[[25*8=200]]`) in the 'Solution' as they reveal the precise mathematical operations to implement. **Note**: Some lines in the solution may not contain calculator annotations, but you should still pay attention to the logic and calculations described in those lines.\n",
      "\n",
      "6.  **Final Answer:** Store the final answer in a variable named 'answer', and on the same line, add the comment `# FINAL ANSWER`. In the next line, return the 'answer' variable.\n",
      "\n",
      "7. **No extra output:** Your output should end with the ``` closing the code block. Do not include any additional text, explanations, or comments outside of the code block.\n",
      "\n",
      "--- EXAMPLES ---\n",
      "\n",
      "*Index*: \n",
      "310\n",
      "\n",
      "*Question*: \n",
      "Janet hires six employees. Four of them are warehouse workers who make $15/hour, and the other two are managers who make $20/hour. Janet has to pay 10% of her workers' salaries in FICA taxes. If everyone works 25 days a month and 8 hours a day, how much does Janet owe total for their wages and taxes for one month?\n",
      "\n",
      "*Solution*: \n",
      "{\"L1\": \"First figure out how many hours each worker works per month by multiplying the number of days they work by the number of hours a day they work: 25 days * 8 hours/day = [[25*8=200]]200 hours\", \"L2\": \"Then calculate how much one warehouse worker makes per month by multiplying their hourly rate by the number of hours they work: 200 hours * $15/hour = $[[200*15=3000]]3000\", \"L3\": \"Then multiply that number by 4 to find out how much all the warehouse workers make: $3000/worker * 4 workers = $[[3000*4=12000]]12,000\", \"L4\": \"Now multiply the hours each manager works (also 200) by their hourly wage to find out how much one manager makes per month: 200 hours * $20/hour = $[[200*20=4000]]4,000\", \"L5\": \"Now multiply one manager's wages by the number of managers (2) to find their total wage amount: $4,000/manager * 2 managers = $[[4000*2=8000]]8,000\", \"L6\": \"Now add the wages for the managers and the workers to find the total cost of the wages: $8,000 + $12,000 = $[[8000+12000=20000]]20,000\", \"L7\": \"Now multiply the total wage bill by 10% to find how much the FICA taxes are: $20,000 * .1 = $[[20000*.1=2000]]2,000\", \"L8\": \"Now add the total wage bill to the total tax amount to find the grand total: $2,000 + $20,000 = $[[2000+20000=22000]]22,000\"}\n",
      "\n",
      "*Code*:\n",
      "```python\n",
      "def solve(\n",
      "        num_employees: int = 6, # Janet hires six employees\n",
      "        num_warehouse_workers: int = 4, # Four of them are warehouse workers\n",
      "        num_managers: int = 2, # the other two are managers\n",
      "        hourly_wage_warehouse: int = 15, # warehouse workers make $15/hour\n",
      "        hourly_wage_manager: int = 20, # managers make $20/hour\n",
      "        fica_tax_rate: float = 0.1, # FICA tax rate is 10%\n",
      "        days_per_month: int = 25, # everyone works 25 days a month\n",
      "        hours_per_day: int = 8 # everyone works 8 hours a day\n",
      "    ):\n",
      "    \"\"\"Index: 310.\n",
      "    Returns: the monthly total wage bill, including FICA taxes.\n",
      "    \"\"\"\n",
      "    #: L1\n",
      "    hours_per_month = days_per_month * hours_per_day\n",
      "\n",
      "    #: L2\n",
      "    monthly_wage_warehouse = hourly_wage_warehouse * hours_per_month\n",
      "\n",
      "    #: L3\n",
      "    total_wage_warehouse = monthly_wage_warehouse * num_warehouse_workers\n",
      "\n",
      "    #: L4\n",
      "    monthly_wage_manager = hourly_wage_manager * hours_per_month\n",
      "\n",
      "    #: L5\n",
      "    total_wage_manager = monthly_wage_manager * num_managers\n",
      "\n",
      "    #: L6\n",
      "    total_wages = total_wage_warehouse + total_wage_manager\n",
      "\n",
      "    #: L7\n",
      "    fica_taxes = total_wages * fica_tax_rate\n",
      "\n",
      "    #: L8\n",
      "    grand_total = total_wages + fica_taxes\n",
      "\n",
      "    answer = grand_total # FINAL ANSWER\n",
      "    return answer\n",
      "```\n",
      "*Index*: \n",
      "3822\n",
      "\n",
      "*Question*: \n",
      "Alec is running for Class President. He thinks that if he can get three-quarters of the class to vote for him then there is no chance anyone else can beat him. Half of the class have already said they will vote for him but out of the remaining students, only 5 have said they are thinking about voting for him. He surveys the students who are thinking about voting for someone else, and changes his flyers to reflect the issues these students are concerned about. This results in a fifth of these students saying they'll vote for him. If Alec's class has 60 students and everyone who said they will vote for him does so, how many more votes does Alec need to reach his goal number of votes?\n",
      "\n",
      "*Solution*: \n",
      "{\"L1\": \"To calculate Alec's goal number of votes, we need to know that 60 students / 4 = [[60/4=15]]15 students is equal to one-quarter of the class students.\", \"L2\": \"Alec's goal is therefore 15 students * 3 quarters = [[15*3=45]]45 votes.\", \"L3\": \"Half of the class said they will vote for him, so there are already 60 students / 2 = [[60/2=30]]30 votes.\", \"L4\": \"Another 5 students are thinking about voting for him which leaves a total so far of 30 + 5 = [[30+5=35]]35 votes.\", \"L5\": \"This means there are 60 students - 35 voting for Alec = [[60-35=25]]25 students not voting for Alec.\", \"L6\": \"A fifth of these decided to vote, so this is a further 25 students / 5 = [[25/5=5]]5 votes.\", \"L7\": \"Alec is therefore receiving a total of 35 + 5 = [[35+5=40]]40 votes.\", \"L8\": \"So he has missed his goal by 45 goal votes - 40 actual votes = [[45-40=5]]5 votes.\"}\n",
      "\n",
      "*Code*:\n",
      "```python\n",
      "def solve(\n",
      "        fraction_needed_to_win: float = 3/4,  # f he can get three-quarters of the class to vote for him then there is no chance anyone else can beat him.\n",
      "        fraction_voting_for_him: float = 1/2,  # Half of the class have already said they will vote for him\n",
      "        students_thinking_about_it: int = 5,  # only 5 have said they are thinking about voting for him\n",
      "        total_students: int = 60  # Alec's class has 60 students\n",
      "):    \n",
      "    \"\"\"Index: 3822.\n",
      "    Returns: the number of votes by which Alec is short of his goal.\n",
      "    \"\"\"\n",
      "    #: L1\n",
      "    students_per_quarter = total_students / 4\n",
      "\n",
      "    #: L2\n",
      "    votes_needed = students_per_quarter * 3\n",
      "\n",
      "    #: L3\n",
      "    votes_for_him = total_students * fraction_voting_for_him\n",
      "\n",
      "    #: L4\n",
      "    votes_so_far = votes_for_him + students_thinking_about_it\n",
      "\n",
      "    #: L5\n",
      "    students_not_voting_for_him = total_students - votes_so_far\n",
      "    \n",
      "    #: L6\n",
      "    new_votes = students_not_voting_for_him / 5\n",
      "\n",
      "    #: L7\n",
      "    total_votes_for_him = votes_so_far + new_votes\n",
      "\n",
      "    #: L8\n",
      "    votes_short_of_goal = votes_needed - total_votes_for_him\n",
      "\n",
      "    answer = votes_short_of_goal  # FINAL ANSWER\n",
      "    return answer\n",
      "```\n",
      "*Index*: \n",
      "7371\n",
      "\n",
      "*Question*: \n",
      "Karen's students are about to take a standardized test. Karen gets a $500 bonus if their average score is above 75, plus an extra $10 bonus for every additional point the average score increases above 75. So far, Karen has graded 8 tests, and the average is 70. Given that each student can have a maximum score of 150, what combined score do the last two tests need to have for Karen to earn a $600 bonus?\n",
      "\n",
      "*Solution*: \n",
      "{\"L1\": \"First subtract $500 from Karen's goal bonus amount to find how much she makes from the extra $10/point bonus: $600 - $500 = $[[600-500=100]]100\", \"L2\": \"Then divide the extra bonus by the extra rate: $100 / $10/point = [[100/10=10]]10 points\", \"L3\": \"Then add the 10 extra points to the baseline 75 point goal to find the students' average test score: 10 points + 75 points = [[10+75=85]]85 points\", \"L4\": \"Then added the 8 graded tests to the 2 ungraded tests to find the total number of tests: 2 tests + 8 tests = [[2+8=10]]10 tests\", \"L5\": \"Then multiply the 85 point average by the number of tests to find the total number of points the students need to earn: 85 points/test * 10 tests = 850 points\", \"L6\": \"Then multiply the current average by the current number of graded tests to find how many points have been earned so far: 70 points/test * 8 tests = [[70*8=560]]560 points\", \"L7\": \"Then subtract the number of points earned from the number of points needed to find the combine score the last two tests need: 850 points - 560 points = [[850-560=290]]290 points\"}\n",
      "\n",
      "*Code*:\n",
      "```python\n",
      "def solve(\n",
      "    baseline_bonus: int = 500, # Karen gets a $500 bonus\n",
      "    baseline_avg_score: int = 75, # if their average score is above 75\n",
      "    extra_bonus_per_point: int = 10, # plus an extra $10 bonus for every additional point the average score increases above 75\n",
      "    tests_graded_so_far: int = 8, # So far, Karen has graded 8 tests\n",
      "    avg_so_far: int = 70, # and the average is 70\n",
      "    max_score_per_student: int = 150, # each student can have a maximum score of 150\n",
      "    desired_bonus: int = 600 # Karen wants to earn a $600 bonus\n",
      "):\n",
      "    \"\"\"Index: 7371.\n",
      "    Returns: the combined score needed in the last two tests to ensure that Karen earns a $600 bonus.\"\"\"\n",
      "    #: L1\n",
      "    extra_bonus_needed = desired_bonus - baseline_bonus\n",
      "\n",
      "    #: L2\n",
      "    extra_points_needed = extra_bonus_needed / extra_bonus_per_point\n",
      "\n",
      "    #: L3\n",
      "    target_avg_score = baseline_avg_score + extra_points_needed\n",
      "\n",
      "    #: L4\n",
      "    total_tests = tests_graded_so_far + 2\n",
      "\n",
      "    #: L5\n",
      "    total_points_needed = target_avg_score * total_tests\n",
      "\n",
      "    #: L6\n",
      "    points_earned_so_far = avg_so_far * tests_graded_so_far\n",
      "\n",
      "    #: L7\n",
      "    points_needed_last_two_tests = total_points_needed - points_earned_so_far\n",
      "\n",
      "    answer = points_needed_last_two_tests  # FINAL ANSWER\n",
      "    return answer\n",
      "```\n",
      "--- TASK ---\n",
      "\n",
      "*Index*: \n",
      "6237\n",
      "\n",
      "*Question*: \n",
      "Brendan makes $6/hour as a waiter. He's scheduled for 2 8-hour shifts and 1 12-hour shift this week. He also makes an average of $12 in tips each hour. Brendan is supposed to pay 20% of his income in taxes, but he only reports 1/3rd of his tips to the IRS. How much money does Brendan pay in taxes each week?\n",
      "\n",
      "*Solution*: \n",
      "{\"L1\": \"First find the total number of hours Brendan works for the 8-hour shifts: 2 shifts * 8 hours/shift = [[2*8=16]]16 hours\", \"L2\": \"Then find the total number of hours Brendan works by adding those hours to the 12-hour shift: 16 hours + 12 hours = [[16+12=28]]28 hours\", \"L3\": \"Now find Brendan's total wage earnings by multiplying his $6/hour wage by the number of hours he works: $6/hour * 28 hours = $[[6*28=168]]168/week\", \"L4\": \"Now figure out how much Brendan makes in tips by multiplying the number of hours he works by the amount of tips he makes per hour: $12/hour * 28 hours/week = $[[12*28=336]]336/week\", \"L5\": \"Now divide that number by 3, since Brendan only reports a third of his tips: $336/week / 3 = $[[336/3=112]]112/week\", \"L6\": \"Now add Brendan's wage earnings to that number to find how much income he reports to the IRS each week: $168/week + $112/week = $[[168+112=280]]280/week\", \"L7\": \"Finally, multiply Brendan's reported income by his tax rate to find how much he pays in taxes each week: $280/week * .2 = $[[280*.2=56]]56/week\"}\n",
      "\n",
      "*Code*:\n"
     ]
    }
   ],
   "source": [
    "def generate_and_print_sample_prompt(target_index: int, example_indices: List[int]):\n",
    "    \"\"\"\n",
    "    Generates and prints the full user prompt for a single target index\n",
    "    for debugging and inspection.\n",
    "\n",
    "    Args:\n",
    "        target_index: The GSM8K index for the final task in the prompt.\n",
    "        example_indices: A list of GSM8K indices to use as few-shot examples.\n",
    "    \"\"\"\n",
    "    print(f\"--- Generating sample prompt for target index: {target_index} ---\")\n",
    "\n",
    "    # 1. Load the code strings for the few-shot examples using the same\n",
    "    #    function as the main pipeline. This tests if the examples are loading correctly.\n",
    "    code_examples = get_code_strings(indices=example_indices)\n",
    "\n",
    "    # 2. Craft the full user prompt.\n",
    "    full_prompt = craft_user_prompt(\n",
    "        index=target_index,\n",
    "        example_indices=example_indices,\n",
    "        code_examples=code_examples\n",
    "    )\n",
    "    print(full_prompt)\n",
    "\n",
    "generate_and_print_sample_prompt(\n",
    "    target_index=6237,\n",
    "    example_indices=[310, 3822, 7371]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c266cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
