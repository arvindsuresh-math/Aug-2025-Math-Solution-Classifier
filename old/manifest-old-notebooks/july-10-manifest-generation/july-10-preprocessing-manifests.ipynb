{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35831ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Raw Manifests: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/tier-manifests-gen-txt\n",
      "Output for Processed Files: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/tier-manifests-gen-processed\n",
      "\n",
      "--- Starting Pre-processing of Raw Manifests ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9add0b0b1a246a5b7986e821ed0dc6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Tiers:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pre-processing Complete ---\n",
      "Successfully processed: 4796 files\n",
      "Failed to process:      1056 files\n",
      "Failure log saved to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/tier-manifests-gen-txt/failed_manifests_log.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd # <-- Make sure pandas is imported\n",
    "\n",
    "# --- 1. Define Paths and Models ---\n",
    "def find_project_root(marker: str = \".git\") -> Path:\n",
    "    current_path = Path.cwd().resolve()\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / marker).exists():\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    raise FileNotFoundError(f\"Could not find project root. Marker '{marker}' not found.\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "\n",
    "RAW_MANIFEST_DIR = DATA_DIR / \"tier-manifests-gen-txt\"\n",
    "PROCESSED_MANIFEST_DIR = DATA_DIR / \"tier-manifests-gen-processed\"\n",
    "\n",
    "MODELS = ['openai_gpt-4.1', 'google_gemini-2.5-flash']\n",
    "\n",
    "print(f\"Input Raw Manifests: {RAW_MANIFEST_DIR}\")\n",
    "print(f\"Output for Processed Files: {PROCESSED_MANIFEST_DIR}\")\n",
    "\n",
    "\n",
    "# --- 2. MODIFIED Helper Function for Processing ---\n",
    "def process_single_raw_manifest(\n",
    "    raw_file_path: Path,\n",
    "    output_dir: Path,\n",
    "    model_name: str\n",
    ") -> tuple[str, str | None]:\n",
    "    \"\"\"\n",
    "    Reads a single raw manifest .txt file and processes it.\n",
    "\n",
    "    --- MODIFIED: Returns a tuple (status, reason) ---\n",
    "    - ('success', None) on success.\n",
    "    - ('failure', 'reason_string') on failure.\n",
    "    \"\"\"\n",
    "    if not raw_file_path.exists():\n",
    "        return 'failure', 'FileNotFound'\n",
    "\n",
    "    try:\n",
    "        content = raw_file_path.read_text(encoding='utf-8').strip()\n",
    "        if not content:\n",
    "            return 'failure', 'FileIsEmpty'\n",
    "\n",
    "        # Extract content from ```json ... ``` block if it exists\n",
    "        match = re.search(r'```json\\s*([\\s\\S]*?)\\s*```', content, re.DOTALL)\n",
    "        json_string = match.group(1) if match else content\n",
    "\n",
    "        manifest_data = json.loads(json_string)\n",
    "\n",
    "        function_code = manifest_data.get(\"function_code\")\n",
    "        logical_steps = manifest_data.get(\"logical_steps\")\n",
    "\n",
    "        if not function_code or not logical_steps:\n",
    "            return 'failure', 'MissingKeys'\n",
    "\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        (output_dir / f\"{model_name}.py\").write_text(function_code, encoding='utf-8')\n",
    "        with open(output_dir / f\"{model_name}.json\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(logical_steps, f, indent=2)\n",
    "\n",
    "        return 'success', None\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        return 'failure', 'JSONDecodeError'\n",
    "    except Exception as e:\n",
    "        return 'failure', f'UnexpectedError:{type(e).__name__}'\n",
    "\n",
    "\n",
    "# --- 3. MODIFIED Main Driver Function ---\n",
    "def preprocess_all_raw_manifests(\n",
    "    raw_dir: Path,\n",
    "    processed_dir: Path,\n",
    "    models: list[str]\n",
    "):\n",
    "    \"\"\"\n",
    "    Iterates through all raw manifests, saves successes, and logs failures.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Pre-processing of Raw Manifests ---\")\n",
    "    if not raw_dir.is_dir():\n",
    "        print(f\"ERROR: Source directory not found: {raw_dir}\")\n",
    "        return\n",
    "\n",
    "    success_count = 0\n",
    "    # --- NEW: List to store details of failed files ---\n",
    "    failures = []\n",
    "    \n",
    "    tier_dirs = sorted([d for d in raw_dir.iterdir() if d.is_dir() and d.name.startswith('tier')])\n",
    "\n",
    "    for tier_dir in tqdm(tier_dirs, desc=\"Processing Tiers\"):\n",
    "        index_dirs = sorted([d for d in tier_dir.iterdir() if d.is_dir() and d.name.isdigit()], key=lambda p: int(p.name))\n",
    "        \n",
    "        for index_dir in index_dirs:\n",
    "            for model_name in models:\n",
    "                raw_file = index_dir / f\"{model_name}.txt\"\n",
    "                output_dir = processed_dir / tier_dir.name / index_dir.name\n",
    "                \n",
    "                status, reason = process_single_raw_manifest(raw_file, output_dir, model_name)\n",
    "                \n",
    "                if status == 'success':\n",
    "                    success_count += 1\n",
    "                else:\n",
    "                    failures.append({\n",
    "                        'filepath': str(raw_file.relative_to(PROJECT_ROOT)),\n",
    "                        'reason': reason\n",
    "                    })\n",
    "    \n",
    "    print(\"\\n--- Pre-processing Complete ---\")\n",
    "    print(f\"Successfully processed: {success_count} files\")\n",
    "    \n",
    "    # --- NEW: Save the failure log to a CSV file ---\n",
    "    if failures:\n",
    "        print(f\"Failed to process:      {len(failures)} files\")\n",
    "        failure_log_path = raw_dir / \"failed_manifests_log.csv\"\n",
    "        df_failures = pd.DataFrame(failures)\n",
    "        df_failures.to_csv(failure_log_path, index=False)\n",
    "        print(f\"Failure log saved to: {failure_log_path}\")\n",
    "    else:\n",
    "        print(\"Failed to process:      0 files\")\n",
    "\n",
    "\n",
    "# --- 4. Execute the Pipeline ---\n",
    "preprocess_all_raw_manifests(RAW_MANIFEST_DIR, PROCESSED_MANIFEST_DIR, MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f07951b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
