{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92cb78d",
   "metadata": {},
   "source": [
    "### Cell 1: Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75ca7c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math\n",
      "Input (Split Manifests): /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/tier-manifests-gen-processed\n",
      "Output (Generated Errors): /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/computational-errors-generated\n"
     ]
    }
   ],
   "source": [
    "# --- Python Standard Library Imports ---\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "import inspect\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "from types import ModuleType\n",
    "from typing import Callable, Any, Dict, List\n",
    "from fractions import Fraction\n",
    "import datetime\n",
    "import functools\n",
    "import random\n",
    "import copy\n",
    "\n",
    "# --- Third-Party Imports ---\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# --- MODIFIED: Path and Directory Definitions ---\n",
    "def find_project_root(marker: str = \".git\") -> Path:\n",
    "    current_path = Path.cwd().resolve()\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / marker).exists():\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    raise FileNotFoundError(f\"Could not find project root. Marker '{marker}' not found.\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "\n",
    "PROCESSED_MANIFEST_DIR = DATA_DIR / \"tier-manifests-gen-processed\"\n",
    "GENERATED_ERRORS_DIR = DATA_DIR / \"computational-errors-generated\"\n",
    "\n",
    "# --- NEW: Define the list of models we will process ---\n",
    "MODELS = ['openai_gpt-4.1', 'google_gemini-2.5-flash']\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Input (Split Manifests): {PROCESSED_MANIFEST_DIR}\")\n",
    "print(f\"Output (Generated Errors): {GENERATED_ERRORS_DIR}\")\n",
    "\n",
    "# --- Ensure Output Directory Exists ---\n",
    "PROCESSED_MANIFEST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "GENERATED_ERRORS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56474573",
   "metadata": {},
   "source": [
    "### Cell 2: Load dataset and define tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28ec494d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier definitions loaded and samples categorized.\n",
      "tier1     : 2767 samples\n",
      "tier2     : 837 samples\n",
      "tier3     : 3113 samples\n",
      "tier4     : 544 samples\n",
      "tier5     : 212 samples\n"
     ]
    }
   ],
   "source": [
    "# --- Load GSM8K Dataset ---\n",
    "GSM8K_TRAIN: Dataset = load_dataset(\"gsm8k\", \"main\")[\"train\"]\n",
    "\n",
    "# --- Tier Definition Functions ---\n",
    "def has_computational_division(solution_text: str) -> bool:\n",
    "    pattern = re.compile(r'/\\s*\\d')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def has_float(solution_text: str) -> bool:\n",
    "    pattern = re.compile(r'(?<!\\d)\\.\\d+|\\d+\\.\\d+')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def is_symbolic(solution_text: str) -> bool:\n",
    "    pattern = re.compile(r'^Let [a-zA-Z] ', re.MULTILINE)\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def mutually_disjoint_tiers(dataset: Dataset) -> dict[str, list[int]]:\n",
    "    # (Function content is unchanged)\n",
    "    tiers = {}\n",
    "    symbolic_set = set(idx for idx, sample in enumerate(dataset) if is_symbolic(sample.get(\"answer\", \"\")))\n",
    "    non_symbolic_indices = [idx for idx in range(len(dataset)) if idx not in symbolic_set]\n",
    "    tiers[\"tier1\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier2\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier3\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier4\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier5\"] = sorted(list(symbolic_set))\n",
    "    return tiers\n",
    "\n",
    "TIER_LISTS = mutually_disjoint_tiers(GSM8K_TRAIN)\n",
    "print(\"Tier definitions loaded and samples categorized.\")\n",
    "for tier, indices in TIER_LISTS.items():\n",
    "    print(f\"{tier:<10}: {len(indices)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fc6ad0",
   "metadata": {},
   "source": [
    "### Cell 3: Manifest loading and processing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f74917a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifest loading functions updated to read from the split-file directory.\n"
     ]
    }
   ],
   "source": [
    "def load_function_module(\n",
    "    tier: str,\n",
    "    index: int,\n",
    "    model_name: str, \n",
    "    base_dir: Path = PROCESSED_MANIFEST_DIR # \n",
    ") -> ModuleType | None:\n",
    "    \"\"\"\n",
    "    Dynamically loads the '{model_name}.py' file for a given tier, index, and model.\n",
    "    \"\"\"\n",
    "    py_file_path = base_dir / tier / str(index) / f\"{model_name}.py\"\n",
    "    if not py_file_path.exists():\n",
    "        return None\n",
    "\n",
    "    # Make module name unique to avoid import caching issues\n",
    "    module_name = f\"manifests.t{tier}.i{index}.m_{model_name.replace('.', '_')}.solve\"\n",
    "    spec = importlib.util.spec_from_file_location(module_name, py_file_path)\n",
    "    if spec and spec.loader:\n",
    "        module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(module)\n",
    "        return module\n",
    "    return None\n",
    "\n",
    "def load_logical_steps(\n",
    "    tier: str,\n",
    "    index: int,\n",
    "    model_name: str, \n",
    "    base_dir: Path = PROCESSED_MANIFEST_DIR\n",
    ") -> list[dict] | None:\n",
    "    \"\"\"\n",
    "    Loads the '{model_name}.json' file for a given tier, index, and model.\n",
    "    \"\"\"\n",
    "    json_file_path = base_dir / tier / str(index) / f\"{model_name}.json\"\n",
    "    try:\n",
    "        with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def build_solution_mapping(index: int, dataset: Dataset = GSM8K_TRAIN):\n",
    "    \"\"\"\n",
    "    (Function is unchanged)\n",
    "    Extracts the original NL solution for comparison. Not strictly needed for the\n",
    "    pipeline but useful for debugging.\n",
    "    \"\"\"\n",
    "    solution_mapping = {}\n",
    "    solution_text = dataset[index][\"answer\"]\n",
    "    lines = [ln.strip() for ln in solution_text.splitlines() if ln.strip()]\n",
    "    if lines and re.match(r\"^####\\s*[\\d\\.,]+$\", lines[-1]):\n",
    "        lines.pop(-1)\n",
    "    for i, line in enumerate(lines, 1):\n",
    "        solution_mapping[f\"L{i}\"] = line\n",
    "    return solution_mapping\n",
    "\n",
    "\n",
    "print(\"Manifest loading functions updated to read from the split-file directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc9976b",
   "metadata": {},
   "source": [
    "### Cell 4: General and core utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba31dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Cell 4 of BOTH notebooks, add this class at the top.\n",
    "\n",
    "from fractions import Fraction as BuiltinFraction\n",
    "\n",
    "class NonSimplifyingFraction(BuiltinFraction):\n",
    "    \"\"\"\n",
    "    A subclass of fractions.Fraction that does NOT simplify when converted\n",
    "    to a string. This preserves the original representation from the manifest.\n",
    "    \n",
    "    For example, str(NonSimplifyingFraction(80, 100)) will be \"80/100\", \n",
    "    not \"4/5\".\n",
    "    \"\"\"\n",
    "    def __new__(cls, numerator=0, denominator=None):\n",
    "        # We must use __new__ because Fraction is immutable\n",
    "        self = super(NonSimplifyingFraction, cls).__new__(cls, numerator, denominator)\n",
    "        # Store the original denominator for the __str__ method.\n",
    "        # The built-in .denominator will be simplified.\n",
    "        if denominator is not None:\n",
    "            self._original_denominator = denominator\n",
    "            self._original_numerator = numerator if isinstance(numerator, int) else numerator.numerator\n",
    "        else: # Handle cases like Fraction(0.5)\n",
    "            self._original_numerator, self._original_denominator = self.as_integer_ratio()\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self._original_numerator}/{self._original_denominator}\"\n",
    "\n",
    "\n",
    "# --- General Numeric and String Helpers ---\n",
    "def normalize_value(value):\n",
    "    if isinstance(value, float) and value.is_integer(): return int(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "def get_sign(n) -> int:\n",
    "    if n > 0: return 1\n",
    "    if n < 0: return -1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def has_distinct_adjacent_digits(n: int) -> bool:\n",
    "    s = str(abs(n))\n",
    "    return len(s) >= 2 and any(s[i] != s[i+1] for i in range(len(s) - 1))\n",
    "\n",
    "\n",
    "\n",
    "def execution_trace(func: Callable[[], Any]) -> dict[str, Any] | None:\n",
    "    \"\"\"\n",
    "    --- MODIFIED ---\n",
    "    Now uses the NonSimplifyingFraction class in its execution environment\n",
    "    to prevent auto-simplification of fractions in the variable trace.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "        func_def = tree.body[0]\n",
    "        # This is the key change: 'Fraction' now points to our custom class.\n",
    "        global_namespace = {'Fraction': NonSimplifyingFraction}\n",
    "        local_env = {}\n",
    "        for stmt in func_def.body:\n",
    "            if isinstance(stmt, ast.Assign):\n",
    "                module_node = ast.Module([stmt], type_ignores=[])\n",
    "                code_obj = compile(module_node, '<string>', 'exec')\n",
    "                exec(code_obj, global_namespace, local_env)\n",
    "        return local_env\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_flawed_trace(func: Callable, error_details: dict[str, Any]) -> dict[str, Any] | None:\n",
    "    \"\"\"\n",
    "    --- MODIFIED ---\n",
    "    Also uses the NonSimplifyingFraction class to ensure consistency.\n",
    "    \"\"\"\n",
    "    # ... (the first part of the function that modifies the AST is unchanged) ...\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "        func_def = tree.body[0]\n",
    "        variable_to_change = error_details[\"variable\"]\n",
    "        flawed_value = error_details[\"flawed_value\"]\n",
    "        modified_body = copy.deepcopy(func_def.body)\n",
    "        node_found_and_modified = False\n",
    "        for node in modified_body:\n",
    "            if isinstance(node, ast.Assign) and any(isinstance(t, ast.Name) and t.id == variable_to_change for t in node.targets):\n",
    "                if isinstance(flawed_value, BuiltinFraction): # Check against the base class\n",
    "                    # When creating a new node, we use the custom class name\n",
    "                    new_value_node = ast.Call(\n",
    "                        func=ast.Name(id='Fraction', ctx=ast.Load()),\n",
    "                        args=[ast.Constant(value=flawed_value.numerator), ast.Constant(value=flawed_value.denominator)],\n",
    "                        keywords=[]\n",
    "                    )\n",
    "                else: new_value_node = ast.Constant(value=flawed_value)\n",
    "                ast.copy_location(new_value_node, node.value)\n",
    "                ast.fix_missing_locations(new_value_node)\n",
    "                node.value = new_value_node\n",
    "                node_found_and_modified = True\n",
    "                break\n",
    "        if not node_found_and_modified: return None\n",
    "\n",
    "        # This is the key change, same as in execution_trace.\n",
    "        global_namespace = {'Fraction': NonSimplifyingFraction}\n",
    "        env = {}\n",
    "        for stmt in modified_body:\n",
    "            if isinstance(stmt, ast.Assign):\n",
    "                code_obj = compile(ast.Module([stmt], type_ignores=[]), '<string>', 'exec')\n",
    "                exec(code_obj, global_namespace, env)\n",
    "        return env\n",
    "    except Exception: return None\n",
    "\n",
    "\n",
    "def reconstruct_solution_lines_enhanced(logical_steps: list[dict], eval_trace: dict[str, Any]) -> dict[str, str]:\n",
    "    # (Function content is unchanged from old Cell 4)\n",
    "    reconstructed_mapping = {}\n",
    "    placeholder_pattern = re.compile(r'\\{([a-zA-Z0-9_]+)\\}')\n",
    "    for step in logical_steps:\n",
    "        line_number = step.get(\"line_number\")\n",
    "        template = step.get(\"solution_line_template\")\n",
    "        if not line_number or not template: continue\n",
    "        def replacer(match):\n",
    "            variable_name = match.group(1)\n",
    "            value = eval_trace.get(variable_name)\n",
    "            if value is None: return f\"{{ERROR}}\"\n",
    "            if isinstance(value, Fraction):\n",
    "                if value.denominator == 1: return str(value.numerator)\n",
    "                return f\"{value.numerator}/{value.denominator}\"\n",
    "            return str(normalize_value(value))\n",
    "        reconstructed_mapping[line_number] = placeholder_pattern.sub(replacer, template)\n",
    "    return reconstructed_mapping\n",
    "\n",
    "\n",
    "def is_trace_valid(\n",
    "    flawed_trace: dict[str, Any],\n",
    "    correct_trace: dict[str, Any]\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Validates a flawed trace to ensure it adheres to project constraints.\n",
    "\n",
    "    Checks for two conditions:\n",
    "    1. Type Integrity: An integer-like value must remain integer-like.\n",
    "       (e.g., 15 students cannot become 15.5 students).\n",
    "    2. Sign Integrity: A value cannot change its sign\n",
    "       (e.g., a cost of $20 cannot become -$20).\n",
    "    \"\"\"\n",
    "    for var_name, correct_val in correct_trace.items():\n",
    "        if var_name not in flawed_trace:\n",
    "            continue\n",
    "\n",
    "        flawed_val = flawed_trace.get(var_name)\n",
    "        \n",
    "        # Rule 1: Type Integrity Check\n",
    "        is_correct_int_like = isinstance(normalize_value(correct_val), int)\n",
    "        is_flawed_int_like = isinstance(normalize_value(flawed_val), int)\n",
    "\n",
    "        if is_correct_int_like and not is_flawed_int_like:\n",
    "            return False\n",
    "\n",
    "        # Rule 2: Sign Integrity Check\n",
    "        processed_correct = normalize_value(correct_val)\n",
    "        processed_flawed = normalize_value(flawed_val)\n",
    "        \n",
    "        if isinstance(processed_correct, (int, float)) and processed_correct != 0:\n",
    "            if get_sign(processed_correct) != get_sign(processed_flawed):\n",
    "                return False\n",
    "                \n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07618b44",
   "metadata": {},
   "source": [
    "### Cell 5: Individual error generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ff50735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "\n",
    "def generate_off_by_n_error(\n",
    "    correct_value: int,\n",
    "    offset_range: tuple[int, int] = (1, 5)\n",
    "    ):\n",
    "    \"\"\"Generates a minor miscalculation error, preventing sign changes.\"\"\"\n",
    "    offset = random.randint(offset_range[0], offset_range[1])\n",
    "    if random.random() < 0.5:\n",
    "        offset = -offset\n",
    "\n",
    "    flawed_value = correct_value + offset\n",
    "    \n",
    "    # --- THIS IS THE FIX ---\n",
    "    # If the sign flips, either use a smaller offset or flip the offset's sign\n",
    "    if get_sign(correct_value) != get_sign(flawed_value) and correct_value != 0:\n",
    "        flawed_value = correct_value - offset # Try the opposite offset\n",
    "\n",
    "    # Ensure value actually changes, especially if the fix above reverted it\n",
    "    if flawed_value == correct_value:\n",
    "        flawed_value += 1 if correct_value >= 0 else -1\n",
    "    # --- END FIX ---\n",
    "    \n",
    "    return {\n",
    "        \"flawed_value\": flawed_value,\n",
    "        \"explanation_type\": \"This appears to be a minor miscalculation.\"\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_off_by_factor_of_10_error(correct_value: int):\n",
    "    \"\"\"Generates a dropped/added zero error. Assumes input is a multiple of 100.\"\"\"\n",
    "    options = [\"divide\", \"multiply\"]\n",
    "    choice = random.choice(options)\n",
    "    \n",
    "    if choice == \"divide\":\n",
    "        flawed_value = correct_value // 10\n",
    "        explanation = \"It appears a zero was dropped from the number.\"\n",
    "    else: # multiply\n",
    "        flawed_value = correct_value * 10\n",
    "        explanation = \"It appears an extra zero was added to the number.\"\n",
    "\n",
    "    return {\n",
    "        \"flawed_value\": flawed_value,\n",
    "        \"explanation_type\": explanation\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_digit_transposition_error(correct_value: int) -> dict[str, Any] | None:\n",
    "    \"\"\"\n",
    "    Swaps two adjacent digits. Now includes a check to prevent creating\n",
    "    a leading zero, which would alter the number's magnitude.\n",
    "    \"\"\"\n",
    "    # This check is important as this function should only ever receive integers\n",
    "    if not isinstance(correct_value, int):\n",
    "        return None\n",
    "\n",
    "    s_val = str(abs(correct_value))\n",
    "    \n",
    "    # Pre-condition: must have at least 2 digits to swap.\n",
    "    if len(s_val) < 2:\n",
    "        return None\n",
    "\n",
    "    # Find all indices where adjacent digits are different\n",
    "    possible_indices = [i for i in range(len(s_val) - 1) if s_val[i] != s_val[i+1]]\n",
    "    \n",
    "    # --- NEW VALIDATION LOGIC ---\n",
    "    # Filter out swaps that would create a leading zero.\n",
    "    # A swap at index i is invalid if i=0 and the digit at i+1 is '0'.\n",
    "    valid_indices = [\n",
    "        i for i in possible_indices\n",
    "        if not (i == 0 and s_val[i+1] == '0')\n",
    "    ]\n",
    "    \n",
    "    # If no valid swaps are possible, we cannot generate this error.\n",
    "    if not valid_indices:\n",
    "        return None\n",
    "    # --- END NEW LOGIC ---\n",
    "\n",
    "    idx_to_swap = random.choice(valid_indices)\n",
    "    \n",
    "    s_list = list(s_val)\n",
    "    s_list[idx_to_swap], s_list[idx_to_swap+1] = s_list[idx_to_swap+1], s_list[idx_to_swap]\n",
    "    \n",
    "    flawed_value = int(\"\".join(s_list))\n",
    "    if correct_value < 0:\n",
    "        flawed_value = -flawed_value\n",
    "\n",
    "    return {\n",
    "        \"flawed_value\": flawed_value,\n",
    "        \"explanation_type\": \"It appears two adjacent digits were swapped.\"\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_stem_off_by_n_error(\n",
    "    correct_value: int,\n",
    "    offset_range: tuple[int, int] = (1, 3)\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Applies a small offset to the 'stem' of a number (the part before the final zero).\n",
    "    Assumes the input is a non-zero multiple of 10.\n",
    "    \"\"\"\n",
    "    stem = correct_value // 10\n",
    "    \n",
    "    offset = random.randint(offset_range[0], offset_range[1])\n",
    "    if random.random() < 0.5:\n",
    "        offset = -offset\n",
    "\n",
    "    flawed_stem = stem + offset\n",
    "    if flawed_stem == stem:\n",
    "        flawed_stem += 1 # Ensure the value changes\n",
    "\n",
    "    flawed_value = flawed_stem * 10\n",
    "\n",
    "    return {\n",
    "        \"flawed_value\": flawed_value,\n",
    "        \"explanation_type\": \"It appears there was a miscalculation with the digits before the final zero.\"\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_decimal_shift_error(correct_value: float) -> dict[str, Any]:\n",
    "    \"\"\"Multiplies or divides a float by 10 to simulate a decimal shift.\"\"\"\n",
    "    choice = random.choice([\"multiply\", \"divide\"])\n",
    "    flawed_value = correct_value * 10 if choice == \"multiply\" else correct_value / 10\n",
    "    return {\n",
    "        \"flawed_value\": round(flawed_value, 10), # Round to avoid precision issues\n",
    "        \"explanation_type\": \"It appears the decimal point was misplaced.\"\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_float_off_by_n_error(correct_value: float) -> dict[str, Any]:\n",
    "    \"\"\"Applies a small offset to a general float.\"\"\"\n",
    "    # This creates an offset that is roughly 10-20% of the original value's magnitude\n",
    "    magnitude = abs(correct_value)\n",
    "    offset = random.uniform(magnitude * 0.1, magnitude * 0.2)\n",
    "    if random.random() < 0.5:\n",
    "        offset = -offset\n",
    "        \n",
    "    flawed_value = correct_value + offset\n",
    "    return {\n",
    "        \"flawed_value\": round(flawed_value, 10),\n",
    "        \"explanation_type\": \"This appears to be a minor miscalculation.\"\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_reciprocal_error(correct_value: NonSimplifyingFraction) -> dict[str, Any] | None:\n",
    "    \"\"\"Swaps the numerator and denominator of a fraction.\"\"\"\n",
    "    if correct_value.denominator == 0: return None\n",
    "    \n",
    "    # --- MODIFIED: Return our custom class to preserve the representation ---\n",
    "    flawed_value = NonSimplifyingFraction(correct_value.denominator, correct_value.numerator)\n",
    "    return {\n",
    "        \"flawed_value\": flawed_value,\n",
    "        \"explanation_type\": \"It appears the numerator and denominator were swapped.\"\n",
    "    }\n",
    "\n",
    "def generate_off_by_one_in_fraction_part_error(correct_value: NonSimplifyingFraction) -> dict[str, Any]:\n",
    "    \"\"\"Adds or subtracts 1 from either the numerator or the denominator.\"\"\"\n",
    "    part_to_change = random.choice([\"numerator\", \"denominator\"])\n",
    "    offset = random.choice([-1, 1])\n",
    "\n",
    "    if part_to_change == \"numerator\":\n",
    "        new_num = correct_value.numerator + offset\n",
    "        new_den = correct_value.denominator\n",
    "    else:\n",
    "        new_num = correct_value.numerator\n",
    "        new_den = correct_value.denominator + offset\n",
    "        if new_den == 0:\n",
    "            new_den = correct_value.denominator + (offset * 2)\n",
    "\n",
    "    # --- MODIFIED: Return our custom class ---\n",
    "    return {\n",
    "        \"flawed_value\": NonSimplifyingFraction(new_num, new_den),\n",
    "        \"explanation_type\": \"It appears there was an off-by-one error in the fraction.\"\n",
    "    }\n",
    "\n",
    "def generate_multiplication_by_reciprocal_error(\n",
    "    numeric_val: Any, \n",
    "    fraction_val: NonSimplifyingFraction\n",
    ") -> dict[str, Any] | None:\n",
    "    \"\"\"Simulates an error where a value is multiplied by the reciprocal.\"\"\"\n",
    "    if fraction_val.numerator == 0:\n",
    "        return None\n",
    "\n",
    "    # This creates a standard, simplifying fraction for the calculation.\n",
    "    reciprocal_fraction = BuiltinFraction(fraction_val.denominator, fraction_val.numerator)\n",
    "    flawed_value_result = numeric_val * reciprocal_fraction\n",
    "    \n",
    "    # --- MODIFIED: The final return value must be a NonSimplifyingFraction ---\n",
    "    # We must construct it from the un-simplified components to preserve the logic.\n",
    "    new_numerator = numeric_val * fraction_val.denominator\n",
    "    new_denominator = fraction_val.numerator\n",
    "    \n",
    "    return {\n",
    "        # The value is correct, but the representation now preserves the logic.\n",
    "        \"flawed_value\": NonSimplifyingFraction(new_numerator, new_denominator),\n",
    "        \"explanation_type\": \"It appears the value was multiplied by the reciprocal of the intended fraction.\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f9aa6",
   "metadata": {},
   "source": [
    "### Cell 6: AST and Logical Step Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca578f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import random\n",
    "from typing import Callable, Any\n",
    "\n",
    "def get_target_variables(logical_steps: list[dict]) -> list[str]:\n",
    "    \"\"\"Extracts all 'output_variable' names from the logical steps.\"\"\"\n",
    "    return [step['output_variable'] for step in logical_steps if 'output_variable' in step]\n",
    "\n",
    "\n",
    "def get_operator_for_variable(func: Callable, variable_name: str) -> str | None:\n",
    "    \"\"\"Inspects the AST to find the operator used to compute a variable.\"\"\"\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "    except (TypeError, FileNotFoundError, SyntaxError):\n",
    "        return None\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Assign) and any(isinstance(t, ast.Name) and t.id == variable_name for t in node.targets):\n",
    "            if isinstance(node.value, ast.BinOp):\n",
    "                op = node.value.op\n",
    "                if isinstance(op, ast.Add): return \"add\"\n",
    "                if isinstance(op, ast.Sub): return \"sub\"\n",
    "                if isinstance(op, ast.Mult): return \"mult\"\n",
    "                if isinstance(op, ast.Div): return \"div\"\n",
    "            return \"other\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_operand_names_for_variable(func: Callable, variable_name: str) -> list[str]:\n",
    "    \"\"\"Finds the names of variables used as operands for a target variable.\"\"\"\n",
    "    operand_names = []\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "    except (TypeError, FileNotFoundError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Assign) and any(isinstance(t, ast.Name) and t.id == variable_name for t in node.targets):\n",
    "            for sub_node in ast.walk(node.value):\n",
    "                if isinstance(sub_node, ast.Name):\n",
    "                    operand_names.append(sub_node.id)\n",
    "            return list(set(operand_names))\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d072a42",
   "metadata": {},
   "source": [
    "### Cell 7: Error applicability logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab6d7048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _get_applicable_integer_errors(\n",
    "    correct_value: int,\n",
    "    operator: str,\n",
    "    operand_values: list\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Returns a list of applicable error generator functions for an integer.\n",
    "    Refined to separate logic for addition/subtraction vs. other operations.\n",
    "    \"\"\"\n",
    "    applicable_generators = []\n",
    "    \n",
    "    # Rule 1: Off-by-n and stem errors are only for addition/subtraction.\n",
    "    if operator in [\"add\", \"sub\"]:\n",
    "        all_end_in_zero = all(isinstance(v, int) and v % 10 == 0 for v in operand_values) if operand_values else False\n",
    "        if all_end_in_zero and correct_value % 10 == 0 and correct_value != 0:\n",
    "            applicable_generators.append(generate_stem_off_by_n_error)\n",
    "        else:\n",
    "            applicable_generators.append(generate_off_by_n_error)\n",
    "\n",
    "    # Rule 2: Factor-of-10 error applies to any operation resulting in a multiple of 100.\n",
    "    if correct_value % 100 == 0 and correct_value != 0:\n",
    "        applicable_generators.append(generate_off_by_factor_of_10_error)\n",
    "    \n",
    "    # Rule 3: Digit transposition applies to any operation resulting in a suitable integer.\n",
    "    if has_distinct_adjacent_digits(correct_value):\n",
    "        applicable_generators.append(generate_digit_transposition_error)\n",
    "        \n",
    "    return applicable_generators\n",
    "\n",
    "\n",
    "def get_applicable_generators(\n",
    "    func: Callable,\n",
    "    correct_trace: dict[str, Any],\n",
    "    variable_name: str\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Identifies and partially instantiates all applicable error generators for a variable.\n",
    "    This version correctly handles integer multiplication.\n",
    "    \"\"\"\n",
    "    applicable_generators = []\n",
    "    correct_value = correct_trace.get(variable_name)\n",
    "    if not isinstance(correct_value, (int, float, Fraction)):\n",
    "        return []\n",
    "\n",
    "    def add_generator(gen_func, value_to_pass):\n",
    "        \"\"\"Creates a callable partial function with the correct value and name.\"\"\"\n",
    "        partial_gen = functools.partial(gen_func, value_to_pass)\n",
    "        partial_gen.__name__ = gen_func.__name__\n",
    "        applicable_generators.append(partial_gen)\n",
    "\n",
    "    # --- Part 1: Type-Based Error Selection ---\n",
    "    if isinstance(correct_value, int) or (isinstance(correct_value, float) and correct_value.is_integer()) or (isinstance(correct_value, Fraction) and correct_value.denominator == 1):\n",
    "        int_val = int(correct_value)\n",
    "        operator = get_operator_for_variable(func, variable_name)\n",
    "        op_names = get_operand_names_for_variable(func, variable_name)\n",
    "        op_vals = [correct_trace.get(name) for name in op_names if name in correct_trace]\n",
    "        \n",
    "        # This now correctly applies integer errors (including transposition) to multiplication results.\n",
    "        integer_gens = _get_applicable_integer_errors(int_val, operator, op_vals)\n",
    "        for gen_func in integer_gens:\n",
    "            add_generator(gen_func, int_val)\n",
    "\n",
    "    elif isinstance(correct_value, float):\n",
    "        add_generator(generate_float_off_by_n_error, correct_value)\n",
    "        if correct_value != 0:\n",
    "            add_generator(generate_decimal_shift_error, correct_value)\n",
    "\n",
    "    elif isinstance(correct_value, Fraction) and correct_value.denominator != 1:\n",
    "        add_generator(generate_off_by_one_in_fraction_part_error, correct_value)\n",
    "        if correct_value.numerator != 0:\n",
    "            add_generator(generate_reciprocal_error, correct_value)\n",
    "\n",
    "    # --- Part 2: Context-Based Error Selection (Multiplication by Reciprocal) ---\n",
    "    operator = get_operator_for_variable(func, variable_name)\n",
    "    if operator == \"mult\":\n",
    "        operand_names = get_operand_names_for_variable(func, variable_name)\n",
    "        operand_values = [correct_trace.get(name) for name in operand_names if name in correct_trace]\n",
    "        \n",
    "        if len(operand_values) == 2:\n",
    "            num_op = next((op for op in operand_values if isinstance(op, (int, float))), None)\n",
    "            frac_op = next((op for op in operand_values if isinstance(op, Fraction)), None)\n",
    "\n",
    "            if num_op is not None and frac_op is not None and frac_op.denominator != 1:\n",
    "                # This error is specific and does not use the standard `add_generator`\n",
    "                reciprocal_mult_gen = functools.partial(\n",
    "                    generate_multiplication_by_reciprocal_error,\n",
    "                    numeric_val=num_op,\n",
    "                    fraction_val=frac_op\n",
    "                )\n",
    "                reciprocal_mult_gen.__name__ = 'generate_multiplication_by_reciprocal_error'\n",
    "                applicable_generators.append(reciprocal_mult_gen)\n",
    "\n",
    "    # Return unique generators, as some rules might overlap\n",
    "    return list(dict.fromkeys(applicable_generators))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b32217",
   "metadata": {},
   "source": [
    "### Cell 8: Orchestrator and artifact generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f775eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_error_line_number(variable_name: str, logical_steps: list[dict]) -> str | None:\n",
    "    \"\"\"Finds the line number corresponding to a given output variable.\"\"\"\n",
    "    for step in logical_steps:\n",
    "        if step.get(\"output_variable\") == variable_name:\n",
    "            return step.get(\"line_number\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def generate_training_artifacts(\n",
    "    logical_steps: list[dict],\n",
    "    error_details: dict[str, Any],\n",
    "    flawed_trace: dict[str, Any]\n",
    ") -> tuple[str, dict] | None:\n",
    "    \"\"\"Generates the final training data: a flawed NL solution and a JSON label.\"\"\"\n",
    "    flawed_solution_map = reconstruct_solution_lines_enhanced(logical_steps, flawed_trace)\n",
    "    if not flawed_solution_map:\n",
    "        return None\n",
    "    \n",
    "    sorted_lines = sorted(flawed_solution_map.items(), key=lambda item: int(item[0][1:]))\n",
    "    flawed_nl_solution = \"\\n\".join([line for _, line in sorted_lines])\n",
    "\n",
    "    erroneous_line = find_error_line_number(error_details[\"variable\"], logical_steps)\n",
    "    if not erroneous_line:\n",
    "        return None\n",
    "\n",
    "    base_explanation = (\n",
    "        f\"The result of this computation should be {error_details['correct_value']}, \"\n",
    "        f\"not {error_details['flawed_value']}.\"\n",
    "    )\n",
    "    type_explanation = error_details[\"explanation_type\"]\n",
    "    final_explanation = f\"{base_explanation} {type_explanation}\"\n",
    "\n",
    "    target_json = {\n",
    "        \"verdict\": \"Flawed\",\n",
    "        \"error_details\": {\n",
    "            \"error_type\": \"computational_error\",\n",
    "            \"erroneous_line_number\": erroneous_line,\n",
    "            \"explanation\": final_explanation,\n",
    "        }\n",
    "    }\n",
    "    return flawed_nl_solution, target_json\n",
    "\n",
    "\n",
    "# def generate_all_valid_errors(\n",
    "#     func: Callable,\n",
    "#     logical_steps: list[dict],\n",
    "#     correct_trace: dict[str, Any]\n",
    "# ) -> list[dict]:\n",
    "#     \"\"\"\n",
    "#     Deterministically generates and validates all possible computational errors for a problem.\n",
    "\n",
    "#     This function iterates through every target variable and every applicable error type,\n",
    "#     producing a comprehensive list of valid flawed examples without retries.\n",
    "\n",
    "#     Returns:\n",
    "#         A list of dictionaries, where each dictionary represents a single valid\n",
    "#         flawed example and has the structure:\n",
    "#         {\n",
    "#             \"variable\": str,\n",
    "#             \"error_type\": str,\n",
    "#             \"flawed_nl_solution\": str,\n",
    "#             \"target_json\": dict\n",
    "#         }\n",
    "#     \"\"\"\n",
    "#     all_generated_examples = []\n",
    "#     target_variables = get_target_variables(logical_steps)\n",
    "\n",
    "#     for variable_name in target_variables:\n",
    "#         correct_value = correct_trace.get(variable_name)\n",
    "        \n",
    "#         # Use a consistent seed for each variable to ensure deterministic error generation\n",
    "#         seed = hash(f\"{variable_name}\")\n",
    "        \n",
    "#         applicable_generators = get_applicable_generators(func, correct_trace, variable_name)\n",
    "\n",
    "#         for generator_func in applicable_generators:\n",
    "#             # Seed based on variable and generator for reproducibility\n",
    "#             random.seed(seed + hash(generator_func.__name__))\n",
    "\n",
    "#             error_result = generator_func()\n",
    "#             if not error_result:\n",
    "#                 continue\n",
    "\n",
    "#             error_details = {\"variable\": variable_name, \"correct_value\": correct_value, **error_result}\n",
    "            \n",
    "#             # Ensure integer-like floats remain floats after error injection\n",
    "#             if isinstance(correct_value, float) and correct_value.is_integer():\n",
    "#                 error_details['flawed_value'] = float(error_details['flawed_value'])\n",
    "\n",
    "#             flawed_trace = generate_flawed_trace(func, error_details)\n",
    "#             if not flawed_trace or not is_trace_valid(flawed_trace, correct_trace):\n",
    "#                 continue\n",
    "            \n",
    "#             artifacts = generate_training_artifacts(logical_steps, error_details, flawed_trace)\n",
    "#             if artifacts:\n",
    "#                 flawed_nl_solution, target_json = artifacts\n",
    "#                 all_generated_examples.append({\n",
    "#                     \"variable\": variable_name,\n",
    "#                     \"error_type\": generator_func.__name__,\n",
    "#                     \"flawed_nl_solution\": flawed_nl_solution,\n",
    "#                     \"target_json\": target_json\n",
    "#                 })\n",
    "\n",
    "#     return all_generated_examples\n",
    "\n",
    "# In Cell 8\n",
    "\n",
    "def generate_all_valid_errors(\n",
    "    func: Callable,\n",
    "    logical_steps: list[dict],\n",
    "    correct_trace: dict[str, Any]\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Deterministically generates and validates all possible computational errors.\n",
    "    --- MODIFIED ---\n",
    "    Now includes correct/flawed values and the specific seed in its output\n",
    "    for enhanced metadata logging.\n",
    "    \"\"\"\n",
    "    all_generated_examples = []\n",
    "    target_variables = get_target_variables(logical_steps)\n",
    "\n",
    "    for variable_name in target_variables:\n",
    "        correct_value = correct_trace.get(variable_name)\n",
    "        base_seed = hash(f\"{variable_name}\")\n",
    "        \n",
    "        applicable_generators = get_applicable_generators(func, correct_trace, variable_name)\n",
    "\n",
    "        for generator_func in applicable_generators:\n",
    "            # --- MODIFIED: Create a reproducible seed specific to this generator ---\n",
    "            repro_seed = base_seed + hash(generator_func.__name__)\n",
    "            random.seed(repro_seed)\n",
    "\n",
    "            error_result = generator_func()\n",
    "            if not error_result:\n",
    "                continue\n",
    "\n",
    "            error_details = {\"variable\": variable_name, \"correct_value\": correct_value, **error_result}\n",
    "            \n",
    "            if isinstance(correct_value, float) and correct_value.is_integer():\n",
    "                error_details['flawed_value'] = float(error_details['flawed_value'])\n",
    "\n",
    "            flawed_trace = generate_flawed_trace(func, error_details)\n",
    "            if not flawed_trace or not is_trace_valid(flawed_trace, correct_trace):\n",
    "                continue\n",
    "            \n",
    "            artifacts = generate_training_artifacts(logical_steps, error_details, flawed_trace)\n",
    "            if artifacts:\n",
    "                flawed_nl_solution, target_json = artifacts\n",
    "                \n",
    "                # --- MODIFIED: Append a richer dictionary ---\n",
    "                all_generated_examples.append({\n",
    "                    \"variable\": variable_name,\n",
    "                    \"error_type\": generator_func.__name__,\n",
    "                    \"flawed_nl_solution\": flawed_nl_solution,\n",
    "                    \"target_json\": target_json,\n",
    "                    \"correct_value\": error_details['correct_value'],\n",
    "                    \"flawed_value\": error_details['flawed_value'],\n",
    "                    \"repro_seed\": repro_seed  # <-- Add the seed\n",
    "                })\n",
    "\n",
    "    return all_generated_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1cbc07",
   "metadata": {},
   "source": [
    "### Cell 9: Serialization Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae8c076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_error_artifacts(\n",
    "#     tier: str,\n",
    "#     index: int,\n",
    "#     model_name: str,\n",
    "#     valid_errors: list[dict],\n",
    "#     base_output_dir: Path = GENERATED_ERRORS_DIR\n",
    "# ) -> list[dict]:\n",
    "#     \"\"\"\n",
    "#     Saves all valid error artifacts to disk in a structured format and\n",
    "#     returns a list of metadata records for the catalog, now including a timestamp.\n",
    "#     \"\"\"\n",
    "#     output_dir = base_output_dir / tier / str(index)\n",
    "#     output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "#     metadata_records = []\n",
    "\n",
    "#     for error_example in valid_errors:\n",
    "#         variable = error_example['variable']\n",
    "#         error_type = error_example['error_type']\n",
    "        \n",
    "#         filename = f\"{model_name}_{variable}_{error_type}.json\"\n",
    "#         filepath = output_dir / filename\n",
    "        \n",
    "#         artifact_content = {\n",
    "#             \"flawed_nl_solution\": error_example[\"flawed_nl_solution\"],\n",
    "#             \"target_json\": error_example[\"target_json\"]\n",
    "#         }\n",
    "        \n",
    "#         with open(filepath, 'w', encoding='utf-8') as f:\n",
    "#             json.dump(artifact_content, f, indent=2)\n",
    "\n",
    "#         # Create a record for the metadata catalog\n",
    "#         record = {\n",
    "#             \"index\": index,\n",
    "#             \"tier\": tier,\n",
    "#             \"model\": model_name,\n",
    "#             \"target_variable\": variable,\n",
    "#             \"error_type\": error_type,\n",
    "#             \"filepath\": str(filepath.relative_to(PROJECT_ROOT)),\n",
    "#             # --- ADDED: Generate a timezone-aware ISO format timestamp ---\n",
    "#             \"utc_timestamp\": datetime.datetime.now(datetime.timezone.utc).isoformat(timespec='seconds')\n",
    "#         }\n",
    "#         metadata_records.append(record)\n",
    "        \n",
    "#     return metadata_records\n",
    "\n",
    "\n",
    "# In Cell 9\n",
    "\n",
    "def save_error_artifacts(\n",
    "    tier: str,\n",
    "    index: int,\n",
    "    model_name: str,\n",
    "    valid_errors: list[dict],\n",
    "    base_output_dir: Path = GENERATED_ERRORS_DIR\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Saves all valid error artifacts to disk and returns metadata records.\n",
    "    --- MODIFIED ---\n",
    "    - Extracts correct/flawed values and the seed.\n",
    "    - Formats the timestamp into separate date and time columns.\n",
    "    \"\"\"\n",
    "    output_dir = base_output_dir / tier / str(index)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    metadata_records = []\n",
    "    now_utc = datetime.datetime.now(datetime.timezone.utc)\n",
    "\n",
    "    for error_example in valid_errors:\n",
    "        variable = error_example['variable']\n",
    "        error_type = error_example['error_type']\n",
    "        \n",
    "        filename = f\"{model_name}_{variable}_{error_type}.json\"\n",
    "        filepath = output_dir / filename\n",
    "        \n",
    "        artifact_content = {\n",
    "            \"flawed_nl_solution\": error_example[\"flawed_nl_solution\"],\n",
    "            \"target_json\": error_example[\"target_json\"]\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(artifact_content, f, indent=2)\n",
    "\n",
    "        # --- MODIFIED: Create the enhanced metadata record ---\n",
    "        record = {\n",
    "            \"index\": index,\n",
    "            \"tier\": tier,\n",
    "            \"model\": model_name,\n",
    "            \"target_variable\": variable,\n",
    "            \"error_type\": error_type,\n",
    "            \"correct_value\": normalize_value(error_example['correct_value']),\n",
    "            \"flawed_value\": normalize_value(error_example['flawed_value']),\n",
    "            \"repro_seed\": error_example['repro_seed'],\n",
    "            \"date_utc\": now_utc.strftime('%Y-%m-%d'),\n",
    "            \"time_utc\": now_utc.strftime('%H:%M:%S'),\n",
    "            \"filepath\": str(filepath.relative_to(PROJECT_ROOT))\n",
    "        }\n",
    "        metadata_records.append(record)\n",
    "        \n",
    "    return metadata_records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfefc9e2",
   "metadata": {},
   "source": [
    "### Cell 10: Main function for error injection pipeline execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed158b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def generate_errors_for_all_manifests(\n",
    "#     manifest_dir: Path,\n",
    "#     output_dir: Path,\n",
    "#     models: list[str]\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Main driver function to orchestrate error generation for all processed manifests.\n",
    "#     \"\"\"\n",
    "#     print(\"\\n--- Starting Error Generation for All Processed Manifests ---\")\n",
    "#     all_metadata = []\n",
    "    \n",
    "#     tier_dirs = sorted([d for d in manifest_dir.iterdir() if d.is_dir() and d.name.startswith('tier')])\n",
    "\n",
    "#     for tier_dir in tqdm(tier_dirs, desc=\"Tiers\"):\n",
    "#         index_dirs = sorted([d for d in tier_dir.iterdir() if d.is_dir()], key=lambda p: int(p.name))\n",
    "        \n",
    "#         for index_dir in tqdm(index_dirs, desc=f\"Processing {tier_dir.name}\", leave=False):\n",
    "#             index = int(index_dir.name)\n",
    "            \n",
    "#             for model_name in models:\n",
    "#                 # Load components using the modified loading functions\n",
    "#                 solve_module = load_function_module(tier_dir.name, index, model_name)\n",
    "#                 logical_steps = load_logical_steps(tier_dir.name, index, model_name)\n",
    "\n",
    "#                 if not (solve_module and logical_steps):\n",
    "#                     continue\n",
    "                \n",
    "#                 # Generate correct trace (from Cell 4)\n",
    "#                 solve_function = solve_module.solve\n",
    "#                 correct_trace = execution_trace(solve_function)\n",
    "#                 if not correct_trace:\n",
    "#                     continue\n",
    "                \n",
    "#                 # Generate all valid errors using the orchestrator (from Cell 8)\n",
    "#                 valid_errors = generate_all_valid_errors(solve_function, logical_steps, correct_trace)\n",
    "                \n",
    "#                 # Save artifacts and collect metadata (from Cell 9)\n",
    "#                 if valid_errors:\n",
    "#                     records = save_error_artifacts(\n",
    "#                         tier=tier_dir.name,\n",
    "#                         index=index,\n",
    "#                         model_name=model_name,\n",
    "#                         valid_errors=valid_errors\n",
    "#                     )\n",
    "#                     all_metadata.extend(records)\n",
    "\n",
    "#     # Create and Save the Final Metadata Catalog\n",
    "#     if all_metadata:\n",
    "#         catalog_df = pd.DataFrame(all_metadata)\n",
    "#         catalog_path = output_dir / \"computational_error_catalog.csv\"\n",
    "#         catalog_df.to_csv(catalog_path, index=False)\n",
    "#         print(f\"\\nSuccessfully generated {len(catalog_df)} error examples.\")\n",
    "#         print(f\"Metadata catalog saved to: {catalog_path}\")\n",
    "#     else:\n",
    "#         print(\"\\nNo error examples were generated.\")\n",
    "        \n",
    "#     print(\"\\n--- Error Generation Pipeline Complete ---\")\n",
    "\n",
    "\n",
    "# In Cell 10, replace the main driver function.\n",
    "\n",
    "def generate_errors_for_all_manifests(\n",
    "    manifest_dir: Path,\n",
    "    output_dir: Path,\n",
    "    models: list[str]\n",
    "):\n",
    "    \"\"\"\n",
    "    Main driver function.\n",
    "    --- MODIFIED ---\n",
    "    Now logs a record for every manifest, including those where execution_trace fails,\n",
    "    and adds a 'correct_trace_generated' column to the final catalog.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Error Generation for All Processed Manifests ---\")\n",
    "    all_metadata = []\n",
    "    \n",
    "    tier_dirs = sorted([d for d in manifest_dir.iterdir() if d.is_dir() and d.name.startswith('tier')])\n",
    "\n",
    "    for tier_dir in tqdm(tier_dirs, desc=\"Tiers\"):\n",
    "        index_dirs = sorted([d for d in tier_dir.iterdir() if d.is_dir() and d.name.isdigit()], key=lambda p: int(p.name))\n",
    "        \n",
    "        for index_dir in tqdm(index_dirs, desc=f\"Processing {tier_dir.name}\", leave=False):\n",
    "            index = int(index_dir.name)\n",
    "            \n",
    "            for model_name in models:\n",
    "                solve_module = load_function_module(tier_dir.name, index, model_name)\n",
    "                logical_steps = load_logical_steps(tier_dir.name, index, model_name)\n",
    "\n",
    "                if not (solve_module and logical_steps):\n",
    "                    continue\n",
    "                \n",
    "                # --- MODIFIED LOGIC BLOCK ---\n",
    "                solve_function = solve_module.solve\n",
    "                correct_trace = execution_trace(solve_function)\n",
    "                \n",
    "                # If the trace fails, log a failure record and move on.\n",
    "                if not correct_trace:\n",
    "                    failure_record = {\n",
    "                        \"index\": index, \"tier\": tier_dir.name, \"model\": model_name,\n",
    "                        \"correct_trace_generated\": False,\n",
    "                        # Add null values for other columns for a consistent schema\n",
    "                        \"target_variable\": None, \"error_type\": None,\n",
    "                        \"correct_value\": None, \"flawed_value\": None,\n",
    "                        \"repro_seed\": None, \"date_utc\": None, \"time_utc\": None,\n",
    "                        \"filepath\": None\n",
    "                    }\n",
    "                    all_metadata.append(failure_record)\n",
    "                    continue # Move to the next manifest\n",
    "\n",
    "                # If the trace succeeds, proceed with error generation.\n",
    "                valid_errors = generate_all_valid_errors(solve_function, logical_steps, correct_trace)\n",
    "                \n",
    "                if valid_errors:\n",
    "                    # `save_error_artifacts` returns records for successfully generated errors.\n",
    "                    records = save_error_artifacts(\n",
    "                        tier=tier_dir.name,\n",
    "                        index=index,\n",
    "                        model_name=model_name,\n",
    "                        valid_errors=valid_errors\n",
    "                    )\n",
    "                    # Add the success flag to each of these records.\n",
    "                    for record in records:\n",
    "                        record['correct_trace_generated'] = True\n",
    "                    all_metadata.extend(records)\n",
    "                else:\n",
    "                    # If trace succeeded but no valid errors could be made (e.g., all failed validation)\n",
    "                    # we still log a record to show it was processed.\n",
    "                    no_valid_error_record = {\n",
    "                        \"index\": index, \"tier\": tier_dir.name, \"model\": model_name,\n",
    "                        \"correct_trace_generated\": True,\n",
    "                        \"target_variable\": \"N/A\", \"error_type\": \"NoValidErrorsFound\",\n",
    "                        \"correct_value\": None, \"flawed_value\": None,\n",
    "                        \"repro_seed\": None, \"date_utc\": None, \"time_utc\": None,\n",
    "                        \"filepath\": None\n",
    "                    }\n",
    "                    all_metadata.append(no_valid_error_record)\n",
    "\n",
    "    # --- The rest of the function is unchanged ---\n",
    "    if all_metadata:\n",
    "        catalog_df = pd.DataFrame(all_metadata)\n",
    "        catalog_path = output_dir / \"computational_error_catalog.csv\"\n",
    "        catalog_df.to_csv(catalog_path, index=False)\n",
    "        print(f\"\\nCatalog with {len(catalog_df)} records saved to: {catalog_path}\")\n",
    "    else:\n",
    "        print(\"\\nNo manifests were found to process.\")\n",
    "        \n",
    "    print(\"\\n--- Error Generation Pipeline Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0a02af",
   "metadata": {},
   "source": [
    "### Executing the whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98b8e0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Error Generation for All Processed Manifests ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe6c8857d874b62af5b1e74b31cfdf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tiers:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79a0d37d12646c4899769f843a15881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tier1:   0%|          | 0/1138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4084e4b68e844daca8f687af7a5c1ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tier2:   0%|          | 0/332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bb7019facd415487a7a24042983dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tier3:   0%|          | 0/1262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "both arguments should be Rational instances",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- Execute the Pipeline ---\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mgenerate_errors_for_all_manifests\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanifest_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPROCESSED_MANIFEST_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGENERATED_ERRORS_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODELS\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 110\u001b[39m, in \u001b[36mgenerate_errors_for_all_manifests\u001b[39m\u001b[34m(manifest_dir, output_dir, models)\u001b[39m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m \u001b[38;5;66;03m# Move to the next manifest\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# If the trace succeeds, proceed with error generation.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m valid_errors = \u001b[43mgenerate_all_valid_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolve_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogical_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrect_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m valid_errors:\n\u001b[32m    113\u001b[39m     \u001b[38;5;66;03m# `save_error_artifacts` returns records for successfully generated errors.\u001b[39;00m\n\u001b[32m    114\u001b[39m     records = save_error_artifacts(\n\u001b[32m    115\u001b[39m         tier=tier_dir.name,\n\u001b[32m    116\u001b[39m         index=index,\n\u001b[32m    117\u001b[39m         model_name=model_name,\n\u001b[32m    118\u001b[39m         valid_errors=valid_errors\n\u001b[32m    119\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 133\u001b[39m, in \u001b[36mgenerate_all_valid_errors\u001b[39m\u001b[34m(func, logical_steps, correct_trace)\u001b[39m\n\u001b[32m    130\u001b[39m repro_seed = base_seed + \u001b[38;5;28mhash\u001b[39m(generator_func.\u001b[34m__name__\u001b[39m)\n\u001b[32m    131\u001b[39m random.seed(repro_seed)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m error_result = \u001b[43mgenerator_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error_result:\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 196\u001b[39m, in \u001b[36mgenerate_multiplication_by_reciprocal_error\u001b[39m\u001b[34m(numeric_val, fraction_val)\u001b[39m\n\u001b[32m    191\u001b[39m new_numerator = numeric_val * fraction_val.denominator\n\u001b[32m    192\u001b[39m new_denominator = fraction_val.numerator\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    195\u001b[39m     \u001b[38;5;66;03m# The value is correct, but the representation now preserves the logic.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mflawed_value\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mNonSimplifyingFraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_numerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_denominator\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    197\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mexplanation_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mIt appears the value was multiplied by the reciprocal of the intended fraction.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    198\u001b[39m }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mNonSimplifyingFraction.__new__\u001b[39m\u001b[34m(cls, numerator, denominator)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, numerator=\u001b[32m0\u001b[39m, denominator=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# We must use __new__ because Fraction is immutable\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNonSimplifyingFraction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__new__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenominator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# Store the original denominator for the __str__ method.\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# The built-in .denominator will be simplified.\u001b[39;00m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m denominator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos-dl/lib/python3.12/fractions.py:277\u001b[39m, in \u001b[36mFraction.__new__\u001b[39m\u001b[34m(cls, numerator, denominator)\u001b[39m\n\u001b[32m    272\u001b[39m     numerator, denominator = (\n\u001b[32m    273\u001b[39m         numerator.numerator * denominator.denominator,\n\u001b[32m    274\u001b[39m         denominator.numerator * numerator.denominator\n\u001b[32m    275\u001b[39m         )\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mboth arguments should be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mRational instances\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m denominator == \u001b[32m0\u001b[39m:\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mFraction(\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m, 0)\u001b[39m\u001b[33m'\u001b[39m % numerator)\n",
      "\u001b[31mTypeError\u001b[39m: both arguments should be Rational instances"
     ]
    }
   ],
   "source": [
    "# --- Execute the Pipeline ---\n",
    "generate_errors_for_all_manifests(\n",
    "    manifest_dir=PROCESSED_MANIFEST_DIR,\n",
    "    output_dir=GENERATED_ERRORS_DIR,\n",
    "    models=MODELS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be01e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 manifests that failed the execution_trace step.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "target_variable",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "error_type",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "correct_value",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "flawed_value",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "repro_seed",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date_utc",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "time_utc",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "filepath",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "correct_trace_generated",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "4221fa68-6aa6-4d1d-8731-a957da78d4fd",
       "rows": [
        [
         "307",
         "116",
         "tier1",
         "google_gemini-2.5-flash",
         null,
         null,
         null,
         null,
         "",
         null,
         null,
         null,
         "False"
        ],
        [
         "11822",
         "497",
         "tier3",
         "openai_gpt-4.1",
         null,
         null,
         null,
         null,
         "",
         null,
         null,
         null,
         "False"
        ],
        [
         "15868",
         "2250",
         "tier4",
         "openai_gpt-4.1",
         null,
         null,
         null,
         null,
         "",
         null,
         null,
         null,
         "False"
        ],
        [
         "15869",
         "2250",
         "tier4",
         "google_gemini-2.5-flash",
         null,
         null,
         null,
         null,
         "",
         null,
         null,
         null,
         "False"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tier</th>\n",
       "      <th>model</th>\n",
       "      <th>target_variable</th>\n",
       "      <th>error_type</th>\n",
       "      <th>correct_value</th>\n",
       "      <th>flawed_value</th>\n",
       "      <th>repro_seed</th>\n",
       "      <th>date_utc</th>\n",
       "      <th>time_utc</th>\n",
       "      <th>filepath</th>\n",
       "      <th>correct_trace_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>116</td>\n",
       "      <td>tier1</td>\n",
       "      <td>google_gemini-2.5-flash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>497</td>\n",
       "      <td>tier3</td>\n",
       "      <td>openai_gpt-4.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15868</th>\n",
       "      <td>2250</td>\n",
       "      <td>tier4</td>\n",
       "      <td>openai_gpt-4.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15869</th>\n",
       "      <td>2250</td>\n",
       "      <td>tier4</td>\n",
       "      <td>google_gemini-2.5-flash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index   tier                    model target_variable error_type  \\\n",
       "307      116  tier1  google_gemini-2.5-flash             NaN        NaN   \n",
       "11822    497  tier3           openai_gpt-4.1             NaN        NaN   \n",
       "15868   2250  tier4           openai_gpt-4.1             NaN        NaN   \n",
       "15869   2250  tier4  google_gemini-2.5-flash             NaN        NaN   \n",
       "\n",
       "      correct_value flawed_value repro_seed date_utc time_utc filepath  \\\n",
       "307             NaN          NaN                 NaN      NaN      NaN   \n",
       "11822           NaN          NaN                 NaN      NaN      NaN   \n",
       "15868           NaN          NaN                 NaN      NaN      NaN   \n",
       "15869           NaN          NaN                 NaN      NaN      NaN   \n",
       "\n",
       "       correct_trace_generated  \n",
       "307                      False  \n",
       "11822                    False  \n",
       "15868                    False  \n",
       "15869                    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In a new cell, after the pipeline finishes:\n",
    "df = pd.read_csv(GENERATED_ERRORS_DIR / \"computational_error_catalog.csv\")\n",
    "\n",
    "# Find all manifests where execution_trace failed\n",
    "trace_failures = df[df['correct_trace_generated'] == False]\n",
    "\n",
    "print(f\"Found {len(trace_failures)} manifests that failed the execution_trace step.\")\n",
    "display(trace_failures.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
