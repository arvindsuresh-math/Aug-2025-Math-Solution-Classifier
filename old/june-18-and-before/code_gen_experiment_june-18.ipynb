{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac80d1a",
   "metadata": {},
   "source": [
    "# Project Summary: Fine-Tuning an LLM for Mathematical Problem Classification\n",
    "\n",
    "The core objective of this project is to fine-tune a small, efficient Large Language Model (LLM) to classify mathematical word problems into three distinct categories based on their solvability.\n",
    "\n",
    "The methodology is divided into three main phases:\n",
    "\n",
    "### 1. Rigorous Dataset Generation via Code Formalization\n",
    "\n",
    "The primary challenge is creating a high-quality, verifiably correct dataset. This is addressed by converting each natural language math problem (from a source like GSM8K) into a parameterized Python function.\n",
    "\n",
    "*   A powerful generator LLM is used to translate the problem's text and step-by-step solution into a generalized `solve()` function.\n",
    "*   This function acts as a formal, executable representation of the problem's underlying logic.\n",
    "*   By making the problem's numerical values the function's arguments, the logic becomes testable and easy to manipulate.\n",
    "\n",
    "### 2. Creating a Labeled Dataset with Three Solvability Classes\n",
    "\n",
    "Using the verified Python functions from Phase 1, the final labeled dataset is constructed by programmatically modifying the original problems to fit into one of three classes:\n",
    "\n",
    "*   **Class 1: Has a Unique Solution**\n",
    "    *   This is the original, verified problem where all parameters are defined, leading to a single correct answer.\n",
    "\n",
    "*   **Class 2: Has Multiple Solutions**\n",
    "    *   Generated by taking a Class 1 problem and removing a key piece of numerical information from the problem statement. This makes the problem underspecified, as different values for the now-missing parameter would lead to different valid solutions.\n",
    "\n",
    "*   **Class 0: Has No Solution**\n",
    "    *   Generated by manipulating the parameters of the Python function to yield a logically or physically absurd result (e.g., a negative count of objects) or by introducing a direct contradiction into the problem statement.\n",
    "\n",
    "### 3. Fine-Tuning the Classifier LLM\n",
    "\n",
    "The resulting dataset, with its high-confidence labels, is used to fine-tune a smaller, more efficient LLM. The final model will be trained to take a new math problem as input and output its classification (Class 1, 2, or 0), having learned the underlying patterns of solvability, ambiguity, and contradiction from the generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e3488001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import importlib\n",
    "import inspect\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import openai\n",
    "import google.generativeai as genai\n",
    "import anthropic\n",
    "from openai import OpenAI\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d5a77881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize clients\n",
    "load_dotenv()\n",
    "openai_client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "anthropic_client = anthropic.Client(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "# Load the GSM8K dataset (train split)\n",
    "gsm8k_train = load_dataset(\"gsm8k\", \"main\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "821c5323",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"You are an expert Python programmer specializing in data formalization. Your role is to meticulously convert natural language math problems and their step-by-step solutions into a single, well-structured Python function. You will be presented with examples of the required format followed by a final task to complete.\"\n",
    "\n",
    "PROMPT_GUIDELINES = \"\"\"### Guidelines\n",
    "\n",
    "1.  **Function Naming & Docstring:** The function must be named `solve`. It must begin with a docstring that has exactly two lines:\n",
    "    *   The first line must be: \"Code for Q [Index] from the GSM8K dataset (train).\", using the index from the task header.\n",
    "    *   The second line must be a succinct, one-sentence description of what the function returns (e.g., \"Returns the total cost of wages and taxes.\").\n",
    "\n",
    "2.  **Function Arguments:** The function arguments must be derived from the 'Question' text. \n",
    "    *   Create a distinct argument for every numerical value that is directly stated in the text.\n",
    "    *   **Note:** Some of these arguments may end up not being used in the function body. This is expected. Do not worry about this and leave the unused arguments in the function signature.\n",
    "\n",
    "3.  **Argument Formatting:** Each argument must include a type-hint (e.g., `int`, `float`) and a default value equal to its value in the 'Question'. You must also add a comment (`#`) next to each argument that quotes or describes the phrase in the 'Question' it comes from.\n",
    "\n",
    "4.  **Function Body:** The body of the function should follow the logic of the provided 'Solution'. Each relevant line from the 'Solution' that involves a computation must be included as a comment, immediately followed by the Python code that formalizes that step.\n",
    "\n",
    "5.  **Calculator Annotations:** Pay close attention to the calculator annotations (e.g., `<<25*8=200>>`) in the 'Solution' as they reveal the precise mathematical operations to implement.\n",
    "\n",
    "6.  **Final Answer Comment:** Before the final `return` statement, you must add a comment identifying the variable that holds the final answer (e.g., `# The final answer is the grand total`).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "16c5314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [310, 3822, 2345, 1202, 7371]\n",
    "code_strings = {}\n",
    "\n",
    "for idx in indices:\n",
    "    module = importlib.import_module(f\"code_examples._{idx}\")\n",
    "    code = inspect.getsource(module.solve)\n",
    "    code_strings[idx] = code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1984c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_prompt_query(\n",
    "        index: int, \n",
    "        code_strings: dict = code_strings,\n",
    "        with_code: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Internal helper function to format a single entry.\n",
    "    It creates the text for a problem's Index, Question, Solution, and (if `with_code == True`) the corresponding code.\n",
    "    \"\"\"\n",
    "    sample = gsm8k_train[index] # type: ignore\n",
    "    question = sample[\"question\"]\n",
    "    raw_answer = sample[\"answer\"]\n",
    "    solution = raw_answer.split('####')[0].strip()\n",
    "    out = \\\n",
    "f\"\"\"*Index*: \n",
    "{index}\n",
    "\n",
    "*Question*: \n",
    "{question}\n",
    "\n",
    "*Solution*: \n",
    "{solution}\n",
    "\n",
    "*Code*:\n",
    "\"\"\"\n",
    "    if with_code:\n",
    "        out += f\"\"\"\\n```python\n",
    "{code_strings[index]}\n",
    "```\n",
    "\"\"\"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4b68b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def craft_user_prompt(\n",
    "    index: int,\n",
    "    example_indices: List[int],\n",
    "    code_examples: Dict[int, str]\n",
    "    ):\n",
    "    \"\"\"\n",
    "Generates a complete user prompt for the LLM to generate code. This function assembles the guidelines, few-shot examples, and the final unsolved task into a single string, ready to be sent to an LLM.\n",
    "\n",
    "Args:\n",
    "    index: The index of the target problem to generate code for.\n",
    "    example_indices: A list of indices to use as few-shot examples.\n",
    "    code_examples: A dictionary mapping example indices to their code strings.\n",
    "\n",
    "Returns:\n",
    "    A single string containing the full user prompt.\n",
    "\"\"\"\n",
    "    # This function assumes a variable `PROMPT_GUIDELINES` exists in its scope.\n",
    "\n",
    "    # Generate the formatted strings for the few-shot examples\n",
    "    example_prompts = [\n",
    "        _format_prompt_query(index=idx, \n",
    "                             code_strings=code_examples,\n",
    "                             with_code=True)\n",
    "        for idx in example_indices\n",
    "    ]\n",
    "\n",
    "    # Generate the formatted string for the final task to be completed by the LLM\n",
    "    task_prompt = _format_prompt_query(index=index, code_strings=code_examples)\n",
    "\n",
    "    # Combine all parts into a single prompt string\n",
    "    # We use two newlines to visually separate major sections\n",
    "    full_prompt = \"\\n\".join([\n",
    "        PROMPT_GUIDELINES,\n",
    "        \"\\n--- EXAMPLES ---\\n\",\n",
    "        \"\\n\".join(example_prompts),\n",
    "        \"--- TASK ---\\n\",\n",
    "        task_prompt\n",
    "    ])\n",
    "\n",
    "    return full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e9694838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Guidelines\n",
      "\n",
      "1.  **Function Naming & Docstring:** The function must be named `solve`. It must begin with a docstring that has exactly two lines:\n",
      "    *   The first line must be: \"Code for Q [Index] from the GSM8K dataset (train).\", using the index from the task header.\n",
      "    *   The second line must be a succinct, one-sentence description of what the function returns (e.g., \"Returns the total cost of wages and taxes.\").\n",
      "\n",
      "2.  **Function Arguments:** The function arguments must be derived from the 'Question' text. \n",
      "    *   Create a distinct argument for every numerical value that is directly stated in the text.\n",
      "    *   **Note:** Some of these arguments may end up not being used in the function body. This is expected. Do not worry about this and leave the unused arguments in the function signature.\n",
      "\n",
      "3.  **Argument Formatting:** Each argument must include a type-hint (e.g., `int`, `float`) and a default value equal to its value in the 'Question'. You must also add a comment (`#`) next to each argument that quotes or describes the phrase in the 'Question' it comes from.\n",
      "\n",
      "4.  **Function Body:** The body of the function should follow the logic of the provided 'Solution'. Each relevant line from the 'Solution' that involves a computation must be included as a comment, immediately followed by the Python code that formalizes that step.\n",
      "\n",
      "5.  **Calculator Annotations:** Pay close attention to the calculator annotations (e.g., `<<25*8=200>>`) in the 'Solution' as they reveal the precise mathematical operations to implement.\n",
      "\n",
      "6.  **Final Answer Comment:** Before the final `return` statement, you must add a comment identifying the variable that holds the final answer (e.g., `# The final answer is the grand total`).\n",
      "\n",
      "--- EXAMPLES ---\n",
      "\n",
      "*Index*: \n",
      "310\n",
      "\n",
      "*Question*: \n",
      "Janet hires six employees. Four of them are warehouse workers who make $15/hour, and the other two are managers who make $20/hour. Janet has to pay 10% of her workers' salaries in FICA taxes. If everyone works 25 days a month and 8 hours a day, how much does Janet owe total for their wages and taxes for one month?\n",
      "\n",
      "*Solution*: \n",
      "First figure out how many hours each worker works per month by multiplying the number of days they work by the number of hours a day they work: 25 days * 8 hours/day = <<25*8=200>>200 hours\n",
      "Then calculate how much one warehouse worker makes per month by multiplying their hourly rate by the number of hours they work: 200 hours * $15/hour = $<<200*15=3000>>3000\n",
      "Then multiply that number by 4 to find out how much all the warehouse workers make: $3000/worker * 4 workers = $<<3000*4=12000>>12,000\n",
      "Now multiply the hours each manager works (also 200) by their hourly wage to find out how much one manager makes per month: 200 hours * $20/hour = $<<200*20=4000>>4,000\n",
      "Now multiply one manager's wages by the number of managers (2) to find their total wage amount: $4,000/manager * 2 managers = $<<4000*2=8000>>8,000\n",
      "Now add the wages for the managers and the workers to find the total cost of the wages: $8,000 + $12,000 = $<<8000+12000=20000>>20,000\n",
      "Now multiply the total wage bill by 10% to find how much the FICA taxes are: $20,000 * .1 = $<<20000*.1=2000>>2,000\n",
      "Now add the total wage bill to the total tax amount to find the grand total: $2,000 + $20,000 = $<<2000+20000=22000>>22,000\n",
      "\n",
      "*Code*:\n",
      "\n",
      "```python\n",
      "def solve(\n",
      "        num_employees: int = 6, # Janet hires six employees\n",
      "        num_warehouse_workers: int = 4, # four of them are warehouse workers\n",
      "        num_managers: int = 2, # the other two are managers\n",
      "        hourly_wage_warehouse: int = 15, # warehouse workers make $15/hour\n",
      "        hourly_wage_manager: int = 20, # managers make $20/hour\n",
      "        fica_tax_rate: float = 0.1, # FICA tax rate is 10%\n",
      "        days_per_month: int = 25, # each worker works 25 days a month\n",
      "        hours_per_day: int = 8 # each worker works 8 hours a day\n",
      "    ):\n",
      "    \"\"\"Code for Q 310 from the GSM8K dataset (train).\n",
      "    Returns the monthly total wage bill, including FICA taxes.\n",
      "    \"\"\"\n",
      "    # First figure out how many hours each worker works per month by multiplying the number of days they work by the number of hours a day they work: 25 days * 8 hours/day = <<25*8=200>>200 hours\n",
      "    hours_per_month = days_per_month * hours_per_day\n",
      "\n",
      "    # Then calculate how much one warehouse worker makes per month by multiplying their hourly rate by the number of hours they work: 200 hours * $15/hour = $<<200*15=3000>>3000\n",
      "    monthly_wage_warehouse = hourly_wage_warehouse * hours_per_month\n",
      "\n",
      "    # Then multiply that number by 4 to find out how much all the warehouse workers make: $3000/worker * 4 workers = $<<3000*4=12000>>12,000\n",
      "    total_wage_warehouse = monthly_wage_warehouse * num_warehouse_workers\n",
      "\n",
      "    # Now multiply the hours each manager works (also 200) by their hourly wage to find out how much one manager makes per month: 200 hours * $20/hour = $<<200*20=4000>>4,000\n",
      "    monthly_wage_manager = hourly_wage_manager * hours_per_month\n",
      "\n",
      "    # Now multiply one manager's wages by the number of managers (2) to find their total wage amount: $4,000/manager * 2 managers = $<<4000*2=8000>>8,000\n",
      "    total_wage_manager = monthly_wage_manager * num_managers\n",
      "\n",
      "    # Now add the wages for the managers and the workers to find the total cost of the wages: $8,000 + $12,000 = $<<8000+12000=20000>>20,000\n",
      "    total_wages = total_wage_warehouse + total_wage_manager\n",
      "\n",
      "    # Now multiply the total wage bill by 10% to find how much the FICA taxes are: $20,000 * .1 = $<<20000*.1=2000>>2,000\n",
      "    fica_taxes = total_wages * fica_tax_rate\n",
      "\n",
      "    # Now add the total wage bill to the total tax amount to find the grand total: $20,000 + $2,000 = $<<20000+2000=22000>>22,000\n",
      "    grand_total = total_wages + fica_taxes\n",
      "\n",
      "    # The final answer is the grand total\n",
      "    return grand_total\n",
      "\n",
      "```\n",
      "\n",
      "*Index*: \n",
      "3822\n",
      "\n",
      "*Question*: \n",
      "Alec is running for Class President. He thinks that if he can get three-quarters of the class to vote for him then there is no chance anyone else can beat him. Half of the class have already said they will vote for him but out of the remaining students, only 5 have said they are thinking about voting for him. He surveys the students who are thinking about voting for someone else, and changes his flyers to reflect the issues these students are concerned about. This results in a fifth of these students saying they'll vote for him. If Alec's class has 60 students and everyone who said they will vote for him does so, how many more votes does Alec need to reach his goal number of votes?\n",
      "\n",
      "*Solution*: \n",
      "To calculate Alec's goal number of votes, we need to know that 60 students / 4 = <<60/4=15>>15 students is equal to one-quarter of the class students.\n",
      "Alec's goal is therefore 15 students * 3 quarters = <<15*3=45>>45 votes.\n",
      "Half of the class said they will vote for him, so there are already 60 students / 2 = <<60/2=30>>30 votes.\n",
      "Another 5 students are thinking about voting for him which leaves a total so far of 30 + 5 = <<30+5=35>>35 votes.\n",
      "This means there are 60 students - 35 voting for Alec = <<60-35=25>>25 students not voting for Alec.\n",
      "A fifth of these decided to vote, so this is a further 25 students / 5 = <<25/5=5>>5 votes.\n",
      "Alec is therefore receiving a total of 35 + 5 = <<35+5=40>>40 votes.\n",
      "So he has missed his goal by 45 goal votes - 40 actual votes = <<45-40=5>>5 votes.\n",
      "\n",
      "*Code*:\n",
      "\n",
      "```python\n",
      "def solve(\n",
      "        fraction_needed_to_win: float = 3/4,  # Alec needs three-quarters of the class to vote for him\n",
      "        fraction_voting_for_him: float = 1/2,  # Half of the class has already said they will vote for him\n",
      "        students_thinking_about_it: int = 5,  # Number of students thinking about voting for him\n",
      "        total_students: int = 60  # Total number of students in Alec's class\n",
      "):    \n",
      "    \"\"\"Code for Q 3822 from the GSM8K dataset (train).\n",
      "    Returns the number of votes by which Alec is short of his goal.\n",
      "    \"\"\"\n",
      "    # To calculate Alec's goal number of votes, we need to know that 60 students / 4 = <<60/4=15>>15 students is equal to one-quarter of the class students.\n",
      "    students_per_quarter = total_students / 4\n",
      "\n",
      "    # Alec's goal is therefore 15 students * 3 quarters = <<15*3=45>>45 votes.\n",
      "    votes_needed = students_per_quarter * 3\n",
      "\n",
      "    # Half of the class said they will vote for him, so there are already 60 students / 2 = <<60/2=30>>30 votes.\n",
      "    votes_for_him = total_students * fraction_voting_for_him\n",
      "\n",
      "    # Another 5 students are thinking about voting for him which leaves a total so far of 30 + 5 = <<30+5=35>>35 votes.\n",
      "    votes_so_far = votes_for_him + students_thinking_about_it\n",
      "\n",
      "    # This means there are 60 students - 35 voting for Alec = <<60-35=25>>25 students not voting for Alec.\n",
      "    students_not_voting_for_him = total_students - votes_so_far\n",
      "    \n",
      "    # A fifth of these say they will vote for him, so this is a further 25 students / 5 = <<25/5=5>>5 votes.\n",
      "    new_votes = students_not_voting_for_him / 5\n",
      "\n",
      "    # Alec is therefore receiving a total of 35 + 5 = <<35+5=40>>40 votes.\n",
      "    total_votes_for_him = votes_so_far + new_votes\n",
      "\n",
      "    # So he has missed his goal by 45 goal votes - 40 actual votes = <<45-40=5>>5 votes.\n",
      "    votes_short_of_goal = votes_needed - total_votes_for_him\n",
      "\n",
      "    # The final answer is the number of students Alec is short of his goal\n",
      "    return votes_short_of_goal\n",
      "\n",
      "```\n",
      "\n",
      "*Index*: \n",
      "7371\n",
      "\n",
      "*Question*: \n",
      "Karen's students are about to take a standardized test. Karen gets a $500 bonus if their average score is above 75, plus an extra $10 bonus for every additional point the average score increases above 75. So far, Karen has graded 8 tests, and the average is 70. Given that each student can have a maximum score of 150, what combined score do the last two tests need to have for Karen to earn a $600 bonus?\n",
      "\n",
      "*Solution*: \n",
      "First subtract $500 from Karen's goal bonus amount to find how much she makes from the extra $10/point bonus: $600 - $500 = $<<600-500=100>>100\n",
      "Then divide the extra bonus by the extra rate: $100 / $10/point = <<100/10=10>>10 points\n",
      "Then add the 10 extra points to the baseline 75 point goal to find the students' average test score: 10 points + 75 points = <<10+75=85>>85 points\n",
      "Then added the 8 graded tests to the 2 ungraded tests to find the total number of tests: 2 tests + 8 tests = <<2+8=10>>10 tests\n",
      "Then multiply the 85 point average by the number of tests to find the total number of points the students need to earn: 85 points/test * 10 tests = 850 points\n",
      "Then multiply the current average by the current number of graded tests to find how many points have been earned so far: 70 points/test * 8 tests = <<70*8=560>>560 points\n",
      "Then subtract the number of points earned from the number of points needed to find the combine score the last two tests need: 850 points - 560 points = <<850-560=290>>290 points\n",
      "\n",
      "*Code*:\n",
      "\n",
      "```python\n",
      "def solve(\n",
      "    baseline_avg_score: int = 75, # Karen wants an average score of 75\n",
      "    bonus_if_avg_above_baseline = 500, # Karen gets a $500 bonus if their average score is above 75\n",
      "    extra_bonus_per_point = 10, # Karen gets an extra $10 for every point above 75\n",
      "    tests_graded_so_far = 8, # So far, Karen has graded 8 tests\n",
      "    avg_so_far = 70, # The average score so far is 70\n",
      "    max_score_per_student = 150, # each student can have a maximum score of 150\n",
      "    desired_bonus = 600 # Karen wants to earn a $600 bonus\n",
      "):\n",
      "    \"\"\"Code for Q 7371 from the GSM8K dataset (train).\n",
      "    Returns the combined score needed in the last two tests to ensure that Karen earns a $600 bonus.\"\"\"\n",
      "    # First subtract $500 from Karen's goal bonus amount to find how much she makes from the extra $10/point bonus: $600 - $500 = $<<600-500=100>>100\n",
      "    extra_bonus_needed = desired_bonus - bonus_if_avg_above_baseline\n",
      "\n",
      "    # Then divide the extra bonus by the extra rate: $100 / $10/point = <<100/10=10>>10 points\n",
      "    extra_points_needed = extra_bonus_needed / extra_bonus_per_point\n",
      "\n",
      "    # Then add the 10 extra points to the baseline 75 point goal to find the students' average test score: 10 points + 75 points = <<10+75=85>>85 points\n",
      "    target_avg_score = baseline_avg_score + extra_points_needed\n",
      "\n",
      "    # Then added the 8 graded tests to the 2 ungraded tests to find the total number of tests: 2 tests + 8 tests = <<2+8=10>>10 tests\n",
      "    total_tests = tests_graded_so_far + 2\n",
      "\n",
      "    # Then multiply the 85 point average by the number of tests to find the total number of points the students need to earn: 85 points/test * 10 tests = 850 points\n",
      "    total_points_needed = target_avg_score * total_tests\n",
      "\n",
      "    # Then multiply the current average by the current number of graded tests to find how many points have been earned so far: 70 points/test * 8 tests = <<70*8=560>>560 points\n",
      "    points_earned_so_far = avg_so_far * tests_graded_so_far\n",
      "\n",
      "    # Then subtract the number of points earned from the number of points needed to find the combine score the last two tests need: 850 points - 560 points = <<850-560=290>>290 points\n",
      "    points_needed_last_two_tests = total_points_needed - points_earned_so_far\n",
      "\n",
      "    # The final answer is the combined score needed in the last two tests\n",
      "    return points_needed_last_two_tests\n",
      "\n",
      "```\n",
      "\n",
      "--- TASK ---\n",
      "\n",
      "*Index*: \n",
      "5\n",
      "\n",
      "*Question*: \n",
      "Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden?\n",
      "\n",
      "*Solution*: \n",
      "There are 80/100 * 10 = <<80/100*10=8>>8 more purple flowers than yellow flowers.\n",
      "So in Mark's garden, there are 10 + 8 = <<10+8=18>>18 purple flowers.\n",
      "Purple and yellow flowers sum up to 10 + 18 = <<10+18=28>>28 flowers.\n",
      "That means in Mark's garden there are 25/100 * 28 = <<25/100*28=7>>7 green flowers.\n",
      "So in total Mark has 28 + 7 = <<28+7=35>>35 plants in his garden.\n",
      "\n",
      "*Code*:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check = craft_user_prompt(\n",
    "    index = 5,\n",
    "    example_indices= [310, 3822, 7371],\n",
    "    code_examples=code_strings\n",
    ")\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a19ec04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = \\\n",
    "{\n",
    "  \"anthropic\": [\n",
    "    \"claude-sonnet-4-20250514\",\n",
    "    \"claude-3-7-sonnet-20250219\",\n",
    "    \"claude-3-5-sonnet-20240620\",\n",
    "    \"claude-3-5-haiku-20241022\",\n",
    "    \"claude-3-haiku-20240307\"\n",
    "  ],\n",
    "  \"openai\": [\n",
    "    \"gpt-4.1\",\n",
    "    \"o3-mini\",\n",
    "    \"o4-mini\",\n",
    "    \"gpt-4.1-mini\"\n",
    "  ],\n",
    "  \"google\": [\n",
    "    \"gemini-2.5-pro-preview-06-05\",\n",
    "    \"gemini-2.5-pro\",\n",
    "    \"gemini-2.5-flash\",\n",
    "    \"gemini-2.5-flash-preview-04-17-thinking\",\n",
    "    \"gemini-2.0-flash-thinking-exp\",\n",
    "    \"gemini-2.5-flash-lite-preview-06-17\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "78569380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model_api(\n",
    "        provider: str, \n",
    "        model: str, \n",
    "        system_prompt: str, \n",
    "        user_prompt: str):\n",
    "    \"\"\"\n",
    "    Calls the appropriate LLM API based on the provider and returns the raw text response.\n",
    "    \n",
    "    This function handles special cases for reasoning models like o3-mini that do not\n",
    "    support the temperature parameter.\n",
    "\n",
    "    Args:\n",
    "        provider: The API provider (\"google\", \"anthropic\", or \"openai\").\n",
    "        model: The specific model name to use.\n",
    "        system_prompt: The system-level instructions for the model.\n",
    "        user_prompt: The user-level prompt containing examples and the task.\n",
    "\n",
    "    Returns:\n",
    "        The model's generated text content as a string, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if provider == \"google\":\n",
    "            gemini = genai.GenerativeModel(\n",
    "                model_name=model,\n",
    "                system_instruction=system_prompt\n",
    "            )\n",
    "            generation_config = genai.types.GenerationConfig(\n",
    "                temperature=0.1,\n",
    "                max_output_tokens=4000\n",
    "            )\n",
    "            response = gemini.generate_content(\n",
    "                user_prompt,\n",
    "                generation_config=generation_config\n",
    "            )\n",
    "            return response.text\n",
    "\n",
    "        elif provider == \"anthropic\":\n",
    "            response = anthropic_client.messages.create(\n",
    "                model=model,\n",
    "                max_tokens=4000,\n",
    "                temperature=0.1,\n",
    "                system=system_prompt,\n",
    "                messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
    "            )\n",
    "            return response.content[0].text\n",
    "\n",
    "        elif provider == \"openai\":\n",
    "            # Prepare the arguments for the API call\n",
    "            kwargs = {\n",
    "                \"model\": model,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            # Conditionally set parameters based on model type\n",
    "            if model not in [\"o3-mini\", \"o4-mini\"]:\n",
    "                kwargs[\"temperature\"] = 0.1\n",
    "                kwargs[\"max_tokens\"] = 4000\n",
    "\n",
    "            response = openai_client.chat.completions.create(**kwargs)\n",
    "            return response.choices[0].message.content\n",
    "        \n",
    "        else:\n",
    "            print(f\"Unknown provider: {provider}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An API error occurred for {provider} model {model}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "75e64094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_GSM8K_code(\n",
    "    model_dict: Dict[str, List[str]],\n",
    "    indices_to_generate: List[int],\n",
    "    example_indices: List[int],\n",
    "    system_prompt: str = SYSTEM_PROMPT\n",
    "):\n",
    "    \"\"\"\n",
    "    Calls multiple LLM APIs, saves the raw output, and logs performance.\n",
    "\n",
    "    Args:\n",
    "        model_dict: Dictionary of providers and their models to test.\n",
    "        indices_to_generate: List of GSM8K problem indices to generate code for.\n",
    "        example_indices: List of indices to use as few-shot examples in the prompt.\n",
    "        system_prompt: The system prompt to send to the models.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Initialize performance logging\n",
    "    performance_data = []\n",
    "    base_output_dir = 'code_generation_outputs'\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "    # Loop over each problem you want to solve\n",
    "    for index in indices_to_generate:\n",
    "        print(f\"\\n{'='*20} Starting Generation for Index: {index} {'='*20}\")\n",
    "\n",
    "        # 2. Create the output directory for the current problem index\n",
    "        problem_dir = os.path.join(base_output_dir, str(index))\n",
    "        os.makedirs(problem_dir, exist_ok=True)\n",
    "        print(f\"Output directory: {problem_dir}\")\n",
    "\n",
    "        # 3. Create the user prompt once for this problem index\n",
    "        print(\"Crafting user prompt...\")\n",
    "        user_prompt = craft_user_prompt(\n",
    "            index=index,\n",
    "            example_indices=example_indices,\n",
    "            code_examples=code_strings\n",
    "        )\n",
    "\n",
    "        # 4. Loop over each provider and model in your dictionary\n",
    "        for provider, models in model_dict.items():\n",
    "            for model_name in models:\n",
    "                print(f\"\\n--- Calling {provider.capitalize()} model: {model_name} ---\")\n",
    "\n",
    "                # 5. Call the API and time the request\n",
    "                start_time = time.time()\n",
    "                raw_response = call_model_api(provider, model_name, system_prompt, user_prompt)\n",
    "                end_time = time.time()\n",
    "                \n",
    "                time_taken = end_time - start_time\n",
    "                print(f\"  Response received in {time_taken:.2f} seconds.\")\n",
    "\n",
    "                # Log the performance data\n",
    "                performance_data.append({\n",
    "                    'provider': provider,\n",
    "                    'model': model_name,\n",
    "                    'index': index,\n",
    "                    'time_taken': time_taken\n",
    "                })\n",
    "\n",
    "                # 6. Save the raw response to a file\n",
    "                if raw_response:\n",
    "                    output_filename = f'{provider}_{model_name}.txt'\n",
    "                    output_path = os.path.join(problem_dir, output_filename)\n",
    "                    try:\n",
    "                        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                            f.write(raw_response)\n",
    "                        print(f\"  Successfully saved raw output to: {output_path}\")\n",
    "                    except IOError as e:\n",
    "                        print(f\"  Error: Failed to write file. Reason: {e}\")\n",
    "                else:\n",
    "                    print(\"  No response received. Skipping file save.\")\n",
    "\n",
    "    print(f\"\\n{'='*20} Generation Complete {'='*20}\")\n",
    "\n",
    "    # 7. Save the performance data to a CSV file at the end\n",
    "    df = pd.DataFrame(performance_data)\n",
    "    csv_path = os.path.join(base_output_dir, 'generation_performance.csv')\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Performance data successfully saved to {csv_path}; displayed below:\")\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e3ec5da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test run for indices [3779, 4483, 6237] across all models...\n",
      "\n",
      "==================== Starting Generation for Index: 3779 ====================\n",
      "Output directory: code_generation_outputs/3779\n",
      "Crafting user prompt...\n",
      "\n",
      "--- Calling Anthropic model: claude-sonnet-4-20250514 ---\n",
      "  Response received in 14.59 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/3779/anthropic_claude-sonnet-4-20250514.txt\n",
      "\n",
      "--- Calling Anthropic model: claude-3-7-sonnet-20250219 ---\n",
      "  Response received in 9.77 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/3779/anthropic_claude-3-7-sonnet-20250219.txt\n",
      "\n",
      "--- Calling Anthropic model: claude-3-5-sonnet-20240620 ---\n",
      "  Response received in 13.57 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/3779/anthropic_claude-3-5-sonnet-20240620.txt\n",
      "\n",
      "--- Calling Anthropic model: claude-3-5-haiku-20241022 ---\n",
      "  Response received in 9.21 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/3779/anthropic_claude-3-5-haiku-20241022.txt\n",
      "\n",
      "--- Calling Anthropic model: claude-3-haiku-20240307 ---\n",
      "  Response received in 7.41 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/3779/anthropic_claude-3-haiku-20240307.txt\n",
      "\n",
      "--- Calling Openai model: gpt-4.1 ---\n",
      "  Response received in 7.14 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/3779/openai_gpt-4.1.txt\n",
      "\n",
      "--- Calling Openai model: o3-mini ---\n",
      "  Response received in 10.64 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/3779/openai_o3-mini.txt\n",
      "\n",
      "--- Calling Openai model: o4-mini ---\n",
      "  Response received in 23.34 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/3779/openai_o4-mini.txt\n",
      "\n",
      "--- Calling Openai model: gpt-4.1-mini ---\n",
      "  Response received in 9.33 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/3779/openai_gpt-4.1-mini.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.5-pro-preview-06-05 ---\n",
      "  Response received in 18.29 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/3779/google_gemini-2.5-pro-preview-06-05.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.5-pro ---\n",
      "An API error occurred for google model gemini-2.5-pro: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "  Response received in 36.02 seconds.\n",
      "  No response received. Skipping file save.\n",
      "\n",
      "--- Calling Google model: gemini-2.5-flash ---\n",
      "  Response received in 7.35 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/3779/google_gemini-2.5-flash.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.5-flash-preview-04-17-thinking ---\n",
      "  Response received in 6.01 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/3779/google_gemini-2.5-flash-preview-04-17-thinking.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.0-flash-thinking-exp ---\n",
      "  Response received in 4.71 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/3779/google_gemini-2.0-flash-thinking-exp.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.5-flash-lite-preview-06-17 ---\n",
      "  Response received in 1.74 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/3779/google_gemini-2.5-flash-lite-preview-06-17.txt\n",
      "\n",
      "==================== Starting Generation for Index: 4483 ====================\n",
      "Output directory: code_generation_outputs/4483\n",
      "Crafting user prompt...\n",
      "\n",
      "--- Calling Anthropic model: claude-sonnet-4-20250514 ---\n",
      "  Response received in 15.87 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/4483/anthropic_claude-sonnet-4-20250514.txt\n",
      "\n",
      "--- Calling Anthropic model: claude-3-7-sonnet-20250219 ---\n",
      "  Response received in 9.46 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/4483/anthropic_claude-3-7-sonnet-20250219.txt\n",
      "\n",
      "--- Calling Anthropic model: claude-3-5-sonnet-20240620 ---\n",
      "  Response received in 9.28 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/4483/anthropic_claude-3-5-sonnet-20240620.txt\n",
      "\n",
      "--- Calling Anthropic model: claude-3-5-haiku-20241022 ---\n",
      "  Response received in 8.29 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/4483/anthropic_claude-3-5-haiku-20241022.txt\n",
      "\n",
      "--- Calling Anthropic model: claude-3-haiku-20240307 ---\n",
      "  Response received in 5.12 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/4483/anthropic_claude-3-haiku-20240307.txt\n",
      "\n",
      "--- Calling Openai model: gpt-4.1 ---\n",
      "  Response received in 6.36 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/4483/openai_gpt-4.1.txt\n",
      "\n",
      "--- Calling Openai model: o3-mini ---\n",
      "  Response received in 10.02 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/4483/openai_o3-mini.txt\n",
      "\n",
      "--- Calling Openai model: o4-mini ---\n",
      "  Response received in 13.52 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/4483/openai_o4-mini.txt\n",
      "\n",
      "--- Calling Openai model: gpt-4.1-mini ---\n",
      "  Response received in 8.19 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/4483/openai_gpt-4.1-mini.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.5-pro-preview-06-05 ---\n",
      "  Response received in 15.97 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/4483/google_gemini-2.5-pro-preview-06-05.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.5-pro ---\n",
      "  Response received in 19.04 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/4483/google_gemini-2.5-pro.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.5-flash ---\n",
      "  Response received in 3.46 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/4483/google_gemini-2.5-flash.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.5-flash-preview-04-17-thinking ---\n",
      "  Response received in 4.50 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/4483/google_gemini-2.5-flash-preview-04-17-thinking.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.0-flash-thinking-exp ---\n",
      "  Response received in 5.76 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/4483/google_gemini-2.0-flash-thinking-exp.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.5-flash-lite-preview-06-17 ---\n",
      "  Response received in 1.84 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/4483/google_gemini-2.5-flash-lite-preview-06-17.txt\n",
      "\n",
      "==================== Starting Generation for Index: 6237 ====================\n",
      "Output directory: code_generation_outputs/6237\n",
      "Crafting user prompt...\n",
      "\n",
      "--- Calling Anthropic model: claude-sonnet-4-20250514 ---\n",
      "  Response received in 14.74 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/6237/anthropic_claude-sonnet-4-20250514.txt\n",
      "\n",
      "--- Calling Anthropic model: claude-3-7-sonnet-20250219 ---\n",
      "  Response received in 9.62 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/6237/anthropic_claude-3-7-sonnet-20250219.txt\n",
      "\n",
      "--- Calling Anthropic model: claude-3-5-sonnet-20240620 ---\n",
      "  Response received in 8.81 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/6237/anthropic_claude-3-5-sonnet-20240620.txt\n",
      "\n",
      "--- Calling Anthropic model: claude-3-5-haiku-20241022 ---\n",
      "  Response received in 9.21 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/6237/anthropic_claude-3-5-haiku-20241022.txt\n",
      "\n",
      "--- Calling Anthropic model: claude-3-haiku-20240307 ---\n",
      "  Response received in 5.61 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/6237/anthropic_claude-3-haiku-20240307.txt\n",
      "\n",
      "--- Calling Openai model: gpt-4.1 ---\n",
      "  Response received in 6.47 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/6237/openai_gpt-4.1.txt\n",
      "\n",
      "--- Calling Openai model: o3-mini ---\n",
      "  Response received in 12.07 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/6237/openai_o3-mini.txt\n",
      "\n",
      "--- Calling Openai model: o4-mini ---\n",
      "  Response received in 58.17 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/6237/openai_o4-mini.txt\n",
      "\n",
      "--- Calling Openai model: gpt-4.1-mini ---\n",
      "  Response received in 9.34 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/6237/openai_gpt-4.1-mini.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.5-pro-preview-06-05 ---\n",
      "  Response received in 17.60 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/6237/google_gemini-2.5-pro-preview-06-05.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.5-pro ---\n",
      "  Response received in 16.89 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/6237/google_gemini-2.5-pro.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.5-flash ---\n",
      "  Response received in 8.66 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/6237/google_gemini-2.5-flash.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.5-flash-preview-04-17-thinking ---\n",
      "  Response received in 6.92 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/6237/google_gemini-2.5-flash-preview-04-17-thinking.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.0-flash-thinking-exp ---\n",
      "  Response received in 8.55 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/6237/google_gemini-2.0-flash-thinking-exp.txt\n",
      "\n",
      "--- Calling Google model: gemini-2.5-flash-lite-preview-06-17 ---\n",
      "  Response received in 2.29 seconds.\n",
      "  Successfully saved raw output to: code_generation_outputs/6237/google_gemini-2.5-flash-lite-preview-06-17.txt\n",
      "\n",
      "==================== Generation Complete ====================\n",
      "Performance data successfully saved to code_generation_outputs/generation_performance.csv; displayed below:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provider</th>\n",
       "      <th>model</th>\n",
       "      <th>index</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-sonnet-4-20250514</td>\n",
       "      <td>3779</td>\n",
       "      <td>14.588613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>3779</td>\n",
       "      <td>9.771739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>3779</td>\n",
       "      <td>13.573699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-5-haiku-20241022</td>\n",
       "      <td>3779</td>\n",
       "      <td>9.208251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>3779</td>\n",
       "      <td>7.411340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>openai</td>\n",
       "      <td>gpt-4.1</td>\n",
       "      <td>3779</td>\n",
       "      <td>7.136371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>openai</td>\n",
       "      <td>o3-mini</td>\n",
       "      <td>3779</td>\n",
       "      <td>10.644770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>openai</td>\n",
       "      <td>o4-mini</td>\n",
       "      <td>3779</td>\n",
       "      <td>23.341708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>openai</td>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>3779</td>\n",
       "      <td>9.332341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.5-pro-preview-06-05</td>\n",
       "      <td>3779</td>\n",
       "      <td>18.293231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.5-pro</td>\n",
       "      <td>3779</td>\n",
       "      <td>36.015916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>3779</td>\n",
       "      <td>7.349540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.5-flash-preview-04-17-thinking</td>\n",
       "      <td>3779</td>\n",
       "      <td>6.012402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.0-flash-thinking-exp</td>\n",
       "      <td>3779</td>\n",
       "      <td>4.708428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.5-flash-lite-preview-06-17</td>\n",
       "      <td>3779</td>\n",
       "      <td>1.739979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-sonnet-4-20250514</td>\n",
       "      <td>4483</td>\n",
       "      <td>15.872541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>4483</td>\n",
       "      <td>9.464058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>4483</td>\n",
       "      <td>9.276653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-5-haiku-20241022</td>\n",
       "      <td>4483</td>\n",
       "      <td>8.286101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>4483</td>\n",
       "      <td>5.117208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>openai</td>\n",
       "      <td>gpt-4.1</td>\n",
       "      <td>4483</td>\n",
       "      <td>6.357189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>openai</td>\n",
       "      <td>o3-mini</td>\n",
       "      <td>4483</td>\n",
       "      <td>10.023685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>openai</td>\n",
       "      <td>o4-mini</td>\n",
       "      <td>4483</td>\n",
       "      <td>13.517191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>openai</td>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>4483</td>\n",
       "      <td>8.189097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.5-pro-preview-06-05</td>\n",
       "      <td>4483</td>\n",
       "      <td>15.965249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.5-pro</td>\n",
       "      <td>4483</td>\n",
       "      <td>19.042066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>4483</td>\n",
       "      <td>3.457495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.5-flash-preview-04-17-thinking</td>\n",
       "      <td>4483</td>\n",
       "      <td>4.497331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.0-flash-thinking-exp</td>\n",
       "      <td>4483</td>\n",
       "      <td>5.763515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.5-flash-lite-preview-06-17</td>\n",
       "      <td>4483</td>\n",
       "      <td>1.842858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-sonnet-4-20250514</td>\n",
       "      <td>6237</td>\n",
       "      <td>14.744323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>6237</td>\n",
       "      <td>9.624284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>6237</td>\n",
       "      <td>8.812229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-5-haiku-20241022</td>\n",
       "      <td>6237</td>\n",
       "      <td>9.206881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>6237</td>\n",
       "      <td>5.607631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>openai</td>\n",
       "      <td>gpt-4.1</td>\n",
       "      <td>6237</td>\n",
       "      <td>6.473034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>openai</td>\n",
       "      <td>o3-mini</td>\n",
       "      <td>6237</td>\n",
       "      <td>12.071107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>openai</td>\n",
       "      <td>o4-mini</td>\n",
       "      <td>6237</td>\n",
       "      <td>58.174930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>openai</td>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>6237</td>\n",
       "      <td>9.343878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.5-pro-preview-06-05</td>\n",
       "      <td>6237</td>\n",
       "      <td>17.596895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.5-pro</td>\n",
       "      <td>6237</td>\n",
       "      <td>16.888259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>6237</td>\n",
       "      <td>8.655537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.5-flash-preview-04-17-thinking</td>\n",
       "      <td>6237</td>\n",
       "      <td>6.916175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.0-flash-thinking-exp</td>\n",
       "      <td>6237</td>\n",
       "      <td>8.547362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>google</td>\n",
       "      <td>gemini-2.5-flash-lite-preview-06-17</td>\n",
       "      <td>6237</td>\n",
       "      <td>2.290247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     provider                                    model  index  time_taken\n",
       "0   anthropic                 claude-sonnet-4-20250514   3779   14.588613\n",
       "1   anthropic               claude-3-7-sonnet-20250219   3779    9.771739\n",
       "2   anthropic               claude-3-5-sonnet-20240620   3779   13.573699\n",
       "3   anthropic                claude-3-5-haiku-20241022   3779    9.208251\n",
       "4   anthropic                  claude-3-haiku-20240307   3779    7.411340\n",
       "5      openai                                  gpt-4.1   3779    7.136371\n",
       "6      openai                                  o3-mini   3779   10.644770\n",
       "7      openai                                  o4-mini   3779   23.341708\n",
       "8      openai                             gpt-4.1-mini   3779    9.332341\n",
       "9      google             gemini-2.5-pro-preview-06-05   3779   18.293231\n",
       "10     google                           gemini-2.5-pro   3779   36.015916\n",
       "11     google                         gemini-2.5-flash   3779    7.349540\n",
       "12     google  gemini-2.5-flash-preview-04-17-thinking   3779    6.012402\n",
       "13     google            gemini-2.0-flash-thinking-exp   3779    4.708428\n",
       "14     google      gemini-2.5-flash-lite-preview-06-17   3779    1.739979\n",
       "15  anthropic                 claude-sonnet-4-20250514   4483   15.872541\n",
       "16  anthropic               claude-3-7-sonnet-20250219   4483    9.464058\n",
       "17  anthropic               claude-3-5-sonnet-20240620   4483    9.276653\n",
       "18  anthropic                claude-3-5-haiku-20241022   4483    8.286101\n",
       "19  anthropic                  claude-3-haiku-20240307   4483    5.117208\n",
       "20     openai                                  gpt-4.1   4483    6.357189\n",
       "21     openai                                  o3-mini   4483   10.023685\n",
       "22     openai                                  o4-mini   4483   13.517191\n",
       "23     openai                             gpt-4.1-mini   4483    8.189097\n",
       "24     google             gemini-2.5-pro-preview-06-05   4483   15.965249\n",
       "25     google                           gemini-2.5-pro   4483   19.042066\n",
       "26     google                         gemini-2.5-flash   4483    3.457495\n",
       "27     google  gemini-2.5-flash-preview-04-17-thinking   4483    4.497331\n",
       "28     google            gemini-2.0-flash-thinking-exp   4483    5.763515\n",
       "29     google      gemini-2.5-flash-lite-preview-06-17   4483    1.842858\n",
       "30  anthropic                 claude-sonnet-4-20250514   6237   14.744323\n",
       "31  anthropic               claude-3-7-sonnet-20250219   6237    9.624284\n",
       "32  anthropic               claude-3-5-sonnet-20240620   6237    8.812229\n",
       "33  anthropic                claude-3-5-haiku-20241022   6237    9.206881\n",
       "34  anthropic                  claude-3-haiku-20240307   6237    5.607631\n",
       "35     openai                                  gpt-4.1   6237    6.473034\n",
       "36     openai                                  o3-mini   6237   12.071107\n",
       "37     openai                                  o4-mini   6237   58.174930\n",
       "38     openai                             gpt-4.1-mini   6237    9.343878\n",
       "39     google             gemini-2.5-pro-preview-06-05   6237   17.596895\n",
       "40     google                           gemini-2.5-pro   6237   16.888259\n",
       "41     google                         gemini-2.5-flash   6237    8.655537\n",
       "42     google  gemini-2.5-flash-preview-04-17-thinking   6237    6.916175\n",
       "43     google            gemini-2.0-flash-thinking-exp   6237    8.547362\n",
       "44     google      gemini-2.5-flash-lite-preview-06-17   6237    2.290247"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A few problem indices to generate code for in this test run\n",
    "problems_to_solve = [3779, 4483, 6237]\n",
    "\n",
    "# The hand-made examples to include in the prompt\n",
    "examples_for_prompt = [310, 3822, 7371]\n",
    "\n",
    "# --- Run the main generation function ---\n",
    "print(f\"Starting test run for indices {problems_to_solve} across all models...\")\n",
    "generate_GSM8K_code(\n",
    "    model_dict=model_dict,\n",
    "    indices_to_generate=problems_to_solve,\n",
    "    example_indices=examples_for_prompt\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
