{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c68369f",
   "metadata": {},
   "source": [
    "# Conceptual Error Candidate Generation\n",
    "\n",
    "This notebook contains the end-to-end pipeline for generating conceptual error \"candidates\" from validated `Formalization Templates`. The process involves programmatically applying logical mutations to the Abstract Syntax Tree (AST) of the correct `function_code`, executing the mutated code to generate a flawed numerical trace, and then packaging all relevant information for a human-in-the-loop validation and annotation stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e26a2ad",
   "metadata": {},
   "source": [
    "#### **Cell 1: Imports and Setup**\n",
    "*   **Functionality:** Standard project setup.\n",
    "*   **Logic:**\n",
    "    *   Imports necessary libraries (`json`, `ast`, `pathlib`, etc.).\n",
    "    *   Defines a robust `find_project_root` function to make path definitions portable.\n",
    "    *   Sets up key `Path` objects for input (`PROCESSED_TEMPLATE_DIR`) and output (`CONCEPTUAL_CANDIDATES_DIR`).\n",
    "    *   Ensures the output directory exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7dbe5cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math\n",
      "Input (Processed Templates): /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/template-generated-processed\n",
      "Output (Conceptual Candidates): /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates\n"
     ]
    }
   ],
   "source": [
    "# --- Imports and Path Definitions ---\n",
    "\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "import inspect\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "from types import ModuleType\n",
    "from typing import Callable, Any, Dict, List\n",
    "from fractions import Fraction as BuiltinFraction\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "def find_project_root(marker: str = \".git\") -> Path:\n",
    "    \"\"\"Traverse upwards to find the project root, marked by the git repository.\"\"\"\n",
    "    current_path = Path.cwd().resolve()\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / marker).exists():\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    raise FileNotFoundError(f\"Could not find project root. Marker '{marker}' not found.\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "\n",
    "# --- Directory Paths ---\n",
    "PROCESSED_TEMPLATE_DIR = DATA_DIR / \"template-generated-processed\"\n",
    "CONCEPTUAL_CANDIDATES_DIR = DATA_DIR / \"conceptual-error-candidates\"\n",
    "\n",
    "# --- Models ---\n",
    "MODELS = ['openai_gpt-4.1', 'google_gemini-2.5-flash']\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Input (Processed Templates): {PROCESSED_TEMPLATE_DIR}\")\n",
    "print(f\"Output (Conceptual Candidates): {CONCEPTUAL_CANDIDATES_DIR}\")\n",
    "\n",
    "# --- Ensure Directories Exist ---\n",
    "PROCESSED_TEMPLATE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CONCEPTUAL_CANDIDATES_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715b8d8",
   "metadata": {},
   "source": [
    "#### **Cell 2: Load Dataset and Tiers**\n",
    "*   **Functionality:** Loads the ground-truth dataset and categorizes problems into tiers.\n",
    "*   **Logic:**\n",
    "    *   Loads the `gsm8k` training set.\n",
    "    *   Defines several helper functions (`has_computational_division`, `has_float`, `is_symbolic`) that use regular expressions to classify the solution text of each problem.\n",
    "    *   `mutually_disjoint_tiers` uses these helpers to partition all problem indices into distinct tiers (e.g., `tier1` for simple integer arithmetic, `tier5` for symbolic algebra). This organizes the data generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "902dd185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier definitions loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Load GSM8K Dataset ---\n",
    "GSM8K_TRAIN: Dataset = load_dataset(\"gsm8k\", \"main\")[\"train\"] #type: ignore\n",
    "\n",
    "# --- Tier Definition Functions ---\n",
    "def has_computational_division(solution_text: str) -> bool:\n",
    "    pattern = re.compile(r'/\\s*\\d')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def has_float(solution_text: str) -> bool:\n",
    "    pattern = re.compile(r'(?<!\\d)\\.\\d+|\\d+\\.\\d+')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def is_symbolic(solution_text: str) -> bool:\n",
    "    pattern = re.compile(r'^Let [a-zA-Z] ', re.MULTILINE)\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def mutually_disjoint_tiers(dataset: Dataset) -> dict[str, list[int]]:\n",
    "    tiers = {}\n",
    "    symbolic_set = set(idx for idx, sample in enumerate(dataset) if is_symbolic(sample.get(\"answer\", \"\")))\n",
    "    non_symbolic_indices = [idx for idx in range(len(dataset)) if idx not in symbolic_set]\n",
    "    tiers[\"tier1\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier2\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier3\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier4\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier5\"] = sorted(list(symbolic_set))\n",
    "    return tiers\n",
    "\n",
    "TIER_LISTS = mutually_disjoint_tiers(GSM8K_TRAIN)\n",
    "print(\"Tier definitions loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b24eaef",
   "metadata": {},
   "source": [
    "#### **Cell 3: Template Loading Utilities**\n",
    "*   **Functionality:** Provides helper functions to load the validated `Formalization Template` components.\n",
    "*   **Logic:**\n",
    "    *   `load_function_module`: Takes a tier, index, and model name. It constructs the path to the `.py` file and uses `importlib.util` to dynamically load the file as a Python module, making its `solve` function accessible.\n",
    "    *   `load_logical_steps`: Takes the same inputs, constructs the path to the `.json` file, and returns the parsed list of dictionaries representing the solution's logical steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6aa7f309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template loading functions defined.\n"
     ]
    }
   ],
   "source": [
    "def load_function_module(tier: str, index: int, model_name: str) -> ModuleType | None:\n",
    "    \"\"\"Dynamically loads the '{model_name}.py' file for a given template.\"\"\"\n",
    "    py_file_path = PROCESSED_TEMPLATE_DIR / tier / str(index) / f\"{model_name}.py\"\n",
    "    if not py_file_path.exists():\n",
    "        return None\n",
    "    module_name = f\"templates.t{tier}.i{index}.m_{model_name.replace('.', '_')}.solve\"\n",
    "    spec = importlib.util.spec_from_file_location(module_name, py_file_path)\n",
    "    if spec and spec.loader:\n",
    "        module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(module)\n",
    "        return module\n",
    "    return None\n",
    "\n",
    "def load_logical_steps(tier: str, index: int, model_name: str) -> list[dict] | None:\n",
    "    \"\"\"Loads the '{model_name}.json' file for a given template.\"\"\"\n",
    "    json_file_path = PROCESSED_TEMPLATE_DIR / tier / str(index) / f\"{model_name}.json\"\n",
    "    try:\n",
    "        return json.loads(json_file_path.read_text(encoding='utf-8'))\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        return None\n",
    "\n",
    "print(\"Template loading functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710a1d07",
   "metadata": {},
   "source": [
    "#### **Cell 3.5: Solution mapping construction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d7a1ec8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanitization and Solution Mapping utilities defined.\n"
     ]
    }
   ],
   "source": [
    "# In a new cell (e.g., Cell 3.5)\n",
    "\n",
    "def sanitize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Replaces a comprehensive set of problematic Unicode characters with their\n",
    "    ASCII equivalents to prevent model generation and string parsing errors.\n",
    "    \"\"\"\n",
    "    replacements = {\n",
    "        \"\\u2212\": \"-\",  # Minus Sign\n",
    "        \"\\u00d7\": \"*\",  # Multiplication Sign\n",
    "        \"\\u00f7\": \"/\",  # Division Sign\n",
    "        \"\\u22c5\": \"*\",  # Dot Operator\n",
    "        \"\\u201c\": '\"',  # Left Double Quotation Mark\n",
    "        \"\\u201d\": '\"',  # Right Double Quotation Mark\n",
    "        \"\\u2018\": \"'\",  # Left Single Quotation Mark\n",
    "        \"\\u2019\": \"'\",  # Right Single Quotation Mark\n",
    "        \"\\u2014\": \"-\",  # Em Dash\n",
    "        \"\\u2013\": \"-\",  # En Dash\n",
    "        \"\\u2026\": \"...\", # Horizontal Ellipsis\n",
    "        \"\\u00a0\": \" \",  # Non-breaking Space\n",
    "    }\n",
    "    for uni, ascii_char in replacements.items():\n",
    "        text = text.replace(uni, ascii_char)\n",
    "    return text\n",
    "\n",
    "def build_solution_mapping(index: int) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts the original natural language solution, sanitizes it, and\n",
    "    structures it into a line-numbered dictionary including the 'FA' line.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        solution_text = GSM8K_TRAIN[index][\"answer\"]\n",
    "        sanitized_text = sanitize_text(solution_text)\n",
    "        lines = [ln.strip() for ln in sanitized_text.splitlines() if ln.strip()]\n",
    "\n",
    "        solution_mapping = {}\n",
    "        if lines and re.match(r\"^####\\s*[\\d\\.,]+$\", lines[-1]):\n",
    "            solution_mapping[\"FA\"] = lines.pop(-1).strip()\n",
    "        \n",
    "        for i, line in enumerate(lines, 1):\n",
    "            solution_mapping[f\"L{i}\"] = line\n",
    "            \n",
    "        return solution_mapping\n",
    "    except IndexError:\n",
    "        return {}\n",
    "\n",
    "print(\"Sanitization and Solution Mapping utilities defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c2b877",
   "metadata": {},
   "source": [
    "#### **Cell 4: Core AST and Trace Utilities**\n",
    "*   **Functionality:** Contains the engine for executing and mutating the abstract syntax tree (AST) of the `function_code`.\n",
    "*   **Logic:**\n",
    "    *   `_execute_ast_statements`: A low-level executor that takes a list of AST statements. It iterates through them, compiling and executing each `ast.Assign` node to build a dictionary representing the final variable state (a trace).\n",
    "    *   `execution_trace`: A wrapper around `_execute_ast_statements`. It takes a Python function, parses its source code into an AST, extracts the function body's statements, and passes them to the executor to get a full, correct execution trace.\n",
    "    *   `get_scope_at_node`: A critical utility that executes a function's code only *up to* a specified AST node. This is used to determine the set of valid, in-scope variables available at a specific line of code, which is essential for discovering \"Wrong Reference\" errors.\n",
    "    *   `is_plausible_trace`: A validation function that compares a `flawed_trace` to the `correct_trace`. It enforces rules to filter out nonsensical errors, such as a variable's sign changing incorrectly or a non-zero value becoming zero. It contains a `FIXME` noting that it could be more robust in handling non-numeric types.\n",
    "    *   `apply_mutation`: The core mutation engine. It uses an `ast.NodeTransformer` to traverse a copy of the function's AST. When it finds the `target_variable` specified in `mutation_details`, it applies the corresponding logical change (e.g., swapping an operator, replacing a variable `ast.Name` node). It then unparses the mutated AST back into a string and executes it to produce the `flawed_trace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "20a961c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonSimplifyingFraction(BuiltinFraction):\n",
    "    \"\"\"A subclass of fractions.Fraction that preserves original representation for printing.\"\"\"\n",
    "    def __new__(cls, numerator=0, denominator=None):\n",
    "        self = super().__new__(cls, numerator, denominator)\n",
    "        if denominator is not None:\n",
    "            self._original_denominator = denominator\n",
    "            self._original_numerator = numerator\n",
    "        else:\n",
    "            self._original_numerator, self._original_denominator = self.as_integer_ratio()\n",
    "        return self\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self._original_numerator}/{self._original_denominator}\"\n",
    "\n",
    "def _execute_ast_statements(stmts: List[ast.stmt]) -> Dict[str, Any] | None:\n",
    "    \"\"\"Executes a list of AST assignment statements and returns the final local environment.\"\"\"\n",
    "    try:\n",
    "        global_namespace = {'Fraction': NonSimplifyingFraction}\n",
    "        local_env = {}\n",
    "        for stmt in stmts:\n",
    "            if isinstance(stmt, ast.Assign):\n",
    "                module_node = ast.Module([stmt], type_ignores=[])\n",
    "                code_obj = compile(module_node, '<string>', 'exec')\n",
    "                exec(code_obj, global_namespace, local_env)\n",
    "        return local_env\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def execution_trace(func: Callable[[], Any]) -> dict[str, Any] | None:\n",
    "    \"\"\"Executes a function's source code line by line to build a full variable trace.\"\"\"\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "        func_def = tree.body[0]\n",
    "        if not isinstance(func_def, ast.FunctionDef): return None\n",
    "        return _execute_ast_statements(func_def.body)\n",
    "    except (FileNotFoundError, TypeError, IndexError):\n",
    "        return None\n",
    "\n",
    "def get_scope_at_node(func: Callable, target_assign_node: ast.Assign) -> Dict[str, Any] | None:\n",
    "    \"\"\"Executes a function's AST up to a specific node to get the current variable scope.\"\"\"\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "        func_def = tree.body[0]\n",
    "        if not isinstance(func_def, ast.FunctionDef): return None\n",
    "\n",
    "        statements_before = []\n",
    "        for stmt in func_def.body:\n",
    "            if isinstance(stmt, ast.Assign) and stmt.lineno == target_assign_node.lineno:\n",
    "                return _execute_ast_statements(statements_before)\n",
    "            statements_before.append(stmt)\n",
    "        return None\n",
    "    except (FileNotFoundError, TypeError, IndexError):\n",
    "        return None\n",
    "\n",
    "def is_plausible_trace(correct_trace: dict, flawed_trace: dict) -> bool:\n",
    "    \"\"\"\n",
    "    Validates a flawed trace against a correct one for type and value integrity.\n",
    "\n",
    "    A trace is considered implausible if any numeric variable:\n",
    "    1. Becomes non-numeric.\n",
    "    2. Was an integer (or integer-like float) and becomes a non-integer float.\n",
    "    3. Flips its sign (e.g., positive to negative), unless it was zero.\n",
    "    4. Was non-zero and becomes zero.\n",
    "    \"\"\"\n",
    "    for key, correct_val in correct_trace.items():\n",
    "        # This function only validates the stability of numeric types.\n",
    "        if not isinstance(correct_val, (int, float, BuiltinFraction)):\n",
    "            continue\n",
    "\n",
    "        flawed_val = flawed_trace.get(key)\n",
    "\n",
    "        # 1. Type Consistency Check: If correct is numeric, flawed must be too.\n",
    "        # This is the primary fix for the AttributeError.\n",
    "        if not isinstance(flawed_val, (int, float, BuiltinFraction)):\n",
    "            return False  # Invalid: type changed from numeric to non-numeric.\n",
    "\n",
    "        # 2. Integer-like Preservation Check\n",
    "        is_correct_int_like = isinstance(correct_val, int) or \\\n",
    "                              (isinstance(correct_val, float) and correct_val.is_integer())\n",
    "        is_flawed_int_like = isinstance(flawed_val, int) or \\\n",
    "                             (isinstance(flawed_val, float) and flawed_val.is_integer())\n",
    "        if is_correct_int_like and not is_flawed_int_like:\n",
    "            return False  # Invalid: integer-like value became a true float.\n",
    "\n",
    "        # 3. Sign Preservation Check\n",
    "        correct_sign = (correct_val > 0) - (correct_val < 0)\n",
    "        flawed_sign = (flawed_val > 0) - (flawed_val < 0)\n",
    "        if correct_val != 0 and correct_sign != flawed_sign:\n",
    "            return False  # Invalid: sign flipped for a non-zero value.\n",
    "\n",
    "        # 4. Zero-Value Preservation Check\n",
    "        if correct_val != 0 and flawed_val == 0:\n",
    "            return False  # Invalid: non-zero value became zero.\n",
    "\n",
    "    return True # All numeric variables passed the plausibility checks.\n",
    "\n",
    "def apply_mutation(\n",
    "    func: Callable, mutation_details: Dict[str, Any]\n",
    ") -> tuple[str | None, Dict[str, Any] | None]:\n",
    "    \"\"\"\n",
    "    Applies a single logical mutation to a function's AST and returns the mutated code and trace.\n",
    "\n",
    "    This function serves as the central engine for creating flawed versions of the \n",
    "    `function_code`. It parses the source, uses a NodeTransformer to apply a specific\n",
    "    mutation based on the `mutation_details`, and then executes the modified AST\n",
    "    to generate a `flawed_trace`.\n",
    "\n",
    "    Args:\n",
    "        func: The original, correct solve() function from the template.\n",
    "        mutation_details: A dictionary describing the mutation to apply, including\n",
    "                          its 'type', 'target_variable', and other relevant info.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "        - The mutated function code as a string, or None if mutation failed.\n",
    "        - The flawed execution trace (a dict of variable states), or None if execution failed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "\n",
    "        class ASTMutator(ast.NodeTransformer):\n",
    "            def __init__(self, details):\n",
    "                self.details = details\n",
    "                self.mutation_applied = False\n",
    "\n",
    "            def visit_Assign(self, node):\n",
    "                # Ensure the node is a simple assignment and matches the target variable\n",
    "                if not (isinstance(node.targets[0], ast.Name) and \n",
    "                        node.targets[0].id == self.details['target_variable']):\n",
    "                    return node\n",
    "\n",
    "                mutation_type = self.details['type']\n",
    "                \n",
    "                # --- Case 1: Incomplete Calculation ---\n",
    "                # Handles removing an operand from a multi-operand sum or product.\n",
    "                if mutation_type == 'incomplete_calculation' and isinstance(node.value, ast.BinOp):\n",
    "                    unrolled = _unroll_binop(node.value)\n",
    "                    if unrolled:\n",
    "                        operands, op_type = unrolled\n",
    "                        operand_to_remove = self.details['operand_to_remove']\n",
    "                        \n",
    "                        new_operands = [op for op in operands if not (isinstance(op, ast.Name) and op.id == operand_to_remove)]\n",
    "                        \n",
    "                        if len(new_operands) >= 2:\n",
    "                            node.value = _build_binop_tree_from_list(new_operands, op_type)\n",
    "                            self.mutation_applied = True\n",
    "                \n",
    "                # --- Case 2: Operator Swap ---\n",
    "                # Handles changing the operator in a binary operation (e.g., + to -).\n",
    "                elif mutation_type == 'operator_swap' and isinstance(node.value, ast.BinOp):\n",
    "                    node.value.op = self.details['new_op']\n",
    "                    self.mutation_applied = True\n",
    "                \n",
    "                # --- Case 3: Variable Name Replacement ---\n",
    "                # Handles multiple error types that all involve swapping one variable for another.\n",
    "                # This includes incorrect operands, input misrepresentation, and incorrect final answer selection.\n",
    "                elif mutation_type in ['incorrect_operand', 'input_misrepresentation', 'incorrect_final_answer_selection']:\n",
    "                    class OperandSwapper(ast.NodeTransformer):\n",
    "                        def __init__(self, to_replace, new_name):\n",
    "                            self.to_replace = to_replace\n",
    "                            self.new_name = new_name\n",
    "                        def visit_Name(self, name_node):\n",
    "                            if name_node.id == self.to_replace:\n",
    "                                return ast.Name(id=self.new_name, ctx=name_node.ctx)\n",
    "                            return name_node\n",
    "                    \n",
    "                    swapper = OperandSwapper(self.details['operand_to_replace'], self.details['replacement_variable'])\n",
    "                    node.value = swapper.visit(node.value)\n",
    "                    self.mutation_applied = True\n",
    "                \n",
    "                return node\n",
    "\n",
    "        mutator = ASTMutator(mutation_details)\n",
    "        mutated_tree = mutator.visit(copy.deepcopy(tree))\n",
    "        \n",
    "        # If the mutation was not successfully applied, abort.\n",
    "        if not mutator.mutation_applied:\n",
    "            return None, None\n",
    "\n",
    "        ast.fix_missing_locations(mutated_tree)\n",
    "        mutated_code_str = ast.unparse(mutated_tree)\n",
    "\n",
    "        # Execute the mutated code to get the flawed trace.\n",
    "        func_def = mutated_tree.body[0]\n",
    "        flawed_trace = _execute_ast_statements(func_def.body) if isinstance(func_def, ast.FunctionDef) else None\n",
    "        \n",
    "        return mutated_code_str, flawed_trace\n",
    "    \n",
    "    except Exception:\n",
    "        # Catch any error during parsing, mutation, or execution and fail gracefully.\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2799ac",
   "metadata": {},
   "source": [
    "#### **Cell 5: Mutation Discovery**\n",
    "*   **Functionality:** Traverses a function's AST to find all valid opportunities for conceptual mutations. This is the \"discovery phase.\"\n",
    "*   **Logic:**\n",
    "    *   `discover_mutation_opportunities`: The main orchestrator. It parses the `function_code`, builds a dependency map, and iterates through each `ast.Assign` node. For each node, it calls specialized discovery helpers.\n",
    "    *   `_discover_operator_swaps`: Identifies `ast.BinOp` nodes and generates potential mutations by swapping the operator (e.g., `+` to `-`, `*` to `/`).\n",
    "    *   `_discover_plausible_wrong_references`: For a given assignment, it identifies all operand variables. It then uses `get_scope_at_node` to find all other numerically-compatible variables in scope and generates mutations to substitute them. It correctly classifies these as either `input_misrepresentation` or `incorrect_operand`.\n",
    "    *   `_discover_omitted_final_steps`: Identifies the final `answer = ...` assignment. It proposes mutations that replace the correct final variable with other intermediate variables calculated earlier in the function, simulating a \"stopped one step short\" error. The `FIXME` comment correctly identifies a necessary edge-case check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "73327a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutation Discovery functions defined.\n"
     ]
    }
   ],
   "source": [
    "def get_variable_dependencies(node: ast.Assign) -> List[str]:\n",
    "    \"\"\"Extracts the names of variables used as operands in an assignment's value.\"\"\"\n",
    "    return sorted([n.id for n in ast.walk(node.value) if isinstance(n, ast.Name) and n.id != 'int'])\n",
    "\n",
    "def _unroll_binop(node: ast.BinOp) -> tuple[list[ast.AST], type[ast.operator]] | None:\n",
    "    \"\"\"\n",
    "    Recursively unrolls a nested ast.BinOp structure into a flat list of operands.\n",
    "    Returns None if operators are inconsistent.\n",
    "    \"\"\"\n",
    "    op_type = type(node.op)\n",
    "    \n",
    "    def recurse(n):\n",
    "        if isinstance(n, ast.BinOp) and type(n.op) == op_type:\n",
    "            yield from recurse(n.left)\n",
    "            yield from recurse(n.right)\n",
    "        else:\n",
    "            yield n\n",
    "            \n",
    "    operands = list(recurse(node))\n",
    "    return operands, op_type\n",
    "\n",
    "def _build_binop_tree_from_list(operands: list[ast.AST], op_constructor: type[ast.operator]) -> ast.BinOp:\n",
    "    \"\"\"Reconstructs a left-associative ast.BinOp tree from a list of operand nodes.\"\"\"\n",
    "    if len(operands) < 2:\n",
    "        raise ValueError(\"Cannot build a BinOp tree with fewer than 2 operands.\")\n",
    "    \n",
    "    tree = ast.BinOp(left=operands[0], op=op_constructor(), right=operands[1])\n",
    "    for i in range(2, len(operands)):\n",
    "        tree = ast.BinOp(left=tree, op=op_constructor(), right=operands[i])\n",
    "\n",
    "    return tree\n",
    "\n",
    "def _discover_incomplete_calculations(node: ast.Assign) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Discovers opportunities for an Incomplete Calculation error.\n",
    "    \n",
    "    This error models a student forgetting to include a term in a multi-operand\n",
    "    calculation (e.g., A + B instead of A + B + C). It targets nested\n",
    "    binary operations with a consistent operator (+ or *).\n",
    "    \"\"\"\n",
    "    if not (isinstance(node.value, ast.BinOp) and hasattr(node.targets[0], 'id')):\n",
    "        return []\n",
    "        \n",
    "    target_variable = node.targets[0].id\n",
    "    \n",
    "    # Unroll the AST to see if it's a multi-operand calculation.\n",
    "    unrolled = _unroll_binop(node.value)\n",
    "    if not unrolled:\n",
    "        return []\n",
    "    \n",
    "    operands, op_type = unrolled\n",
    "    \n",
    "    # We need at least 3 operands to create an incomplete calculation.\n",
    "    if len(operands) < 3:\n",
    "        return []\n",
    "\n",
    "    # Only apply to associative operations where omission is plausible.\n",
    "    if op_type not in [ast.Add, ast.Mult]:\n",
    "        return []\n",
    "\n",
    "    mutations = []\n",
    "    operand_names = [op.id for op in operands if isinstance(op, ast.Name)]\n",
    "\n",
    "    # For each operand, generate a mutation where it is the one omitted.\n",
    "    for i, operand_node in enumerate(operands):\n",
    "        if not isinstance(operand_node, ast.Name):\n",
    "            continue # Skip constants for now\n",
    "            \n",
    "        mutations.append({\n",
    "            \"type\": \"incomplete_calculation\",\n",
    "            \"target_variable\": target_variable,\n",
    "            \"operand_to_remove\": operand_node.id,\n",
    "            \"original_operands\": tuple(sorted(operand_names))\n",
    "        })\n",
    "        \n",
    "    return mutations\n",
    "\n",
    "def _discover_operator_swaps(node: ast.Assign) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Finds all valid OperatorSwap mutations, capturing the operand names.\"\"\"\n",
    "    if not (isinstance(node.value, ast.BinOp) and hasattr(node.targets[0], 'id') and\n",
    "            isinstance(node.value.left, ast.Name) and isinstance(node.value.right, ast.Name)):\n",
    "        return []\n",
    "\n",
    "    target_variable, original_op_node = node.targets[0].id, node.value.op\n",
    "    swap_map = {\n",
    "        ast.Add: [ast.Sub, ast.Mult], ast.Sub: [ast.Add, ast.Div],\n",
    "        ast.Mult: [ast.Div, ast.Add], ast.Div: [ast.Mult, ast.Sub]\n",
    "    }\n",
    "    original_op_type = type(original_op_node)\n",
    "    mutations = []\n",
    "    if original_op_type in swap_map:\n",
    "        for new_op_constructor in swap_map[original_op_type]:\n",
    "            mutations.append({\"type\": \"operator_swap\", \"target_variable\": target_variable, \"original_op_type\": original_op_type,\n",
    "                              \"new_op\": new_op_constructor(), \"left_operand\": node.value.left.id, \"right_operand\": node.value.right.id})\n",
    "    return mutations\n",
    "\n",
    "# In Cell 5\n",
    "def _discover_plausible_wrong_references(\n",
    "    func: Callable, node: ast.Assign, all_input_vars: set, debug: bool = False\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Discovers and classifies plausible operand substitution mutations.\n",
    "    This function is now explicitly prohibited from targeting the 'answer' variable.\n",
    "    \"\"\"\n",
    "    mutations = []\n",
    "    if not hasattr(node.targets[0], 'id'):\n",
    "        return []\n",
    "        \n",
    "    target_variable = node.targets[0].id\n",
    "\n",
    "    # --- FIX: Prevent this function from targeting the 'answer' variable. ---\n",
    "    # Mutations on 'answer' are handled exclusively by the final answer selection discoverer.\n",
    "    if target_variable == 'answer':\n",
    "        return []\n",
    "    # --- END FIX ---\n",
    "    \n",
    "    scope = get_scope_at_node(func, node)\n",
    "    if scope is None:\n",
    "        return []\n",
    "\n",
    "    operands = [n.id for n in ast.walk(node.value) if isinstance(n, ast.Name) and n.id != 'int']\n",
    "    \n",
    "    for operand_to_replace in set(operands):\n",
    "        if operand_to_replace not in scope:\n",
    "            continue\n",
    "        \n",
    "        for replacement_candidate in scope:\n",
    "            if replacement_candidate in (operand_to_replace, 'Fraction'):\n",
    "                continue\n",
    "            \n",
    "            # Ensure we are only swapping numeric types.\n",
    "            if isinstance(scope.get(operand_to_replace), (int, float, BuiltinFraction)) and \\\n",
    "               isinstance(scope.get(replacement_candidate), (int, float, BuiltinFraction)):\n",
    "                \n",
    "                # Classify the error based on whether the original operand was a direct input.\n",
    "                mutation_type = \"input_misrepresentation\" if operand_to_replace in all_input_vars else \"incorrect_operand\"\n",
    "                \n",
    "                mutations.append({\n",
    "                    \"type\": mutation_type, \n",
    "                    \"target_variable\": target_variable,\n",
    "                    \"operand_to_replace\": operand_to_replace, \n",
    "                    \"replacement_variable\": replacement_candidate\n",
    "                })\n",
    "                \n",
    "    # Deduplicate the list of found mutations.\n",
    "    return [dict(t) for t in {tuple(d.items()) for d in mutations}]\n",
    "\n",
    "def _discover_incorrect_final_answer_selections(\n",
    "    func: Callable, \n",
    "    node: ast.Assign,\n",
    "    all_output_vars: set, # <-- New argument\n",
    "    debug: bool = False\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Discovers opportunities to select an incorrect final answer.\n",
    "    This is now constrained to only select from previously computed output variables.\n",
    "    \"\"\"\n",
    "    if not hasattr(node.targets[0], 'id') or node.targets[0].id != 'answer':\n",
    "        return []\n",
    "\n",
    "    # Get the correct final variable being assigned to 'answer'.\n",
    "    correct_operands = [n.id for n in ast.walk(node.value) if isinstance(n, ast.Name)]\n",
    "    if not correct_operands: return []\n",
    "    correct_final_var = correct_operands[0]\n",
    "\n",
    "    mutations = []\n",
    "    # --- FIX: Only iterate through plausible INTERMEDIATE variables. ---\n",
    "    for var_name in all_output_vars:\n",
    "        # A plausible incorrect answer is a previously calculated output that is not the correct final answer.\n",
    "        if var_name != correct_final_var:\n",
    "            mutations.append({\n",
    "                \"type\": \"incorrect_final_answer_selection\",\n",
    "                \"target_variable\": \"answer\",\n",
    "                \"operand_to_replace\": correct_final_var,\n",
    "                \"replacement_variable\": var_name\n",
    "            })\n",
    "            \n",
    "    return mutations\n",
    "\n",
    "def discover_mutation_opportunities(\n",
    "    func: Callable, logical_steps: list, correct_trace: dict, debug_mode: bool = False\n",
    ") -> list:\n",
    "    \"\"\"Analyzes a function's AST to find all possible conceptual error mutations.\"\"\"\n",
    "    all_mutations = []\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "        func_def = tree.body[0]\n",
    "        if not isinstance(func_def, ast.FunctionDef): return []\n",
    "    except (FileNotFoundError, TypeError, IndexError): return []\n",
    "\n",
    "    assign_nodes = [node for node in func_def.body if isinstance(node, ast.Assign)]\n",
    "    all_input_vars = set(v for s in logical_steps for k in ('question_inputs', 'WK_inputs') for v in s.get(k, []))\n",
    "    \n",
    "    # --- FIX: Collect all output variable names first. ---\n",
    "    all_output_vars = set(s['output_variable'] for s in logical_steps if 'output_variable' in s)\n",
    "\n",
    "    for node in assign_nodes:\n",
    "        all_mutations.extend(_discover_operator_swaps(node))\n",
    "        all_mutations.extend(_discover_plausible_wrong_references(func, node, all_input_vars, debug=debug_mode))\n",
    "        all_mutations.extend(_discover_incomplete_calculations(node))\n",
    "        # --- FIX: Pass the set of output variables to the discovery function. ---\n",
    "        all_mutations.extend(_discover_incorrect_final_answer_selections(func, node, all_output_vars, debug=debug_mode))\n",
    "        \n",
    "    return [dict(t) for t in {tuple(d.items()) for d in all_mutations}]\n",
    "\n",
    "print(\"Mutation Discovery functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa8c43a",
   "metadata": {},
   "source": [
    "#### **Cell 6: Candidate Generation and Reconstruction**\n",
    "*   **Functionality:** Orchestrates the full candidate generation for a single template and handles the reconstruction of natural language text.\n",
    "*   **Logic:**\n",
    "    *   `generate_candidates_for_template`: The primary function. It calls `discover_mutation_opportunities`, then iterates through each potential mutation. For each one, it calls `apply_mutation`, validates the result with `is_plausible_trace`, checks that the final answer actually changed, and packages all relevant data (`traces`, `codes`, `explanations`) into a candidate dictionary. The `FIX` comment on line number assignment is a correct and important detail.\n",
    "    *   `_cap_candidates`: Applies heuristic rules to limit the number of generated candidates per template, ensuring variety and preventing an unmanageable number of very similar errors.\n",
    "    *   `reconstruct_solution_from_trace`: Reconstructs the natural language solution by populating the `solution_line_template`s with values from a given trace. It uses `_get_mutated_template` to attempt to alter the template text to match the mutation.\n",
    "    *   `_generate_explanation` / `_get_mutated_template`: Helper functions for generating human-readable text for the final candidate package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6b0c7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormattingTrace(dict):\n",
    "    \"\"\"A dictionary subclass that formats numbers for clean reconstruction.\"\"\"\n",
    "    def __getitem__(self, key):\n",
    "        val = super().__getitem__(key)\n",
    "        if isinstance(val, float) and val.is_integer():\n",
    "            return str(int(val))\n",
    "        if isinstance(val, float):\n",
    "            return str(round(val, 2))\n",
    "        return str(val)\n",
    "\n",
    "def _get_mutated_template(original_template: str, mutation: dict) -> str:\n",
    "    \"\"\"Modifies a template string to reflect a given mutation.\"\"\"\n",
    "    mutation_type = mutation['type']\n",
    "\n",
    "    # --- FIX: Add logic for incomplete_calculation ---\n",
    "    if mutation_type == 'incomplete_calculation':\n",
    "        placeholder_to_remove = f\"{{{mutation['operand_to_remove']}}}\"\n",
    "        \n",
    "        # Regex to find the placeholder followed by a multiplication/addition operator.\n",
    "        # This handles symbols like 'x', '*', '×', or '+' surrounded by optional whitespace.\n",
    "        # It correctly removes an operand from the middle or beginning of an expression.\n",
    "        pattern_after = re.compile(re.escape(placeholder_to_remove) + r'\\s*[x*×+]\\s*')\n",
    "        mutated_template, num_subs = pattern_after.subn('', original_template, count=1)\n",
    "        \n",
    "        if num_subs > 0:\n",
    "            return mutated_template\n",
    "\n",
    "        # If no substitution was made, the operand was likely at the end.\n",
    "        # Try finding an operator before the placeholder.\n",
    "        pattern_before = re.compile(r'\\s*[x*×+]\\s*' + re.escape(placeholder_to_remove))\n",
    "        mutated_template, num_subs = pattern_before.subn('', original_template, count=1)\n",
    "        \n",
    "        return mutated_template\n",
    "    # --- END FIX ---\n",
    "\n",
    "    elif mutation_type == 'operator_swap':\n",
    "        # ... (existing logic for operator_swap is correct)\n",
    "        op_map = {ast.Add: '+', ast.Sub: '-', ast.Mult: '*', ast.Div: '/'}\n",
    "        original_op_str, new_op_str = op_map.get(mutation['original_op_type']), op_map.get(type(mutation['new_op']))\n",
    "        left_ph, right_ph = f\"{{{mutation['left_operand']}}}\", f\"{{{mutation['right_operand']}}}\"\n",
    "        if not (original_op_str and new_op_str): return original_template\n",
    "\n",
    "        patterns = [\n",
    "            re.compile(f\"({re.escape(left_ph)})(.*?)({re.escape(original_op_str)})(.*?)({re.escape(right_ph)})\"),\n",
    "            re.compile(f\"({re.escape(right_ph)})(.*?)({re.escape(original_op_str)})(.*?)({re.escape(left_ph)})\")\n",
    "        ]\n",
    "        \n",
    "        mutated_template = original_template\n",
    "        for pattern in patterns:\n",
    "            mutated_template = pattern.sub(f\"\\\\1\\\\2{new_op_str}\\\\4\\\\5\", mutated_template)\n",
    "        return mutated_template\n",
    "\n",
    "    elif mutation_type in ['incorrect_operand', 'input_misrepresentation', 'incorrect_final_answer_selection']:\n",
    "        # This logic is also correct and handles multiple types.\n",
    "        to_replace_ph, new_name_ph = f\"{{{mutation['operand_to_replace']}}}\", f\"{{{mutation['replacement_variable']}}}\"\n",
    "        return original_template.replace(to_replace_ph, new_name_ph)\n",
    "        \n",
    "    return original_template\n",
    "\n",
    "def _reconstruct_incomplete_calc_template(original_template: str, mutation: dict) -> str:\n",
    "    \"\"\"\n",
    "    Reconstructs the solution line template for an 'incomplete_calculation' error.\n",
    "    This version correctly modifies both the outer text and the inner calculator annotation.\n",
    "    \"\"\"\n",
    "    placeholder_to_remove = f\"{{{mutation['operand_to_remove']}}}\"\n",
    "    \n",
    "    # Define regex patterns to remove the placeholder and its associated operator.\n",
    "    pattern_after = re.compile(re.escape(placeholder_to_remove) + r'\\s*[x*×+]\\s*')\n",
    "    pattern_before = re.compile(r'\\s*[x*×+]\\s*' + re.escape(placeholder_to_remove))\n",
    "    \n",
    "    mutated_template = original_template\n",
    "    \n",
    "    # --- FIX: Modify both the calculator annotation and the surrounding text. ---\n",
    "    annotation_match = re.search(r'<<(.*?)>>', mutated_template)\n",
    "    if annotation_match:\n",
    "        full_annotation_str = annotation_match.group(0)\n",
    "        inner_expr_str = annotation_match.group(1)\n",
    "        \n",
    "        # Modify the inner expression by removing the placeholder.\n",
    "        modified_inner_expr = pattern_after.sub('', inner_expr_str, count=1)\n",
    "        if modified_inner_expr == inner_expr_str:\n",
    "            modified_inner_expr = pattern_before.sub('', modified_inner_expr, count=1)\n",
    "        \n",
    "        # Rebuild the full annotation with the modified expression.\n",
    "        new_annotation_str = f\"<<{modified_inner_expr}>>\"\n",
    "        \n",
    "        # Replace the old annotation in the template with the new one.\n",
    "        mutated_template = mutated_template.replace(full_annotation_str, new_annotation_str)\n",
    "\n",
    "    # Now, modify the text outside the annotation using the same logic.\n",
    "    final_template = pattern_after.sub('', mutated_template, count=1)\n",
    "    if final_template == mutated_template:\n",
    "        final_template = pattern_before.sub('', final_template, count=1)\n",
    "\n",
    "    return final_template\n",
    "\n",
    "# In Cell 6\n",
    "\n",
    "def reconstruct_solution_from_trace(\n",
    "    logical_steps: list[dict], eval_trace: dict[str, Any], candidate_mutation: dict | None = None\n",
    ") -> dict[str, str] | None:\n",
    "    \"\"\"\n",
    "    Reconstructs NL solution lines, truncates if necessary, and adds the FA line.\n",
    "    \"\"\"\n",
    "    formatted_trace = FormattingTrace(eval_trace)\n",
    "    reconstructed_mapping = {}\n",
    "    \n",
    "    # --- FIX: Correctly identify the cutoff line for truncation. ---\n",
    "    cutoff_line = None\n",
    "    if candidate_mutation and candidate_mutation['type'] == 'incorrect_final_answer_selection':\n",
    "        incorrect_answer_var = candidate_mutation['replacement_variable']\n",
    "        # The cutoff line is the line where the incorrect intermediate answer was defined.\n",
    "        cutoff_line_info = next((s for s in logical_steps if s.get('output_variable') == incorrect_answer_var), None)\n",
    "        if cutoff_line_info:\n",
    "            cutoff_line = cutoff_line_info['line_number']\n",
    "    # --- END FIX ---\n",
    "\n",
    "    for step in logical_steps:\n",
    "        ln, template = step.get(\"line_number\"), step.get(\"solution_line_template\")\n",
    "        if not (ln and template): continue\n",
    "        \n",
    "        # Apply mutations to the template string before formatting.\n",
    "        if candidate_mutation and candidate_mutation['type'] != 'incorrect_final_answer_selection':\n",
    "            if step.get(\"output_variable\") == candidate_mutation['target_variable']:\n",
    "                mutation_type = candidate_mutation['type']\n",
    "                if mutation_type == 'incomplete_calculation':\n",
    "                    template = _reconstruct_incomplete_calc_template(template, candidate_mutation)\n",
    "                else:\n",
    "\n",
    "                    template = _get_mutated_template(template, candidate_mutation)\n",
    "        \n",
    "        try:\n",
    "            reconstructed_mapping[ln] = template.format_map(formatted_trace)\n",
    "        except (KeyError, ValueError): return None\n",
    "\n",
    "        # --- FIX: Truncate the solution immediately after the cutoff line. ---\n",
    "        if ln == cutoff_line:\n",
    "            break\n",
    "            \n",
    "    # Add the final answer line to the end of the reconstruction.\n",
    "    flawed_final_answer = eval_trace.get('answer')\n",
    "    if flawed_final_answer is not None:\n",
    "        if isinstance(flawed_final_answer, float) and flawed_final_answer.is_integer():\n",
    "            formatted_answer = int(flawed_final_answer)\n",
    "        else:\n",
    "            # Round floats for cleaner output, e.g., 33.333 -> 33.33\n",
    "            formatted_answer = round(flawed_final_answer, 2) if isinstance(flawed_final_answer, float) else flawed_final_answer\n",
    "        reconstructed_mapping['FA'] = f\"#### {formatted_answer}\"\n",
    "            \n",
    "    return reconstructed_mapping\n",
    "\n",
    "def _generate_explanation(mutation: dict, correct_trace: dict) -> str:\n",
    "    \"\"\"Generates a human-readable explanation with values for a given mutation.\"\"\"\n",
    "    m_type = mutation['type']\n",
    "    \n",
    "    def get_val(var_name):\n",
    "        return correct_trace.get(var_name, 'N/A')\n",
    "\n",
    "    if m_type == 'incomplete_calculation':\n",
    "        operand = mutation['operand_to_remove']\n",
    "        return (f\"Incomplete calculation. The term '{operand}' (value: {get_val(operand)}) \"\n",
    "                f\"was omitted from the operation.\")\n",
    "    \n",
    "    elif m_type == 'operator_swap':\n",
    "        op_map = {ast.Add: '+', ast.Sub: '-', ast.Mult: '*', ast.Div: '/'}\n",
    "        original_op_str = op_map.get(mutation['original_op_type'], '?')\n",
    "        new_op_str = op_map.get(type(mutation['new_op']), '?')\n",
    "        return f\"Incorrect operation. The calculation should use '{original_op_str}' but used '{new_op_str}' instead.\"\n",
    "    \n",
    "    elif m_type == 'incorrect_operand':\n",
    "        original_var, replacement_var = mutation['operand_to_replace'], mutation['replacement_variable']\n",
    "        return (f\"Incorrect operand. The variable '{replacement_var}' (value: {get_val(replacement_var)}) was used \"\n",
    "                f\"instead of the correct variable '{original_var}' (value: {get_val(original_var)}).\")\n",
    "\n",
    "    elif m_type == 'input_misrepresentation':\n",
    "        original_var, replacement_var = mutation['operand_to_replace'], mutation['replacement_variable']\n",
    "        return (f\"Input misrepresentation. The value for '{replacement_var}' ({get_val(replacement_var)}) was used \"\n",
    "                f\"instead of the correct input value for '{original_var}' ({get_val(original_var)}).\")\n",
    "\n",
    "    elif m_type == 'incorrect_final_answer_selection':\n",
    "        original_var, replacement_var = mutation['operand_to_replace'], mutation['replacement_variable']\n",
    "        return (f\"Incorrect final answer. An intermediate value '{replacement_var}' (value: {get_val(replacement_var)}) was reported \"\n",
    "                f\"instead of the correct final answer '{original_var}' (value: {get_val(original_var)}).\")\n",
    "    \n",
    "    return \"An unknown conceptual error occurred.\"\n",
    "\n",
    "def _cap_candidates(candidates: List[Dict], repro_seed: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Applies constraints to the list of generated candidates to ensure variety.\n",
    "    This selection process is made deterministic by the provided seed.\n",
    "    \n",
    "    Constraints:\n",
    "    1. No more than 2 of any individual mutation type per sample.\n",
    "    2. No more than 2 errors targeting any individual line per sample.\n",
    "    3. No more than 5 errors in total per sample.\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    \n",
    "    # Apply type and line constraints\n",
    "    type_counts = Counter()\n",
    "    line_counts = Counter()\n",
    "    \n",
    "    filtered_candidates = []\n",
    "    for cand in candidates:\n",
    "        m_type = cand['mutation_details']['type']\n",
    "        err_line = cand['erroneous_line_number']\n",
    "        \n",
    "        type_counts[m_type] += 1\n",
    "        line_counts[err_line] += 1\n",
    "        \n",
    "        if type_counts[m_type] <= 2 and line_counts[err_line] <= 2:\n",
    "            filtered_candidates.append(cand)\n",
    "            \n",
    "    # Apply total constraint, using the seed for reproducible shuffling\n",
    "    if len(filtered_candidates) > 5:\n",
    "        import random\n",
    "        # --- FIX: Use the reproducible seed ---\n",
    "        random.seed(repro_seed)\n",
    "        # --- END FIX ---\n",
    "        random.shuffle(filtered_candidates)\n",
    "        return filtered_candidates[:5]\n",
    "        \n",
    "    return filtered_candidates\n",
    "\n",
    "def generate_candidates_for_template(\n",
    "    func: Callable, \n",
    "    logical_steps: list, \n",
    "    correct_trace: dict, \n",
    "    original_solution_mapping: dict, # <-- New argument\n",
    "    index: int, \n",
    "    debug_mode: bool = False\n",
    ") -> list[dict]:\n",
    "    \"\"\"Orchestrates the generation of all possible conceptual error candidates.\"\"\"\n",
    "    # ... (code inside this function remains the same until the candidate_package creation) ...\n",
    "    mutations = discover_mutation_opportunities(func, logical_steps, correct_trace, debug_mode=debug_mode)\n",
    "    candidates = []\n",
    "    original_code = inspect.getsource(func)\n",
    "    repro_seed = hash(f\"conceptual_{index}\")\n",
    "\n",
    "    for mutation in mutations:\n",
    "        # ... (inner loop logic is unchanged) ...\n",
    "        mutated_code, flawed_trace = apply_mutation(func, mutation)\n",
    "        if not flawed_trace or not is_plausible_trace(correct_trace, flawed_trace): continue\n",
    "        correct_answer, flawed_answer = correct_trace.get('answer'), flawed_trace.get('answer')\n",
    "        norm_correct = str(float(correct_answer)) if isinstance(correct_answer, (int, float)) else str(correct_answer)\n",
    "        norm_flawed = str(float(flawed_answer)) if isinstance(flawed_answer, (int, float)) else str(flawed_answer)\n",
    "        if correct_answer is None or flawed_answer is None or norm_correct == norm_flawed: continue\n",
    "        try:\n",
    "            flawed_nl_reconstruction = reconstruct_solution_from_trace(logical_steps, flawed_trace, candidate_mutation=mutation)\n",
    "            if not flawed_nl_reconstruction: continue\n",
    "        except AttributeError as e:\n",
    "            if \"'str' object has no attribute 'numerator'\" in str(e): print(f\"\\n[DEBUG] Caught AttributeError on index {index}. Skipping mutation: {mutation}\"); continue\n",
    "            else: raise e\n",
    "\n",
    "        # --- FIX: Update erroneous_line_number logic ---\n",
    "        if mutation['type'] == 'incorrect_final_answer_selection':\n",
    "            erroneous_line_number = \"FA\"\n",
    "        else:\n",
    "            erroneous_line_number = next((s['line_number'] for s in logical_steps if s.get('output_variable') == mutation['target_variable']), None)\n",
    "        # --- END FIX ---\n",
    "            \n",
    "        target_var, correct_target_val, flawed_target_val = mutation['target_variable'], correct_trace.get(mutation['target_variable']), flawed_trace.get(mutation['target_variable'])\n",
    "\n",
    "        candidate_package = {\n",
    "            \"index\": index,\n",
    "            # --- FIX: Add original_solution_mapping to the package ---\n",
    "            \"original_solution_mapping\": original_solution_mapping,\n",
    "            # --- END FIX ---\n",
    "            \"original_function_code\": original_code,\n",
    "            \"mutation_details\": mutation, \"correct_trace\": correct_trace, \"flawed_trace\": flawed_trace,\n",
    "            \"correct_value\": correct_target_val, \"flawed_value\": flawed_target_val,\n",
    "            \"logical_steps\": logical_steps, \"flawed_nl_reconstruction\": flawed_nl_reconstruction,\n",
    "            \"erroneous_line_number\": erroneous_line_number,\n",
    "            \"explanation\": _generate_explanation(mutation, correct_trace)\n",
    "        }\n",
    "        candidates.append(candidate_package)\n",
    "        \n",
    "    capped_candidates = _cap_candidates(candidates, repro_seed)\n",
    "    for cand in capped_candidates: cand['repro_seed'] = repro_seed\n",
    "    return capped_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75712cf",
   "metadata": {},
   "source": [
    "#### **Cell 7: Main Driver**\n",
    "*   **Functionality:** Executes the entire pipeline in parallel for a specified range of problem indices.\n",
    "*   **Logic:**\n",
    "    *   `run_candidate_generation_pipeline_parallel`: The entry point. It defines a list of tasks (indices to process) and uses the `joblib` library to run them in parallel across all available CPU cores.\n",
    "    *   `process_single_index`: The worker function executed by each parallel job. It contains the model fallback logic: it tries to load a template from the preferred model (`gemini-2.5-flash`), and if that fails or produces no candidates, it tries the next model (`gpt-4.1`).\n",
    "    *   `save_candidates_and_get_metadata`: A utility to save the generated candidate packages to disk as individual JSON files and compile their metadata into a list for the final CSV catalog. The logic for generating a unique filename is a good safeguard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "be9b6c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_index(index_info: tuple, model_preference: list) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Worker function to process a single problem index for candidate generation.\n",
    "\n",
    "    This function attempts to load a valid Formalization Template according to the\n",
    "    model preference order. For the first successful model, it generates a list of\n",
    "    conceptual error candidates. It includes checks to skip processing for templates\n",
    "    that are malformed (e.g., brittle templates with attribute access).\n",
    "\n",
    "    Args:\n",
    "        index_info: A tuple containing the (tier, index) of the problem.\n",
    "        model_preference: A list of model names to try in order.\n",
    "\n",
    "    Returns:\n",
    "        A list of candidate dictionaries for the first successful model, or an\n",
    "        empty list if no valid candidates could be generated for the index.\n",
    "    \"\"\"\n",
    "    tier, index = index_info\n",
    "    \n",
    "    # Load the original solution text mapping once per index.\n",
    "    original_solution_mapping = build_solution_mapping(index)\n",
    "    if not original_solution_mapping:\n",
    "        return [] # Cannot proceed without the original solution text.\n",
    "\n",
    "    # Iterate through models, attempting to find a valid template.\n",
    "    for model_name in model_preference:\n",
    "        solve_module = load_function_module(tier, index, model_name)\n",
    "        logical_steps = load_logical_steps(tier, index, model_name)\n",
    "        \n",
    "        if solve_module and logical_steps:\n",
    "            # Check for brittle templates with invalid placeholders (e.g., {var.attr}).\n",
    "            is_brittle = False\n",
    "            for step in logical_steps:\n",
    "                template = step.get('solution_line_template', '')\n",
    "                placeholders = re.findall(r'\\{([^}]+)\\}', template)\n",
    "                if any('.' in p for p in placeholders):\n",
    "                    # This template is malformed; log it and try the next model.\n",
    "                    print(f\"[INFO] Skipping brittle template for index {index} (model: {model_name}) due to attribute access in placeholder.\")\n",
    "                    is_brittle = True\n",
    "                    break\n",
    "            if is_brittle:\n",
    "                continue # Try the next model for this index.\n",
    "\n",
    "            # If the template is valid, proceed with trace and candidate generation.\n",
    "            solve_function = solve_module.solve\n",
    "            correct_trace = execution_trace(solve_function)\n",
    "            if not correct_trace:\n",
    "                continue # If code is not executable, try the next model.\n",
    "            \n",
    "            # Generate candidates using the validated template and original solution text.\n",
    "            candidates = generate_candidates_for_template(\n",
    "                func=solve_function,\n",
    "                logical_steps=logical_steps,\n",
    "                correct_trace=correct_trace,\n",
    "                original_solution_mapping=original_solution_mapping,\n",
    "                index=index\n",
    "            )\n",
    "            \n",
    "            # If candidates were successfully generated, tag them and return.\n",
    "            if candidates:\n",
    "                for cand in candidates:\n",
    "                    cand['model_name'] = model_name\n",
    "                return candidates # Success, no need to try other models for this index.\n",
    "            \n",
    "    # Return an empty list if no model produced valid candidates for this index.\n",
    "    return []\n",
    "\n",
    "def save_candidates_and_get_metadata(tier: str, index: int, model_name: str, candidates: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Saves candidate packages to JSON files and returns a list of metadata records.\"\"\"\n",
    "    output_dir = CONCEPTUAL_CANDIDATES_DIR / tier / str(index)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    metadata_records = []\n",
    "    \n",
    "    for cand in candidates:\n",
    "        mutation = cand['mutation_details']\n",
    "        m_type = mutation['type']\n",
    "        target_var = mutation['target_variable']\n",
    "        \n",
    "        # Use a more descriptive filename including the error type\n",
    "        filename = f\"{model_name}_{m_type}_{target_var}.json\"\n",
    "        filepath = output_dir / filename\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(cand, f, indent=2, default=str)\n",
    "        \n",
    "        record = {\n",
    "            \"index\": index, \"tier\": tier, \"model\": model_name,\n",
    "            \"mutation_type\": m_type, \"target_variable\": target_var,\n",
    "            \"mutation_details\": json.dumps(mutation, default=str),\n",
    "            \"filepath\": str(filepath.relative_to(PROJECT_ROOT))\n",
    "        }\n",
    "        metadata_records.append(record)\n",
    "        \n",
    "    return metadata_records\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def run_candidate_generation_pipeline_parallel(indices_to_generate: List[int]):\n",
    "    \"\"\"Drives the conceptual error candidate generation pipeline in parallel using joblib.\"\"\"\n",
    "    print(\"--- Starting Conceptual Error Candidate Generation (PARALLEL MODE) ---\")\n",
    "    \n",
    "    model_preference = ['google_gemini-2.5-flash', 'openai_gpt-4.1']\n",
    "    tasks = []\n",
    "    for tier, indices in TIER_LISTS.items():\n",
    "        for index in indices:\n",
    "            if index in indices_to_generate:\n",
    "                tasks.append((tier, index))\n",
    "    \n",
    "    print(f\"Prepared {len(tasks)} indices for processing across all available CPU cores.\")\n",
    "\n",
    "    results_list = Parallel(n_jobs=-1)(\n",
    "        delayed(process_single_index)(task, model_preference) \n",
    "        for task in tqdm(tasks, desc=\"Processing Indices\")\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Parallel processing complete. Saving artifacts... ---\")\n",
    "    \n",
    "    all_candidates = [candidate for sublist in results_list if sublist for candidate in sublist]\n",
    "    all_candidate_metadata = []\n",
    "\n",
    "    if not all_candidates:\n",
    "        print(\"No valid conceptual error candidates were generated.\")\n",
    "        return\n",
    "\n",
    "    # --- FIX: Import datetime for timestamping ---\n",
    "    import datetime\n",
    "    # --- END FIX ---\n",
    "\n",
    "    for cand in tqdm(all_candidates, desc=\"Saving Candidates\"):\n",
    "        mutation, index, model_name = cand['mutation_details'], cand['index'], cand['model_name']\n",
    "        m_type, target_var = mutation['type'], mutation['target_variable']\n",
    "        tier = next((t for t, ids in TIER_LISTS.items() if index in ids), 'unknown')\n",
    "        repro_seed = cand.get('repro_seed')\n",
    "        \n",
    "        # --- FIX: Get the UTC timestamp ---\n",
    "        now_utc = datetime.datetime.now(datetime.timezone.utc)\n",
    "        # --- END FIX ---\n",
    "        \n",
    "        # --- FIX: Extract correct and flawed values ---\n",
    "        correct_value = cand.get('correct_value')\n",
    "        flawed_value = cand.get('flawed_value')\n",
    "        # --- END FIX ---\n",
    "\n",
    "        output_dir = CONCEPTUAL_CANDIDATES_DIR / tier / str(index)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        replacement_var = mutation.get('replacement_variable', '')\n",
    "        filename = f\"{model_name}_{m_type}_{target_var}_{replacement_var}.json\"\n",
    "        filepath = output_dir / filename\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(cand, f, indent=2, default=str)\n",
    "        \n",
    "        # --- FIX: Add new fields to the metadata record ---\n",
    "        record = {\n",
    "            \"index\": index, \n",
    "            \"tier\": tier, \n",
    "            \"model\": model_name, \n",
    "            \"mutation_type\": m_type, \n",
    "            \"target_variable\": target_var,\n",
    "            \"correct_value\": str(correct_value), # Convert to string for CSV\n",
    "            \"flawed_value\": str(flawed_value),   # Convert to string for CSV\n",
    "            \"repro_seed\": repro_seed,\n",
    "            \"date_utc\": now_utc.strftime('%Y-%m-%d'),\n",
    "            \"time_utc\": now_utc.strftime('%H:%M:%S'),\n",
    "            \"mutation_details\": json.dumps(mutation, default=str),\n",
    "            \"filepath\": str(filepath.relative_to(PROJECT_ROOT))\n",
    "        }\n",
    "        # --- END FIX ---\n",
    "        all_candidate_metadata.append(record)\n",
    "\n",
    "    if all_candidate_metadata:\n",
    "        catalog_df = pd.DataFrame(all_candidate_metadata)\n",
    "        # --- FIX: Add new columns to the reindex list ---\n",
    "        cols = [\n",
    "            'index', 'tier', 'model', 'mutation_type', 'target_variable', \n",
    "            'correct_value', 'flawed_value', 'repro_seed', \n",
    "            'date_utc', 'time_utc', 'mutation_details', 'filepath'\n",
    "        ]\n",
    "        # --- END FIX ---\n",
    "        catalog_df = catalog_df.reindex(columns=[c for c in cols if c in catalog_df.columns])\n",
    "        catalog_path = CONCEPTUAL_CANDIDATES_DIR / \"conceptual_candidate_catalog.csv\"\n",
    "        catalog_df.to_csv(catalog_path, index=False)\n",
    "        print(f\"\\n--- Pipeline Complete ---\")\n",
    "        print(f\"Generated and saved {len(all_candidate_metadata)} conceptual error candidates.\")\n",
    "        print(f\"Catalog saved to: {catalog_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae495b50",
   "metadata": {},
   "source": [
    "## Cell 8: Execute Pipeline\n",
    "\n",
    "This final cell executes the main driver function to run the entire test pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "67b2fd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Conceptual Error Candidate Generation (PARALLEL MODE) ---\n",
      "Prepared 3000 indices for processing across all available CPU cores.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa841a9fc614399bfc8ba22a8e3ca29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Indices:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Skipping brittle template for index 1484 (model: google_gemini-2.5-flash) due to attribute access in placeholder.\n",
      "\n",
      "--- Parallel processing complete. Saving artifacts... ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15e1385c8a84d0abe3aba5a8591f12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving Candidates:   0%|          | 0/13521 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pipeline Complete ---\n",
      "Generated and saved 13521 conceptual error candidates.\n",
      "Catalog saved to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/conceptual_candidate_catalog.csv\n"
     ]
    }
   ],
   "source": [
    "run_candidate_generation_pipeline_parallel(indices_to_generate=list(range(3000)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
