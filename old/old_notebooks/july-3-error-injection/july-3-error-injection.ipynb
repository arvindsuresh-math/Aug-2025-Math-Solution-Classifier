{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61c23485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/erdos-dl/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root found: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math\n",
      "Base input directory set to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/code_gen_outputs_formatted\n",
      "Base output directory set to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/code_with_error\n",
      "Available models: ['anthropic_claude-3-5-haiku-20241022', 'openai_gpt-4.1-mini', 'google_gemini-2.0-flash-thinking-exp', 'google_gemini-2.5-flash-lite-preview-06-17', 'google_gemini-2.5-flash']\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------- #\n",
    "#  Imports\n",
    "# ---------------------------------------------------------------------- #\n",
    "\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import json\n",
    "import importlib.util\n",
    "import copy\n",
    "import ast\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Tuple, Optional, List\n",
    "from num2words import num2words\n",
    "\n",
    "# ---------------------------------------------------------------------- #\n",
    "#  Global constants & Configuration\n",
    "# ---------------------------------------------------------------------- #\n",
    "\n",
    "def find_project_root():\n",
    "    \"\"\"Traverse upwards to find the project root, marked by the .git folder.\"\"\"\n",
    "    current_path = Path.cwd()\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / \".git\").is_dir():\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    raise FileNotFoundError(\"Could not find project root. Is this a git repository?\")\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "BASE_INPUT_DIR = PROJECT_ROOT / 'data' / 'code_gen_outputs_formatted'\n",
    "BASE_OUTPUT_DIR = PROJECT_ROOT / 'data' / 'code_with_error'\n",
    "BASE_DIR = PROJECT_ROOT / 'data' / 'code_gen_outputs_traced'\n",
    "\n",
    "#Make the output directory if it doesn't exist\n",
    "if not BASE_OUTPUT_DIR.exists():\n",
    "    BASE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Created output directory: {BASE_OUTPUT_DIR}\")\n",
    "\n",
    "# Confirm the paths\n",
    "print(f\"Project root found: {PROJECT_ROOT}\")\n",
    "print(f\"Base input directory set to: {BASE_INPUT_DIR}\")\n",
    "print(f\"Base output directory set to: {BASE_OUTPUT_DIR}\")\n",
    "\n",
    "MODEL_DICT = {\n",
    "  \"anthropic\": [\"claude-3-5-haiku-20241022\"], \n",
    "  \"openai\": [\"gpt-4.1-mini\"],\n",
    "  \"google\": [\"gemini-2.0-flash-thinking-exp\", \n",
    "             \"gemini-2.5-flash-lite-preview-06-17\",\n",
    "             \"gemini-2.5-flash\"]\n",
    "}\n",
    "\n",
    "MODELS = [f\"{provider}_{model}\" for provider, sublist in MODEL_DICT.items() for model in sublist]\n",
    "print(f\"Available models: {MODELS}\")\n",
    "\n",
    "INDICES = list(range(100))\n",
    "\n",
    "gsm8k_train = load_dataset(\"gsm8k\", \"main\", split=\"train\")\n",
    "\n",
    "# ==============================================================================\n",
    "# Utility Functions\n",
    "# ==============================================================================\n",
    "\n",
    "import re\n",
    "\n",
    "def build_solution_mapping(\n",
    "    index: int,\n",
    "    dataset: \"datasets.Dataset\",\n",
    "    convert_brackets: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    index : int\n",
    "        Position of the sample in the loaded dataset.\n",
    "    dataset : iterable / HuggingFace Dataset\n",
    "    convert_brackets : bool, default ``True``\n",
    "        If ``True`` replace every ``<< … >>`` calculator annotation with\n",
    "        the canonical ``[[ … ]]`` form so downstream code sees a single\n",
    "        bracket style.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, str]\n",
    "        Mapping ``{\"L1\": <first non-empty line>, \"L2\": <second>, …}``.\n",
    "    \"\"\"\n",
    "    solution_mapping = {}\n",
    "\n",
    "    # extract & split solution text\n",
    "    solution_text = dataset[index][\"answer\"]\n",
    "    lines = [ln.strip() for ln in solution_text.splitlines() if ln.strip()]\n",
    "\n",
    "    # Add Final Answer line to the solution_dict if it matches the '####' answer pattern\n",
    "    if re.match(r\"^####\\s*\\d+(\\.\\d+)?$\", lines[-1]):\n",
    "        solution_mapping[\"FA\"] = lines.pop(-1).strip()\n",
    "\n",
    "    # optional bracket normalisation\n",
    "    if convert_brackets:\n",
    "        angle = re.compile(r\"<<([^>]+)>>\")\n",
    "        lines = [angle.sub(r\"[[\\1]]\", ln) for ln in lines]\n",
    "\n",
    "    # build mapping\n",
    "    for i, line in enumerate(lines, 1):\n",
    "        solution_mapping[f\"L{i}\"] = line\n",
    "\n",
    "    return solution_mapping\n",
    "\n",
    "def execution_trace(func):\n",
    "    \"\"\"Placeholder: Simulates execution and returns a variable-to-value map.\"\"\"\n",
    "    src = inspect.getsource(func)\n",
    "    tree = ast.parse(src)\n",
    "    func_def = tree.body[0]\n",
    "    env = {}\n",
    "    # Get default args\n",
    "    arg_names = [arg.arg for arg in func_def.args.args]\n",
    "    defaults = func_def.args.defaults\n",
    "    for name, val_node in zip(arg_names[-len(defaults):], defaults):\n",
    "        env[name] = eval(compile(ast.Expression(val_node), '', 'eval'))\n",
    "\n",
    "    # Execute body\n",
    "    for stmt in func_def.body:\n",
    "        if isinstance(stmt, ast.Assign):\n",
    "            code_obj = compile(ast.Module([stmt], []), '', 'exec')\n",
    "            exec(code_obj, {}, env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8408fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Main Class for Natural Language Error Injection\n",
    "# ==============================================================================\n",
    "\n",
    "class NaturalLanguageErrorInjector:\n",
    "    \"\"\"\n",
    "    Generates a flawed natural language (NL) solution and its corresponding\n",
    "    structured JSON label by injecting a programmatic error from a source\n",
    "    code function.\n",
    "\n",
    "    This class orchestrates the loading of correct and flawed code,\n",
    "    analyzing their execution traces, and programmatically modifying the\n",
    "    original NL solution text to reflect the injected error.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, problem_index: int, model_name: str, error_type: str, project_root: Path):\n",
    "        \"\"\"\n",
    "        Initializes the injector for a specific error instance.\n",
    "\n",
    "        Args:\n",
    "            problem_index: The GSM8K index of the problem.\n",
    "            model_name: The name of the model that generated the code.\n",
    "            error_type: The type of error to inject (e.g., 'computational_error').\n",
    "            project_root: The root path of the project directory.\n",
    "        \"\"\"\n",
    "        self.problem_index = problem_index\n",
    "        self.model_name = model_name\n",
    "        self.error_type = error_type\n",
    "        self.project_root = project_root\n",
    "\n",
    "        # Define paths\n",
    "        self.correct_code_dir = self.project_root / 'data' / 'code_gen_outputs_traced'\n",
    "        self.flawed_code_dir = self.project_root / 'data' / 'code_with_error'\n",
    "        self.metadata_dir = self.project_root / 'data' / 'injection_metadata' # Assuming this path\n",
    "\n",
    "        # Initialize data attributes\n",
    "        self.f_oracle = None\n",
    "        self.f_flawed = None\n",
    "        self.correct_trace = None\n",
    "        self.flawed_trace = None\n",
    "        self.metadata = None\n",
    "        self.original_nl_solution = None\n",
    "        self.deleted_nl_line_text = \"\" # For skipped_step\n",
    "\n",
    "        # Map AST op classes to symbols for explanations\n",
    "        self.op_map = {ast.Add: '+', ast.Sub: '-', ast.Mult: '*', ast.Div: '/'}\n",
    "\n",
    "    def _load_module_from_path(self, file_path: Path, module_name: str):\n",
    "        \"\"\"Loads a Python module from a given file path.\"\"\"\n",
    "        if not file_path.exists():\n",
    "            print(f\"❌ Error: File not found at {file_path}\")\n",
    "            return None\n",
    "        spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "        if spec and spec.loader:\n",
    "            module = importlib.util.module_from_spec(spec)\n",
    "            spec.loader.exec_module(module)\n",
    "            return module\n",
    "        return None\n",
    "\n",
    "    def _load_data_sources(self) -> bool:\n",
    "        \"\"\"\n",
    "        Loads all necessary inputs from disk into instance attributes.\n",
    "        \"\"\"\n",
    "        # 1. Load correct/oracle code and trace\n",
    "        correct_path = self.correct_code_dir / str(self.problem_index) / f\"{self.model_name}.py\"\n",
    "        self.f_oracle = self._load_module_from_path(correct_path, \"f_oracle\")\n",
    "        if not self.f_oracle: return False\n",
    "        self.correct_trace = execution_trace(self.f_oracle.solve)\n",
    "\n",
    "        # 2. Load flawed code and trace\n",
    "        flawed_path = self.flawed_code_dir / self.error_type / str(self.problem_index) / f\"{self.model_name}.py\"\n",
    "        self.f_flawed = self._load_module_from_path(flawed_path, \"f_flawed\")\n",
    "        # For skipped_step, the flawed code may be non-runnable.\n",
    "        if self.f_flawed:\n",
    "            try:\n",
    "                self.flawed_trace = execution_trace(self.f_flawed.solve)\n",
    "            except Exception:\n",
    "                if self.error_type != 'skipped_step':\n",
    "                    print(f\"⚠️ Warning: Could not trace flawed function for {self.error_type}\")\n",
    "                self.flawed_trace = {} # Ensure it exists\n",
    "        else:\n",
    "             if self.error_type != 'skipped_step': return False\n",
    "             self.flawed_trace = {}\n",
    "\n",
    "        # 3. Load injection metadata\n",
    "        metadata_path = self.metadata_dir / f\"metadata_{self.problem_index}_{self.error_type}.json\"\n",
    "        if not metadata_path.exists():\n",
    "            print(f\"❌ Error: Metadata file not found at {metadata_path}\")\n",
    "            return False\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            full_metadata = json.load(f)\n",
    "            self.metadata = full_metadata.get(self.model_name)\n",
    "        if not self.metadata:\n",
    "            print(f\"❌ Error: No metadata found for model '{self.model_name}' in {metadata_path}\")\n",
    "            return False\n",
    "\n",
    "        # 4. Load original NL solution\n",
    "        # This requires the gsm8k dataset to be available.\n",
    "        # self.original_nl_solution = build_solution_mapping(self.problem_index, gsm8k_train)\n",
    "        # For a self-contained example, I will use a placeholder:\n",
    "        if self.problem_index == 0:\n",
    "            self.original_nl_solution = {\n",
    "                \"L1\": 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.',\n",
    "                \"L2\": 'Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.',\n",
    "                \"FA\": '#### 72'\n",
    "            }\n",
    "        else:\n",
    "            # In a real scenario, you would load this from the dataset\n",
    "            print(f\"⚠️ Warning: No placeholder NL solution for index {self.problem_index}\")\n",
    "            self.original_nl_solution = {}\n",
    "            \n",
    "        return True\n",
    "\n",
    "    def _replace_number_in_string(self, text: str, old_num: float, new_num: float) -> str:\n",
    "        \"\"\"A robust helper to replace a number within a string, handling int/float and word forms.\"\"\"\n",
    "        if old_num == new_num:\n",
    "            return text\n",
    "        \n",
    "        # Format the new number (e.g., 72.0 becomes \"72\")\n",
    "        new_num_str = str(int(new_num)) if new_num.is_integer() else str(new_num)\n",
    "        \n",
    "        # Try replacing the word form first for integers\n",
    "        if old_num.is_integer():\n",
    "            old_num_int = int(old_num)\n",
    "            old_num_word = num2words(old_num_int)\n",
    "            # Use regex for whole-word replacement\n",
    "            word_pattern = re.compile(r'\\b' + re.escape(old_num_word) + r'\\b', re.IGNORECASE)\n",
    "            text = word_pattern.sub(new_num_str, text)\n",
    "\n",
    "        # Then, replace the numeral form\n",
    "        old_num_str = str(int(old_num)) if old_num.is_integer() else str(old_num)\n",
    "        numeral_pattern = re.compile(r'\\b' + re.escape(old_num_str) + r'\\b')\n",
    "        text = numeral_pattern.sub(new_num_str, text)\n",
    "        \n",
    "        return text\n",
    "\n",
    "    def _modify_nl_line(self, line_text: str) -> str:\n",
    "        \"\"\"Modifies a single NL line by replacing its result with the flawed value from the trace.\"\"\"\n",
    "        # Regex to find the result in a calculator annotation, e.g., <<...=24>>\n",
    "        match = re.search(r'<<.*?=([\\d\\.]+)>>', line_text)\n",
    "        if not match:\n",
    "            return line_text\n",
    "\n",
    "        original_result = float(match.group(1))\n",
    "        \n",
    "        # Find the variable in the correct trace that produced this result\n",
    "        variable_name = None\n",
    "        for var, val in self.correct_trace.items():\n",
    "            # Using a tolerance for float comparison\n",
    "            if isinstance(val, (int, float)) and abs(val - original_result) < 1e-6:\n",
    "                variable_name = var\n",
    "                break\n",
    "        \n",
    "        if not variable_name:\n",
    "            return line_text # Could not map result to a variable\n",
    "\n",
    "        # Find the new, flawed value of this variable\n",
    "        new_flawed_value = self.flawed_trace.get(variable_name)\n",
    "        if new_flawed_value is None:\n",
    "            return line_text\n",
    "            \n",
    "        # Replace the original result with the flawed one in the NL text\n",
    "        return self._replace_number_in_string(line_text, original_result, new_flawed_value)\n",
    "\n",
    "    def _generate_flawed_nl_solution(self) -> Dict[str, str]:\n",
    "        \"\"\"Creates the flawed NL solution mapping based on the error type.\"\"\"\n",
    "        flawed_nl = copy.deepcopy(self.original_nl_solution)\n",
    "        \n",
    "        if self.error_type == 'skipped_step':\n",
    "            line_to_delete = self.metadata['line_label']\n",
    "            if line_to_delete in flawed_nl:\n",
    "                # Store the deleted text for the JSON label generation\n",
    "                self.deleted_nl_line_text = flawed_nl[line_to_delete]\n",
    "                del flawed_nl[line_to_delete]\n",
    "            return flawed_nl\n",
    "\n",
    "        # For other errors, iterate and propagate changes\n",
    "        # Sorting keys ensures 'L1' is processed before 'L2', etc.\n",
    "        sorted_keys = sorted(flawed_nl.keys(), key=lambda k: (k[0] != 'L', int(k[1:]) if k.startswith('L') else 0))\n",
    "        for key in sorted_keys:\n",
    "            if key.startswith('L'):\n",
    "                flawed_nl[key] = self._modify_nl_line(flawed_nl[key])\n",
    "        \n",
    "        return flawed_nl\n",
    "\n",
    "    def _generate_json_label(self) -> Dict[str, Any]:\n",
    "        \"\"\"Constructs the final structured JSON label using metadata-driven templates.\"\"\"\n",
    "        m = self.metadata\n",
    "        explanation = \"Error: Could not generate explanation.\"\n",
    "        correction = \"Error: Could not generate correction.\"\n",
    "\n",
    "        if self.error_type == 'computational_error':\n",
    "            explanation = f\"There is a computational error. The solution states the result is {m['new_value']}, but the correct value is {m['original_value']}.\"\n",
    "            correction = f\"To correct this, replace the incorrect value {m['new_value']} with the correct value {m['original_value']}.\"\n",
    "\n",
    "        elif self.error_type == 'incorrect_operation':\n",
    "            # Safely get operator symbols\n",
    "            original_op_symbol = self.op_map.get(ast.parse(m['original_op']).body[0].value.__class__, '?')\n",
    "            new_op_symbol = self.op_map.get(ast.parse(m['new_op']).body[0].value.__class__, '?')\n",
    "            \n",
    "            explanation = f\"The solution incorrectly uses a '{new_op_symbol}' operation where a '{original_op_symbol}' operation was needed.\"\n",
    "            correction = f\"To correct this, the operator should be changed from '{new_op_symbol}' to '{original_op_symbol}'.\"\n",
    "\n",
    "        elif self.error_type == 'skipped_step':\n",
    "            explanation = f\"A necessary calculation step is missing. The solution fails to perform the step that would have defined the variable '{m['deleted_variable']}'.\"\n",
    "            correction = f\"To correct this, the following step must be inserted back into the solution: '{self.deleted_nl_line_text}'\"\n",
    "        \n",
    "        elif self.error_type == 'incorrect_operand':\n",
    "            explanation = f\"The calculation uses an incorrect variable. It incorrectly references '{m['new_operand']}' instead of '{m['original_operand']}'.\"\n",
    "            correction = f\"To correct this, the variable '{m['new_operand']}' should be replaced with the correct variable, '{m['original_operand']}'.\"\n",
    "\n",
    "        return {\n",
    "            \"verdict\": \"Flawed\",\n",
    "            \"error_details\": {\n",
    "                \"error_type\": self.error_type,\n",
    "                \"erroneous_line_number\": m['line_label'],\n",
    "                \"explanation\": explanation,\n",
    "                \"correction\": correction\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def inject_nl_error(self) -> Optional[Tuple[Dict[str, str], Dict[str, Any]]]:\n",
    "        \"\"\"\n",
    "        Orchestrates the end-to-end process of generating a flawed NL solution\n",
    "        and its corresponding JSON label.\n",
    "        \"\"\"\n",
    "        if not self._load_data_sources():\n",
    "            print(\"--- Process halted due to data loading failure. ---\")\n",
    "            return None\n",
    "        \n",
    "        flawed_nl_solution = self._generate_flawed_nl_solution()\n",
    "        json_label = self._generate_json_label()\n",
    "        \n",
    "        return flawed_nl_solution, json_label\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Example Usage\n",
    "# ==============================================================================\n",
    "if __name__ == '__main__':\n",
    "    import inspect\n",
    "    \n",
    "    # Define project root relative to this script's location\n",
    "    # In a real scenario, you might use a more robust method like find_project_root()\n",
    "    try:\n",
    "        PROJECT_ROOT = Path(__file__).parent.parent\n",
    "    except NameError:\n",
    "        PROJECT_ROOT = Path.cwd() # Fallback for interactive environments\n",
    "\n",
    "    print(f\"Using project root: {PROJECT_ROOT}\\n\")\n",
    "\n",
    "    # --- Configuration for the example ---\n",
    "    test_problem_index = 0\n",
    "    test_model = \"anthropic_claude-3-5-haiku-20241022\"\n",
    "    \n",
    "    # We will test all relevant error types\n",
    "    # NOTE: 'incorrect_operand' is excluded as per the instructions.\n",
    "    test_error_types = ['computational_error', 'incorrect_operation', 'skipped_step']\n",
    "\n",
    "    for error_type in test_error_types:\n",
    "        print(f\"============================================================\")\n",
    "        print(f\"  Testing Injection for: {error_type.upper()}\")\n",
    "        print(f\"============================================================\\n\")\n",
    "\n",
    "        # 1. Instantiate the injector\n",
    "        injector = NaturalLanguageErrorInjector(\n",
    "            problem_index=test_problem_index,\n",
    "            model_name=test_model,\n",
    "            error_type=error_type,\n",
    "            project_root=PROJECT_ROOT\n",
    "        )\n",
    "\n",
    "        # 2. Run the injection process\n",
    "        result = injector.inject_nl_error()\n",
    "\n",
    "        if result:\n",
    "            flawed_solution, final_label = result\n",
    "            \n",
    "            # 3. Print the results\n",
    "            print(\"--- Original NL Solution ---\")\n",
    "            print(json.dumps(injector.original_nl_solution, indent=4))\n",
    "            \n",
    "            print(\"\\n--- Generated Flawed NL Solution ---\")\n",
    "            print(json.dumps(flawed_solution, indent=4))\n",
    "            \n",
    "            print(\"\\n--- Generated JSON Label ---\")\n",
    "            print(json.dumps(final_label, indent=4))\n",
    "            print(\"\\n\")\n",
    "        else:\n",
    "            print(f\"Injection failed for {error_type}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc00090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_injection(\n",
    "        problem_index: int, \n",
    "        model_name: str, \n",
    "        error_type: str, \n",
    "        project_root: Path, \n",
    "        verbose: bool = True\n",
    "    ):\n",
    "    \"\"\"\n",
    "    A simple wrapper to test the NaturalLanguageErrorInjector for a single case.\n",
    "\n",
    "    Instantiates the injector, runs the process, and prints the inputs and\n",
    "    outputs for easy debugging in a notebook environment.\n",
    "\n",
    "    Args:\n",
    "        problem_index: The GSM8K index to test.\n",
    "        model_name: The model whose output will be used.\n",
    "        error_type: The error type to inject.\n",
    "        project_root: The root path of the project.\n",
    "        verbose: If True, prints detailed step-by-step outputs.\n",
    "\n",
    "    Returns:\n",
    "        The result tuple (flawed_nl, json_label) on success, otherwise None.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"============================================================\")\n",
    "        print(f\"  Testing Injection for: {error_type.upper()}\")\n",
    "        print(f\"  Problem Index: {problem_index}, Model: {model_name}\")\n",
    "        print(f\"============================================================\\n\")\n",
    "\n",
    "    # 1. Instantiate the injector\n",
    "    injector = NaturalLanguageErrorInjector(\n",
    "        problem_index=problem_index,\n",
    "        model_name=model_name,\n",
    "        error_type=error_type,\n",
    "        project_root=project_root\n",
    "    )\n",
    "\n",
    "    # 2. Run the injection process\n",
    "    result = injector.inject_nl_error()\n",
    "\n",
    "    # 3. Print the results if successful\n",
    "    if result:\n",
    "        flawed_solution, final_label = result\n",
    "        if verbose:\n",
    "            print(\"--- Original NL Solution ---\")\n",
    "            print(json.dumps(injector.original_nl_solution, indent=4))\n",
    "            \n",
    "            print(\"\\n--- Generated Flawed NL Solution ---\")\n",
    "            print(json.dumps(flawed_solution, indent=4))\n",
    "            \n",
    "            print(\"\\n--- Generated JSON Label ---\")\n",
    "            print(json.dumps(final_label, indent=4))\n",
    "            print(\"\\n✅ Injection Successful.\\n\")\n",
    "        return result\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f\"❌ Injection Failed for {error_type}.\\n\")\n",
    "        return None\n",
    "\n",
    "# ==============================================================================\n",
    "# Example Usage: Place this in a new cell to run the tests.\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Configuration for the example test ---\n",
    "test_problem_index = 0\n",
    "test_model = \"anthropic_claude-3-5-haiku-20241022\"\n",
    "test_error_types = ['computational_error', 'incorrect_operation', 'skipped_step']\n",
    "\n",
    "for error_type in test_error_types:\n",
    "    # The 'PROJECT_ROOT' variable should already be defined in your first cell.\n",
    "    test_single_injection(\n",
    "        problem_index=test_problem_index,\n",
    "        model_name=test_model,\n",
    "        error_type=error_type,\n",
    "        project_root=PROJECT_ROOT\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
