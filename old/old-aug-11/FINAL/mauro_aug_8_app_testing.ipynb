{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8797998faef475bb1f4a883ab9534e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a85431e28134414d9d1c1b1ae97d3ce5",
              "IPY_MODEL_3213e8cf53104b039306a7dc7762c3ce",
              "IPY_MODEL_ae07d78dd7314d62896c99dd62f691b7"
            ],
            "layout": "IPY_MODEL_6571be2a362f4c529ef5fd4ddcbc8db3"
          }
        },
        "a85431e28134414d9d1c1b1ae97d3ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b26d6f4d792e417783a8da311b1cf179",
            "placeholder": "​",
            "style": "IPY_MODEL_960ee40a709b4f5cb41778508eef24f4",
            "value": "Stage 1 Batches: 100%"
          }
        },
        "3213e8cf53104b039306a7dc7762c3ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1603c469945e4298b268aaac9a888309",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b7710327d514ee2913d667781849b4c",
            "value": 3
          }
        },
        "ae07d78dd7314d62896c99dd62f691b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e46a00ae430446ecb0d4a8f606a0acd7",
            "placeholder": "​",
            "style": "IPY_MODEL_160f6b474fe442b0a2898773b685ae60",
            "value": " 3/3 [02:13&lt;00:00, 46.31s/it]"
          }
        },
        "6571be2a362f4c529ef5fd4ddcbc8db3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b26d6f4d792e417783a8da311b1cf179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "960ee40a709b4f5cb41778508eef24f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1603c469945e4298b268aaac9a888309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b7710327d514ee2913d667781849b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e46a00ae430446ecb0d4a8f606a0acd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160f6b474fe442b0a2898773b685ae60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6cd59da5a7c496595147b68055a65d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ea81555d6c642a68880c0796b2bcfbf",
              "IPY_MODEL_e79d1b5b9884489abe5953a51eaae9cd",
              "IPY_MODEL_627241323a3f46ab936429d63f47299f"
            ],
            "layout": "IPY_MODEL_2b56ef39626747e49c0a279694d3606e"
          }
        },
        "6ea81555d6c642a68880c0796b2bcfbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42054753020d4ab0996116f629589697",
            "placeholder": "​",
            "style": "IPY_MODEL_3c98e995ed55420e85d553ddfab7bd08",
            "value": "Stage 2 Batches: 100%"
          }
        },
        "e79d1b5b9884489abe5953a51eaae9cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57d3d8b9841949c68570dbd461942181",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efa415be76dd40d78d9047ab07e16e26",
            "value": 8
          }
        },
        "627241323a3f46ab936429d63f47299f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2830208b957b454f9bd946229545b871",
            "placeholder": "​",
            "style": "IPY_MODEL_7389848a84fe4ecd9b8fb001f547baae",
            "value": " 8/8 [00:02&lt;00:00,  3.11it/s]"
          }
        },
        "2b56ef39626747e49c0a279694d3606e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42054753020d4ab0996116f629589697": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c98e995ed55420e85d553ddfab7bd08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57d3d8b9841949c68570dbd461942181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efa415be76dd40d78d9047ab07e16e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2830208b957b454f9bd946229545b871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7389848a84fe4ecd9b8fb001f547baae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-1rW_6ETBLF",
        "outputId": "00791fdc-7d9d-4949-c175-b1e7b4d933c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.53.2\n",
            "  Downloading transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (0.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.2) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.2) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.2) (2025.8.3)\n",
            "Downloading transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.55.0\n",
            "    Uninstalling transformers-4.55.0:\n",
            "      Successfully uninstalled transformers-4.55.0\n",
            "Successfully installed transformers-4.53.2\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.34.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.7)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n",
            "Downloading accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.7/374.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.9.0\n",
            "    Uninstalling accelerate-1.9.0:\n",
            "      Successfully uninstalled accelerate-1.9.0\n",
            "Successfully installed accelerate-1.10.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.46.1\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu124\n",
            "Collecting flash-attn==2.7.4.post1\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.7.4.post1) (2.6.0+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.7.4.post1) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn==2.7.4.post1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn==2.7.4.post1) (3.0.2)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187831595 sha256=58853b28a5a926cae14402bfd8d4d93a45ebf8f9e79533f37ab09d0d77a99c05\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.7.4.post1\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Installations\n",
        "!pip install -U transformers==4.53.2\n",
        "!pip install -U accelerate\n",
        "!pip install -U bitsandbytes\n",
        "\n",
        "!pip install flash-attn==2.7.4.post1 \\\n",
        "  --extra-index-url https://download.pytorch.org/whl/cu124 \\\n",
        "  --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton unsloth_zoo\n",
        "!pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "!pip install --no-deps unsloth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUsFe1CrTESy",
        "outputId": "65794ed6-414e-4740-f504-64ad978405d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Collecting xformers==0.0.29.post3\n",
            "  Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
            "Collecting trl\n",
            "  Downloading trl-0.21.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Collecting unsloth_zoo\n",
            "  Downloading unsloth_zoo-2025.8.3-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.21.0-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.9/511.9 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.8.3-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xformers, unsloth_zoo, trl\n",
            "Successfully installed trl-0.21.0 unsloth_zoo-2025.8.3 xformers-0.0.29.post3\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (5.29.5)\n",
            "Collecting datasets<4.0.0,>=3.4.1\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.11/dist-packages (0.34.3)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (0.1.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0) (1.1.7)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (3.12.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: datasets\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "unsloth-zoo 2025.8.3 requires cut_cross_entropy, which is not installed.\n",
            "unsloth-zoo 2025.8.3 requires msgspec, which is not installed.\n",
            "unsloth-zoo 2025.8.3 requires tyro, which is not installed.\n",
            "trl 0.21.0 requires transformers>=4.55.0, but you have transformers 4.53.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0\n",
            "Collecting unsloth\n",
            "  Downloading unsloth-2025.8.4-py3-none-any.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth-2025.8.4-py3-none-any.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.8/306.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unsloth\n",
            "Successfully installed unsloth-2025.8.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unsloth\n",
        "from unsloth import FastModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "from huggingface_hub import hf_hub_download\n",
        "import json\n",
        "import re\n",
        "import math\n",
        "import time\n",
        "\n",
        "print(\"✅ All modules imported.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etqRxpwTZtm1",
        "outputId": "278b3446-b8af-4686-e7bb-ae87cb0197ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "✅ All modules imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# 1. DEFINE CUSTOM CLASSIFIER (Required for Phi-4)\n",
        "# ===================================================================\n",
        "class GPTSequenceClassifier(nn.Module):\n",
        "    def __init__(self, base_model, num_labels):\n",
        "        super().__init__()\n",
        "        self.base = base_model\n",
        "        hidden_size = base_model.config.hidden_size\n",
        "        self.classifier = nn.Linear(hidden_size, num_labels, bias=True)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
        "        outputs = self.base(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True, **kwargs)\n",
        "        last_hidden_state = outputs.hidden_states[-1]\n",
        "        pooled_output = last_hidden_state[:, -1, :]\n",
        "        logits = self.classifier(pooled_output)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = nn.functional.cross_entropy(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "        return {\"loss\": loss, \"logits\": logits} if loss is not None else {\"logits\": logits}"
      ],
      "metadata": {
        "id": "L5P4Xs-sTJSo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# 2. LOAD MODELS AND TOKENIZERS\n",
        "# ===================================================================\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- Model 1: Equation Extractor (Gemma-3 with Unsloth) ---\n",
        "print(\"\\nLoading Equation Extraction Model...\")\n",
        "extractor_adapter_repo = \"arvindsuresh-math/gemma-3-1b-equation-extractor-lora\"\n",
        "base_gemma_model = \"unsloth/gemma-3-1b-it-unsloth-bnb-4bit\"\n",
        "\n",
        "gemma_model, gemma_tokenizer = FastModel.from_pretrained(\n",
        "    model_name=base_gemma_model,\n",
        "    max_seq_length=2048,\n",
        "    dtype=None,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "\n",
        "# --- Gemma tokenizer hygiene (fix the right-padding warning) ---\n",
        "if gemma_tokenizer.pad_token is None:\n",
        "    gemma_tokenizer.pad_token = gemma_tokenizer.eos_token\n",
        "gemma_tokenizer.padding_side = \"left\"   # align last tokens across the batch\n",
        "\n",
        "gemma_model = PeftModel.from_pretrained(gemma_model, extractor_adapter_repo)\n",
        "print(\"✅ Equation Extraction Model loaded.\")\n",
        "\n",
        "\n",
        "# --- Model 2: Conceptual Error Classifier (Phi-4) ---\n",
        "print(\"\\nLoading Conceptual Error Classifier Model...\")\n",
        "classifier_adapter_repo = \"arvindsuresh-math/phi-4-error-binary-classifier\"\n",
        "base_phi_model = \"microsoft/Phi-4-mini-instruct\"\n",
        "\n",
        "DTYPE = torch.bfloat16\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=DTYPE\n",
        "    )\n",
        "classifier_backbone_base = AutoModelForCausalLM.from_pretrained(\n",
        "    base_phi_model,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    )\n",
        "\n",
        "classifier_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_phi_model,\n",
        "    trust_remote_code=True\n",
        "    )\n",
        "classifier_tokenizer.padding_side = \"left\"\n",
        "if classifier_tokenizer.pad_token is None:\n",
        "    classifier_tokenizer.pad_token = classifier_tokenizer.eos_token\n",
        "\n",
        "classifier_backbone_peft = PeftModel.from_pretrained(\n",
        "    classifier_backbone_base,\n",
        "    classifier_adapter_repo\n",
        "    )\n",
        "classifier_model = GPTSequenceClassifier(classifier_backbone_peft, num_labels=2)\n",
        "\n",
        "# Download and load the custom classifier head's state dictionary\n",
        "classifier_head_path = hf_hub_download(repo_id=classifier_adapter_repo, filename=\"classifier_head.pth\")\n",
        "classifier_model.classifier.load_state_dict(torch.load(classifier_head_path, map_location=device))\n",
        "\n",
        "classifier_model.to(device)\n",
        "classifier_model = classifier_model.to(torch.bfloat16)\n",
        "\n",
        "classifier_model.eval() # Set model to evaluation mode\n",
        "print(\"✅ Conceptual Error Classifier Model loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "Ynp6tx1aTEjf",
        "outputId": "85551a49-670d-4579-ed12-560e40185086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Loading Equation Extraction Model...\n",
            "==((====))==  Unsloth 2025.8.4: Fast Gemma3 patching. Transformers: 4.53.2.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = True]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Prompts ---\n",
        "\n",
        "# --- Prompts ---\n",
        "EXTRACTOR_SYSTEM_PROMPT = \\\n",
        "\"\"\"[ROLE]\n",
        "You are an expert at parsing mathematical solutions.\n",
        "[TASK]\n",
        "You are given a mathematical solution. Your task is to extract the calculation performed on each line and represent it as a simple equation.\n",
        "**This is a literal transcription task. Follow these rules with extreme precision:**\n",
        "- **RULE 1: Transcribe EXACTLY.** Do not correct mathematical errors. If a line implies `2+2=5`, your output for that line must be `2+2=5`.\n",
        "- **RULE 2: Isolate the Equation.** Your output must contain ONLY the equation. Do not include any surrounding text, units (like `/hour`), or currency symbols (like `$`).\n",
        "- **RULE 3: Use Standard Operators.** Always use `*` for multiplication. Never use `x`.\n",
        "[RESPONSE FORMAT]\n",
        "Your response must be ONLY a single, valid JSON object, adhering strictly to these rules:\n",
        "For each line of the solution, create a key-value pair.\n",
        "- The key should be the line identifier (e.g., \"L1\", \"L2\", \"FA\" for the final answer line).\n",
        "- The value should be the extracted equation string (e.g., \"10+5=15\").\n",
        "- If a line contains no calculation, the value must be an empty string.\n",
        "\"\"\"\n",
        "\n",
        "CLASSIFIER_SYSTEM_PROMPT = \\\n",
        "\"\"\"You are a mathematics tutor.\n",
        "You will be given a math word problem and a solution written by a student.\n",
        "Carefully analyze the problem and solution LINE-BY-LINE and determine whether there are any errors in the solution.\"\"\"\n",
        "\n",
        "# --- Example 1 ---\n",
        "FEW_SHOT_EXAMPLE_1_SOLUTION = {\n",
        "  \"L1\": \"2% of $90 is (2/100)*$90 = $1.8\",\n",
        "  \"L2\": \"2% of $60 is (2/100)*$60 = $1.2\",\n",
        "  \"L3\": \"The second transaction was reversed without the service charge so only a total of $90+$1.8+$1.2 = $39 was deducted from his account\",\n",
        "  \"L4\": \"He will have a balance of $400-$39 = $361\",\n",
        "  \"FA\": \"361\"\n",
        "}\n",
        "\n",
        "FEW_SHOT_EXAMPLE_1_EQUATIONS = {\n",
        "  \"L1\": \"(2/100)*90=1.8\",\n",
        "  \"L2\": \"(2/100)*60=1.2\",\n",
        "  \"L3\": \"90+1.8+1.2=39\",\n",
        "  \"L4\": \"400-39=361\",\n",
        "  \"FA\": \"\"\n",
        "}\n",
        "\n",
        "\n",
        "# --- Example 2 ---\n",
        "FEW_SHOT_EXAMPLE_2_SOLUTION = {\n",
        "  \"L1\": \"She drinks 2 bottles a day and there are 24 bottles in a case so a case will last 24/2 = 12 days\",\n",
        "  \"L2\": \"She needs enough to last her 240 days and 1 case will last her 12 days so she needs 240/12 = 20 cases\",\n",
        "  \"L3\": \"Each case is on sale for $12.00 and she needs 20 cases so that's 12*20 = $240.00\",\n",
        "  \"FA\": \"240\"\n",
        "}\n",
        "\n",
        "FEW_SHOT_EXAMPLE_2_EQUATIONS = {\n",
        "  \"L1\": \"24/2=12\",\n",
        "  \"L2\": \"240/12=20\",\n",
        "  \"L3\": \"12*20=240.00\",\n",
        "  \"FA\": \"\"\n",
        "}\n",
        "\n",
        "def create_extractor_messages(solution_json_str: str) -> list:\n",
        "    \"\"\"\n",
        "    Returns a list of dictionaries representing the conversation history for the prompt.\n",
        "    \"\"\"\n",
        "    # Start with the constant few-shot examples defined globally\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": f\"{EXTRACTOR_SYSTEM_PROMPT}\\n\\n### Solution:\\n{json.dumps(FEW_SHOT_EXAMPLE_1_SOLUTION, indent=2)}\"},\n",
        "        {\"role\": \"assistant\", \"content\": json.dumps(FEW_SHOT_EXAMPLE_1_EQUATIONS, indent=2)},\n",
        "        {\"role\": \"user\", \"content\": f\"### Solution:\\n{json.dumps(FEW_SHOT_EXAMPLE_2_SOLUTION, indent=2)}\"},\n",
        "        {\"role\": \"assistant\", \"content\": json.dumps(FEW_SHOT_EXAMPLE_2_EQUATIONS, indent=2)},\n",
        "    ]\n",
        "\n",
        "    # Add the final user query to the end of the conversation\n",
        "    final_user_prompt = f\"### Solution:\\n{solution_json_str}\"\n",
        "    messages.append({\"role\": \"user\", \"content\": final_user_prompt})\n",
        "\n",
        "    return messages"
      ],
      "metadata": {
        "id": "DBEhNWaWouKo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper Functions ---\n",
        "def format_solution_into_json_str(solution_text: str) -> str:\n",
        "    lines = [line.strip() for line in solution_text.strip().split('\\n') if line.strip()]\n",
        "    final_answer = \"\"\n",
        "    if lines and \"FINAL ANSWER:\" in lines[-1].upper():\n",
        "        final_answer = lines[-1][len(\"FINAL ANSWER:\"):].strip()\n",
        "        lines = lines[:-1]\n",
        "    solution_dict = {f\"L{i+1}\": line for i, line in enumerate(lines)}\n",
        "    solution_dict[\"FA\"] = final_answer\n",
        "    return json.dumps(solution_dict, indent=2)\n",
        "\n",
        "def sanitize_equation_string(expression: str) -> str:\n",
        "    if not isinstance(expression, str):\n",
        "        return \"\"\n",
        "\n",
        "    s = expression.strip()\n",
        "\n",
        "    # Normalize common symbols\n",
        "    s = s.replace('×', '*').replace('·', '*').replace('x', '*')\n",
        "\n",
        "    # Convert percentages like '12%' -> '(12/100)'\n",
        "    s = re.sub(r'(?<!\\d)(\\d+(?:\\.\\d+)?)\\s*%', r'(\\1/100)', s)\n",
        "\n",
        "    # Simple paren balancing trims (only when a single stray exists at an edge)\n",
        "    if s.count('(') > s.count(')') and s.startswith('('):\n",
        "        s = s[1:]\n",
        "    elif s.count(')') > s.count('(') and s.endswith(')'):\n",
        "        s = s[:-1]\n",
        "\n",
        "    # Drop units right after a slash: /hr, /dogs\n",
        "    s = re.sub(r'/([a-zA-Z]+)', '', s)\n",
        "\n",
        "    # Keep only numeric math tokens\n",
        "    s = re.sub(r'[^\\d.()+\\-*/=%]', '', s)\n",
        "\n",
        "    # Collapse repeated '=' (e.g., '==24/2=12' -> '=24/2=12')\n",
        "    s = re.sub(r'=+', '=', s)\n",
        "\n",
        "    return s\n",
        "\n",
        "import re, math\n",
        "\n",
        "def _parse_equation(eq_str: str):\n",
        "    s = sanitize_equation_string(eq_str or \"\")\n",
        "    s = s.lstrip('=')  # handle lines like '=24/2=12'\n",
        "    if '=' not in s:\n",
        "        return None\n",
        "    if s.count('=') > 1:\n",
        "        pos = s.rfind('=')\n",
        "        lhs, rhs = s[:pos], s[pos+1:]\n",
        "    else:\n",
        "        lhs, rhs = s.split('=', 1)\n",
        "    lhs, rhs = lhs.strip(), rhs.strip()\n",
        "    if not lhs or not rhs:\n",
        "        return None\n",
        "    return lhs, rhs\n",
        "\n",
        "def _abs_tol_from_display(rhs_str: str):\n",
        "    \"\"\"\n",
        "    If RHS is a single numeric literal like 0.33, use half-ULP at that precision.\n",
        "    e.g., '0.33' -> 0.5 * 10^-2 = 0.005\n",
        "    Otherwise return None and fall back to base tolerances.\n",
        "    \"\"\"\n",
        "    s = rhs_str.strip()\n",
        "    # allow optional parens and sign\n",
        "    m = re.fullmatch(r'\\(?\\s*[-+]?\\d+(?:\\.(\\d+))?\\s*\\)?', s)\n",
        "    if not m:\n",
        "        return None\n",
        "    frac = m.group(1) or \"\"\n",
        "    d = len(frac)\n",
        "    return 0.5 * (10 ** (-d)) if d > 0 else 0.5  # if integer shown, allow ±0.5\n",
        "\n",
        "def evaluate_equations(eq_dict: dict, sol_dict: dict,\n",
        "                       base_rel_tol: float = 1e-6,\n",
        "                       base_abs_tol: float = 1e-9,\n",
        "                       honor_display_precision: bool = True):\n",
        "    \"\"\"\n",
        "    Evaluates extracted equations. Accepts rounded RHS values based on displayed precision.\n",
        "    \"\"\"\n",
        "    for key, eq_str in (eq_dict or {}).items():\n",
        "        parsed = _parse_equation(eq_str)\n",
        "        if not parsed:\n",
        "            continue\n",
        "        lhs, rhs_str = parsed\n",
        "\n",
        "        try:\n",
        "            lhs_val = eval(lhs, {\"__builtins__\": None}, {})\n",
        "            rhs_val = eval(rhs_str, {\"__builtins__\": None}, {})\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "        # dynamic absolute tolerance from RHS formatting (e.g., 0.33 -> 0.005)\n",
        "        abs_tol = base_abs_tol\n",
        "        if honor_display_precision:\n",
        "            dyn = _abs_tol_from_display(rhs_str)\n",
        "            if dyn is not None:\n",
        "                abs_tol = max(abs_tol, dyn)\n",
        "\n",
        "        if not math.isclose(lhs_val, rhs_val, rel_tol=base_rel_tol, abs_tol=abs_tol):\n",
        "            correct_rhs_val = round(lhs_val, 6)\n",
        "            correct_rhs_str = f\"{correct_rhs_val:.6f}\".rstrip('0').rstrip('.')\n",
        "            return {\n",
        "                \"error\": True,\n",
        "                \"line_key\": key,\n",
        "                \"line_text\": sol_dict.get(key, \"N/A\"),\n",
        "                \"original_flawed_calc\": eq_str,\n",
        "                \"sanitized_lhs\": lhs,\n",
        "                \"original_rhs\": rhs_str,\n",
        "                \"correct_rhs\": correct_rhs_str,\n",
        "            }\n",
        "\n",
        "    return {\"error\": False}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def extract_json_from_response(response: str) -> dict:\n",
        "    \"\"\"\n",
        "    Recover equations from the extractor's output.\n",
        "\n",
        "    Strategy:\n",
        "      1) Try to parse a real JSON object (if present).\n",
        "      2) Parse relaxed key-value lines like 'L1: ...' or 'FA=...'.\n",
        "      3) Also fall back to linewise equations (e.g., '=24/2=12', '7*2=14') and\n",
        "         merge them as L1, L2, ... preserving order. Keep FA if present.\n",
        "    \"\"\"\n",
        "    out = {}\n",
        "\n",
        "    if not response or not isinstance(response, str):\n",
        "        return out\n",
        "\n",
        "    text = response.strip()\n",
        "\n",
        "    # --- 1) strict JSON block, if any ---\n",
        "    m = re.search(r'\\{.*\\}', text, flags=re.S)\n",
        "    if m:\n",
        "        try:\n",
        "            obj = json.loads(m.group(0))\n",
        "            if isinstance(obj, dict) and any(k.startswith(\"L\") for k in obj):\n",
        "                return obj\n",
        "            elif isinstance(obj, dict):\n",
        "                out.update(obj)  # keep FA etc., then continue\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # --- 2) relaxed key/value lines: Lk : value   or   FA = value ---\n",
        "    relaxed = {}\n",
        "    for ln in text.splitlines():\n",
        "        ln = ln.strip().strip(',')\n",
        "        if not ln:\n",
        "            continue\n",
        "        m = re.match(r'(?i)^(L\\d+|FA)\\s*[:=]\\s*(.+?)\\s*$', ln)\n",
        "        if m:\n",
        "            k = m.group(1).strip()\n",
        "            v = m.group(2).strip().rstrip(',')\n",
        "            relaxed[k] = v\n",
        "    out.update(relaxed)\n",
        "\n",
        "    # Count how many L-keys we already have\n",
        "    existing_L = sorted(\n",
        "        int(k[1:]) for k in out.keys()\n",
        "        if k.startswith(\"L\") and k[1:].isdigit()\n",
        "    )\n",
        "    next_L = (max(existing_L) + 1) if existing_L else 1\n",
        "\n",
        "    # --- 3) linewise fallback: harvest bare equations and merge ---\n",
        "    def _looks_like_equation(s: str) -> str | None:\n",
        "        s = sanitize_equation_string(s or \"\").lstrip('=')\n",
        "        if '=' in s and any(ch.isdigit() for ch in s):\n",
        "            return s\n",
        "        return None\n",
        "\n",
        "    # set of existing equation strings to avoid duplicates\n",
        "    seen_vals = set(v for v in out.values() if isinstance(v, str))\n",
        "\n",
        "    for ln in text.splitlines():\n",
        "        ln = ln.strip().strip(',')\n",
        "        if not ln or re.match(r'(?i)^(L\\d+|FA)\\s*[:=]', ln):\n",
        "            # skip lines we already captured as relaxed pairs\n",
        "            continue\n",
        "        eq = _looks_like_equation(ln)\n",
        "        if eq and eq not in seen_vals:\n",
        "            out[f\"L{next_L}\"] = eq\n",
        "            seen_vals.add(eq)\n",
        "            next_L += 1\n",
        "\n",
        "    return out\n",
        "\n",
        "########################## old functions below\n",
        "\n",
        "\n",
        "def old_sanitize_equation_string(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Enhanced version with your requested simplified parenthesis logic.\n",
        "    \"\"\"\n",
        "    if not isinstance(expression, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Your requested parenthesis logic:\n",
        "    if expression.count('(') > expression.count(')') and expression.startswith('('):\n",
        "        expression = expression[1:]\n",
        "    elif expression.count(')') > expression.count('(') and expression.endswith(')'):\n",
        "        expression = expression[:-1]\n",
        "\n",
        "    sanitized = expression.replace(' ', '')\n",
        "    sanitized = sanitized.replace('x', '*').replace('×', '*')\n",
        "    sanitized = re.sub(r'/([a-zA-Z]+)', '', sanitized)\n",
        "    sanitized = re.sub(r'[^\\d.()+\\-*/=]', '', sanitized)\n",
        "    return sanitized\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def old_evaluate_equations(eq_dict: dict, sol_dict: dict):\n",
        "    \"\"\"\n",
        "    Evaluates extracted equations and returns a more detailed dictionary for\n",
        "    building clearer explanations.\n",
        "    \"\"\"\n",
        "    for key, eq_str in eq_dict.items():\n",
        "        if not eq_str or \"=\" not in eq_str:\n",
        "            continue\n",
        "        try:\n",
        "            sanitized_eq = sanitize_equation_string(eq_str)\n",
        "\n",
        "            if not sanitized_eq or \"=\" not in sanitized_eq:\n",
        "                continue\n",
        "\n",
        "            lhs, rhs_str = sanitized_eq.split('=', 1)\n",
        "\n",
        "            if not lhs or not rhs_str:\n",
        "                continue\n",
        "\n",
        "            lhs_val = eval(lhs, {\"__builtins__\": None}, {})\n",
        "            rhs_val = eval(rhs_str, {\"__builtins__\": None}, {})\n",
        "\n",
        "            if not math.isclose(lhs_val, rhs_val, rel_tol=1e-2):\n",
        "                correct_rhs_val = round(lhs_val, 4)\n",
        "                correct_rhs_str = f\"{correct_rhs_val:.4f}\".rstrip('0').rstrip('.')\n",
        "\n",
        "                # Return a more detailed dictionary for better explanations\n",
        "                return {\n",
        "                    \"error\": True,\n",
        "                    \"line_key\": key,\n",
        "                    \"line_text\": sol_dict.get(key, \"N/A\"),\n",
        "                    \"original_flawed_calc\": eq_str, # The raw model output\n",
        "                    \"sanitized_lhs\": lhs,           # The clean left side\n",
        "                    \"original_rhs\": rhs_str,        # The clean right side\n",
        "                    \"correct_rhs\": correct_rhs_str, # The correct right side\n",
        "                }\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    return {\"error\": False}\n",
        "\n",
        "\n",
        "\n",
        "def old_extract_json_from_response(response: str) -> dict:\n",
        "    \"\"\"\n",
        "    (old version that doesnt do well)\n",
        "    Manually parses the model's output using regex instead of relying on\n",
        "    perfectly-formed JSON. This is robust to syntax errors from the LLM.\n",
        "    \"\"\"\n",
        "    # Regex to find all keys like \"L1\", \"L2\", \"FA\", etc.\n",
        "    keys = re.findall(r'\"(L\\d+|FA)\"\\s*:', response)\n",
        "\n",
        "    # Regex to find all values associated with the keys.\n",
        "    # It looks for text enclosed in double quotes.\n",
        "    values = re.findall(r':\\s*\"([^\"]*)\"', response)\n",
        "\n",
        "    # If the number of keys and values doesn't match, something is very wrong.\n",
        "    # This is a safety check.\n",
        "    if len(keys) != len(values):\n",
        "        # Fallback for cases where the format is extremely broken\n",
        "        if not keys and not values:\n",
        "            return {} # Truly empty\n",
        "        # Try to at least salvage something if possible\n",
        "        min_len = min(len(keys), len(values))\n",
        "        return dict(zip(keys[:min_len], values[:min_len]))\n",
        "\n",
        "    # Combine the extracted keys and values into a dictionary\n",
        "    return dict(zip(keys, values))\n",
        "\n",
        "def old_evaluate_equations(eq_dict: dict, sol_dict: dict, *, rel_tol=1e-6, abs_tol=1e-9):\n",
        "    \"\"\"\n",
        "    Scan equations; return the first mismatch with details, else {\"error\": False}.\n",
        "    \"\"\"\n",
        "    for key, eq_str in (eq_dict or {}).items():\n",
        "        parsed = _parse_equation(eq_str)\n",
        "        if not parsed:\n",
        "            continue\n",
        "        lhs, rhs_str = parsed\n",
        "        try:\n",
        "            lhs_val = eval(lhs, {\"__builtins__\": None}, {})\n",
        "            rhs_val = eval(rhs_str, {\"__builtins__\": None}, {})\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "        if not math.isclose(lhs_val, rhs_val, rel_tol=rel_tol, abs_tol=abs_tol):\n",
        "            correct_rhs_val = round(lhs_val, 6)\n",
        "            correct_rhs_str = f\"{correct_rhs_val:.6f}\".rstrip('0').rstrip('.')\n",
        "            return {\n",
        "                \"error\": True,\n",
        "                \"line_key\": key,\n",
        "                \"line_text\": sol_dict.get(key, \"N/A\"),\n",
        "                \"original_flawed_calc\": eq_str,\n",
        "                \"sanitized_lhs\": lhs,\n",
        "                \"original_rhs\": rhs_str,\n",
        "                \"correct_rhs\": correct_rhs_str,\n",
        "            }\n",
        "\n",
        "    return {\"error\": False}\n",
        "\n",
        "\n",
        "\n",
        "# def extract_json_from_response(response: str) -> dict:\n",
        "#     match = re.search(r'```json\\s*(\\{.*?\\})\\s*```', response, re.DOTALL)\n",
        "#     json_str = match.group(1) if match else re.search(r'(\\{.*?\\})', response, re.DOTALL)\n",
        "#     if not json_str: return {}\n",
        "#     try:\n",
        "#         return json.loads(json_str.group(0) if hasattr(json_str, 'group') else json_str)\n",
        "#     except (json.JSONDecodeError, AttributeError): return {}"
      ],
      "metadata": {
        "id": "ko7W_ooyTFgJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_analysis_pipeline(math_question, proposed_solution):\n",
        "    \"\"\"\n",
        "    Notebook version of the analysis pipeline for testing.\n",
        "    Prints progress and returns a final dictionary.\n",
        "    \"\"\"\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Testing problem: {math_question[:50]}...\")\n",
        "\n",
        "    # --- STAGE 1: COMPUTATIONAL CHECK ---\n",
        "    print(\"Step 1: Extracting equations...\")\n",
        "    solution_json_str = format_solution_into_json_str(proposed_solution)\n",
        "    messages = [{\"role\": \"user\", \"content\": f\"{EXTRACTOR_SYSTEM_PROMPT}\\n\\n### Solution:\\n{solution_json_str}\"}]\n",
        "    prompt = gemma_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "    inputs = gemma_tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
        "\n",
        "    outputs = gemma_model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=300,\n",
        "        use_cache=True,\n",
        "        pad_token_id=gemma_tokenizer.pad_token_id,\n",
        "        do_sample=False,\n",
        "        temperature=0.0,\n",
        "    )\n",
        "    extracted_text = gemma_tokenizer.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)[0]\n",
        "    extracted_eq_dict = extract_json_from_response(extracted_text)\n",
        "    print(f\"  > Extracted equations: {json.dumps(extracted_eq_dict)}\")\n",
        "\n",
        "    computational_error = evaluate_equations(extracted_eq_dict, json.loads(solution_json_str))\n",
        "\n",
        "    if computational_error[\"error\"]:\n",
        "        explanation = (\n",
        "            f\"A computational error was found.\\n\"\n",
        "            f\"On line: \\\"{computational_error['line_text']}\\\"\\n\"\n",
        "            f\"The calculation was: {computational_error['flawed_calc']}\\n\"\n",
        "            f\"The correct calculation should be: {computational_error['correct_calc']}\"\n",
        "        )\n",
        "        return {\"classification\": \"Computational Error\", \"confidence\": \"100%\", \"explanation\": explanation}\n",
        "\n",
        "    # --- STAGE 2: CONCEPTUAL CHECK ---\n",
        "    print(\"\\nStep 2: Checking for conceptual errors...\")\n",
        "    input_text = f\"{CLASSIFIER_SYSTEM_PROMPT}\\n\\n### Problem:\\n{math_question}\\n\\n### Answer:\\n{proposed_solution}\"\n",
        "    inputs = classifier_tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = classifier_model(**inputs)\n",
        "        logits = outputs[\"logits\"]\n",
        "        probs = torch.softmax(logits, dim=-1).squeeze().tolist()\n",
        "        print(f\"  > Raw probabilities [Correct, Flawed]: {probs}\")\n",
        "\n",
        "    is_flawed_prob = probs[1]\n",
        "    is_correct_prob = probs[0]\n",
        "\n",
        "    if is_flawed_prob > 0.5:\n",
        "        return {\"classification\": \"Conceptual Error\", \"confidence\": f\"{is_flawed_prob:.2%}\", \"explanation\": \"Logic or setup appears to have a conceptual error.\"}\n",
        "    else:\n",
        "        return {\"classification\": \"Correct\", \"confidence\": f\"{is_correct_prob:.2%}\", \"explanation\": \"Solution appears correct.\"}"
      ],
      "metadata": {
        "id": "UFB3JRXdTvgs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def debug_analysis_pipeline(math_question, proposed_solution):\n",
        "    \"\"\"\n",
        "    (Complete, Refactored Version)\n",
        "    Orchestrates the pipeline by calling helper functions and printing the\n",
        "    inputs/outputs at each stage for clear debugging.\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(f\"🕵️  STARTING DEBUG FOR: {math_question[:60]}...\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # ===================================================================\n",
        "    # --- STAGE 1: COMPUTATIONAL CHECK (GEMMA MODEL) ---\n",
        "    # ===================================================================\n",
        "    stage1_start_time = time.monotonic()\n",
        "    print(\"\\n--- STAGE 1: Equation Extraction (Gemma) ---\")\n",
        "\n",
        "    # [1.1] Format the solution\n",
        "    print(\"\\n[1.1] Calling format_solution_into_json_str...\")\n",
        "    solution_json_str = format_solution_into_json_str(proposed_solution)\n",
        "    solution_dict = json.loads(solution_json_str)\n",
        "    print(\"  > Output:\")\n",
        "    print(solution_json_str)\n",
        "\n",
        "    # [1.2] Build the message list using the new helper function\n",
        "    print(\"\\n[1.2] Calling create_extractor_messages...\")\n",
        "    messages = create_extractor_messages(solution_json_str)\n",
        "    print(f\"  > Output: Generated a list of {len(messages)} messages.\")\n",
        "\n",
        "    # [1.3] Apply the chat template to create the full prompt string\n",
        "    prompt = gemma_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    print(\"\\n[1.3] Full Prompt for Gemma Model (with few-shot examples):\")\n",
        "    print(\"--------------------\")\n",
        "    print(prompt)\n",
        "    print(\"--------------------\")\n",
        "\n",
        "    # [1.4] Run inference with the Gemma model\n",
        "    inputs = gemma_tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
        "\n",
        "    outputs = gemma_model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=300,\n",
        "        use_cache=True,\n",
        "        pad_token_id=gemma_tokenizer.pad_token_id,\n",
        "        do_sample=False,\n",
        "        temperature=0.0,\n",
        "    )\n",
        "\n",
        "\n",
        "    extracted_text = gemma_tokenizer.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)[0]\n",
        "\n",
        "    print(\"\\n[1.4] Raw Text Output from Gemma Model:\")\n",
        "    print(\"--------------------\")\n",
        "    print(extracted_text)\n",
        "    print(\"--------------------\")\n",
        "\n",
        "    # [1.5] Parse the raw text using the robust regex-based function\n",
        "    print(\"\\n[1.5] Calling extract_json_from_response...\")\n",
        "    extracted_eq_dict = extract_json_from_response(extracted_text)\n",
        "    print(\"  > Output (Parsed JSON dict):\")\n",
        "    print(json.dumps(extracted_eq_dict, indent=2))\n",
        "\n",
        "    # [1.6] Filter out equations for lines that contain no digits\n",
        "    print(\"\\n[1.6] Filtering out equations for non-numeric lines:\")\n",
        "    final_eq_to_eval = {}\n",
        "    for key, eq_str in extracted_eq_dict.items():\n",
        "        original_line = solution_dict.get(key, \"\")\n",
        "        if any(char.isdigit() for char in original_line):\n",
        "            final_eq_to_eval[key] = eq_str\n",
        "        else:\n",
        "            print(f\"  > Line '{key}' has no digits. Discarding extracted equation: '{eq_str}'\")\n",
        "    print(\"  > Final equations to be evaluated:\", json.dumps(final_eq_to_eval, indent=2))\n",
        "\n",
        "    # [1.7] Evaluate the final, filtered set of equations\n",
        "    print(\"\\n[1.7] Calling evaluate_equations...\")\n",
        "    computational_error = evaluate_equations(final_eq_to_eval, solution_dict)\n",
        "    stage1_end_time = time.monotonic()\n",
        "    print(f\"  > Output (Latency: {stage1_end_time - stage1_start_time:.2f}s):\")\n",
        "    print(f\"  > {computational_error}\")\n",
        "\n",
        "    # [1.8] Check the result and exit if a computational error was found\n",
        "    if computational_error[\"error\"]:\n",
        "        print(\"\\n  > 🔴 Error Found!\")\n",
        "        lhs, rhs, correct_rhs = computational_error['sanitized_lhs'], computational_error['original_rhs'], computational_error['correct_rhs']\n",
        "        explanation = f\"A computational error was found.\\nOn line: \\\"{computational_error['line_text']}\\\"\\nThe student wrote '{lhs} = {rhs}', but the correct result of '{lhs}' is {correct_rhs}.\"\n",
        "        final_result = {\"classification\": \"Computational Error\", \"confidence\": \"100%\", \"explanation\": explanation}\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\"🏁 FINAL RESULT: {final_result['classification']}\")\n",
        "        print(\"=\"*80 + \"\\n\\n\")\n",
        "        return final_result\n",
        "    else:\n",
        "        print(\"\\n  > ✅ All calculations are correct. Proceeding to Stage 2.\")\n",
        "\n",
        "    # ===================================================================\n",
        "    # --- STAGE 2: CONCEPTUAL CHECK (PHI-4 MODEL) ---\n",
        "    # ===================================================================\n",
        "    stage2_start_time = time.monotonic()\n",
        "    print(\"\\n\\n--- STAGE 2: Conceptual Check (Phi-4) ---\")\n",
        "\n",
        "    # [2.1] Create the prompt for the Phi-4 model\n",
        "    input_text = f\"{CLASSIFIER_SYSTEM_PROMPT}\\n\\n### Problem:\\n{math_question}\\n\\n### Answer:\\n{proposed_solution}\"\n",
        "    print(\"\\n[2.1] Full Prompt for Phi-4 Model:\")\n",
        "    print(\"--------------------\")\n",
        "    print(input_text)\n",
        "    print(\"--------------------\")\n",
        "\n",
        "    # [2.2] Run inference with the Phi-4 model\n",
        "    inputs = classifier_tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = classifier_model(**inputs)\n",
        "        logits = outputs[\"logits\"]\n",
        "        probs = torch.softmax(logits, dim=-1).squeeze().tolist()\n",
        "\n",
        "    # [2.3] Display the model's raw outputs\n",
        "    print(f\"\\n[2.3] Raw Logits from Phi-4 Model: {logits.to(torch.float32).cpu().numpy()}\")\n",
        "    print(f\"\\n[2.4] Softmax Probabilities [Correct, Flawed]: {probs}\")\n",
        "\n",
        "    # [2.5] Determine the final classification based on the probabilities\n",
        "    stage2_end_time = time.monotonic()\n",
        "    print(f\"\\n[2.5] Final Decision Logic (Latency: {stage2_end_time - stage2_start_time:.2f}s):\")\n",
        "\n",
        "    is_flawed_prob = probs[1]\n",
        "    is_correct_prob = probs[0]\n",
        "\n",
        "    if is_flawed_prob > 0.5:\n",
        "        print(f\"  > Flawed probability ({is_flawed_prob:.2%}) is > 50%.\")\n",
        "        final_result = {\"classification\": \"Conceptual Error\", \"confidence\": f\"{is_flawed_prob:.2%}\", \"explanation\": \"Logic or setup appears to have a conceptual error.\"}\n",
        "    else:\n",
        "        print(f\"  > Correct probability ({is_correct_prob:.2%}) is > 50%.\")\n",
        "        final_result = {\"classification\": \"Correct\", \"confidence\": f\"{is_correct_prob:.2%}\", \"explanation\": \"Solution appears correct.\"}\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"🏁 FINAL RESULT: {final_result['classification']}\")\n",
        "    print(\"=\"*80 + \"\\n\\n\")\n",
        "    return final_result"
      ],
      "metadata": {
        "id": "rCrJoCH2dnOj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_cases = [\n",
        "    {\n",
        "        \"name\": \"Computational Error\",\n",
        "        \"question\": \"John has three apples and Mary has seven, how many apples do they have together?\",\n",
        "        \"solution\": \"They have 7 + 3 = 11 apples.\\nFINAL ANSWER: 11\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Correct Solution\",\n",
        "        \"question\": \"A grocery store sells apples for $0.50 each and oranges for $0.75 each. If a customer buys 10 apples and 5 oranges, what is the total cost?\",\n",
        "        \"solution\": \"Apple cost: 10 * 0.50 = 5.00\\nOrange cost: 5 * 0.75 = 3.75\\nTotal cost: 5.00 + 3.75 = 8.75\\nFINAL ANSWER: 8.75\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Conceptual Error\",\n",
        "        \"question\": \"A car travels at 60 miles per hour. How long will it take to travel 180 miles?\",\n",
        "        \"solution\": \"Time = Speed / Distance\\nTime = 60 / 180 = 0.33 hours\\nFINAL ANSWER: 0.33\"\n",
        "    }\n",
        "]\n",
        "\n",
        "for test in test_cases:\n",
        "    result = debug_analysis_pipeline(test[\"question\"], test[\"solution\"])\n",
        "    print(\"\\n--- FINAL RESULT ---\")\n",
        "    print(f\"Case: {test['name']}\")\n",
        "    print(f\"Classification: {result['classification']}\")\n",
        "    print(f\"Confidence: {result['confidence']}\")\n",
        "    print(f\"Explanation: {result['explanation']}\")\n",
        "    print(\"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypuadbs-Tya5",
        "outputId": "9d9fb125-465c-450f-8800-f197ca3d6a9e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "🕵️  STARTING DEBUG FOR: John has three apples and Mary has seven, how many apples do...\n",
            "================================================================================\n",
            "\n",
            "--- STAGE 1: Equation Extraction (Gemma) ---\n",
            "\n",
            "[1.1] Calling format_solution_into_json_str...\n",
            "  > Output:\n",
            "{\n",
            "  \"L1\": \"They have 7 + 3 = 11 apples.\",\n",
            "  \"FA\": \"11\"\n",
            "}\n",
            "\n",
            "[1.2] Calling create_extractor_messages...\n",
            "  > Output: Generated a list of 5 messages.\n",
            "\n",
            "[1.3] Full Prompt for Gemma Model (with few-shot examples):\n",
            "--------------------\n",
            "<bos><start_of_turn>user\n",
            "[ROLE]\n",
            "You are an expert at parsing mathematical solutions.\n",
            "[TASK]\n",
            "You are given a mathematical solution. Your task is to extract the calculation performed on each line and represent it as a simple equation.\n",
            "**This is a literal transcription task. Follow these rules with extreme precision:**\n",
            "- **RULE 1: Transcribe EXACTLY.** Do not correct mathematical errors. If a line implies `2+2=5`, your output for that line must be `2+2=5`.\n",
            "- **RULE 2: Isolate the Equation.** Your output must contain ONLY the equation. Do not include any surrounding text, units (like `/hour`), or currency symbols (like `$`).\n",
            "- **RULE 3: Use Standard Operators.** Always use `*` for multiplication. Never use `x`.\n",
            "[RESPONSE FORMAT]\n",
            "Your response must be ONLY a single, valid JSON object, adhering strictly to these rules:\n",
            "For each line of the solution, create a key-value pair.\n",
            "- The key should be the line identifier (e.g., \"L1\", \"L2\", \"FA\" for the final answer line).\n",
            "- The value should be the extracted equation string (e.g., \"10+5=15\").\n",
            "- If a line contains no calculation, the value must be an empty string.\n",
            "\n",
            "\n",
            "### Solution:\n",
            "{\n",
            "  \"L1\": \"2% of $90 is (2/100)*$90 = $1.8\",\n",
            "  \"L2\": \"2% of $60 is (2/100)*$60 = $1.2\",\n",
            "  \"L3\": \"The second transaction was reversed without the service charge so only a total of $90+$1.8+$1.2 = $39 was deducted from his account\",\n",
            "  \"L4\": \"He will have a balance of $400-$39 = $361\",\n",
            "  \"FA\": \"361\"\n",
            "}<end_of_turn>\n",
            "<start_of_turn>model\n",
            "{\n",
            "  \"L1\": \"(2/100)*90=1.8\",\n",
            "  \"L2\": \"(2/100)*60=1.2\",\n",
            "  \"L3\": \"90+1.8+1.2=39\",\n",
            "  \"L4\": \"400-39=361\",\n",
            "  \"FA\": \"\"\n",
            "}<end_of_turn>\n",
            "<start_of_turn>user\n",
            "### Solution:\n",
            "{\n",
            "  \"L1\": \"She drinks 2 bottles a day and there are 24 bottles in a case so a case will last 24/2 = 12 days\",\n",
            "  \"L2\": \"She needs enough to last her 240 days and 1 case will last her 12 days so she needs 240/12 = 20 cases\",\n",
            "  \"L3\": \"Each case is on sale for $12.00 and she needs 20 cases so that's 12*20 = $240.00\",\n",
            "  \"FA\": \"240\"\n",
            "}<end_of_turn>\n",
            "<start_of_turn>model\n",
            "{\n",
            "  \"L1\": \"24/2=12\",\n",
            "  \"L2\": \"240/12=20\",\n",
            "  \"L3\": \"12*20=240.00\",\n",
            "  \"FA\": \"\"\n",
            "}<end_of_turn>\n",
            "<start_of_turn>user\n",
            "### Solution:\n",
            "{\n",
            "  \"L1\": \"They have 7 + 3 = 11 apples.\",\n",
            "  \"FA\": \"11\"\n",
            "}<end_of_turn>\n",
            "<start_of_turn>model\n",
            "\n",
            "--------------------\n",
            "\n",
            "[1.4] Raw Text Output from Gemma Model:\n",
            "--------------------\n",
            "{\n",
            "  \"L1\": \"7+3=11\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "--------------------\n",
            "\n",
            "[1.5] Calling extract_json_from_response...\n",
            "  > Output (Parsed JSON dict):\n",
            "{\n",
            "  \"L1\": \"7+3=11\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "[1.6] Filtering out equations for non-numeric lines:\n",
            "  > Final equations to be evaluated: {\n",
            "  \"L1\": \"7+3=11\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "[1.7] Calling evaluate_equations...\n",
            "  > Output (Latency: 27.64s):\n",
            "  > {'error': True, 'line_key': 'L1', 'line_text': 'They have 7 + 3 = 11 apples.', 'original_flawed_calc': '7+3=11', 'sanitized_lhs': '7+3', 'original_rhs': '11', 'correct_rhs': '10'}\n",
            "\n",
            "  > 🔴 Error Found!\n",
            "\n",
            "================================================================================\n",
            "🏁 FINAL RESULT: Computational Error\n",
            "================================================================================\n",
            "\n",
            "\n",
            "\n",
            "--- FINAL RESULT ---\n",
            "Case: Computational Error\n",
            "Classification: Computational Error\n",
            "Confidence: 100%\n",
            "Explanation: A computational error was found.\n",
            "On line: \"They have 7 + 3 = 11 apples.\"\n",
            "The student wrote '7+3 = 11', but the correct result of '7+3' is 10.\n",
            "==================================================\n",
            "\n",
            "================================================================================\n",
            "🕵️  STARTING DEBUG FOR: A grocery store sells apples for $0.50 each and oranges for ...\n",
            "================================================================================\n",
            "\n",
            "--- STAGE 1: Equation Extraction (Gemma) ---\n",
            "\n",
            "[1.1] Calling format_solution_into_json_str...\n",
            "  > Output:\n",
            "{\n",
            "  \"L1\": \"Apple cost: 10 * 0.50 = 5.00\",\n",
            "  \"L2\": \"Orange cost: 5 * 0.75 = 3.75\",\n",
            "  \"L3\": \"Total cost: 5.00 + 3.75 = 8.75\",\n",
            "  \"FA\": \"8.75\"\n",
            "}\n",
            "\n",
            "[1.2] Calling create_extractor_messages...\n",
            "  > Output: Generated a list of 5 messages.\n",
            "\n",
            "[1.3] Full Prompt for Gemma Model (with few-shot examples):\n",
            "--------------------\n",
            "<bos><start_of_turn>user\n",
            "[ROLE]\n",
            "You are an expert at parsing mathematical solutions.\n",
            "[TASK]\n",
            "You are given a mathematical solution. Your task is to extract the calculation performed on each line and represent it as a simple equation.\n",
            "**This is a literal transcription task. Follow these rules with extreme precision:**\n",
            "- **RULE 1: Transcribe EXACTLY.** Do not correct mathematical errors. If a line implies `2+2=5`, your output for that line must be `2+2=5`.\n",
            "- **RULE 2: Isolate the Equation.** Your output must contain ONLY the equation. Do not include any surrounding text, units (like `/hour`), or currency symbols (like `$`).\n",
            "- **RULE 3: Use Standard Operators.** Always use `*` for multiplication. Never use `x`.\n",
            "[RESPONSE FORMAT]\n",
            "Your response must be ONLY a single, valid JSON object, adhering strictly to these rules:\n",
            "For each line of the solution, create a key-value pair.\n",
            "- The key should be the line identifier (e.g., \"L1\", \"L2\", \"FA\" for the final answer line).\n",
            "- The value should be the extracted equation string (e.g., \"10+5=15\").\n",
            "- If a line contains no calculation, the value must be an empty string.\n",
            "\n",
            "\n",
            "### Solution:\n",
            "{\n",
            "  \"L1\": \"2% of $90 is (2/100)*$90 = $1.8\",\n",
            "  \"L2\": \"2% of $60 is (2/100)*$60 = $1.2\",\n",
            "  \"L3\": \"The second transaction was reversed without the service charge so only a total of $90+$1.8+$1.2 = $39 was deducted from his account\",\n",
            "  \"L4\": \"He will have a balance of $400-$39 = $361\",\n",
            "  \"FA\": \"361\"\n",
            "}<end_of_turn>\n",
            "<start_of_turn>model\n",
            "{\n",
            "  \"L1\": \"(2/100)*90=1.8\",\n",
            "  \"L2\": \"(2/100)*60=1.2\",\n",
            "  \"L3\": \"90+1.8+1.2=39\",\n",
            "  \"L4\": \"400-39=361\",\n",
            "  \"FA\": \"\"\n",
            "}<end_of_turn>\n",
            "<start_of_turn>user\n",
            "### Solution:\n",
            "{\n",
            "  \"L1\": \"She drinks 2 bottles a day and there are 24 bottles in a case so a case will last 24/2 = 12 days\",\n",
            "  \"L2\": \"She needs enough to last her 240 days and 1 case will last her 12 days so she needs 240/12 = 20 cases\",\n",
            "  \"L3\": \"Each case is on sale for $12.00 and she needs 20 cases so that's 12*20 = $240.00\",\n",
            "  \"FA\": \"240\"\n",
            "}<end_of_turn>\n",
            "<start_of_turn>model\n",
            "{\n",
            "  \"L1\": \"24/2=12\",\n",
            "  \"L2\": \"240/12=20\",\n",
            "  \"L3\": \"12*20=240.00\",\n",
            "  \"FA\": \"\"\n",
            "}<end_of_turn>\n",
            "<start_of_turn>user\n",
            "### Solution:\n",
            "{\n",
            "  \"L1\": \"Apple cost: 10 * 0.50 = 5.00\",\n",
            "  \"L2\": \"Orange cost: 5 * 0.75 = 3.75\",\n",
            "  \"L3\": \"Total cost: 5.00 + 3.75 = 8.75\",\n",
            "  \"FA\": \"8.75\"\n",
            "}<end_of_turn>\n",
            "<start_of_turn>model\n",
            "\n",
            "--------------------\n",
            "\n",
            "[1.4] Raw Text Output from Gemma Model:\n",
            "--------------------\n",
            "{\n",
            "  \"L1\": \"10*0.50=5.00\",\n",
            "  \"L2\": \"5*0.75=3.75\",\n",
            "  \"L3\": \"5+3.75=8.75\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "--------------------\n",
            "\n",
            "[1.5] Calling extract_json_from_response...\n",
            "  > Output (Parsed JSON dict):\n",
            "{\n",
            "  \"L1\": \"10*0.50=5.00\",\n",
            "  \"L2\": \"5*0.75=3.75\",\n",
            "  \"L3\": \"5+3.75=8.75\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "[1.6] Filtering out equations for non-numeric lines:\n",
            "  > Final equations to be evaluated: {\n",
            "  \"L1\": \"10*0.50=5.00\",\n",
            "  \"L2\": \"5*0.75=3.75\",\n",
            "  \"L3\": \"5+3.75=8.75\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "[1.7] Calling evaluate_equations...\n",
            "  > Output (Latency: 10.56s):\n",
            "  > {'error': False}\n",
            "\n",
            "  > ✅ All calculations are correct. Proceeding to Stage 2.\n",
            "\n",
            "\n",
            "--- STAGE 2: Conceptual Check (Phi-4) ---\n",
            "\n",
            "[2.1] Full Prompt for Phi-4 Model:\n",
            "--------------------\n",
            "You are a mathematics tutor.\n",
            "You will be given a math word problem and a solution written by a student.\n",
            "Carefully analyze the problem and solution LINE-BY-LINE and determine whether there are any errors in the solution.\n",
            "\n",
            "### Problem:\n",
            "A grocery store sells apples for $0.50 each and oranges for $0.75 each. If a customer buys 10 apples and 5 oranges, what is the total cost?\n",
            "\n",
            "### Answer:\n",
            "Apple cost: 10 * 0.50 = 5.00\n",
            "Orange cost: 5 * 0.75 = 3.75\n",
            "Total cost: 5.00 + 3.75 = 8.75\n",
            "FINAL ANSWER: 8.75\n",
            "--------------------\n",
            "\n",
            "[2.3] Raw Logits from Phi-4 Model: [[ 2.421875 -3.546875]]\n",
            "\n",
            "[2.4] Softmax Probabilities [Correct, Flawed]: [0.99609375, 0.0025482177734375]\n",
            "\n",
            "[2.5] Final Decision Logic (Latency: 0.33s):\n",
            "  > Correct probability (99.61%) is > 50%.\n",
            "\n",
            "================================================================================\n",
            "🏁 FINAL RESULT: Correct\n",
            "================================================================================\n",
            "\n",
            "\n",
            "\n",
            "--- FINAL RESULT ---\n",
            "Case: Correct Solution\n",
            "Classification: Correct\n",
            "Confidence: 99.61%\n",
            "Explanation: Solution appears correct.\n",
            "==================================================\n",
            "\n",
            "================================================================================\n",
            "🕵️  STARTING DEBUG FOR: A car travels at 60 miles per hour. How long will it take to...\n",
            "================================================================================\n",
            "\n",
            "--- STAGE 1: Equation Extraction (Gemma) ---\n",
            "\n",
            "[1.1] Calling format_solution_into_json_str...\n",
            "  > Output:\n",
            "{\n",
            "  \"L1\": \"Time = Speed / Distance\",\n",
            "  \"L2\": \"Time = 60 / 180 = 0.33 hours\",\n",
            "  \"FA\": \"0.33\"\n",
            "}\n",
            "\n",
            "[1.2] Calling create_extractor_messages...\n",
            "  > Output: Generated a list of 5 messages.\n",
            "\n",
            "[1.3] Full Prompt for Gemma Model (with few-shot examples):\n",
            "--------------------\n",
            "<bos><start_of_turn>user\n",
            "[ROLE]\n",
            "You are an expert at parsing mathematical solutions.\n",
            "[TASK]\n",
            "You are given a mathematical solution. Your task is to extract the calculation performed on each line and represent it as a simple equation.\n",
            "**This is a literal transcription task. Follow these rules with extreme precision:**\n",
            "- **RULE 1: Transcribe EXACTLY.** Do not correct mathematical errors. If a line implies `2+2=5`, your output for that line must be `2+2=5`.\n",
            "- **RULE 2: Isolate the Equation.** Your output must contain ONLY the equation. Do not include any surrounding text, units (like `/hour`), or currency symbols (like `$`).\n",
            "- **RULE 3: Use Standard Operators.** Always use `*` for multiplication. Never use `x`.\n",
            "[RESPONSE FORMAT]\n",
            "Your response must be ONLY a single, valid JSON object, adhering strictly to these rules:\n",
            "For each line of the solution, create a key-value pair.\n",
            "- The key should be the line identifier (e.g., \"L1\", \"L2\", \"FA\" for the final answer line).\n",
            "- The value should be the extracted equation string (e.g., \"10+5=15\").\n",
            "- If a line contains no calculation, the value must be an empty string.\n",
            "\n",
            "\n",
            "### Solution:\n",
            "{\n",
            "  \"L1\": \"2% of $90 is (2/100)*$90 = $1.8\",\n",
            "  \"L2\": \"2% of $60 is (2/100)*$60 = $1.2\",\n",
            "  \"L3\": \"The second transaction was reversed without the service charge so only a total of $90+$1.8+$1.2 = $39 was deducted from his account\",\n",
            "  \"L4\": \"He will have a balance of $400-$39 = $361\",\n",
            "  \"FA\": \"361\"\n",
            "}<end_of_turn>\n",
            "<start_of_turn>model\n",
            "{\n",
            "  \"L1\": \"(2/100)*90=1.8\",\n",
            "  \"L2\": \"(2/100)*60=1.2\",\n",
            "  \"L3\": \"90+1.8+1.2=39\",\n",
            "  \"L4\": \"400-39=361\",\n",
            "  \"FA\": \"\"\n",
            "}<end_of_turn>\n",
            "<start_of_turn>user\n",
            "### Solution:\n",
            "{\n",
            "  \"L1\": \"She drinks 2 bottles a day and there are 24 bottles in a case so a case will last 24/2 = 12 days\",\n",
            "  \"L2\": \"She needs enough to last her 240 days and 1 case will last her 12 days so she needs 240/12 = 20 cases\",\n",
            "  \"L3\": \"Each case is on sale for $12.00 and she needs 20 cases so that's 12*20 = $240.00\",\n",
            "  \"FA\": \"240\"\n",
            "}<end_of_turn>\n",
            "<start_of_turn>model\n",
            "{\n",
            "  \"L1\": \"24/2=12\",\n",
            "  \"L2\": \"240/12=20\",\n",
            "  \"L3\": \"12*20=240.00\",\n",
            "  \"FA\": \"\"\n",
            "}<end_of_turn>\n",
            "<start_of_turn>user\n",
            "### Solution:\n",
            "{\n",
            "  \"L1\": \"Time = Speed / Distance\",\n",
            "  \"L2\": \"Time = 60 / 180 = 0.33 hours\",\n",
            "  \"FA\": \"0.33\"\n",
            "}<end_of_turn>\n",
            "<start_of_turn>model\n",
            "\n",
            "--------------------\n",
            "\n",
            "[1.4] Raw Text Output from Gemma Model:\n",
            "--------------------\n",
            "{\n",
            "  \"L1\": \"Time=Speed/Distance\",\n",
            "  \"L2\": \"60/180=0.33\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "--------------------\n",
            "\n",
            "[1.5] Calling extract_json_from_response...\n",
            "  > Output (Parsed JSON dict):\n",
            "{\n",
            "  \"L1\": \"Time=Speed/Distance\",\n",
            "  \"L2\": \"60/180=0.33\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "[1.6] Filtering out equations for non-numeric lines:\n",
            "  > Line 'L1' has no digits. Discarding extracted equation: 'Time=Speed/Distance'\n",
            "  > Final equations to be evaluated: {\n",
            "  \"L2\": \"60/180=0.33\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "[1.7] Calling evaluate_equations...\n",
            "  > Output (Latency: 6.47s):\n",
            "  > {'error': False}\n",
            "\n",
            "  > ✅ All calculations are correct. Proceeding to Stage 2.\n",
            "\n",
            "\n",
            "--- STAGE 2: Conceptual Check (Phi-4) ---\n",
            "\n",
            "[2.1] Full Prompt for Phi-4 Model:\n",
            "--------------------\n",
            "You are a mathematics tutor.\n",
            "You will be given a math word problem and a solution written by a student.\n",
            "Carefully analyze the problem and solution LINE-BY-LINE and determine whether there are any errors in the solution.\n",
            "\n",
            "### Problem:\n",
            "A car travels at 60 miles per hour. How long will it take to travel 180 miles?\n",
            "\n",
            "### Answer:\n",
            "Time = Speed / Distance\n",
            "Time = 60 / 180 = 0.33 hours\n",
            "FINAL ANSWER: 0.33\n",
            "--------------------\n",
            "\n",
            "[2.3] Raw Logits from Phi-4 Model: [[-7.      5.9375]]\n",
            "\n",
            "[2.4] Softmax Probabilities [Correct, Flawed]: [2.3990869522094727e-06, 1.0]\n",
            "\n",
            "[2.5] Final Decision Logic (Latency: 0.11s):\n",
            "  > Flawed probability (100.00%) is > 50%.\n",
            "\n",
            "================================================================================\n",
            "🏁 FINAL RESULT: Conceptual Error\n",
            "================================================================================\n",
            "\n",
            "\n",
            "\n",
            "--- FINAL RESULT ---\n",
            "Case: Conceptual Error\n",
            "Classification: Conceptual Error\n",
            "Confidence: 100.00%\n",
            "Explanation: Logic or setup appears to have a conceptual error.\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "import json\n",
        "import torch\n",
        "\n",
        "def run_batch_evaluation(df: pd.DataFrame, batch_size: int = 24) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Performs a full, timed, batched evaluation of the two-stage pipeline.\n",
        "\n",
        "    Args:\n",
        "        df: The input DataFrame with columns 'index', 'question', 'correct_answer',\n",
        "            'wrong_answer', and 'error_type'.\n",
        "        batch_size: The number of samples to process in each batch.\n",
        "\n",
        "    Returns:\n",
        "        A pandas DataFrame containing detailed results and metadata for each test sample.\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"🚀 Starting Batch Evaluation...\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    overall_start_time = time.monotonic()\n",
        "\n",
        "    # 1. Double the test set by preparing correct and incorrect samples\n",
        "    print(f\"[1/5] Preparing {len(df) * 2} test samples...\")\n",
        "    prepared_samples = []\n",
        "    for _, row in df.iterrows():\n",
        "        # Case 1: The correct solution\n",
        "        prepared_samples.append({\n",
        "            'original_index': row['index'],\n",
        "            'question': row['question'],\n",
        "            'solution': row['correct_answer'],\n",
        "            'true_label': 'Correct'\n",
        "        })\n",
        "        # Case 2: The flawed solution\n",
        "        error_map = {'comp': 'Computational Error', 'concep': 'Conceptual Error'}\n",
        "        prepared_samples.append({\n",
        "            'original_index': row['index'],\n",
        "            'question': row['question'],\n",
        "            'solution': row['wrong_answer'],\n",
        "            'true_label': error_map.get(row['error_type'], 'Unknown Error')\n",
        "        })\n",
        "\n",
        "    # ===================================================================\n",
        "    # --- STAGE 1: BATCHED EQUATION EXTRACTION (GEMMA) ---\n",
        "    # ===================================================================\n",
        "    print(f\"[2/5] Running Stage 1 (Gemma Equation Extraction) on {len(prepared_samples)} samples...\")\n",
        "    stage1_start_time = time.monotonic()\n",
        "\n",
        "    # Generate all prompts for Stage 1 first\n",
        "    gemma_prompts = []\n",
        "    for sample in prepared_samples:\n",
        "        solution_json_str = format_solution_into_json_str(sample['solution'])\n",
        "        messages = create_extractor_messages(solution_json_str)\n",
        "        gemma_prompts.append(gemma_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True))\n",
        "\n",
        "    # Run batched inference\n",
        "    gemma_raw_outputs = []\n",
        "    for i in tqdm(range(0, len(gemma_prompts), batch_size), desc=\"Stage 1 Batches\"):\n",
        "        batch_prompts = gemma_prompts[i:i + batch_size]\n",
        "        inputs = gemma_tokenizer(batch_prompts, return_tensors=\"pt\", padding=True).to(device)\n",
        "        outputs = gemma_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=300,\n",
        "            use_cache=True,\n",
        "            pad_token_id=gemma_tokenizer.pad_token_id,\n",
        "            eos_token_id=gemma_tokenizer.eos_token_id,\n",
        "            do_sample=False,      # deterministic\n",
        "            temperature=0.0\n",
        "        )\n",
        "        # Decode only the newly generated tokens\n",
        "        decoded_outputs = gemma_tokenizer.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
        "        gemma_raw_outputs.extend(decoded_outputs)\n",
        "\n",
        "    stage1_latency = time.monotonic() - stage1_start_time\n",
        "\n",
        "\n",
        "    try:\n",
        "        del inputs, outputs, decoded_outputs\n",
        "    except NameError:\n",
        "        pass\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    # ===================================================================\n",
        "    # --- STAGE 1 POST-PROCESSING & STAGE 2 PREPARATION ---\n",
        "    # ===================================================================\n",
        "    print(f\"[3/5] Processing Stage 1 results and preparing Stage 2 batch...\")\n",
        "\n",
        "    results_data = []\n",
        "    stage2_batch = [] # This will hold only the samples that need conceptual checking\n",
        "\n",
        "    for i, sample in enumerate(prepared_samples):\n",
        "        # Initial data entry\n",
        "        result_entry = {\n",
        "            'original_index': sample['original_index'],\n",
        "            'question': sample['question'],\n",
        "            'solution': sample['solution'],\n",
        "            'true_label': sample['true_label'],\n",
        "            'gemma_raw_output': gemma_raw_outputs[i]\n",
        "        }\n",
        "\n",
        "        # Process Gemma's output\n",
        "        extracted_eq_dict = extract_json_from_response(gemma_raw_outputs[i])\n",
        "        result_entry['extracted_json_str'] = json.dumps(extracted_eq_dict)\n",
        "\n",
        "        # Filter and evaluate\n",
        "        solution_dict = json.loads(format_solution_into_json_str(sample['solution']))\n",
        "        final_eq_to_eval = {\n",
        "            k: v for k, v in extracted_eq_dict.items()\n",
        "            if any(char.isdigit() for char in solution_dict.get(k, \"\"))\n",
        "        }\n",
        "        computational_error = evaluate_equations(final_eq_to_eval, solution_dict)\n",
        "\n",
        "        # Make a decision: stop or proceed to Stage 2\n",
        "        if computational_error[\"error\"]:\n",
        "            result_entry['predicted_classification'] = 'Computational Error'\n",
        "            result_entry['pipeline_stage_stopped'] = 1\n",
        "        else:\n",
        "            result_entry['predicted_classification'] = None # Placeholder\n",
        "            result_entry['pipeline_stage_stopped'] = 2\n",
        "            # This sample needs to go to Stage 2. We store its prompt and its index in the main results list.\n",
        "            stage2_batch.append({\n",
        "                'prompt': f\"{CLASSIFIER_SYSTEM_PROMPT}\\n\\n### Problem:\\n{sample['question']}\\n\\n### Answer:\\n{sample['solution']}\",\n",
        "                'result_index': i\n",
        "            })\n",
        "\n",
        "        results_data.append(result_entry)\n",
        "    # ===================================================================\n",
        "    # --- STAGE 2: BATCHED CONCEPTUAL CHECK (PHI-4) ---\n",
        "    # ===================================================================\n",
        "    print(f\"[4/5] Running Stage 2 (Phi-4 Conceptual Check) on {len(stage2_batch)} samples...\")\n",
        "    stage2_start_time = time.monotonic()\n",
        "\n",
        "    # Smaller batch + shorter length; keep end of prompt (tail) which matters most\n",
        "    B2 = min(24, batch_size)     # was 128; 16–24 is safe on 40GB A100\n",
        "    MAX_LEN_STAGE2 = 256\n",
        "    classifier_tokenizer.truncation_side = \"left\"\n",
        "\n",
        "    if stage2_batch:\n",
        "        phi4_prompts = [item['prompt'] for item in stage2_batch]\n",
        "        phi4_logits_list = []\n",
        "\n",
        "        for i in tqdm(range(0, len(phi4_prompts), B2), desc=\"Stage 2 Batches\"):\n",
        "            batch_prompts = phi4_prompts[i:i + B2]\n",
        "\n",
        "            inputs = classifier_tokenizer(\n",
        "                batch_prompts,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=MAX_LEN_STAGE2\n",
        "            ).to(device)\n",
        "\n",
        "            outputs = None\n",
        "            try:\n",
        "                # No cache, inference_mode: lower activation/KV memory\n",
        "                with torch.inference_mode():\n",
        "                    outputs = classifier_model(**inputs, use_cache=False)\n",
        "                phi4_logits_list.extend(outputs[\"logits\"].to(torch.float32).cpu())\n",
        "            except RuntimeError as e:\n",
        "                if \"CUDA out of memory\" in str(e):\n",
        "                    # Fallback: split batch in half and retry\n",
        "                    torch.cuda.empty_cache()\n",
        "                    mid = len(batch_prompts) // 2 or 1\n",
        "                    halves = (batch_prompts[:mid], batch_prompts[mid:])\n",
        "                    for sub in halves:\n",
        "                        sub_inputs = classifier_tokenizer(\n",
        "                            sub,\n",
        "                            return_tensors=\"pt\",\n",
        "                            padding=True,\n",
        "                            truncation=True,\n",
        "                            max_length=MAX_LEN_STAGE2\n",
        "                        ).to(device)\n",
        "                        with torch.inference_mode():\n",
        "                            sub_out = classifier_model(**sub_inputs, use_cache=False)\n",
        "                        phi4_logits_list.extend(outputs[\"logits\"].to(torch.float32).cpu())\n",
        "                        del sub_inputs, sub_out\n",
        "                        torch.cuda.empty_cache()\n",
        "                else:\n",
        "                    raise\n",
        "            finally:\n",
        "                # Clean up this batch\n",
        "                del inputs\n",
        "                if outputs is not None:\n",
        "                    del outputs\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    # Update the main results list with the Stage 2 outcomes\n",
        "    for i, item in enumerate(stage2_batch):\n",
        "        result_index = item['result_index']\n",
        "\n",
        "        # Keep the original behavior: str(np.array(...))\n",
        "        logits = phi4_logits_list[i].to(torch.float32).cpu()   # <-- cast off bf16\n",
        "        probs  = torch.softmax(logits, dim=-1).tolist()\n",
        "\n",
        "        results_data[result_index]['phi4_correct_proba'] = float(probs[0])\n",
        "        results_data[result_index]['phi4_flawed_proba']  = float(probs[1])\n",
        "        results_data[result_index]['phi4_raw_logits']    = str(logits.numpy())  # same format as before\n",
        "\n",
        "        results_data[result_index]['predicted_classification'] = (\n",
        "            'Conceptual Error' if probs[1] > 0.5 else 'Correct'\n",
        "        )\n",
        "\n",
        "\n",
        "    stage2_latency = time.monotonic() - stage2_start_time\n",
        "\n",
        "\n",
        "    # ===================================================================\n",
        "    # --- FINALIZATION ---\n",
        "    # ===================================================================\n",
        "    print(\"[5/5] Finalizing results and creating DataFrame...\")\n",
        "\n",
        "    results_df = pd.DataFrame(results_data)\n",
        "\n",
        "    overall_latency = time.monotonic() - overall_start_time\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"✅ Batch Evaluation Complete!\")\n",
        "    print(f\"  > Total Samples Processed: {len(results_df)}\")\n",
        "    print(f\"  > Overall Time: {overall_latency:.2f} seconds\")\n",
        "    print(f\"  > Avg Time per Sample: {overall_latency / len(results_df):.3f} seconds\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"  > Stage 1 Latency (Gemma): {stage1_latency:.2f} seconds\")\n",
        "    print(f\"  > Stage 2 Latency (Phi-4): {stage2_latency:.2f} seconds\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\"  > Predicted Classification Counts:\")\n",
        "    print(results_df['predicted_classification'].value_counts().to_string())\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return results_df"
      ],
      "metadata": {
        "id": "vCXxSO_Cd0Z7"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/final-test-with-wrong-answers.csv')"
      ],
      "metadata": {
        "id": "LsNk4cl7rg8J"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure all your models and helper functions are defined in previous cells\n",
        "evaluation_results_df = run_batch_evaluation(df, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570,
          "referenced_widgets": [
            "b8797998faef475bb1f4a883ab9534e8",
            "a85431e28134414d9d1c1b1ae97d3ce5",
            "3213e8cf53104b039306a7dc7762c3ce",
            "ae07d78dd7314d62896c99dd62f691b7",
            "6571be2a362f4c529ef5fd4ddcbc8db3",
            "b26d6f4d792e417783a8da311b1cf179",
            "960ee40a709b4f5cb41778508eef24f4",
            "1603c469945e4298b268aaac9a888309",
            "8b7710327d514ee2913d667781849b4c",
            "e46a00ae430446ecb0d4a8f606a0acd7",
            "160f6b474fe442b0a2898773b685ae60",
            "f6cd59da5a7c496595147b68055a65d2",
            "6ea81555d6c642a68880c0796b2bcfbf",
            "e79d1b5b9884489abe5953a51eaae9cd",
            "627241323a3f46ab936429d63f47299f",
            "2b56ef39626747e49c0a279694d3606e",
            "42054753020d4ab0996116f629589697",
            "3c98e995ed55420e85d553ddfab7bd08",
            "57d3d8b9841949c68570dbd461942181",
            "efa415be76dd40d78d9047ab07e16e26",
            "2830208b957b454f9bd946229545b871",
            "7389848a84fe4ecd9b8fb001f547baae"
          ]
        },
        "id": "-6hJubz-rhRQ",
        "outputId": "ef40e86f-7bf2-4e22-8b15-2c224bfcc1d5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "🚀 Starting Batch Evaluation...\n",
            "================================================================================\n",
            "[1/5] Preparing 302 test samples...\n",
            "[2/5] Running Stage 1 (Gemma Equation Extraction) on 302 samples...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Stage 1 Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8797998faef475bb1f4a883ab9534e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3/5] Processing Stage 1 results and preparing Stage 2 batch...\n",
            "[4/5] Running Stage 2 (Phi-4 Conceptual Check) on 192 samples...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Stage 2 Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6cd59da5a7c496595147b68055a65d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5/5] Finalizing results and creating DataFrame...\n",
            "\n",
            "================================================================================\n",
            "✅ Batch Evaluation Complete!\n",
            "  > Total Samples Processed: 302\n",
            "  > Overall Time: 135.72 seconds\n",
            "  > Avg Time per Sample: 0.449 seconds\n",
            "----------------------------------------\n",
            "  > Stage 1 Latency (Gemma): 133.26 seconds\n",
            "  > Stage 2 Latency (Phi-4): 2.38 seconds\n",
            "----------------------------------------\n",
            "  > Predicted Classification Counts:\n",
            "predicted_classification\n",
            "Correct                117\n",
            "Computational Error    110\n",
            "Conceptual Error        75\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the detailed output\n",
        "display(evaluation_results_df.head())\n",
        "\n",
        "# Save the results to a CSV for offline analysis in Excel, etc.\n",
        "evaluation_results_df.to_csv(\"/content/batch_evaluation_results.csv\", index=False)"
      ],
      "metadata": {
        "id": "uDQYTzPErgrd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "ae76e931-f999-4abc-fad2-1ea13e0a2ade"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   original_index                                           question  \\\n",
              "0               0  A community garden is rectangular and measures...   \n",
              "1               0  A community garden is rectangular and measures...   \n",
              "2               1  Sarah is building a model rocket. The body of ...   \n",
              "3               1  Sarah is building a model rocket. The body of ...   \n",
              "4               2  A bakery sells muffins for $3 each and cookies...   \n",
              "\n",
              "                                            solution           true_label  \\\n",
              "0  The total area of the garden is 15 * 10 = 150 ...              Correct   \n",
              "1  The total area of the garden is 2*(15 + 10) = ...     Conceptual Error   \n",
              "2  Convert the pipe length to centimeters: 1.2 * ...              Correct   \n",
              "3  Convert the pipe length to centimeters: 1.2 * ...  Computational Error   \n",
              "4  Monday's muffin revenue was 45 * 3 = $135.\\r\\n...              Correct   \n",
              "\n",
              "                                    gemma_raw_output  \\\n",
              "0                          =15*10=150\\n0.20*150=30\\n   \n",
              "1                                              =10\\n   \n",
              "2                  =120*100=120\\n-30*100=90\\nFA=90\\n   \n",
              "3                  =120*100=120\\n-30*100=80\\nFA=80\\n   \n",
              "4  {\\n  \"L1\": \"45*3=135\",\\n  \"L2\": \"60*2=120\",\\n ...   \n",
              "\n",
              "                                  extracted_json_str predicted_classification  \\\n",
              "0           {\"L1\": \"15*10=150\", \"L2\": \"0.20*150=30\"}                  Correct   \n",
              "1                                                 {}         Conceptual Error   \n",
              "2  {\"FA\": \"90\", \"L1\": \"120*100=120\", \"L2\": \"-30*1...      Computational Error   \n",
              "3  {\"FA\": \"80\", \"L1\": \"120*100=120\", \"L2\": \"-30*1...      Computational Error   \n",
              "4  {\"L1\": \"45*3=135\", \"L2\": \"60*2=120\", \"L3\": \"30...                  Correct   \n",
              "\n",
              "   pipeline_stage_stopped  phi4_correct_proba  phi4_flawed_proba  \\\n",
              "0                       2            0.999170           0.000830   \n",
              "1                       2            0.000003           0.999997   \n",
              "2                       1                 NaN                NaN   \n",
              "3                       1                 NaN                NaN   \n",
              "4                       2            0.999975           0.000025   \n",
              "\n",
              "       phi4_raw_logits  \n",
              "0  [ 3.375   -3.71875]  \n",
              "1  [-6.59375  6.125  ]  \n",
              "2                  NaN  \n",
              "3                  NaN  \n",
              "4  [ 5.      -5.59375]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-571c384f-85de-4684-82e5-a8b1fc134045\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_index</th>\n",
              "      <th>question</th>\n",
              "      <th>solution</th>\n",
              "      <th>true_label</th>\n",
              "      <th>gemma_raw_output</th>\n",
              "      <th>extracted_json_str</th>\n",
              "      <th>predicted_classification</th>\n",
              "      <th>pipeline_stage_stopped</th>\n",
              "      <th>phi4_correct_proba</th>\n",
              "      <th>phi4_flawed_proba</th>\n",
              "      <th>phi4_raw_logits</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A community garden is rectangular and measures...</td>\n",
              "      <td>The total area of the garden is 15 * 10 = 150 ...</td>\n",
              "      <td>Correct</td>\n",
              "      <td>=15*10=150\\n0.20*150=30\\n</td>\n",
              "      <td>{\"L1\": \"15*10=150\", \"L2\": \"0.20*150=30\"}</td>\n",
              "      <td>Correct</td>\n",
              "      <td>2</td>\n",
              "      <td>0.999170</td>\n",
              "      <td>0.000830</td>\n",
              "      <td>[ 3.375   -3.71875]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>A community garden is rectangular and measures...</td>\n",
              "      <td>The total area of the garden is 2*(15 + 10) = ...</td>\n",
              "      <td>Conceptual Error</td>\n",
              "      <td>=10\\n</td>\n",
              "      <td>{}</td>\n",
              "      <td>Conceptual Error</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.999997</td>\n",
              "      <td>[-6.59375  6.125  ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Sarah is building a model rocket. The body of ...</td>\n",
              "      <td>Convert the pipe length to centimeters: 1.2 * ...</td>\n",
              "      <td>Correct</td>\n",
              "      <td>=120*100=120\\n-30*100=90\\nFA=90\\n</td>\n",
              "      <td>{\"FA\": \"90\", \"L1\": \"120*100=120\", \"L2\": \"-30*1...</td>\n",
              "      <td>Computational Error</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Sarah is building a model rocket. The body of ...</td>\n",
              "      <td>Convert the pipe length to centimeters: 1.2 * ...</td>\n",
              "      <td>Computational Error</td>\n",
              "      <td>=120*100=120\\n-30*100=80\\nFA=80\\n</td>\n",
              "      <td>{\"FA\": \"80\", \"L1\": \"120*100=120\", \"L2\": \"-30*1...</td>\n",
              "      <td>Computational Error</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>A bakery sells muffins for $3 each and cookies...</td>\n",
              "      <td>Monday's muffin revenue was 45 * 3 = $135.\\r\\n...</td>\n",
              "      <td>Correct</td>\n",
              "      <td>{\\n  \"L1\": \"45*3=135\",\\n  \"L2\": \"60*2=120\",\\n ...</td>\n",
              "      <td>{\"L1\": \"45*3=135\", \"L2\": \"60*2=120\", \"L3\": \"30...</td>\n",
              "      <td>Correct</td>\n",
              "      <td>2</td>\n",
              "      <td>0.999975</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>[ 5.      -5.59375]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-571c384f-85de-4684-82e5-a8b1fc134045')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-571c384f-85de-4684-82e5-a8b1fc134045 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-571c384f-85de-4684-82e5-a8b1fc134045');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-74362fb1-c6ae-46f8-ac31-c1080d1eab74\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74362fb1-c6ae-46f8-ac31-c1080d1eab74')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-74362fb1-c6ae-46f8-ac31-c1080d1eab74 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"evaluation_results_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"original_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"A community garden is rectangular and measures 15 meters in length and 10 meters in width. The gardeners decide to dedicate 20% of the garden's area to growing tomatoes. How many square meters are dedicated to growing tomatoes?\",\n          \"Sarah is building a model rocket. The body of the rocket requires a tube that is 30 cm long. She has a pipe that is 1.2 meters long. After cutting the piece for the rocket body, how many centimeters of pipe does she have left?\",\n          \"A bakery sells muffins for $3 each and cookies for $2 each. On Monday, they sold 45 muffins and 60 cookies. On Tuesday, they sold 30 muffins and 75 cookies. What was the total revenue from muffins and cookies over both days?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"solution\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The total area of the garden is 2*(15 + 10) = 50 square meters.\\r\\nThe area for tomatoes is 20% of the total area: 50 * 0.20 = 10 square meters.\\r\\nFINAL ANSWER: 10\",\n          \"Monday's muffin revenue was 45 * 3 = $135.\\r\\nMonday's cookie revenue was 60 * 2 = $120.\\r\\nTuesday's muffin revenue was 30 * 3 = $90.\\r\\nTuesday's cookie revenue was 75 * 2 = $150.\\r\\nThe total revenue over both days is 135 + 120 + 90 + 150 = $495.\\r\\nFINAL ANSWER: 495\",\n          \"Convert the pipe length to centimeters: 1.2 * 100 = 120 cm.\\r\\nSubtract the length of the rocket body to find the remaining pipe: 120 - 30 = 90 cm.\\r\\nFINAL ANSWER: 90\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Correct\",\n          \"Conceptual Error\",\n          \"Computational Error\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gemma_raw_output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"=10\\n\",\n          \"{\\n  \\\"L1\\\": \\\"45*3=135\\\",\\n  \\\"L2\\\": \\\"60*2=120\\\",\\n  \\\"L3\\\": \\\"30*3=90\\\",\\n  \\\"L4\\\": \\\"75*2=150\\\",\\n  \\\"L5\\\": \\\"135+120+90+150=495\\\",\\n  \\\"FA\\\": \\\"\\\"\\n}\",\n          \"=120*100=120\\n-30*100=90\\nFA=90\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"extracted_json_str\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"{}\",\n          \"{\\\"L1\\\": \\\"45*3=135\\\", \\\"L2\\\": \\\"60*2=120\\\", \\\"L3\\\": \\\"30*3=90\\\", \\\"L4\\\": \\\"75*2=150\\\", \\\"L5\\\": \\\"135+120+90+150=495\\\", \\\"FA\\\": \\\"\\\"}\",\n          \"{\\\"FA\\\": \\\"90\\\", \\\"L1\\\": \\\"120*100=120\\\", \\\"L2\\\": \\\"-30*100=90\\\"}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_classification\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Correct\",\n          \"Conceptual Error\",\n          \"Computational Error\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pipeline_stage_stopped\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phi4_correct_proba\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5771019754910458,\n        \"min\": 2.9944410471216543e-06,\n        \"max\": 0.9999749660491943,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9991704225540161,\n          2.9944410471216543e-06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phi4_flawed_proba\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.577101969424375,\n        \"min\": 2.5071594791370444e-05,\n        \"max\": 0.9999970197677612,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0008295892039313912,\n          0.9999970197677612\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phi4_raw_logits\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"[ 3.375   -3.71875]\",\n          \"[-6.59375  6.125  ]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "labels = [\"Correct\", \"Computational Error\", \"Conceptual Error\"]\n",
        "\n",
        "df_cm = evaluation_results_df.copy()\n",
        "\n",
        "# Keep only rows that match our 3 classes on both sides\n",
        "df_cm = df_cm[\n",
        "    df_cm[\"true_label\"].isin(labels) &\n",
        "    df_cm[\"predicted_classification\"].isin(labels)\n",
        "]\n",
        "\n",
        "# Counts matrix (fixed row/col order)\n",
        "cm = pd.crosstab(\n",
        "    df_cm[\"true_label\"], df_cm[\"predicted_classification\"],\n",
        "    rownames=[\"True\"], colnames=[\"Pred\"], dropna=False\n",
        ").reindex(index=labels, columns=labels, fill_value=0)\n",
        "\n",
        "print(\"Confusion matrix (counts):\")\n",
        "print(cm)\n",
        "\n",
        "# Row-normalized percentages (per true class)\n",
        "cm_pct = (cm.div(cm.sum(axis=1).replace(0, 1), axis=0) * 100).round(1)\n",
        "print(\"\\nConfusion matrix (row-normalized, %):\")\n",
        "print(cm_pct)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wxUD7QUCwjB",
        "outputId": "c3a88d0f-37b7-422e-9133-e3e7d512efa4"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix (counts):\n",
            "Pred                 Correct  Computational Error  Conceptual Error\n",
            "True                                                               \n",
            "Correct                  101                   39                11\n",
            "Computational Error        8                   42                25\n",
            "Conceptual Error           8                   29                39\n",
            "\n",
            "Confusion matrix (row-normalized, %):\n",
            "Pred                 Correct  Computational Error  Conceptual Error\n",
            "True                                                               \n",
            "Correct                 66.9                 25.8               7.3\n",
            "Computational Error     10.7                 56.0              33.3\n",
            "Conceptual Error        10.5                 38.2              51.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- config ---\n",
        "labels = [\"Correct\", \"Computational Error\", \"Conceptual Error\"]\n",
        "title  = \"Final model — 3-class confusion matrix\"\n",
        "save_path = \"/content/confusion_matrix_3class.png\"   # change or set to None\n",
        "\n",
        "# --- prep data ---\n",
        "df = evaluation_results_df.copy()\n",
        "mask = df[\"true_label\"].isin(labels) & df[\"predicted_classification\"].isin(labels)\n",
        "dropped = len(df) - mask.sum()\n",
        "df = df[mask]\n",
        "\n",
        "cm = pd.crosstab(\n",
        "    df[\"true_label\"], df[\"predicted_classification\"],\n",
        "    rownames=[\"True label\"], colnames=[\"Predicted label\"], dropna=False\n",
        ").reindex(index=labels, columns=labels, fill_value=0)\n",
        "\n",
        "# row-normalized percentages\n",
        "cm_pct = (cm.div(cm.sum(axis=1).replace(0, 1), axis=0) * 100).round(1)\n",
        "\n",
        "# --- plot ---\n",
        "fig, ax = plt.subplots(figsize=(7.5, 6.5), dpi=120)\n",
        "im = ax.imshow(cm.values, cmap=\"Blues\", vmin=0)\n",
        "\n",
        "# annotations: \"count\\nxx.x%\"\n",
        "for i in range(len(labels)):\n",
        "    for j in range(len(labels)):\n",
        "        count = cm.iat[i, j]\n",
        "        pct   = cm_pct.iat[i, j]\n",
        "        ax.text(j, i, f\"{count}\\n{pct:.1f}%\", ha=\"center\", va=\"center\", fontsize=11)\n",
        "\n",
        "# axes, ticks, labels\n",
        "ax.set_xticks(np.arange(len(labels)), labels, rotation=0)\n",
        "ax.set_yticks(np.arange(len(labels)), labels)\n",
        "ax.set_xlabel(\"Predicted label\", labelpad=10)\n",
        "ax.set_ylabel(\"True label\", labelpad=10)\n",
        "ax.set_title(title, pad=14)\n",
        "\n",
        "# colorbar\n",
        "cbar = fig.colorbar(im, ax=ax)\n",
        "cbar.ax.set_ylabel(\"Count\", rotation=270, labelpad=15)\n",
        "\n",
        "# grid lines for readability\n",
        "ax.set_xticks(np.arange(-.5, len(labels), 1), minor=True)\n",
        "ax.set_yticks(np.arange(-.5, len(labels), 1), minor=True)\n",
        "ax.grid(which=\"minor\", color=\"white\", linewidth=1, alpha=0.7)\n",
        "ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
        "\n",
        "plt.tight_layout()\n",
        "if save_path:\n",
        "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Dropped rows with missing labels: {dropped}\")\n",
        "print(\"\\nCounts:\\n\", cm)\n",
        "print(\"\\nRow %:\\n\", cm_pct)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 997
        },
        "id": "GdrV-8mVEWca",
        "outputId": "f00e0241-3f71-4a52-8f22-61ec201d70f4"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x780 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped rows with missing labels: 0\n",
            "\n",
            "Counts:\n",
            " Predicted label      Correct  Computational Error  Conceptual Error\n",
            "True label                                                         \n",
            "Correct                  101                   39                11\n",
            "Computational Error        8                   42                25\n",
            "Conceptual Error           8                   29                39\n",
            "\n",
            "Row %:\n",
            " Predicted label      Correct  Computational Error  Conceptual Error\n",
            "True label                                                         \n",
            "Correct                 66.9                 25.8               7.3\n",
            "Computational Error     10.7                 56.0              33.3\n",
            "Conceptual Error        10.5                 38.2              51.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOHQlRX4G0nW",
        "outputId": "ff026ff6-f0bb-4a84-b95e-94071ef74b65"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['original_index', 'question', 'solution', 'true_label',\n",
              "       'gemma_raw_output', 'extracted_json_str', 'predicted_classification',\n",
              "       'pipeline_stage_stopped', 'phi4_correct_proba', 'phi4_flawed_proba',\n",
              "       'phi4_raw_logits'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Debugging the equation extraction/evaluation process"
      ],
      "metadata": {
        "id": "aUF-hsu7XdOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are (as seen in the confusion matrix above) a couple issues with our process.\n",
        "\n",
        "* One is that many solutions are predicted to contain computational errors when\n",
        "in fact they do not. We can actually see that this happens for most of the solutions predicted to contain computational errors. One cause of this is incorrect output by Gemma: essentially, hallucinated equations which are not in the original solution, and happen to be incorrect.\n",
        "\n",
        "* The other one is that many solutions which do in fact contain computational errors are not detected. A cause of this is that Gemma misses these equations, or more commonly makes some formatting mistake when reporting them, which causes the function that parses Gemma's raw output and turns it into JSON to ignore the incorrect calculation.\n",
        "\n",
        "In the following cells, we attempt to detect where and how the model and/or the parsing function is going wrong.\n",
        "\n",
        "............................................"
      ],
      "metadata": {
        "id": "7owYh2w2Xhej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In the next cell, we take a look at the solutions which contain computational errors but are not detected by the equation extraction/evaluation process (Stage 1).**"
      ],
      "metadata": {
        "id": "Crc4UX5lZVxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "df = evaluation_results_df  # rename if yours is different\n",
        "\n",
        "# \"Slipped through\" = true comp error but Stage 1 did NOT stop the pipeline\n",
        "slipped = df[\n",
        "    (df[\"true_label\"] == \"Computational Error\") &\n",
        "    (df[\"pipeline_stage_stopped\"] != 1)  # 2 means it went to Stage 2\n",
        "].copy()\n",
        "\n",
        "\n",
        "for i, row in slipped.iterrows():\n",
        "    print(\"=\"*80)\n",
        "    print(f\"original_index: {row['original_index']} | predicted: {row['predicted_classification']}\")\n",
        "    print(\"- Question -\")\n",
        "    print(row[\"question\"])\n",
        "    print(\"\\n- Solution -\")\n",
        "    print(row[\"solution\"])\n",
        "    print(\"\\n- Gemma raw output -\")\n",
        "    print(row[\"gemma_raw_output\"])\n",
        "    print(\"\\n- Extracted JSON (parsed) -\")\n",
        "    try:\n",
        "        print(json.dumps(json.loads(row[\"extracted_json_str\"]), indent=2))\n",
        "    except Exception:\n",
        "        print(row[\"extracted_json_str\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSsTpw9bIIJB",
        "outputId": "9ada8323-3b96-4dc0-ce10-0a4c6f1d545c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "original_index: 9 | predicted: Correct\n",
            "- Question -\n",
            "A train travels at a constant speed of 80 kilometers per hour. How long will it take to travel a distance of 360 kilometers?\n",
            "\n",
            "- Solution -\n",
            "The time taken is the distance divided by the speed: 360 / 80 = 4 hours.\r\n",
            "FINAL ANSWER: 4\n",
            "\n",
            "- Gemma raw output -\n",
            "=360/80=4\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"360/80=4\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 16 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A box of 8 identical batteries costs $12. How much would it cost to buy 20 batteries?\n",
            "\n",
            "- Solution -\n",
            "The cost of a single battery is 12 / 8 = $2.50.\r\n",
            "The cost for 20 batteries is 20 * 2.50 = $50.\r\n",
            "FINAL ANSWER: 50\n",
            "\n",
            "- Gemma raw output -\n",
            "=2.50\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 20 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A factory produces 1,200 widgets per day. 5% of the widgets are found to be defective. The factory operates 5 days a week. How many non-defective widgets does the factory produce in one week?\n",
            "\n",
            "- Solution -\n",
            "The number of non-defective widgets produced per day is 1200 * (1 - 0.05) = 1100.\r\n",
            "The total number of non-defective widgets produced in a week is 1100 * 5 = 5500.\r\n",
            "FINAL ANSWER: 5500\n",
            "\n",
            "- Gemma raw output -\n",
            "=1100\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 21 | predicted: Conceptual Error\n",
            "- Question -\n",
            "Emily is saving for a bicycle that costs $250. She saves $15 each week from her allowance. She also received $40 for her birthday to put towards the bike. How many weeks will it take her to save enough money?\n",
            "\n",
            "- Solution -\n",
            "The amount Emily still needs to save is $250 - $40 = $210.\r\n",
            "The number of weeks it will take her to save is 210 / 15 = 12.\r\n",
            "FINAL ANSWER: 12\n",
            "\n",
            "- Gemma raw output -\n",
            "=250-40=210\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"250-40=210\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 22 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A jug contains 2 liters of juice. If one glass holds 250 milliliters, how many glasses can be completely filled from the jug?\n",
            "\n",
            "- Solution -\n",
            "The total amount of juice in milliliters is 2 * 1000 = 3000 ml.\r\n",
            "The number of glasses that can be filled is 3000 / 250 = 12.\r\n",
            "FINAL ANSWER: 12\n",
            "\n",
            "- Gemma raw output -\n",
            "=3000*250\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 29 | predicted: Correct\n",
            "- Question -\n",
            "A train left City A at 8:45 AM and arrived at City B at 1:15 PM. How long did the journey take in minutes?\n",
            "\n",
            "- Solution -\n",
            "The time from 8:45 AM to 12:45 PM is 5 hours.\r\n",
            "The time from 12:45 PM to 1:15 PM is 30 minutes.\r\n",
            "The total journey time is 5 hours and 30 minutes, which is (5 * 60) + 30 = 330 minutes.\r\n",
            "FINAL ANSWER: 330\n",
            "\n",
            "- Gemma raw output -\n",
            "=5*60+30\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 34 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A car travels 240 miles on 10 gallons of gas. How many miles can it travel on 15 gallons of gas?\n",
            "\n",
            "- Solution -\n",
            "The car's fuel efficiency is 240 / 10 = 34 miles per gallon.\r\n",
            "The distance the car can travel on 15 gallons is 34 * 15 = 510 miles.\r\n",
            "FINAL ANSWER: 510\n",
            "\n",
            "- Gemma raw output -\n",
            "=34*15=510\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"34*15=510\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 46 | predicted: Correct\n",
            "- Question -\n",
            "A movie started at 6:50 PM and ended at 9:20 PM. How long was the movie in minutes?\n",
            "\n",
            "- Solution -\n",
            "From 6:50 PM to 7:00 PM is 20 minutes.\r\n",
            "From 7:00 PM to 9:00 PM is 2 hours, which is 2 * 60 = 120 minutes.\r\n",
            "From 9:00 PM to 9:20 PM is 20 minutes.\r\n",
            "The total duration is 20 + 120 + 20 = 160 minutes.\r\n",
            "FINAL ANSWER: 160\n",
            "\n",
            "- Gemma raw output -\n",
            "=0\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 47 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A subscription service costs $12.99 per month. How much does it cost for a full year?\n",
            "\n",
            "- Solution -\n",
            "The total annual cost is 12.99 * 12 = $154.88.\r\n",
            "FINAL ANSWER: 154.88\n",
            "\n",
            "- Gemma raw output -\n",
            "=12.99*12\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 50 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A class has 28 students. On a particular day, 25% of the students were absent. How many students were present?\n",
            "\n",
            "- Solution -\n",
            "The number of students who were absent is 28 * 0.25 = 6.\r\n",
            "The number of students present is 28 - 6 = 22.\r\n",
            "FINAL ANSWER: 22\n",
            "\n",
            "- Gemma raw output -\n",
            "=6\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 53 | predicted: Conceptual Error\n",
            "- Question -\n",
            "Liam is 150 cm tall. His younger sister, Chloe, is 2/3 of his height. How tall is Chloe in centimeters?\n",
            "\n",
            "- Solution -\n",
            "Chloe's height is 150 * (2/3) = 120 cm.\r\n",
            "FINAL ANSWER: 120\n",
            "\n",
            "- Gemma raw output -\n",
            "=150*2/3\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 55 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A rectangular tank measures 50 cm by 30 cm by 20 cm. How many liters of water can it hold? (1 liter = 1000 cubic cm)\n",
            "\n",
            "- Solution -\n",
            "The volume of the tank in cubic centimeters is 50 * 30 * 20 = 40000.\r\n",
            "The volume in liters is 40000 / 1000 = 40.\r\n",
            "FINAL ANSWER: 40\n",
            "\n",
            "- Gemma raw output -\n",
            "=50*30*20\n",
            "40000\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 56 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A team won 15 games and lost 5 games. What is the ratio of wins to total games played?\n",
            "\n",
            "- Solution -\n",
            "The total number of games played is 15 + 5 = 20.\r\n",
            "The ratio of wins to total games is 15:20, which simplifies to 3:5.\r\n",
            "FINAL ANSWER: 3:5\n",
            "\n",
            "- Gemma raw output -\n",
            "=15+5\n",
            "3*5\n",
            "FA=3*5\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"3*5\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 62 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A map has a scale of 1 inch : 20 miles. The distance between two cities on the map is 4.5 inches. What is the actual distance between the cities in miles?\n",
            "\n",
            "- Solution -\n",
            "The actual distance is 4.5 * 20 = 70 miles.\r\n",
            "FINAL ANSWER: 70\n",
            "\n",
            "- Gemma raw output -\n",
            "=4.5*20\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 66 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A company's stock price was $120. It dropped by 10% on Monday and then rose by 10% on Tuesday. What was the stock price at the end of Tuesday?\n",
            "\n",
            "- Solution -\n",
            "The price on Monday was 120 * (1 - 0.10) = $108.\r\n",
            "The price on Tuesday was 108 * (1 + 0.10) = $119.80.\r\n",
            "FINAL ANSWER: 119.80\n",
            "\n",
            "- Gemma raw output -\n",
            "=108\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 68 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A printing press can print 300 pages in 5 minutes. How many pages can it print in one hour?\n",
            "\n",
            "- Solution -\n",
            "The printing rate is 300 / 5 = 70 pages per minute.\r\n",
            "In one hour, it can print 70 * 60 = 4200 pages.\r\n",
            "FINAL ANSWER: 4200\n",
            "\n",
            "- Gemma raw output -\n",
            "=70*60\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 70 | predicted: Conceptual Error\n",
            "- Question -\n",
            "Three friends share a pizza that costs $18.60. They also buy a bottle of soda for $2.40. If they split the total cost equally, how much does each person pay?\n",
            "\n",
            "- Solution -\n",
            "The total cost of the pizza and soda is $18.60 + $2.40 = $24.00.\r\n",
            "Each person pays $24.00 / 3 = $8.00.\r\n",
            "FINAL ANSWER: 8\n",
            "\n",
            "- Gemma raw output -\n",
            "=24.00\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 73 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A survey of 200 people found that 3 out of 5 prefer coffee to tea. How many people prefer coffee?\n",
            "\n",
            "- Solution -\n",
            "The number of people who prefer coffee is 200 * (3/5) = 80.\r\n",
            "FINAL ANSWER: 80\n",
            "\n",
            "- Gemma raw output -\n",
            "=3/5*200\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 75 | predicted: Correct\n",
            "- Question -\n",
            "A store owner buys a box of 24 pens for $18. He sells each pen for $1.25. What is his total profit if he sells all the pens?\n",
            "\n",
            "- Solution -\n",
            "The total revenue from selling all the pens is 24 * 1.25 = $30.\r\n",
            "The total profit is the revenue minus the cost: $30 - $18 = $22.\r\n",
            "FINAL ANSWER: 22\n",
            "\n",
            "- Gemma raw output -\n",
            "=30\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 78 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A circle has a diameter of 20 inches. Using pi = 3.14, what is its area?\n",
            "\n",
            "- Solution -\n",
            "The radius of the circle is 20 / 2 = 10 inches.\r\n",
            "The area is 3.14 * (10 * 10) = 3140 square inches.\r\n",
            "FINAL ANSWER: 3140\n",
            "\n",
            "- Gemma raw output -\n",
            "=10+10\n",
            "3140\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 79 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A recipe requires 3/4 cup of sugar. You only have a 1/8 cup measuring scoop. How many scoops of sugar do you need?\n",
            "\n",
            "- Solution -\n",
            "The number of scoops needed is (3/4) / (1/8) = 3.\r\n",
            "FINAL ANSWER: 3\n",
            "\n",
            "- Gemma raw output -\n",
            "=3\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 83 | predicted: Correct\n",
            "- Question -\n",
            "The formula to convert Celsius to Fahrenheit is F = (9/5)C + 32. What is 35 degrees Celsius in Fahrenheit?\n",
            "\n",
            "- Solution -\n",
            "Substitute C = 35 into the formula: F = (9/5) * 35 + 32.\r\n",
            "First, (9/5) * 35 = 54.\r\n",
            "Then, 54 + 32 = 86.\r\n",
            "FINAL ANSWER: 86\n",
            "\n",
            "- Gemma raw output -\n",
            "=9/5*35+32\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 91 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A school trip requires 1 adult for every 12 students. If 108 students are going on the trip, how many adults are required?\n",
            "\n",
            "- Solution -\n",
            "The number of adults required is 108 / 12 = 11.\r\n",
            "FINAL ANSWER: 11\n",
            "\n",
            "- Gemma raw output -\n",
            "=108/12\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 94 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A bakery made 3 batches of cookies. The first batch had 48 cookies, the second had 56, and the third had 40. The cookies were then packaged into boxes of 8. If each box is sold for $12, how much money will the bakery make from these cookies?\n",
            "\n",
            "- Solution -\n",
            "The total number of cookies is 48 + 56 + 40 = 160.\r\n",
            "The number of boxes is 160 / 8 = 20.\r\n",
            "The total revenue is 20 * 12 = $240.\r\n",
            "FINAL ANSWER: 240\n",
            "\n",
            "- Gemma raw output -\n",
            "=160\n",
            "160/8=20\n",
            "20*12=240\n",
            "FA=240\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"240\",\n",
            "  \"L1\": \"160/8=20\",\n",
            "  \"L2\": \"20*12=240\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 98 | predicted: Correct\n",
            "- Question -\n",
            "A company produces 800 laptops a day. It costs $350 to produce one laptop. The company sells each laptop for $600. If 5% of the laptops produced are defective and cannot be sold, what is the company's potential profit per day?\n",
            "\n",
            "- Solution -\n",
            "The number of sellable laptops is 800 * (1 - 0.05) = 760.\r\n",
            "The total revenue is 760 * 600 = $466,000.\r\n",
            "The total cost of production is 800 * 350 = $280,000.\r\n",
            "The potential profit per day is $466,000 - $280,000 = $186,000.\r\n",
            "FINAL ANSWER: 186000\n",
            "\n",
            "- Gemma raw output -\n",
            "=760,\n",
            "=466000,\n",
            "=800*350,\n",
            "=466000-280000,\n",
            "=186000,\n",
            "\"\"\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 102 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A catering company is preparing for an event with 150 guests. They plan for each guest to have 2 sandwiches and 3 cookies. Sandwiches cost $1.50 each to make, and cookies cost $0.50 each. The company charges the client $800 for the service fee plus the total cost of the food. What is the total charge to the client?\n",
            "\n",
            "- Solution -\n",
            "The cost of sandwiches is 150 * 2 * 1.50 = $450.\r\n",
            "The cost of cookies is 150 * 3 * 0.50 = $225.\r\n",
            "The total food cost is $450 + $225 = $775.\r\n",
            "The total charge to the client is $775 + $800 = $1575.\r\n",
            "FINAL ANSWER: 1575\n",
            "\n",
            "- Gemma raw output -\n",
            "=150*2*1.50,\n",
            "=150*3*0.50,\n",
            "=450+225,\n",
            "=775,\n",
            "=775+800,\n",
            "=1575\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 105 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A school has 800 students. The ratio of boys to girls is 5:3. 25% of the boys and 50% of the girls play a school sport. How many students in total play a school sport?\n",
            "\n",
            "- Solution -\n",
            "The number of boys is 800 * (5/8) = 500.\r\n",
            "The number of girls is 800 * (3/8) = 300.\r\n",
            "The number of boys who play sports is 500 * 0.25 = 135.\r\n",
            "The number of girls who play sports is 300 * 0.50 = 150.\r\n",
            "The total number of students who play sports is 135 + 150 = 285.\r\n",
            "FINAL ANSWER: 285\n",
            "\n",
            "- Gemma raw output -\n",
            "=500,\n",
            "=300,\n",
            "=135,\n",
            "=150,\n",
            "=135+150=285,\n",
            "FA:\"\"\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"\\\"\\\"\",\n",
            "  \"L1\": \"135+150=285\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 106 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A clothing store buys jeans for $30 a pair. They sell them at a 60% markup. At the end of the season, the remaining jeans are put on a clearance sale for 40% off the selling price. What is the profit on a pair of jeans sold during the clearance sale?\n",
            "\n",
            "- Solution -\n",
            "The regular selling price is 30 * 1.60 = $48.\r\n",
            "The clearance sale price is 48 * (1 - 0.40) = $28.80.\r\n",
            "The profit on a clearance sale pair is $28.80 - $30 = $1.20.\r\n",
            "FINAL ANSWER: 1.2\n",
            "\n",
            "- Gemma raw output -\n",
            "=48,\n",
            "=28.80,\n",
            "=28.80-30,\n",
            "\"1.2\":\"\"\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 108 | predicted: Correct\n",
            "- Question -\n",
            "A rectangular garden measuring 12 meters by 16 meters is to have a walkway 1 meter wide installed all the way around its outer edge. The walkway material costs $25 per square meter. What will be the total cost of the walkway?\n",
            "\n",
            "- Solution -\n",
            "The area of the garden only is 12 * 16 = 192 square meters.\r\n",
            "The new dimensions including the walkway are (12 + 2) by (16 + 2), so 14 by 18 meters.\r\n",
            "The total area is 14 * 18 = 262 square meters.\r\n",
            "The area of the walkway is 262 - 192 = 70 square meters.\r\n",
            "The total cost of the walkway is 70 * 25 = $1750.\r\n",
            "FINAL ANSWER: 1750\n",
            "\n",
            "- Gemma raw output -\n",
            "=192,\n",
            "=14*18,\n",
            "=14*18,\n",
            "=262,\n",
            "=262-192,\n",
            "=70,\n",
            "=70*25,\n",
            "=1750\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 110 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A company has 240 employees. 3/8 of the employees are in the marketing department. 1/3 are in the production department. The rest are split equally between the HR and finance departments. How many employees are in the finance department?\n",
            "\n",
            "- Solution -\n",
            "The number of marketing employees is 240 * (3/8) = 90.\r\n",
            "The number of production employees is 240 * (1/3) = 90.\r\n",
            "The number of remaining employees is 240 - 90 - 90 = 60.\r\n",
            "The number of employees in the finance department is 60 / 2 = 30.\r\n",
            "FINAL ANSWER: 30\n",
            "\n",
            "- Gemma raw output -\n",
            "=90,\n",
            "=90,\n",
            "=60,\n",
            "=2,\n",
            "=30\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{}\n",
            "================================================================================\n",
            "original_index: 115 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A small business owner's revenue was $120,000 in the first year. In the second year, it increased by 15%. In the third year, it decreased by 10% from the second year's revenue. The owner's profit margin is 25% of the revenue each year. What was the total profit over the three years?\n",
            "\n",
            "- Solution -\n",
            "Year 1 profit: 120000 * 0.25 = $30,000.\r\n",
            "Year 2 revenue: 120000 * 1.15 = $138,000. Year 2 profit: 138000 * 0.25 = $32,500.\r\n",
            "Year 3 revenue: 138000 * 0.90 = $124,200. Year 3 profit: 124200 * 0.25 = $31,050.\r\n",
            "Total profit: $30,000 + $32,500 + $31,050 = $93,550.\r\n",
            "FINAL ANSWER: 93550\n",
            "\n",
            "- Gemma raw output -\n",
            "{\n",
            "  \"L1\": \"120000*0.25=30000\",\n",
            "  \"L2\": \"120000*1.15=138000\",\n",
            "  \"L3\": \"138000*0.90=124200\",\n",
            "  \"L4\": \"30000+32500+31050=93550\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"120000*0.25=30000\",\n",
            "  \"L2\": \"120000*1.15=138000\",\n",
            "  \"L3\": \"138000*0.90=124200\",\n",
            "  \"L4\": \"30000+32500+31050=93550\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 122 | predicted: Conceptual Error\n",
            "- Question -\n",
            "A delivery truck travels 150 km to City A, then 120 km to City B, then 180 km back to its origin. The truck's fuel efficiency is 5 km per liter. Fuel costs $1.80 per liter. How much did the fuel for the day's trip cost?\n",
            "\n",
            "- Solution -\n",
            "The total distance traveled is 150 + 120 + 180 = 400 km.\r\n",
            "The total fuel consumed is 400 / 5 = 80 liters.\r\n",
            "The total fuel cost is 80 * 1.80 = $144.\r\n",
            "FINAL ANSWER: 144\n",
            "\n",
            "- Gemma raw output -\n",
            "=150+120+180\n",
            "400/5=80\n",
            "80*1.80=144\n",
            "FA=144\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"144\",\n",
            "  \"L1\": \"400/5=80\",\n",
            "  \"L2\": \"80*1.80=144\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 127 | predicted: Correct\n",
            "- Question -\n",
            "A company is comparing two shipping services for a 5 kg package. Service A charges a base fee of $10 plus $2 per kg. Service B charges a base fee of $5 plus $2.80 per kg. The company also has a 15% discount coupon that can only be applied to the total cost of Service A. Which service is cheaper, and by how much?\n",
            "\n",
            "- Solution -\n",
            "The cost of Service A with the discount is (10 + 2 * 5) * (1 - 0.15) = $15.\r\n",
            "The cost of Service B is 5 + 2.80 * 5 = $19.\r\n",
            "Service A is cheaper by $19 - $15 = $4.\r\n",
            "FINAL ANSWER: 4\n",
            "\n",
            "- Gemma raw output -\n",
            "=15\n",
            "5+2.80*5=19\n",
            "19-15=4\n",
            "4\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"5+2.80*5=19\",\n",
            "  \"L2\": \"19-15=4\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now, we look at the correct solutions which were mistakenly classified as containing computational errors.**"
      ],
      "metadata": {
        "id": "DcKSl9glZ_cQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "df = evaluation_results_df  # or rename if different\n",
        "\n",
        "# False positives of Stage 1: true Correct → predicted Computational Error\n",
        "fp_comp = df[\n",
        "    (df[\"true_label\"] == \"Correct\") &\n",
        "    (df[\"predicted_classification\"] == \"Computational Error\")\n",
        "].copy()\n",
        "\n",
        "print(f\"Total 'Correct' samples: {(df['true_label']=='Correct').sum()}\")\n",
        "print(f\"'Correct' misclassified as Computational Error: {len(fp_comp)}\\n\")\n",
        "\n",
        "for _, row in fp_comp.iterrows():\n",
        "    print(\"=\"*80)\n",
        "    print(f\"original_index: {row['original_index']} | predicted: {row['predicted_classification']}\")\n",
        "    print(\"- Question -\")\n",
        "    print(row[\"question\"])\n",
        "    print(\"\\n- Solution -\")\n",
        "    print(row[\"solution\"])\n",
        "    print(\"\\n- Gemma raw output -\")\n",
        "    print(row.get(\"gemma_raw_output\", \"\"))\n",
        "    print(\"\\n- Extracted JSON (parsed) -\")\n",
        "    try:\n",
        "        print(json.dumps(json.loads(row.get(\"extracted_json_str\", \"{}\")), indent=2))\n",
        "    except Exception:\n",
        "        print(row.get(\"extracted_json_str\", \"\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjdbPvgxWx6x",
        "outputId": "030efa45-3418-4120-8b76-4cb14cfe9832"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 'Correct' samples: 151\n",
            "'Correct' misclassified as Computational Error: 39\n",
            "\n",
            "================================================================================\n",
            "original_index: 1 | predicted: Computational Error\n",
            "- Question -\n",
            "Sarah is building a model rocket. The body of the rocket requires a tube that is 30 cm long. She has a pipe that is 1.2 meters long. After cutting the piece for the rocket body, how many centimeters of pipe does she have left?\n",
            "\n",
            "- Solution -\n",
            "Convert the pipe length to centimeters: 1.2 * 100 = 120 cm.\r\n",
            "Subtract the length of the rocket body to find the remaining pipe: 120 - 30 = 90 cm.\r\n",
            "FINAL ANSWER: 90\n",
            "\n",
            "- Gemma raw output -\n",
            "=120*100=120\n",
            "-30*100=90\n",
            "FA=90\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"90\",\n",
            "  \"L1\": \"120*100=120\",\n",
            "  \"L2\": \"-30*100=90\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 11 | predicted: Computational Error\n",
            "- Question -\n",
            "A water tank holds 5,000 liters. A pump removes water at a rate of 250 liters per hour. If the tank is full, how many hours will it take to empty half of the tank?\n",
            "\n",
            "- Solution -\n",
            "Half of the tank's capacity is 5000 / 2 = 2500 liters.\r\n",
            "The time to remove this amount of water is 2500 / 250 = 10 hours.\r\n",
            "FINAL ANSWER: 10\n",
            "\n",
            "- Gemma raw output -\n",
            "=5000/2=2500\n",
            "10/250=10\n",
            "FA=10\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"10\",\n",
            "  \"L1\": \"5000/2=2500\",\n",
            "  \"L2\": \"10/250=10\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 17 | predicted: Computational Error\n",
            "- Question -\n",
            "A snail crawls 5 cm every minute, but then rests for a minute, during which it slides back 2 cm. How many minutes will it take for the snail to be 16 cm away from its starting point for the first time?\n",
            "\n",
            "- Solution -\n",
            "The snail's net progress in a 2-minute cycle is 5 - 2 = 3 cm.\r\n",
            "After 4 cycles (8 minutes), the snail is at 4 * 3 = 12 cm.\r\n",
            "In the 9th minute, the snail crawls forward 5 cm, reaching 12 + 5 = 17 cm, passing the 16 cm mark.\r\n",
            "FINAL ANSWER: 9\n",
            "\n",
            "- Gemma raw output -\n",
            "=5-2=3\n",
            "=4*3=12\n",
            "=5+5=17\n",
            "=16+5=17\n",
            "{\n",
            "  \"L1\": \"5-2=3\",\n",
            "  \"L2\": \"4*3=12\",\n",
            "  \"L3\": \"5+5=17\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"5-2=3\",\n",
            "  \"L2\": \"4*3=12\",\n",
            "  \"L3\": \"5+5=17\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 22 | predicted: Computational Error\n",
            "- Question -\n",
            "A jug contains 2 liters of juice. If one glass holds 250 milliliters, how many glasses can be completely filled from the jug?\n",
            "\n",
            "- Solution -\n",
            "The total amount of juice in milliliters is 2 * 1000 = 2000 ml.\r\n",
            "The number of glasses that can be filled is 2000 / 250 = 8.\r\n",
            "FINAL ANSWER: 8\n",
            "\n",
            "- Gemma raw output -\n",
            "=2*1000=2000\n",
            "8*2000=2000\n",
            "FA=8\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"8\",\n",
            "  \"L1\": \"2*1000=2000\",\n",
            "  \"L2\": \"8*2000=2000\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 23 | predicted: Computational Error\n",
            "- Question -\n",
            "A farmer plants corn in a field that is 100 meters long and 80 meters wide. He uses a special fertilizer that costs $2.50 per 100 square meters. What is the total cost of the fertilizer for the entire field?\n",
            "\n",
            "- Solution -\n",
            "The area of the field is 100 * 80 = 8000 square meters.\r\n",
            "The number of 100-square-meter units is 8000 / 100 = 80.\r\n",
            "The total cost of the fertilizer is 80 * 2.50 = $200.\r\n",
            "FINAL ANSWER: 200\n",
            "\n",
            "- Gemma raw output -\n",
            "=8000*100=8000,\n",
            "=80*2.50=200,\n",
            "=80*2.50=200,\n",
            "FA=200\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"200\",\n",
            "  \"L1\": \"8000*100=8000\",\n",
            "  \"L2\": \"80*2.50=200\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 27 | predicted: Computational Error\n",
            "- Question -\n",
            "David is 12 years old. His father is three times his age. His mother is 4 years younger than his father. How old is David's mother?\n",
            "\n",
            "- Solution -\n",
            "David's father's age is 12 * 3 = 36 years old.\r\n",
            "David's mother's age is 36 - 4 = 32 years old.\r\n",
            "FINAL ANSWER: 32\n",
            "\n",
            "- Gemma raw output -\n",
            "=36*3=36\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"36*3=36\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 35 | predicted: Computational Error\n",
            "- Question -\n",
            "A concert ticket costs $75. A processing fee of 8% is added to the ticket price. What is the total cost of the ticket?\n",
            "\n",
            "- Solution -\n",
            "The processing fee amount is 75 * 0.08 = $6.\r\n",
            "The total cost of the ticket is $75 + $6 = $81.\r\n",
            "FINAL ANSWER: 81\n",
            "\n",
            "- Gemma raw output -\n",
            "=75*0.08=6\n",
            "81+6=81\n",
            "FA=81\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"81\",\n",
            "  \"L1\": \"75*0.08=6\",\n",
            "  \"L2\": \"81+6=81\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 42 | predicted: Computational Error\n",
            "- Question -\n",
            "A school fundraiser sold 250 raffle tickets at $5 each. The prize for the raffle was a $300 gift card. After paying for the prize, how much money did the fundraiser make?\n",
            "\n",
            "- Solution -\n",
            "The total revenue from ticket sales is 250 * 5 = $1250.\r\n",
            "The profit is the revenue minus the cost of the prize: $1250 - $300 = $950.\r\n",
            "FINAL ANSWER: 950\n",
            "\n",
            "- Gemma raw output -\n",
            "=5*250=1250\n",
            "-300*1250=950\n",
            "FA=950\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"950\",\n",
            "  \"L1\": \"5*250=1250\",\n",
            "  \"L2\": \"-300*1250=950\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 43 | predicted: Computational Error\n",
            "- Question -\n",
            "A box contains 12 red marbles, 18 blue marbles, and 10 green marbles. What percentage of the marbles are blue?\n",
            "\n",
            "- Solution -\n",
            "The total number of marbles is 12 + 18 + 10 = 40.\r\n",
            "The fraction of marbles that are blue is 18 / 40 = 0.45.\r\n",
            "The percentage of blue marbles is 0.45 * 100 = 45%.\r\n",
            "FINAL ANSWER: 45\n",
            "\n",
            "- Gemma raw output -\n",
            "=18+10=40\n",
            "=18/40=0.45\n",
            "=0.45*100=45\n",
            "FA=45\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"45\",\n",
            "  \"L1\": \"18+10=40\",\n",
            "  \"L2\": \"18/40=0.45\",\n",
            "  \"L3\": \"0.45*100=45\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 54 | predicted: Computational Error\n",
            "- Question -\n",
            "A restaurant bill is $80. A 15% tip is to be added. What is the total amount to be paid?\n",
            "\n",
            "- Solution -\n",
            "The tip amount is 80 * 0.15 = $12.\r\n",
            "The total amount to be paid is $80 + $12 = $92.\r\n",
            "FINAL ANSWER: 92\n",
            "\n",
            "- Gemma raw output -\n",
            "=80*0.15=12\n",
            "90+12=92\n",
            "FA=92\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"92\",\n",
            "  \"L1\": \"80*0.15=12\",\n",
            "  \"L2\": \"90+12=92\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 55 | predicted: Computational Error\n",
            "- Question -\n",
            "A rectangular tank measures 50 cm by 30 cm by 20 cm. How many liters of water can it hold? (1 liter = 1000 cubic cm)\n",
            "\n",
            "- Solution -\n",
            "The volume of the tank in cubic centimeters is 50 * 30 * 20 = 30000.\r\n",
            "The volume in liters is 30000 / 1000 = 30.\r\n",
            "FINAL ANSWER: 30\n",
            "\n",
            "- Gemma raw output -\n",
            "=30*20=30000\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"30*20=30000\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 58 | predicted: Computational Error\n",
            "- Question -\n",
            "A car's odometer reads 24,580 miles at the start of a trip and 25,130 miles at the end. The car used 22 gallons of gas. How many miles per gallon did the car get on this trip?\n",
            "\n",
            "- Solution -\n",
            "The total distance traveled is 25130 - 24580 = 550 miles.\r\n",
            "The car's miles per gallon is 550 / 22 = 25.\r\n",
            "FINAL ANSWER: 25\n",
            "\n",
            "- Gemma raw output -\n",
            "=550-24580=550\n",
            "25/22=25\n",
            "550/22=25\n",
            "FA=25\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"25\",\n",
            "  \"L1\": \"550-24580=550\",\n",
            "  \"L2\": \"25/22=25\",\n",
            "  \"L3\": \"550/22=25\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 70 | predicted: Computational Error\n",
            "- Question -\n",
            "Three friends share a pizza that costs $18.60. They also buy a bottle of soda for $2.40. If they split the total cost equally, how much does each person pay?\n",
            "\n",
            "- Solution -\n",
            "The total cost of the pizza and soda is $18.60 + $2.40 = $21.00.\r\n",
            "Each person pays $21.00 / 3 = $7.00.\r\n",
            "FINAL ANSWER: 7\n",
            "\n",
            "- Gemma raw output -\n",
            "=21.00+2.40=21.00\n",
            "7.00=7.00\n",
            "FA=7\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"7\",\n",
            "  \"L1\": \"21.00+2.40=21.00\",\n",
            "  \"L2\": \"7.00=7.00\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 74 | predicted: Computational Error\n",
            "- Question -\n",
            "A water barrel contains 150 liters. It has a small leak and loses 500 ml of water every hour. After 24 hours, how many liters of water are left in the barrel?\n",
            "\n",
            "- Solution -\n",
            "The total water lost in milliliters is 500 * 24 = 12000 ml.\r\n",
            "This is equal to 12000 / 1000 = 12 liters.\r\n",
            "The water left is 150 - 12 = 138 liters.\r\n",
            "FINAL ANSWER: 138\n",
            "\n",
            "- Gemma raw output -\n",
            "=12*24=12000\n",
            "12000/1000=12\n",
            "150-12=138\n",
            "138=138\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"12*24=12000\",\n",
            "  \"L2\": \"12000/1000=12\",\n",
            "  \"L3\": \"150-12=138\",\n",
            "  \"L4\": \"138=138\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 76 | predicted: Computational Error\n",
            "- Question -\n",
            "A rectangle's length is twice its width. If the width is 7 cm, what is the perimeter of the rectangle?\n",
            "\n",
            "- Solution -\n",
            "The length of the rectangle is 2 * 7 = 14 cm.\r\n",
            "The perimeter is 2 * (14 + 7) = 42 cm.\r\n",
            "FINAL ANSWER: 42\n",
            "\n",
            "- Gemma raw output -\n",
            "=7*2=14\n",
            "=2*14+7=42\n",
            "42\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"7*2=14\",\n",
            "  \"L2\": \"2*14+7=42\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 82 | predicted: Computational Error\n",
            "- Question -\n",
            "A farm has chickens and cows. There are 25 heads and 70 legs in total. How many chickens are there?\n",
            "\n",
            "- Solution -\n",
            "Let c be the number of chickens and w be the number of cows. c + w = 25 and 2c + 4w = 70.\r\n",
            "From the first equation, w = 25 - c. Substitute this into the second: 2c + 4(25 - c) = 70.\r\n",
            "This simplifies to 2c + 100 - 4c = 70, so -2c = -30.\r\n",
            "Solving for c gives c = 15 chickens.\r\n",
            "FINAL ANSWER: 15\n",
            "\n",
            "- Gemma raw output -\n",
            "=\n",
            "{\n",
            "  \"L1\": \"25+1=25\",\n",
            "  \"L2\": \"2*c+4*25=70\",\n",
            "  \"L3\": \"2*c+100-4*c=70\",\n",
            "  \"L4\": \"c=15\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"25+1=25\",\n",
            "  \"L2\": \"2*c+4*25=70\",\n",
            "  \"L3\": \"2*c+100-4*c=70\",\n",
            "  \"L4\": \"c=15\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 85 | predicted: Computational Error\n",
            "- Question -\n",
            "A store's profit increased from $40,000 in one year to $52,000 in the next year. What was the percentage increase in profit?\n",
            "\n",
            "- Solution -\n",
            "The increase in profit was $52,000 - $40,000 = $12,000.\r\n",
            "The percentage increase is (12000 / 40000) * 100 = 30%.\r\n",
            "FINAL ANSWER: 30\n",
            "\n",
            "- Gemma raw output -\n",
            "=12000/40000=12.000\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"12000/40000=12.000\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 86 | predicted: Computational Error\n",
            "- Question -\n",
            "A project requires 3 people to work for 8 days to complete. How many days would it take for 4 people to complete the same project, assuming they all work at the same rate?\n",
            "\n",
            "- Solution -\n",
            "The total 'person-days' required is 3 * 8 = 24.\r\n",
            "For 4 people, the time taken is 24 / 4 = 6 days.\r\n",
            "FINAL ANSWER: 6\n",
            "\n",
            "- Gemma raw output -\n",
            "=8*24=24\n",
            "6*4=24\n",
            "FA=6\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"6\",\n",
            "  \"L1\": \"8*24=24\",\n",
            "  \"L2\": \"6*4=24\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 101 | predicted: Computational Error\n",
            "- Question -\n",
            "A painter needs to paint the four walls of a rectangular room. The room is 7 meters long, 5 meters wide, and 3 meters high. There is one door that is 2 meters by 1 meter and one window that is 1.5 meters by 1 meter, which will not be painted. One liter of paint covers 10 square meters. How many liters of paint are needed?\n",
            "\n",
            "- Solution -\n",
            "The total area of the four walls is 2 * (7 * 3) + 2 * (5 * 3) = 72 square meters.\r\n",
            "The area of the door and window is (2 * 1) + (1.5 * 1) = 3.5 square meters.\r\n",
            "The area to be painted is 72 - 3.5 = 68.5 square meters.\r\n",
            "The amount of paint needed is 68.5 / 10 = 6.85 liters.\r\n",
            "FINAL ANSWER: 6.85\n",
            "\n",
            "- Gemma raw output -\n",
            "=72+2*5*3=72\n",
            "=3.5+1.5=3.5\n",
            "=72-3.5=68.5\n",
            "=68.5/10=6.85\n",
            "=6.85*10=6.85\n",
            "FA=6.85\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"6.85\",\n",
            "  \"L1\": \"72+2*5*3=72\",\n",
            "  \"L2\": \"3.5+1.5=3.5\",\n",
            "  \"L3\": \"72-3.5=68.5\",\n",
            "  \"L4\": \"68.5/10=6.85\",\n",
            "  \"L5\": \"6.85*10=6.85\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 103 | predicted: Computational Error\n",
            "- Question -\n",
            "An investor bought 200 shares of a stock at $25 per share. He sold 50 shares when the price hit $35 per share. He then sold the remaining shares when the price dropped to $22 per share. What was his total net profit or loss from all transactions?\n",
            "\n",
            "- Solution -\n",
            "The initial cost was 200 * 25 = $5000.\r\n",
            "The revenue from the first sale was 50 * 35 = $1750.\r\n",
            "The revenue from the second sale was (200 - 50) * 22 = $3300.\r\n",
            "The total revenue was $1750 + $3300 = $5050.\r\n",
            "The net profit is $5050 - $5000 = $50.\r\n",
            "FINAL ANSWER: 50\n",
            "\n",
            "- Gemma raw output -\n",
            "=25*20=5000,\n",
            "=35*50=1750,\n",
            "=200-50*22=3300,\n",
            "=1750+3300=5050,\n",
            "=50*50=5000,\n",
            "=5050-5000=50,\n",
            "=50*50=5000,\n",
            "=5050-5000=50\n",
            "}\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"25*20=5000\",\n",
            "  \"L2\": \"35*50=1750\",\n",
            "  \"L3\": \"200-50*22=3300\",\n",
            "  \"L4\": \"1750+3300=5050\",\n",
            "  \"L5\": \"50*50=5000\",\n",
            "  \"L6\": \"5050-5000=50\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 104 | predicted: Computational Error\n",
            "- Question -\n",
            "A cylindrical water tank has a radius of 2 meters and a height of 5 meters. The tank is 3/4 full. A pump starts removing water at a rate of 0.5 cubic meters per minute. How many minutes will it take to empty the tank completely? Use pi = 3.14.\n",
            "\n",
            "- Solution -\n",
            "The total volume of the tank is 3.14 * (2*2) * 5 = 62.8 cubic meters.\r\n",
            "The volume of water in the tank is 62.8 * (3/4) = 47.1 cubic meters.\r\n",
            "The time to empty the tank is 47.1 / 0.5 = 94.2 minutes.\r\n",
            "FINAL ANSWER: 94.2\n",
            "\n",
            "- Gemma raw output -\n",
            "=62.8*2*5=62.8*2*5\n",
            "47.1*3/4=47.1*3/4\n",
            "94.2/0.5=94.2*0.5\n",
            "94.2=94.2\n",
            "{\n",
            "  \"L1\": \"3.14*2*5=62.8\",\n",
            "  \"L2\": \"62.8*3/4=47.1\",\n",
            "  \"L3\": \"47.1/0.5=94.2\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"3.14*2*5=62.8\",\n",
            "  \"L2\": \"62.8*3/4=47.1\",\n",
            "  \"L3\": \"47.1/0.5=94.2\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 106 | predicted: Computational Error\n",
            "- Question -\n",
            "A clothing store buys jeans for $30 a pair. They sell them at a 60% markup. At the end of the season, the remaining jeans are put on a clearance sale for 40% off the selling price. What is the profit on a pair of jeans sold during the clearance sale?\n",
            "\n",
            "- Solution -\n",
            "The regular selling price is 30 * 1.60 = $48.\r\n",
            "The clearance sale price is 48 * (1 - 0.40) = $28.80.\r\n",
            "The profit on a clearance sale pair is $28.80 - $30 = -$1.20.\r\n",
            "FINAL ANSWER: -1.2\n",
            "\n",
            "- Gemma raw output -\n",
            "=30*1.60=48\n",
            "=48*0.40=28.80\n",
            "=28.80-30=-1.2\n",
            "=1.2\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"30*1.60=48\",\n",
            "  \"L2\": \"48*0.40=28.80\",\n",
            "  \"L3\": \"28.80-30=-1.2\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 111 | predicted: Computational Error\n",
            "- Question -\n",
            "A person invests $5000 in a savings account with a 4% annual interest rate, compounded annually. They also invest $2000 in a bond that pays a simple interest of 6% per year. What is the total amount of interest earned from both investments after 3 years?\n",
            "\n",
            "- Solution -\n",
            "The total amount in the savings account after 3 years is 5000 * (1.04)^3 = $5624.32.\r\n",
            "The interest from the savings account is $5624.32 - $5000 = $624.32.\r\n",
            "The simple interest from the bond is 2000 * 0.06 * 3 = $360.\r\n",
            "The total interest earned is $624.32 + $360 = $984.32.\r\n",
            "FINAL ANSWER: 984.32\n",
            "\n",
            "- Gemma raw output -\n",
            "=5624.32\n",
            "-5000=624.32\n",
            "2000*0.06*3=360\n",
            "624.32+360=984.32\n",
            "984.32\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"-5000=624.32\",\n",
            "  \"L2\": \"2000*0.06*3=360\",\n",
            "  \"L3\": \"624.32+360=984.32\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 113 | predicted: Computational Error\n",
            "- Question -\n",
            "A factory has two machines. Machine A produces 150 units per hour but has a 10% defect rate. Machine B produces 120 units per hour with a 4% defect rate. Both machines run for an 8-hour shift. The company needs to ship an order of 2000 non-defective units. How many non-defective units are left over after the order is filled?\n",
            "\n",
            "- Solution -\n",
            "Good units from Machine A in 8 hours: 150 * 8 * (1 - 0.10) = 1080.\r\n",
            "Good units from Machine B in 8 hours: 120 * 8 * (1 - 0.04) = 921.6, which is 921 full units.\r\n",
            "Total good units: 1080 + 921 = 2001.\r\n",
            "Leftover units: 2001 - 2000 = 1.\r\n",
            "FINAL ANSWER: 1\n",
            "\n",
            "- Gemma raw output -\n",
            "=150*8*1-0.10=1080\n",
            "=120*8*1-0.04=921.6=921*1\n",
            "=1080+921=2001\n",
            "=2001-2000=1\n",
            "=1\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"150*8*1-0.10=1080\",\n",
            "  \"L2\": \"120*8*1-0.04=921.6=921*1\",\n",
            "  \"L3\": \"1080+921=2001\",\n",
            "  \"L4\": \"2001-2000=1\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 114 | predicted: Computational Error\n",
            "- Question -\n",
            "A rectangular water tank is 4 meters long, 3 meters wide, and 2.5 meters high. It is initially empty. Water is pumped in at a rate of 0.5 cubic meters per minute. At the same time, a leak at the bottom drains water at a rate of 50 liters per minute. How long will it take to fill the tank, in minutes? (1 cubic meter = 1000 liters)\n",
            "\n",
            "- Solution -\n",
            "The volume of the tank is 4 * 3 * 2.5 = 30 cubic meters.\r\n",
            "The leak rate in cubic meters per minute is 50 / 1000 = 0.05.\r\n",
            "The net fill rate is 0.5 - 0.05 = 0.45 cubic meters per minute.\r\n",
            "The time to fill the tank is 30 / 0.45 = 66.67 minutes.\r\n",
            "FINAL ANSWER: 66.67\n",
            "\n",
            "- Gemma raw output -\n",
            "=30*2.5=30,\n",
            "=50*1000=0.05,\n",
            "=0.5-0.05=0.45,\n",
            "=30*0.45=66.67,\n",
            "FA=66.67\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"66.67\",\n",
            "  \"L1\": \"30*2.5=30\",\n",
            "  \"L2\": \"50*1000=0.05\",\n",
            "  \"L3\": \"0.5-0.05=0.45\",\n",
            "  \"L4\": \"30*0.45=66.67\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 123 | predicted: Computational Error\n",
            "- Question -\n",
            "An artist is creating a mosaic on a rectangular wall that is 5 meters wide and 3 meters high. The mosaic tiles are squares with a side length of 10 cm. 60% of the tiles are blue, 30% are white, and 10% are gold. The gold tiles cost $2 each, while the other tiles cost $0.50 each. What is the total cost of all the tiles?\n",
            "\n",
            "- Solution -\n",
            "The total number of tiles needed is (500 * 300) / (10 * 10) = 1500.\r\n",
            "The number of gold tiles is 1500 * 0.10 = 150. Their cost is 150 * 2 = $300.\r\n",
            "The number of other tiles is 1500 * 0.90 = 1350. Their cost is 1350 * 0.50 = $675.\r\n",
            "The total cost of all tiles is $300 + $675 = $975.\r\n",
            "FINAL ANSWER: 975\n",
            "\n",
            "- Gemma raw output -\n",
            "=300*0.10=150,\n",
            "*150*2=300,\n",
            "*1500*0.90=1350,\n",
            "*300+675=975,\n",
            "*FA=975\n",
            "}\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"300*0.10=150\",\n",
            "  \"L2\": \"*150*2=300\",\n",
            "  \"L3\": \"*1500*0.90=1350\",\n",
            "  \"L4\": \"*300+675=975\",\n",
            "  \"L5\": \"*=975\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 126 | predicted: Computational Error\n",
            "- Question -\n",
            "A farmer has a field shaped like a trapezoid. The two parallel sides are 120 meters and 180 meters long. The height of the trapezoid (the perpendicular distance between the parallel sides) is 100 meters. The farmer wants to apply fertilizer that costs $50 per bag, and each bag covers 400 square meters. How much will the fertilizer cost for the entire field?\n",
            "\n",
            "- Solution -\n",
            "The area of the trapezoid is ((120 + 180) / 2) * 100 = 15,000 square meters.\r\n",
            "The number of bags needed is 15000 / 400 = 37.5, so 38 bags must be bought.\r\n",
            "The total cost is 38 * 50 = $1900.\r\n",
            "FINAL ANSWER: 1900\n",
            "\n",
            "- Gemma raw output -\n",
            "=15*100=15000\n",
            "15000/400=37.5\n",
            "38*50=1900\n",
            "1900\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"15*100=15000\",\n",
            "  \"L2\": \"15000/400=37.5\",\n",
            "  \"L3\": \"38*50=1900\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 129 | predicted: Computational Error\n",
            "- Question -\n",
            "An author writes a book. The publisher pays a royalty of 10% on the first 10,000 copies sold and 15% on all copies sold thereafter. The book sells for $20. If 25,000 copies of the book are sold, what is the total royalty amount the author earns?\n",
            "\n",
            "- Solution -\n",
            "Royalty from the first 10,000 copies: 10000 * 20 * 0.10 = $20,000.\r\n",
            "Royalty from the remaining copies: (25000 - 10000) * 20 * 0.15 = $45,000.\r\n",
            "Total royalty earned: $20,000 + $45,000 = $65,000.\r\n",
            "FINAL ANSWER: 65000\n",
            "\n",
            "- Gemma raw output -\n",
            "\n",
            "{\n",
            "  \"L1\": \"10000*20*0.10=20000\",\n",
            "  \"L2\": \"25000-10000*20*0.15=45000\",\n",
            "  \"L3\": \"20000+45000=65000\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"10000*20*0.10=20000\",\n",
            "  \"L2\": \"25000-10000*20*0.15=45000\",\n",
            "  \"L3\": \"20000+45000=65000\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 131 | predicted: Computational Error\n",
            "- Question -\n",
            "A science experiment requires a solution to be cooled from 80 degrees Celsius to -10 degrees Celsius. The cooling system can reduce the temperature by 4 degrees every minute. However, for the first 5 minutes, the cooling is only 50% effective due to system startup. How long does it take to reach the target temperature?\n",
            "\n",
            "- Solution -\n",
            "The total temperature drop needed is 80 - (-10) = 90 degrees.\r\n",
            "In the first 5 minutes, the temperature drops by 4 * 0.50 * 5 = 10 degrees.\r\n",
            "The remaining temperature drop is 90 - 10 = 80 degrees.\r\n",
            "The time to drop the remaining temperature is 80 / 4 = 20 minutes.\r\n",
            "The total time taken is 5 + 20 = 25 minutes.\r\n",
            "FINAL ANSWER: 25\n",
            "\n",
            "- Gemma raw output -\n",
            "=90-10=10\n",
            "=4*0.5*5=10\n",
            "=90-10=80\n",
            "=80/4=20\n",
            "=5+20=25\n",
            "=5+20=25\n",
            "FA=25\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"FA\": \"25\",\n",
            "  \"L1\": \"90-10=10\",\n",
            "  \"L2\": \"4*0.5*5=10\",\n",
            "  \"L3\": \"90-10=80\",\n",
            "  \"L4\": \"80/4=20\",\n",
            "  \"L5\": \"5+20=25\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 132 | predicted: Computational Error\n",
            "- Question -\n",
            "A company has a budget of $1,000,000 for a new project. 40% is allocated to research and development (R&D), 35% to manufacturing, and 15% to marketing. The remaining 10% is a contingency fund. During the project, R&D costs were 10% over budget, and manufacturing was 5% under budget. Marketing costs were exactly as budgeted. How much of the contingency fund was left?\n",
            "\n",
            "- Solution -\n",
            "R&D overage: (1000000 * 0.40) * 0.10 = $40,000.\r\n",
            "Manufacturing savings: (1000000 * 0.35) * 0.05 = $17,500.\r\n",
            "Net overage to be covered by contingency: $40,000 - $17,500 = $22,500.\r\n",
            "Initial contingency fund: 1000000 * 0.10 = $100,000.\r\n",
            "Remaining contingency: $100,000 - $22,500 = $77,500.\r\n",
            "FINAL ANSWER: 77500\n",
            "\n",
            "- Gemma raw output -\n",
            "=0.40*1000000=40000\n",
            "=0.35*1000000=17500\n",
            "=40000-17500=22500\n",
            "=1000000*0.10=100000\n",
            "=100000-22500=77500\n",
            "=77500\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"0.40*1000000=40000\",\n",
            "  \"L2\": \"0.35*1000000=17500\",\n",
            "  \"L3\": \"40000-17500=22500\",\n",
            "  \"L4\": \"1000000*0.10=100000\",\n",
            "  \"L5\": \"100000-22500=77500\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 133 | predicted: Computational Error\n",
            "- Question -\n",
            "Two friends, Alex and Ben, start a business. Alex invests $30,000 and Ben invests $20,000. They agree to share profits in proportion to their investment. In the first year, the business makes a revenue of $150,000 and has expenses of $80,000. They decide to reinvest 40% of the profit back into the business and distribute the rest. How much money does Alex receive?\n",
            "\n",
            "- Solution -\n",
            "Total profit: $150,000 - $80,000 = $70,000.\r\n",
            "Distributed profit: 70000 * (1 - 0.40) = $42,000.\r\n",
            "Alex's investment share: 30000 / (30000 + 20000) = 0.6.\r\n",
            "Alex's take: $42,000 * 0.60 = $25,200.\r\n",
            "FINAL ANSWER: 25200\n",
            "\n",
            "- Gemma raw output -\n",
            "\n",
            "{\n",
            "  \"L1\": \"150000-80000=70000\",\n",
            "  \"L2\": \"70000*0.40=42000\",\n",
            "  \"L3\": \"30000/30000+20000=0.6\",\n",
            "  \"L4\": \"42000*0.60=25200\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"150000-80000=70000\",\n",
            "  \"L2\": \"70000*0.40=42000\",\n",
            "  \"L3\": \"30000/30000+20000=0.6\",\n",
            "  \"L4\": \"42000*0.60=25200\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 134 | predicted: Computational Error\n",
            "- Question -\n",
            "A rectangular park is 120 meters long and 80 meters wide. A jogging path that is 2 meters wide is built around the inside edge of the park. The park's management decides to cover the path with a special rubber material that costs $40 per square meter. They also plant flowers along the outer edge of the path, which costs $10 per meter. What is the total cost for the material and the flowers?\n",
            "\n",
            "- Solution -\n",
            "The area of the path is (120 * 80) - ((120 - 4) * (80 - 4)) = 784 square meters.\r\n",
            "The material cost is 784 * 40 = $31,360.\r\n",
            "The perimeter for the flowers is 2 * (120 + 80) = 400 meters.\r\n",
            "The flower cost is 400 * 10 = $4000.\r\n",
            "The total cost is $31,360 + $4000 = $35,360.\r\n",
            "FINAL ANSWER: 35360\n",
            "\n",
            "- Gemma raw output -\n",
            "\n",
            "{\n",
            "  \"L1\": \"120*80-((120-4)*80-4)*4=784\",\n",
            "  \"L2\": \"784*40=31360\",\n",
            "  \"L3\": \"2*120+80=400\",\n",
            "  \"L4\": \"400*10=4000\",\n",
            "  \"L5\": \"31360+4000=35360\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"120*80-((120-4)*80-4)*4=784\",\n",
            "  \"L2\": \"784*40=31360\",\n",
            "  \"L3\": \"2*120+80=400\",\n",
            "  \"L4\": \"400*10=4000\",\n",
            "  \"L5\": \"31360+4000=35360\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 136 | predicted: Computational Error\n",
            "- Question -\n",
            "A small IT company has a monthly budget of $50,000. 45% is allocated to salaries, 20% to office rent, and 15% to hardware and software subscriptions. The remainder is for miscellaneous expenses. In July, salaries were 5% over budget and hardware costs were 10% under budget due to a special discount. The rent remained the same. How much money was available for miscellaneous expenses in July?\n",
            "\n",
            "- Solution -\n",
            "Budgeted salaries: 50000 * 0.45 = $22,500.\r\n",
            "Actual July salaries: 22500 * 1.05 = $23,625.\r\n",
            "Budgeted rent: 50000 * 0.20 = $10,000.\r\n",
            "Budgeted hardware/software: 50000 * 0.15 = $7,500.\r\n",
            "Actual July hardware/software costs: 7500 * 0.90 = $6,750.\r\n",
            "Total actual spending on these categories in July: 23625 + 10000 + 6750 = $40,375.\r\n",
            "Amount available for miscellaneous expenses: 50000 - 40375 = $9,625.\r\n",
            "FINAL ANSWER: 9625\n",
            "\n",
            "- Gemma raw output -\n",
            "=0.45*50000=22500\n",
            "=1.05*22500=23625\n",
            "=0.20*50000=10000\n",
            "=0.15*50000=7500\n",
            "=0.90*7500=6750\n",
            "=23625-40375=9625\n",
            "=50000-40375=9625\n",
            "=9625\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"0.45*50000=22500\",\n",
            "  \"L2\": \"1.05*22500=23625\",\n",
            "  \"L3\": \"0.20*50000=10000\",\n",
            "  \"L4\": \"0.15*50000=7500\",\n",
            "  \"L5\": \"0.90*7500=6750\",\n",
            "  \"L6\": \"23625-40375=9625\",\n",
            "  \"L7\": \"50000-40375=9625\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 141 | predicted: Computational Error\n",
            "- Question -\n",
            "A farmer is building a new fence around a rectangular pasture that is 250 meters long and 100 meters wide. The fencing material costs $12 per meter. A gate that is 4 meters wide will be installed, and this gate costs $350. The labor to install the fence costs $8 per meter, but the labor for the gate area is included in the gate's price. After fencing, the farmer buys a new irrigation system that costs $5,000, but gets a 15% discount. What is the total cost of this project?\n",
            "\n",
            "- Solution -\n",
            "Perimeter of the pasture: 2 * (250 + 100) = 700 meters.\r\n",
            "Length of fencing needed: 700 - 4 = 696 meters.\r\n",
            "Cost of fencing material: 696 * 12 = $8,352.\r\n",
            "Cost of labor for the fence: 696 * 8 = $5,568.\r\n",
            "Discount on the irrigation system: 5000 * 0.15 = $750.\r\n",
            "Final cost of the irrigation system: 5000 - 750 = $4,250.\r\n",
            "Total project cost: 8352 + 5568 + 350 (gate) + 4250 (irrigation) = $18,520.\r\n",
            "FINAL ANSWER: 18520\n",
            "\n",
            "- Gemma raw output -\n",
            "\n",
            "{\n",
            "  \"L1\": \"2*500+100=700\",\n",
            "  \"L2\": \"700-4=696\",\n",
            "  \"L3\": \"696*12=8352\",\n",
            "  \"L4\": \"696*8=5568\",\n",
            "  \"L5\": \"5000*0.15=750\",\n",
            "  \"L6\": \"5000-750=4250\",\n",
            "  \"L7\": \"8352+5568+350+4250=18520\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"2*500+100=700\",\n",
            "  \"L2\": \"700-4=696\",\n",
            "  \"L3\": \"696*12=8352\",\n",
            "  \"L4\": \"696*8=5568\",\n",
            "  \"L5\": \"5000*0.15=750\",\n",
            "  \"L6\": \"5000-750=4250\",\n",
            "  \"L7\": \"8352+5568+350+4250=18520\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 142 | predicted: Computational Error\n",
            "- Question -\n",
            "A school is organizing a book fair. They buy 300 books at an average cost of $6 per book. They categorize the books into two types: paperbacks and hardcovers. There are 200 paperbacks and 100 hardcovers. They sell paperbacks for $10 each and hardcovers for $18 each. At the end of the day, 90% of paperbacks and 75% of hardcovers are sold. The school had to pay a $250 fee to rent the space for the fair. What was the school's total profit?\n",
            "\n",
            "- Solution -\n",
            "Total cost of books: 300 * 6 = $1,800.\r\n",
            "Number of paperbacks sold: 200 * 0.90 = 180.\r\n",
            "Revenue from paperbacks: 180 * 10 = $1,800.\r\n",
            "Number of hardcovers sold: 100 * 0.75 = 75.\r\n",
            "Revenue from hardcovers: 75 * 18 = $1,350.\r\n",
            "Total revenue from sales: 1800 + 1350 = $3,150.\r\n",
            "Total expenses: 1800 (books) + 250 (rent) = $2,050.\r\n",
            "Total profit: 3150 - 2050 = $1,100.\r\n",
            "FINAL ANSWER: 1100\n",
            "\n",
            "- Gemma raw output -\n",
            "\n",
            "{\n",
            "  \"L1\": \"300*6=1800\",\n",
            "  \"L2\": \"200*0.90=180\",\n",
            "  \"L3\": \"180*10=1800\",\n",
            "  \"L4\": \"100*0.75=75\",\n",
            "  \"L5\": \"75*18=1350\",\n",
            "  \"L6\": \"1800+250=3150\",\n",
            "  \"L7\": \"1800+2050=2050\",\n",
            "  \"L8\": \"3150-2050=1100\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"300*6=1800\",\n",
            "  \"L2\": \"200*0.90=180\",\n",
            "  \"L3\": \"180*10=1800\",\n",
            "  \"L4\": \"100*0.75=75\",\n",
            "  \"L5\": \"75*18=1350\",\n",
            "  \"L6\": \"1800+250=3150\",\n",
            "  \"L7\": \"1800+2050=2050\",\n",
            "  \"L8\": \"3150-2050=1100\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 144 | predicted: Computational Error\n",
            "- Question -\n",
            "An investor has a portfolio worth $80,000. 40% is invested in stocks, 35% in bonds, and 25% in real estate. In one year, the stocks increase in value by 12%, the bonds increase by 4%, and the real estate decreases by 5%. The investor also has to pay a 1% management fee on the initial total portfolio value. What is the final value of the portfolio after one year, accounting for growth and fees?\n",
            "\n",
            "- Solution -\n",
            "Initial value of stocks: 80000 * 0.40 = $32,000.\r\n",
            "Final value of stocks: 32000 * 1.12 = $35,840.\r\n",
            "Initial value of bonds: 80000 * 0.35 = $28,000.\r\n",
            "Final value of bonds: 28000 * 1.04 = $29,120.\r\n",
            "Initial value of real estate: 80000 * 0.25 = $20,000.\r\n",
            "Final value of real estate: 20000 * 0.95 = $19,000.\r\n",
            "Total portfolio value before fee: 35840 + 29120 + 19000 = $83,960.\r\n",
            "Management fee: 80000 * 0.01 = $800.\r\n",
            "Final portfolio value after fee: 83960 - 800 = $83,160.\r\n",
            "FINAL ANSWER: 83160\n",
            "\n",
            "- Gemma raw output -\n",
            "\n",
            "{\n",
            "  \"L1\": \"80000*0.40=32000\",\n",
            "  \"L2\": \"32000*1.12=35840\",\n",
            "  \"L3\": \"80000*0.35=28000\",\n",
            "  \"L4\": \"28000*1.04=29120\",\n",
            "  \"L5\": \"80000*0.25=20000\",\n",
            "  \"L6\": \"20000*0.95=19000\",\n",
            "  \"L7\": \"35840+29120+19000=83960\",\n",
            "  \"L8\": \"800*0.01=800\",\n",
            "  \"L9\": \"83960-800=83160\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"80000*0.40=32000\",\n",
            "  \"L2\": \"32000*1.12=35840\",\n",
            "  \"L3\": \"80000*0.35=28000\",\n",
            "  \"L4\": \"28000*1.04=29120\",\n",
            "  \"L5\": \"80000*0.25=20000\",\n",
            "  \"L6\": \"20000*0.95=19000\",\n",
            "  \"L7\": \"35840+29120+19000=83960\",\n",
            "  \"L8\": \"800*0.01=800\",\n",
            "  \"L9\": \"83960-800=83160\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 146 | predicted: Computational Error\n",
            "- Question -\n",
            "A clothing company produces shirts and trousers. The cost to produce a shirt is $12 and it sells for $30. The cost to produce a pair of trousers is $20 and they sell for $55. In a week, they produce 500 shirts and 300 trousers. 5% of shirts and 8% of trousers are found to be defective and cannot be sold. The weekly operating cost for the factory is $4,000. What is the company's profit for the week?\n",
            "\n",
            "- Solution -\n",
            "Number of sellable shirts: 500 * (1 - 0.05) = 475.\r\n",
            "Revenue from shirts: 475 * 30 = $14,250.\r\n",
            "Number of sellable trousers: 300 * (1 - 0.08) = 276.\r\n",
            "Revenue from trousers: 276 * 55 = $15,180.\r\n",
            "Total revenue: 14250 + 15180 = $29,430.\r\n",
            "Total production cost (including defective items): (500 * 12) + (300 * 20) = $12,000.\r\n",
            "Total costs including operations: 12000 + 4000 = $16,000.\r\n",
            "Weekly profit: 29430 - 16000 = $13,430.\r\n",
            "FINAL ANSWER: 13430\n",
            "\n",
            "- Gemma raw output -\n",
            "\n",
            "{\n",
            "  \"L1\": \"500*(1-0.05)=475\",\n",
            "  \"L2\": \"475*30=14250\",\n",
            "  \"L3\": \"300*1-0.08=276\",\n",
            "  \"L4\": \"276*55=15180\",\n",
            "  \"L5\": \"14250+15180=29430\",\n",
            "  \"L6\": \"12000+4000=12000\",\n",
            "  \"L7\": \"12000+4000=16000\",\n",
            "  \"L8\": \"29430-16000=13430\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"500*(1-0.05)=475\",\n",
            "  \"L2\": \"475*30=14250\",\n",
            "  \"L3\": \"300*1-0.08=276\",\n",
            "  \"L4\": \"276*55=15180\",\n",
            "  \"L5\": \"14250+15180=29430\",\n",
            "  \"L6\": \"12000+4000=12000\",\n",
            "  \"L7\": \"12000+4000=16000\",\n",
            "  \"L8\": \"29430-16000=13430\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 147 | predicted: Computational Error\n",
            "- Question -\n",
            "A person earns an annual salary of $75,000. They contribute 6% of this salary to a retirement plan. Federal taxes are 15% of the remaining salary, and state taxes are 5% of the same remaining salary. Their monthly expenses include $1,200 for rent, $500 for groceries, $300 for a car payment, and $250 for utilities. How much money do they have left for discretionary spending per year?\n",
            "\n",
            "- Solution -\n",
            "Annual retirement contribution: 75000 * 0.06 = $4,500.\r\n",
            "Salary after retirement contribution: 75000 - 4500 = $70,500.\r\n",
            "Federal tax paid: 70500 * 0.15 = $10,575.\r\n",
            "State tax paid: 70500 * 0.05 = $3,525.\r\n",
            "Take-home pay after all deductions: 70500 - 10575 - 3525 = $56,400.\r\n",
            "Total monthly expenses: 1200 + 500 + 300 + 250 = $2,250.\r\n",
            "Total annual expenses: 2250 * 12 = $27,000.\r\n",
            "Discretionary income per year: 56400 - 27000 = $29,400.\r\n",
            "FINAL ANSWER: 29400\n",
            "\n",
            "- Gemma raw output -\n",
            "=75000*0.06=4500\n",
            "=75000-4500=70500\n",
            "=70500*0.15=10575\n",
            "=70500-10575-3525=3525\n",
            "=1200+500+300+250=2250\n",
            "=2250*12=27000\n",
            "=56400-27000=29400\n",
            "=29400*1=29400\n",
            "\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"75000*0.06=4500\",\n",
            "  \"L2\": \"75000-4500=70500\",\n",
            "  \"L3\": \"70500*0.15=10575\",\n",
            "  \"L4\": \"70500-10575-3525=3525\",\n",
            "  \"L5\": \"1200+500+300+250=2250\",\n",
            "  \"L6\": \"2250*12=27000\",\n",
            "  \"L7\": \"56400-27000=29400\",\n",
            "  \"L8\": \"29400*1=29400\"\n",
            "}\n",
            "================================================================================\n",
            "original_index: 148 | predicted: Computational Error\n",
            "- Question -\n",
            "A bakery is making a three-tier wedding cake. The layers are cylindrical with a height of 10 cm each. The radii are 25 cm, 20 cm, and 15 cm. The entire cake (top of the smallest tier and all exposed sides) needs to be frosted. One can of frosting costs $8 and covers 1,200 square cm. The baker also adds a decorative ribbon around the base of each of the three layers. The ribbon costs $2.50 per meter. What is the total cost for frosting and ribbon? Use pi = 3.14.\n",
            "\n",
            "- Solution -\n",
            "Lateral area of bottom tier: 2 * 3.14 * 25 * 10 = 1570.\r\n",
            "Lateral area of middle tier: 2 * 3.14 * 20 * 10 = 1256.\r\n",
            "Lateral area of top tier: 2 * 3.14 * 15 * 10 = 942.\r\n",
            "Area of the top surface (of the largest tier): 3.14 * (25*25) = 1962.5.\r\n",
            "Total area to be frosted: 1570 + 1256 + 942 + 1962.5 = 5730.5 sq cm.\r\n",
            "Number of frosting cans needed: 5730.5 / 1200 = 4.78, so 5 cans.\r\n",
            "Total cost of frosting: 5 * 8 = $40.\r\n",
            "Circumference for ribbons: (2 * 3.14 * 25) + (2 * 3.14 * 20) + (2 * 3.14 * 15) = 376.8 cm or 3.768 meters.\r\n",
            "Total cost of ribbon: 3.768 * 2.50 = $9.42.\r\n",
            "Total cost: 40 + 9.42 = $49.42.\r\n",
            "FINAL ANSWER: 49.42\n",
            "\n",
            "- Gemma raw output -\n",
            "{\n",
            "  \"L1\": \"2*3.14*25*10=1570\",\n",
            "  \"L2\": \"2*3.14*20*10=1256\",\n",
            "  \"L3\": \"2*3.14*15*10=942\",\n",
            "  \"L4\": \"3.14*25*25=1962.5\",\n",
            "  \"L5\": \"1570+1256+942+1962.5=5730.5\",\n",
            "  \"L6\": \"5730.5/1200=4.78=5\",\n",
            "  \"L7\": \"5*8=40\",\n",
            "  \"L8\": \"376.8*2.50=9.42\",\n",
            "  \"L9\": \"3.768*2.50=9.42\",\n",
            "  \"L10\": \"40+9.42=49.42\",\n",
            "  \"FA\": \"\"\n",
            "}\n",
            "\n",
            "- Extracted JSON (parsed) -\n",
            "{\n",
            "  \"L1\": \"2*3.14*25*10=1570\",\n",
            "  \"L2\": \"2*3.14*20*10=1256\",\n",
            "  \"L3\": \"2*3.14*15*10=942\",\n",
            "  \"L4\": \"3.14*25*25=1962.5\",\n",
            "  \"L5\": \"1570+1256+942+1962.5=5730.5\",\n",
            "  \"L6\": \"5730.5/1200=4.78=5\",\n",
            "  \"L7\": \"5*8=40\",\n",
            "  \"L8\": \"376.8*2.50=9.42\",\n",
            "  \"L9\": \"3.768*2.50=9.42\",\n",
            "  \"L10\": \"40+9.42=49.42\",\n",
            "  \"FA\": \"\"\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}