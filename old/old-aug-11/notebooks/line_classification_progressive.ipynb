{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "378d511b",
      "metadata": {
        "id": "378d511b"
      },
      "source": [
        "### ## Experiment 2: Per-Line Error Detection\n",
        "\n",
        "This notebook refines our approach to error detection. Instead of simply classifying a solution as `correct` or `incorrect`, the goal is to pinpoint the **exact line** where the first logical error occurs.\n",
        "\n",
        "### ### Previous Strategy: Sequence Classification\n",
        "\n",
        "Our initial method treated the task as a standard binary sequence classification problem.\n",
        "\n",
        "* **Process**: The model processed the entire `problem + solution` text and used the hidden state of the **final token** as a representation of the whole sequence. A classifier head then predicted one of two labels: `0` (correct) or `1` (incorrect).\n",
        "* **Limitation**: This approach tells us *if* a solution is flawed, but provides no information about *where* the error is.\n",
        "\n",
        "### ### New Strategy: Per-Line Classification\n",
        "\n",
        "The new strategy re-frames the problem as a **sequence labeling** task, enabling a more granular analysis.\n",
        "\n",
        "* **Process**:\n",
        "    1.  The model processes the full `problem + solution` text in a single forward pass.\n",
        "    2.  We identify and select the hidden state at the end of **each line** (specifically, at each `\\n` token).\n",
        "    3.  A single, shared classifier head is applied in parallel to each of these selected hidden states.\n",
        "    4.  This yields a sequence of logits, one for each line. Each logit represents the model's confidence that its corresponding line contains the first error.\n",
        "    5.  The model is trained using a per-line binary loss, learning to output a high value for the single correct error line and low values for all other lines.\n",
        "\n",
        "### ### Key Differences\n",
        "\n",
        "| Feature | Previous Strategy (Sequence Classification) | New Strategy (Per-Line Classification) |\n",
        "| :--- | :--- | :--- |\n",
        "| **Goal** | Is the solution correct or incorrect? | Which line contains the first error? |\n",
        "| **Output** | A single prediction for the entire solution. | A prediction *for each line* of the solution. |\n",
        "| **Model Input** | Hidden state of the **final token**. | Hidden states of **all line-end tokens**. |\n",
        "| **Label Format** | A single integer (`0` or `1`). | A sequence of binary labels (`[0, 0, 1, 0, ...]`). |\n",
        "| **Advantage**| Simple to implement. | Provides granular, interpretable feedback. |\n",
        "\n",
        "> **Note**: This advanced strategy requires a dataset with line-level labels. The code assumes your dataset contains a `first_error_line` column indicating the index of the first incorrect line, or `-1` if the solution is correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "95419eed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95419eed",
        "outputId": "cd76a865-8550-4eee-b1dc-65acda03a5f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.53.2\n",
            "  Downloading transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.2) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.2) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.2) (2025.7.14)\n",
            "Downloading transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.54.0\n",
            "    Uninstalling transformers-4.54.0:\n",
            "      Successfully uninstalled transformers-4.54.0\n",
            "Successfully installed transformers-4.53.2\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.53.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.9.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.34.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.7.14)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m128.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting trl\n",
            "  Downloading trl-0.20.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.9.0)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.0.0)\n",
            "Requirement already satisfied: transformers>=4.53.2 in /usr/local/lib/python3.11/dist-packages (from trl) (4.53.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (0.34.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.53.2->trl) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.53.2->trl) (0.21.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.12.14)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.7.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.2)\n",
            "Downloading trl-0.20.0-py3-none-any.whl (504 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.6/504.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trl\n",
            "Successfully installed trl-0.20.0\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.34.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.7.14)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.34.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.46.1\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu124\n",
            "Collecting flash-attn==2.7.4.post1\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.7.4.post1) (2.6.0+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.7.4.post1) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn==2.7.4.post1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn==2.7.4.post1) (3.0.2)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187831595 sha256=58853b28a5a926cae14402bfd8d4d93a45ebf8f9e79533f37ab09d0d77a99c05\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.7.4.post1\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Cell 1: Setup and Installations\n",
        "# (No changes from your original script)\n",
        "# ==============================================================================\n",
        "# 1.2 Install required libraries\n",
        "# Note: TRL is included for consistency with your original script, but is not\n",
        "# strictly required for this sequence classification task.\n",
        "!pip install -U transformers==4.53.2\n",
        "!pip install -U peft\n",
        "!pip install -U trl\n",
        "!pip install -U accelerate\n",
        "!pip install -U datasets\n",
        "!pip install -U bitsandbytes\n",
        "\n",
        "# Install Flash Attention 2\n",
        "!pip install flash-attn==2.7.4.post1 \\\n",
        "  --extra-index-url https://download.pytorch.org/whl/cu124 \\\n",
        "  --no-build-isolation\n",
        "\n",
        "# # !unzip -q -o /content/drive/My\\ Drive/level-1-binary.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a88bab47",
      "metadata": {
        "id": "a88bab47"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Cell 2: Project Configuration\n",
        "# ==============================================================================\n",
        "class Config:\n",
        "    \"\"\"\n",
        "    Holds all static configuration for the project.\n",
        "    \"\"\"\n",
        "    # Model ID from Hugging Face Hub\n",
        "    MODEL_ID = \"microsoft/phi-4-mini-instruct\"\n",
        "\n",
        "    # Local path to the unzipped dataset\n",
        "    DATASET_PATH = \"/content/flawed_only_line_classification_dataset.csv\"\n",
        "\n",
        "    # Directory for saving the final model adapter\n",
        "    OUTPUT_DIR = \"/content/line-classifier-output\"\n",
        "\n",
        "    # The head outputs one logit per line for binary (is/is_not_error) classification\n",
        "    NUM_LABELS = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a8ea9871",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372,
          "referenced_widgets": [
            "5345485697384a0cb1fb254eba560d96",
            "f181a3a88f50467b8aa486bc6d3f4fa7",
            "1e9f78c47b08446f87eb8236b6b20513",
            "a9d7f4dbb0b3471fb833dfdeb986e4fc",
            "892fa056882c4156863f77febfa46447",
            "767d432ff15e4beea76a59cc428f3821",
            "c268190cbce5481ca9c2ada012e90d10",
            "73fdc693931947c58b5bd82cff34622d",
            "681264275aa84c118a6bcbcc852e7ab4",
            "f91168ebc4f744289b973dacac92e751",
            "10cb1a4196394f28b391c723995e7c7a",
            "0ada7ee8aa25416da67f3d1ae5cb5f7c",
            "df43fe620a394acbb711c843a78b7bb2",
            "a9a62cd6bd08403691b5a672ec19f702",
            "e4f59a41189d46789d282d707338947c",
            "636ed92805fa4259bd66947339fcfdb7",
            "91db3e1c69e6429d9ab13a59da49ba94",
            "7303fc38bee24bae91a8404c7216f562",
            "6ea29820a969433d996995543edec5e9",
            "141c358145f7419b9d5d1d6bca2b5157",
            "ed882864d8994a0ea5f9540c3b4635df",
            "69613cebf069406f8c0bd69e7d26cbd6",
            "b227276cec014ba5a0a598540828782a",
            "4009405334ed4ebdad424a010586c14e",
            "173bb135f2614d3a8e08a6e83c68499f",
            "3faca1e2431c4c0fa79b8cac1056819b",
            "9d155d3bffa44518a0e8ac440ef9d1d1",
            "63b70b6d41bd412ab2674a764f2deba3",
            "3c8b807d9ad5489483e90595db672341",
            "8545b77e4e754f029de549188dc1c882",
            "56357a846de340f1884425f854e08487",
            "88c54bedf15c4175a9fc2c58584f5ccb",
            "ceff28e2dd554f298c096a9e30f7331f",
            "5820698fa1fb4e3c9b2acd994fb6cc2b",
            "68461ecb7e8a44c2be24fe63a84a8ed7",
            "005822a9ba214e3eae82f2bd9d1404cb",
            "6c4b6597cec84ca896a97fc0d8979c85",
            "8ed5be5c78674e20b8c8521e2b0e2c93",
            "e5ef733dc84d4aef9dee3da5d87811cc",
            "a32d4062b51a46fcb1d7a23cc22624c7",
            "1a4a89e761cb461182f779fdfbf0414f",
            "b348901da7c04d59ab3503b00c7fb5f7",
            "417d37d999f34180bcc5f0ad52eecebb",
            "3b9df550493049379a4ae9aee7780d8d",
            "b4cbdb2b9c444b6fb2ff811990c2660b",
            "402834dece9649838b67d4236ff30f08",
            "9b94586ef9bd4c46bd40be8feba48d45",
            "45dade88e03c4892b5d27412b2ed4047",
            "6ee2645025fe4eda892cb13d758d37bb",
            "7959b16302a6493dad9dba9dfd7f517f",
            "aa6530ab0c2943c381bb4b002caf1607",
            "6f4249f2897344569c3ca10e1b9d385e",
            "30f74c3a46664e24809f5deacea69c87",
            "ddab4a7a340742bcb6c8e21bae1f0782",
            "87a80bd857384d648fb5b200d206f9b6",
            "4303dd97984847a5a7783872ab0e7177",
            "9b5b11efb28d4cae9b9e6d1eb3f07ec5",
            "22100073caf646689ab90c4277a486ed",
            "9ff6f97b428e4f848a3a491fae6ac0f4",
            "590ec88fb86149a0b128d1d6f23e2ace",
            "ab5b6e9c6d14482299cd28199a0c61c6",
            "519aa06a41134a2ab68da0f09a3d884d",
            "1721ca7d9d1e4f428a3b43fbf1856e45",
            "be311bcce96742db8ca4a3da040a2b77",
            "82043032f2134f32860a208b04eb8ff1",
            "bdc96ac7a3004a05bac5382c502dc38e"
          ]
        },
        "id": "a8ea9871",
        "outputId": "604e9e26-27bc-4cbd-f7b3-8338be920478"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5345485697384a0cb1fb254eba560d96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ada7ee8aa25416da67f3d1ae5cb5f7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b227276cec014ba5a0a598540828782a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/15.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5820698fa1fb4e3c9b2acd994fb6cc2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/249 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4cbdb2b9c444b6fb2ff811990c2660b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/587 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4303dd97984847a5a7783872ab0e7177"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 1 special tokens to tokenizer\n",
            "Line separator token '<|LINE_SEP|>' has ID: 200029\n",
            "Loading flawed-only line classification dataset...\n",
            "✅ Dataset loaded successfully: 3487 samples\n",
            "Tokenizer and raw dataset loaded successfully.\n",
            "Dataset columns: ['text', 'correct_answer', 'line_labels', 'error_type', 'index', 'tier', 'source', 'relative_line_position', 'solution_length']\n",
            "Dataset size: 3487\n",
            "Vocabulary size after adding special tokens: 200030\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Cell 3: Enhanced Tokenizer Setup with Special Token Support\n",
        "# ==============================================================================\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_ID, trust_remote_code=True)\n",
        "tokenizer.padding_side = \"left\"\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Special token for reliable line separation (matching dataset creation approach)\n",
        "LINE_SEP_TOKEN = \"<|LINE_SEP|>\"\n",
        "\n",
        "# Add the special line separator token to the tokenizer\n",
        "# This avoids inconsistent newline tokenization issues we discovered\n",
        "special_tokens_dict = {\"additional_special_tokens\": [LINE_SEP_TOKEN]}\n",
        "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "print(f\"Added {num_added_tokens} special tokens to tokenizer\")\n",
        "\n",
        "# Get the token ID for our special line separator\n",
        "line_sep_token_id = tokenizer.convert_tokens_to_ids(LINE_SEP_TOKEN)\n",
        "print(f\"Line separator token '{LINE_SEP_TOKEN}' has ID: {line_sep_token_id}\")\n",
        "\n",
        "# Load the CSV dataset (not using load_from_disk for CSV files)\n",
        "print(\"Loading flawed-only line classification dataset...\")\n",
        "df = pd.read_csv(Config.DATASET_PATH)\n",
        "print(f\"✅ Dataset loaded successfully: {len(df)} samples\")\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "raw_dataset = Dataset.from_pandas(df)\n",
        "\n",
        "print(\"Tokenizer and raw dataset loaded successfully.\")\n",
        "print(f\"Dataset columns: {raw_dataset.column_names}\")\n",
        "print(f\"Dataset size: {len(raw_dataset)}\")\n",
        "print(f\"Vocabulary size after adding special tokens: {len(tokenizer)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cd57589f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd57589f",
        "outputId": "db803cbe-c4d6-450e-afb9-91b11ba7fc97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'Analyze the following mathematical problem and solution to identify the line containing the error.\\n\\n### Problem:\\nWeng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\\n\\n### Solution:\\nWeng earns 12/60 = $0.2 per minute.<|LINE_SEP|>Working 50 minutes, she earned 50 x 50 = $2500.<|LINE_SEP|>#### 2500<|LINE_SEP|>', 'correct_answer': 'Weng earns 12/60 = $0.2 per minute.\\nWorking 50 minutes, she earned 0.2 x 50 = $10.\\n#### 10', 'line_labels': '[0, 1, 0]', 'error_type': 'conceptual_error', 'index': 1, 'tier': 'tier4', 'source': 'programmatic', 'relative_line_position': 0.5, 'solution_length': 3}\n"
          ]
        }
      ],
      "source": [
        "row = df.iloc[0]\n",
        "print(row.to_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7fbd698d",
      "metadata": {
        "id": "7fbd698d"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Cell 4: UPDATED Preprocessing Function for Special Tokens\n",
        "# ==============================================================================\n",
        "def preprocess_for_line_detection(examples):\n",
        "    \"\"\"\n",
        "    Prepares the flawed-only dataset for line-level error detection.\n",
        "\n",
        "    This function uses the pre-preprocessed text with special tokens,\n",
        "    finds the special token indices, and uses the pre-computed line_labels.\n",
        "\n",
        "    Args:\n",
        "        examples (dict): A batch of examples from the flawed-only dataset.\n",
        "                         Expected columns: 'text', 'line_labels'\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the tokenized inputs, attention masks,\n",
        "              the calculated line-end indices, and the per-line labels.\n",
        "    \"\"\"\n",
        "    # Use the pre-processed text directly (already contains special tokens)\n",
        "    input_texts = examples[\"text\"]\n",
        "\n",
        "    tokenized_outputs = tokenizer(\n",
        "        input_texts,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=False\n",
        "    )\n",
        "\n",
        "    # Find special token indices (instead of newlines)\n",
        "    all_line_end_indices = []\n",
        "    for input_ids in tokenized_outputs[\"input_ids\"]:\n",
        "        indices = [i for i, token_id in enumerate(input_ids) if token_id == line_sep_token_id]\n",
        "        all_line_end_indices.append(indices)\n",
        "\n",
        "    tokenized_outputs[\"line_end_indices\"] = all_line_end_indices\n",
        "\n",
        "    # Use the pre-computed line_labels from the dataset\n",
        "    # Convert string representation to list if needed\n",
        "    per_line_labels = []\n",
        "    for line_labels_raw in examples[\"line_labels\"]:\n",
        "        if isinstance(line_labels_raw, str):\n",
        "            # Parse string representation like \"[0, 0, 1, 0]\"\n",
        "            import ast\n",
        "            line_labels = ast.literal_eval(line_labels_raw)\n",
        "        else:\n",
        "            line_labels = line_labels_raw\n",
        "        per_line_labels.append(line_labels)\n",
        "\n",
        "    tokenized_outputs[\"labels\"] = per_line_labels\n",
        "\n",
        "    # For metrics computation, also compute first_error_line\n",
        "    first_error_lines = []\n",
        "    for line_labels in per_line_labels:\n",
        "        try:\n",
        "            first_error_line = line_labels.index(1)  # Find first occurrence of 1\n",
        "        except ValueError:\n",
        "            first_error_line = -1  # No error found (shouldn't happen in flawed-only dataset)\n",
        "        first_error_lines.append(first_error_line)\n",
        "\n",
        "    tokenized_outputs[\"first_error_line\"] = first_error_lines\n",
        "\n",
        "    return tokenized_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "48cf8283",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "20cf9c9f2f154f41b8b73d914ec1947b",
            "e6ed981dad4d4457b44774f0bf3420bb",
            "d73e0d510071416bb700693e7bcb44b4",
            "b72617a255ae4f8fb8d309c3bcdaac52",
            "735d1a316bfa4ba4952cba70c6ccf58d",
            "c8003d111502452a8016cfcee1a96dea",
            "c50d65f51301471f9df4ec1560b4f21e",
            "2372b7004a1e477fafa700b3e3741599",
            "10a7f527ead346dfbef7beaa373f6ae4",
            "ced3afa7419b4a29b76302dfba88aa95",
            "c71c150bd1514bdc9766e45acf2c3078",
            "e07fed6cdd7f4c9684486d122f562f65",
            "bc68a5650bb34b0cae21ad0a4f6747a4",
            "f3d94dae5812486eb6d7de1215a1dde4",
            "7c026b5de4a74d2a913ceb1e6222186e",
            "31fb695829224d12a203d65432f7cab6",
            "69dda00401de4255b19fac7b886caf6b",
            "01e05a2fac294dc3b762f0f866628fa3",
            "10cf529e3b8d49c0bdcbab4167fb1db4",
            "642c30c9bf5f46aabd96e2b0ab5f4eaa",
            "31ecb8654eb24f979d12256c00d9d119",
            "9bc6acc7ae6f4600a0432868dcd53468"
          ]
        },
        "id": "48cf8283",
        "outputId": "b1bf96da-0dd3-4e2a-eef1-3904f5ce8dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying preprocessing to the dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2789 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20cf9c9f2f154f41b8b73d914ec1947b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/698 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e07fed6cdd7f4c9684486d122f562f65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Preprocessing for flawed-only line detection complete ---\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'correct_answer', 'line_labels', 'error_type', 'index', 'tier', 'source', 'relative_line_position', 'solution_length', 'input_ids', 'attention_mask', 'line_end_indices', 'labels', 'first_error_line'],\n",
            "        num_rows: 2789\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'correct_answer', 'line_labels', 'error_type', 'index', 'tier', 'source', 'relative_line_position', 'solution_length', 'input_ids', 'attention_mask', 'line_end_indices', 'labels', 'first_error_line'],\n",
            "        num_rows: 698\n",
            "    })\n",
            "})\n",
            "Train samples: 2789\n",
            "Test samples: 698\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Cell 5: Apply Preprocessing and Finalize Dataset\n",
        "# ==============================================================================\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "# Split into train/test (80/20 split)\n",
        "split_dataset = raw_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "print(\"Applying preprocessing to the dataset...\")\n",
        "tokenized_dataset = split_dataset.map(\n",
        "    preprocess_for_line_detection,\n",
        "    batched=True,\n",
        "    # Keep all original columns for convenience - Trainer will select what it needs\n",
        "    remove_columns=None\n",
        ")\n",
        "\n",
        "final_dataset = DatasetDict({\n",
        "    \"train\": tokenized_dataset[\"train\"],\n",
        "    \"test\": tokenized_dataset[\"test\"]\n",
        "})\n",
        "\n",
        "print(\"\\n--- Preprocessing for flawed-only line detection complete ---\")\n",
        "print(final_dataset)\n",
        "print(f\"Train samples: {len(final_dataset['train'])}\")\n",
        "print(f\"Test samples: {len(final_dataset['test'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "99e1ff30",
      "metadata": {
        "id": "99e1ff30"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Cell 6: Custom Data Collator\n",
        "# ==============================================================================\n",
        "import torch\n",
        "from dataclasses import dataclass\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorForLineClassification:\n",
        "    \"\"\"\n",
        "    A data collator that handles padding for our line-level task.\n",
        "    Updated to work with variable-length line_labels from flawed-only dataset.\n",
        "    \"\"\"\n",
        "    tokenizer: AutoTokenizer\n",
        "    padding_value: int = -100  # Standard value to ignore in loss functions\n",
        "\n",
        "    def __call__(self, features):\n",
        "        batch = {}\n",
        "\n",
        "        # Use the tokenizer's default padding for inputs and attention mask\n",
        "        padded_inputs = self.tokenizer.pad(\n",
        "            [{\"input_ids\": f[\"input_ids\"], \"attention_mask\": f[\"attention_mask\"]} for f in features],\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        batch[\"input_ids\"] = padded_inputs[\"input_ids\"]\n",
        "        batch[\"attention_mask\"] = padded_inputs[\"attention_mask\"]\n",
        "\n",
        "        # Manually pad our custom fields\n",
        "        max_lines = max(len(f[\"line_end_indices\"]) for f in features)\n",
        "        max_labels = max(len(f[\"labels\"]) for f in features)\n",
        "\n",
        "        # Ensure line_end_indices and labels have the same max length\n",
        "        max_length = max(max_lines, max_labels)\n",
        "\n",
        "        padded_line_indices = []\n",
        "        padded_labels = []\n",
        "\n",
        "        for f in features:\n",
        "            line_indices = f[\"line_end_indices\"]\n",
        "            labels = f[\"labels\"]\n",
        "\n",
        "            # Pad line_end_indices\n",
        "            padded_line_indices.append(\n",
        "                line_indices + [self.padding_value] * (max_length - len(line_indices))\n",
        "            )\n",
        "\n",
        "            # Pad labels\n",
        "            padded_labels.append(\n",
        "                labels + [self.padding_value] * (max_length - len(labels))\n",
        "            )\n",
        "\n",
        "        batch[\"line_end_indices\"] = torch.tensor(padded_line_indices, dtype=torch.long)\n",
        "        batch[\"labels\"] = torch.tensor(padded_labels, dtype=torch.float)\n",
        "\n",
        "        # Keep the computed first_error_line for metrics\n",
        "        if \"first_error_line\" in features[0]:\n",
        "            batch[\"first_error_line\"] = torch.tensor([f[\"first_error_line\"] for f in features], dtype=torch.long)\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c8244a71",
      "metadata": {
        "id": "c8244a71"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Cell 7: FIXED Custom Model Definition with Proper Dtype Handling\n",
        "# ==============================================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "class GPTLineErrorDetector(nn.Module):\n",
        "    \"\"\"\n",
        "    A custom model wrapper for line-level error detection.\n",
        "\n",
        "    This model uses a pre-trained transformer backbone and applies a shared\n",
        "    linear classifier head to the hidden state of each line-ending token.\n",
        "    \"\"\"\n",
        "    def __init__(self, base_model: PeftModel, num_labels: int):\n",
        "        super().__init__()\n",
        "        self.base = base_model\n",
        "        hidden_size = base_model.config.hidden_size\n",
        "\n",
        "        # CRITICAL FIX: Create classifier with the same dtype as the base model\n",
        "        # Since we're using 4-bit quantization with bfloat16 compute dtype\n",
        "        self.classifier = nn.Linear(hidden_size, num_labels, bias=True, dtype=torch.bfloat16)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, line_end_indices=None, labels=None, **kw):\n",
        "        \"\"\"\n",
        "        Defines the forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            input_ids (torch.Tensor): Padded token IDs for the batch.\n",
        "            attention_mask (torch.Tensor): Attention mask for the batch.\n",
        "            line_end_indices (torch.Tensor): Padded indices of line-end tokens.\n",
        "            labels (torch.Tensor): Padded per-line binary labels.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing the loss (if labels are provided)\n",
        "                  and the logits for each line.\n",
        "        \"\"\"\n",
        "        outputs = self.base(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_hidden_states=True,\n",
        "        )\n",
        "        last_hidden_state = outputs.hidden_states[-1]\n",
        "\n",
        "        batch_size, max_lines = line_end_indices.shape\n",
        "        hidden_dim = last_hidden_state.shape[-1]\n",
        "\n",
        "        # Create a mask to avoid gathering from padded indices (-100)\n",
        "        valid_indices_mask = (line_end_indices != -100)\n",
        "        clamped_indices = line_end_indices.clamp(min=0)\n",
        "\n",
        "        expanded_indices = clamped_indices.unsqueeze(-1).expand(batch_size, max_lines, hidden_dim)\n",
        "        line_end_hidden_states = torch.gather(last_hidden_state, 1, expanded_indices)\n",
        "\n",
        "        # DTYPE FIX: Ensure both tensors have the same dtype\n",
        "        if line_end_hidden_states.dtype != self.classifier.weight.dtype:\n",
        "            line_end_hidden_states = line_end_hidden_states.to(self.classifier.weight.dtype)\n",
        "\n",
        "        logits = self.classifier(line_end_hidden_states).squeeze(-1)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            # Mask the logits and labels to compute loss only on valid lines\n",
        "            valid_logits = logits[valid_indices_mask]\n",
        "            valid_labels = labels[valid_indices_mask]\n",
        "\n",
        "            # Ensure labels have the same dtype as logits\n",
        "            if valid_labels.dtype != valid_logits.dtype:\n",
        "                valid_labels = valid_labels.to(valid_logits.dtype)\n",
        "\n",
        "            loss = F.binary_cross_entropy_with_logits(valid_logits, valid_labels)\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# Cell 8: FIXED Model Initialization with Proper Dtype Management\n",
        "# ==============================================================================\n",
        "from transformers import BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import torch\n",
        "\n",
        "# Configuration for 4-bit quantization\n",
        "quant_cfg = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# Configuration for LoRA adapters\n",
        "lora_cfg = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    target_modules=\"all-linear\"\n",
        ")\n",
        "\n",
        "# Load the base model with quantization\n",
        "backbone = AutoModelForCausalLM.from_pretrained(\n",
        "    Config.MODEL_ID,\n",
        "    quantization_config=quant_cfg,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        ")\n",
        "backbone.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "# Apply LoRA adapters to the base model\n",
        "peft_backbone = get_peft_model(backbone, lora_cfg)\n",
        "\n",
        "# Create the final custom model\n",
        "model = GPTLineErrorDetector(peft_backbone, Config.NUM_LABELS)\n",
        "\n",
        "# CRITICAL FIX: Move the entire model to GPU and ensure proper dtype\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Ensure classifier is in the right dtype and device\n",
        "if hasattr(model, 'classifier'):\n",
        "    model.classifier = model.classifier.to(device=device, dtype=torch.bfloat16)\n",
        "\n",
        "print(f\"🎯 Model moved to device: {device}\")\n",
        "print(f\"🔧 Classifier dtype: {model.classifier.weight.dtype}\")\n",
        "print(f\"🔧 Classifier device: {model.classifier.weight.device}\")\n",
        "\n",
        "model.base.print_trainable_parameters()\n",
        "print(\"\\n--- Line detection model ready for training ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "0f417866f02f41378a3bd2a6c2c461d7",
            "2db862f6fbd34662b5cd367b529dd6bd",
            "66d8f685f51844a3b3a30a1ecdd9b5b5",
            "5f6b9e7fcf0445f7b7bcc7d600ba4d2b",
            "6055cf94bd894096b58307e4c6a37194",
            "0b36bc4b3f7e430cb207e4aae05e2aee",
            "e811179cefa846b59b54981ec8ca1a1d",
            "6afee8670a3449ff84f69167e3081fd4",
            "754d7b2c931341218427573d8fce2fbc",
            "6f12babf129e4b988307a136a0ce2a07",
            "e84c5eec69e340e684951503d80a2dab"
          ]
        },
        "id": "mRL0PlcXv0du",
        "outputId": "365f6c46-9534-4510-dc1b-66c59d8dd496"
      },
      "id": "mRL0PlcXv0du",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f417866f02f41378a3bd2a6c2c461d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 Model moved to device: cuda\n",
            "🔧 Classifier dtype: torch.bfloat16\n",
            "🔧 Classifier device: cuda:0\n",
            "trainable params: 23,068,672 || all params: 3,859,090,432 || trainable%: 0.5978\n",
            "\n",
            "--- Line detection model ready for training ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "0e49b04d",
      "metadata": {
        "id": "0e49b04d"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# UPDATED: A100-Optimized Testing Functions with Fixed Device Handling\n",
        "# ==============================================================================\n",
        "import torch\n",
        "import time\n",
        "import psutil\n",
        "\n",
        "def test_model_forward_pass_a100(model, data_collator, processed_dataset, device='cuda'):\n",
        "    \"\"\"Test model forward pass optimized for A100 GPU with proper device handling\"\"\"\n",
        "    print(\"\\n🧪 TEST 6: Model Forward Pass Validation (A100 GPU)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # GPU info\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        print(f\"🚀 GPU: {gpu_name}\")\n",
        "        print(f\"💾 Total GPU Memory: {total_memory:.1f} GB\")\n",
        "        print(f\"📍 Using device: {device}\")\n",
        "\n",
        "        # Clear GPU cache\n",
        "        torch.cuda.empty_cache()\n",
        "        print(f\"🧹 Cleared GPU cache\")\n",
        "\n",
        "    try:\n",
        "        # Ensure model is on correct device\n",
        "        model = model.to(device)\n",
        "        print(f\"✅ Model moved to {device}\")\n",
        "\n",
        "        # Create a small batch\n",
        "        batch_samples = [processed_dataset[i] for i in range(min(2, len(processed_dataset)))]\n",
        "        batch = data_collator(batch_samples)\n",
        "\n",
        "        # Move batch to device\n",
        "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
        "\n",
        "        print(f\"🚀 Testing forward pass with batch size: {batch['input_ids'].shape[0]}\")\n",
        "        print(f\"📊 Input sequence length: {batch['input_ids'].shape[1]}\")\n",
        "\n",
        "        # Verify all tensors are on the same device\n",
        "        print(f\"🔍 Device verification:\")\n",
        "        for key, tensor in batch.items():\n",
        "            if isinstance(tensor, torch.Tensor):\n",
        "                print(f\"   {key}: {tensor.device}\")\n",
        "\n",
        "        # Check model device\n",
        "        print(f\"   model.classifier: {next(model.classifier.parameters()).device}\")\n",
        "        print(f\"   model.base device_map: {getattr(model.base, 'hf_device_map', 'Not set')}\")\n",
        "\n",
        "        # Model forward pass with timing\n",
        "        model.eval()\n",
        "        start_time = time.time()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        print(f\"✅ Forward pass successful\")\n",
        "        print(f\"⏱️ Forward pass time: {(end_time - start_time)*1000:.1f}ms\")\n",
        "        print(f\"📤 Output keys: {list(outputs.keys())}\")\n",
        "\n",
        "        # Check output shapes and values\n",
        "        if 'logits' in outputs:\n",
        "            logits = outputs['logits']\n",
        "            print(f\"   Logits shape: {logits.shape}\")\n",
        "            print(f\"   Logits dtype: {logits.dtype}\")\n",
        "            print(f\"   Logits device: {logits.device}\")\n",
        "            print(f\"   Logits range: [{logits.min().item():.3f}, {logits.max().item():.3f}]\")\n",
        "\n",
        "        if 'loss' in outputs and outputs['loss'] is not None:\n",
        "            loss = outputs['loss']\n",
        "            print(f\"   Loss: {loss.item():.4f}\")\n",
        "            print(f\"   Loss device: {loss.device}\")\n",
        "\n",
        "        # GPU memory usage\n",
        "        if torch.cuda.is_available():\n",
        "            memory_used = torch.cuda.memory_allocated(0) / 1e9\n",
        "            memory_cached = torch.cuda.memory_reserved(0) / 1e9\n",
        "            print(f\"💾 GPU Memory Used: {memory_used:.2f} GB\")\n",
        "            print(f\"💾 GPU Memory Cached: {memory_cached:.2f} GB\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Model forward pass failed: {e}\")\n",
        "        print(f\"🔍 Detailed error:\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_model_inference_colab_a100(model, tokenizer, processed_dataset, device='cuda'):\n",
        "    \"\"\"Test complete inference pipeline optimized for Colab A100\"\"\"\n",
        "    print(\"\\n🧪 INFERENCE TEST: Complete Pipeline (A100 GPU)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        # Ensure model is on correct device\n",
        "        model = model.to(device)\n",
        "\n",
        "        print(f\"📝 Testing complete inference pipeline\")\n",
        "        print(f\"🎯 Device: {device}\")\n",
        "\n",
        "        # Get a sample\n",
        "        sample = processed_dataset[0]\n",
        "        print(f\"📋 Testing with sample 0\")\n",
        "        print(f\"   📏 Input length: {len(sample['input_ids'])} tokens\")\n",
        "        print(f\"   📍 Number of lines: {len(sample['line_end_indices'])}\")\n",
        "        print(f\"   🏷️ True labels: {sample['labels']}\")\n",
        "        print(f\"   🎯 True first error line: {sample['first_error_line']}\")\n",
        "\n",
        "        # Create data collator and process single sample\n",
        "        data_collator = DataCollatorForLineClassification(tokenizer=tokenizer)\n",
        "        batch = data_collator([sample])\n",
        "\n",
        "        # Move to device\n",
        "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
        "\n",
        "        # Inference\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        # Process results\n",
        "        logits = outputs['logits'][0]  # Remove batch dimension\n",
        "\n",
        "        # Apply sigmoid to get probabilities\n",
        "        probabilities = torch.sigmoid(logits)\n",
        "\n",
        "        # Find predicted error line\n",
        "        predicted_error_line = torch.argmax(probabilities).item()\n",
        "        confidence = probabilities[predicted_error_line].item()\n",
        "\n",
        "        print(f\"\\n📊 INFERENCE RESULTS:\")\n",
        "        print(f\"   🎯 Predicted error line: {predicted_error_line}\")\n",
        "        print(f\"   🎯 True error line: {sample['first_error_line']}\")\n",
        "        print(f\"   📈 Confidence: {confidence:.3f}\")\n",
        "        print(f\"   ✅ Correct: {'Yes' if predicted_error_line == sample['first_error_line'] else 'No'}\")\n",
        "\n",
        "        # Show per-line probabilities\n",
        "        valid_lines = len(sample['line_end_indices'])\n",
        "        print(f\"\\n📋 Per-line probabilities:\")\n",
        "        for i in range(min(valid_lines, len(probabilities))):\n",
        "            prob = probabilities[i].item()\n",
        "            is_true_error = (i == sample['first_error_line'])\n",
        "            marker = \"🎯\" if is_true_error else \"  \"\n",
        "            print(f\"   {marker} Line {i}: {prob:.3f}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Inference test failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "\n",
        "def test_gpu_performance_a100(model, data_collator, processed_dataset, device='cuda'):\n",
        "    \"\"\"Test GPU performance with different batch sizes on A100\"\"\"\n",
        "    print(\"\\n🧪 GPU PERFORMANCE TEST (A100)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"⚠️ CUDA not available - cannot run GPU performance test\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        # Ensure model is on GPU\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        batch_sizes = [1, 2, 4, 8]\n",
        "        performance_results = []\n",
        "\n",
        "        for batch_size in batch_sizes:\n",
        "            if batch_size > len(processed_dataset):\n",
        "                continue\n",
        "\n",
        "            print(f\"\\n🔬 Testing batch size: {batch_size}\")\n",
        "\n",
        "            # Create batch\n",
        "            batch_samples = [processed_dataset[i] for i in range(batch_size)]\n",
        "            batch = data_collator(batch_samples)\n",
        "            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
        "\n",
        "            # Clear cache and measure memory\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "            memory_before = torch.cuda.memory_allocated(0) / 1e9\n",
        "\n",
        "            # Time forward pass\n",
        "            times = []\n",
        "            for _ in range(5):  # Average over 5 runs\n",
        "                torch.cuda.synchronize()\n",
        "                start_time = time.time()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(**batch)\n",
        "\n",
        "                torch.cuda.synchronize()\n",
        "                end_time = time.time()\n",
        "                times.append(end_time - start_time)\n",
        "\n",
        "            memory_after = torch.cuda.memory_allocated(0) / 1e9\n",
        "            memory_used = memory_after - memory_before\n",
        "\n",
        "            avg_time = sum(times) / len(times)\n",
        "            throughput = batch_size / avg_time\n",
        "\n",
        "            result = {\n",
        "                'batch_size': batch_size,\n",
        "                'avg_time_ms': avg_time * 1000,\n",
        "                'throughput_samples_per_sec': throughput,\n",
        "                'memory_used_gb': memory_used,\n",
        "                'sequence_length': batch['input_ids'].shape[1]\n",
        "            }\n",
        "            performance_results.append(result)\n",
        "\n",
        "            print(f\"   ⏱️ Avg time: {avg_time*1000:.1f}ms\")\n",
        "            print(f\"   🚀 Throughput: {throughput:.1f} samples/sec\")\n",
        "            print(f\"   💾 Memory used: {memory_used:.3f} GB\")\n",
        "\n",
        "        # Find optimal batch size\n",
        "        optimal_batch = max(performance_results, key=lambda x: x['throughput_samples_per_sec'])\n",
        "\n",
        "        print(f\"\\n🏆 OPTIMAL CONFIGURATION:\")\n",
        "        print(f\"   Batch size: {optimal_batch['batch_size']}\")\n",
        "        print(f\"   Throughput: {optimal_batch['throughput_samples_per_sec']:.1f} samples/sec\")\n",
        "        print(f\"   Time per batch: {optimal_batch['avg_time_ms']:.1f}ms\")\n",
        "        print(f\"   Memory usage: {optimal_batch['memory_used_gb']:.3f} GB\")\n",
        "\n",
        "        return performance_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ GPU performance test failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "2dda72a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e91be68e7b134fa2a680a35e68a34935",
            "cc94d6b002444e0d958398402a3fb3d0",
            "785ecd7e4c234485b009e9e84536e43a",
            "f926db3da1d34cfba3b968baf0105f1a",
            "6d5cf285e2e141b4b3421d87eb7fec0c",
            "2d347e4415c6435990690bdf3c10806a",
            "e8bc20da2ef64c0a98342d51d93da7ab",
            "d127b43fbc9846bf9199d169d50440db",
            "8dcefdbf6d5b4591ac6432ed52e26f7c",
            "df809a3560d64d39b98f52fceebc26d7",
            "144b5d94bdee40ed99ba6f5659aba622"
          ]
        },
        "id": "2dda72a5",
        "outputId": "0e6db7a5-c155-4048-987a-cd7cf02fa988"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e91be68e7b134fa2a680a35e68a34935"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧪 TEST 6: Model Forward Pass Validation (A100 GPU)\n",
            "============================================================\n",
            "🚀 GPU: NVIDIA A100-SXM4-40GB\n",
            "💾 Total GPU Memory: 42.5 GB\n",
            "📍 Using device: cuda:0\n",
            "🧹 Cleared GPU cache\n",
            "🚀 Testing forward pass with batch size: 2\n",
            "📊 Input sequence length: 317\n",
            "💾 GPU memory allocated before: 8090.5 MB\n",
            "💾 GPU memory allocated after: 8090.5 MB\n",
            "📈 Memory increase: 0.0 MB\n",
            "✅ Forward pass successful\n",
            "📤 Output keys: ['loss', 'logits']\n",
            "   📊 Logits shape: torch.Size([2, 7])\n",
            "   🔢 Logits dtype: torch.bfloat16\n",
            "   📈 Logits range: [-0.547, 1.570]\n",
            "   🎯 Logits device: cuda:0\n",
            "   💥 Loss: 0.7500\n",
            "   🎯 Loss device: cuda:0\n",
            "   🔮 Predicted error lines: [0, 5]\n",
            "   ✅ True error lines: [6, 0]\n",
            "   🎯 Batch accuracy: 0.000\n",
            "🧹 Cleared GPU cache after test\n",
            "\n",
            "🧪 INFERENCE TEST: Complete Pipeline (A100 GPU)\n",
            "============================================================\n",
            "📝 Testing complete inference pipeline\n",
            "🎯 Device: cuda:0\n",
            "📋 Testing with sample 0\n",
            "   📏 Input length: 317 tokens\n",
            "   📍 Number of lines: 7\n",
            "   🏷️ True labels: [0, 0, 0, 0, 0, 0, 1]\n",
            "   🎯 True first error line: 6\n",
            "\n",
            "📊 INFERENCE RESULTS:\n",
            "   🔮 Predicted error line: 0\n",
            "   ✅ True error line: 6\n",
            "   🎯 Correct: ❌\n",
            "\n",
            "📈 Line-by-line confidence scores:\n",
            "   🔥 Line 0: 0.445   \n",
            "      Line 1: 0.079   \n",
            "      Line 2: 0.092   \n",
            "      Line 3: 0.088   \n",
            "      Line 4: 0.076   \n",
            "      Line 5: 0.100   \n",
            "      Line 6: 0.119 ✅\n",
            "\n",
            "🧪 GPU PERFORMANCE TEST (A100)\n",
            "============================================================\n",
            "🏃‍♂️ Testing different batch sizes...\n",
            "   Batch  1: 0.110s | 9.1 samples/s | 8091MB\n",
            "   Batch  2: 0.126s | 15.8 samples/s | 8091MB\n",
            "   Batch  4: 0.165s | 24.3 samples/s | 8091MB\n",
            "✅ Performance test completed\n"
          ]
        }
      ],
      "source": [
        "test_df = df.sample(5, random_state=42)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "processed_test_dataset = test_dataset.map(preprocess_for_line_detection, batched=True)\n",
        "\n",
        "# Recreate the data collator and test the model forward pass\n",
        "data_collator = DataCollatorForLineClassification(tokenizer=tokenizer)\n",
        "\n",
        "# Test the model forward pass (optimized for A100)\n",
        "test_result = test_model_forward_pass(model, data_collator, processed_test_dataset, device='cuda:0')\n",
        "\n",
        "# Test complete inference pipeline\n",
        "inference_result = test_model_inference_colab(model, tokenizer, data_collator, processed_test_dataset, device='cuda:0')\n",
        "\n",
        "# Test performance characteristics\n",
        "perf_result = test_gpu_performance(model, data_collator, processed_test_dataset, device='cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "3ad6d00c",
      "metadata": {
        "id": "3ad6d00c"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Cell 9: Custom Metrics Function\n",
        "# ==============================================================================\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics_for_line_detection(eval_pred):\n",
        "    \"\"\"\n",
        "    Calculates accuracy for the flawed-only line detection task.\n",
        "\n",
        "    Since all samples have exactly one error line, we compare the predicted\n",
        "    error line (argmax of logits) to the true error line index.\n",
        "    \"\"\"\n",
        "    logits, true_error_lines = eval_pred\n",
        "\n",
        "    # Find the predicted line index by taking the argmax over the line logits\n",
        "    predicted_error_lines = np.argmax(logits, axis=1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = (predicted_error_lines == true_error_lines).mean()\n",
        "\n",
        "    # Additional metrics for better evaluation\n",
        "    total_samples = len(true_error_lines)\n",
        "    correct_predictions = (predicted_error_lines == true_error_lines).sum()\n",
        "\n",
        "    return {\n",
        "        \"line_accuracy\": accuracy,\n",
        "        \"correct_predictions\": correct_predictions,\n",
        "        \"total_samples\": total_samples\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "d599c25d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d599c25d",
        "outputId": "8f7d4566-2a11-4096-fe0a-1ec82539ade9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Trainer initialized for flawed-only line detection ---\n",
            "Training samples: 2789\n",
            "Evaluation samples: 698\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Cell 10: Training Setup\n",
        "# ==============================================================================\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# Define training arguments optimized for flawed-only dataset\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=Config.OUTPUT_DIR,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=8,  # Effective batch size = 32\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    learning_rate=2e-4,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.1,\n",
        "    bf16=True,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=25,\n",
        "    eval_strategy=\"epoch\",  # Added evaluation during training\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=True,  # Load best model based on eval metric\n",
        "    metric_for_best_model=\"line_accuracy\",  # Use our custom metric\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\",\n",
        "    save_safetensors=False,\n",
        "    label_names=[\"first_error_line\"]  # For metrics computation\n",
        ")\n",
        "\n",
        "# Instantiate the updated data collator\n",
        "data_collator = DataCollatorForLineClassification(tokenizer=tokenizer)\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=final_dataset[\"train\"],\n",
        "    eval_dataset=final_dataset[\"test\"],\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics_for_line_detection,\n",
        ")\n",
        "\n",
        "print(\"--- Trainer initialized for flawed-only line detection ---\")\n",
        "print(f\"Training samples: {len(final_dataset['train'])}\")\n",
        "print(f\"Evaluation samples: {len(final_dataset['test'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "fb5efb7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "fb5efb7b",
        "outputId": "c59a6bf5-b6a9-4ae4-c722-19ae93d51a61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting model training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='264' max='264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [264/264 12:46, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Line Accuracy</th>\n",
              "      <th>Correct Predictions</th>\n",
              "      <th>Total Samples</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.206300</td>\n",
              "      <td>0.523020</td>\n",
              "      <td>0.326648</td>\n",
              "      <td>228</td>\n",
              "      <td>698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.823500</td>\n",
              "      <td>0.496404</td>\n",
              "      <td>0.351003</td>\n",
              "      <td>245</td>\n",
              "      <td>698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.504400</td>\n",
              "      <td>0.482553</td>\n",
              "      <td>0.352436</td>\n",
              "      <td>246</td>\n",
              "      <td>698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were unexpected keys in the checkpoint model loaded: ['base.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.0.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.0.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.0.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.0.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.0.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.0.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.1.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.1.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.1.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.1.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.1.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.1.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.2.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.2.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.2.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.2.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.2.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.2.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.3.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.3.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.3.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.3.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.3.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.3.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.4.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.4.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.4.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.4.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.4.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.4.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.5.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.5.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.5.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.5.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.5.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.5.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.6.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.6.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.6.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.6.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.6.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.6.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.7.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.7.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.7.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.7.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.7.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.7.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.8.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.8.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.8.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.8.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.8.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.8.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.9.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.9.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.9.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.9.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.9.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.9.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.10.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.10.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.10.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.10.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.10.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.10.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.11.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.11.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.11.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.11.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.11.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.11.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.12.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.12.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.12.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.12.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.12.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.12.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.13.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.13.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.13.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.13.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.13.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.13.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.14.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.14.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.14.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.14.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.14.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.14.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.15.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.15.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.15.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.15.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.15.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.15.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.16.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.16.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.16.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.16.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.16.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.16.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.16.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.16.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.16.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.17.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.17.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.17.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.17.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.17.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.17.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.17.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.17.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.17.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.18.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.18.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.18.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.18.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.18.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.18.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.18.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.18.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.18.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.19.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.19.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.19.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.19.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.19.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.19.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.19.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.19.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.19.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.20.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.20.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.20.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.20.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.20.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.20.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.20.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.20.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.20.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.21.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.21.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.21.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.21.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.21.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.21.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.21.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.21.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.21.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.22.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.22.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.22.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.22.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.22.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.22.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.22.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.22.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.22.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.23.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.23.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.23.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.23.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.23.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.23.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.23.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.23.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.23.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.24.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.24.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.24.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.24.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.24.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.24.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.24.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.24.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.24.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.25.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.25.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.25.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.25.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.25.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.25.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.25.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.25.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.25.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.26.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.26.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.26.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.26.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.26.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.26.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.26.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.26.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.26.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.27.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.27.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.27.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.27.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.27.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.27.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.27.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.27.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.27.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.28.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.28.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.28.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.28.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.28.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.28.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.28.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.28.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.28.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.29.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.29.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.29.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.29.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.29.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.29.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.29.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.29.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.29.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.30.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.30.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.30.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.30.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.30.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.30.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.30.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.30.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.30.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.31.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.31.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.31.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.31.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.31.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.31.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.31.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.31.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.31.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Cell 11: Execute Training\n",
        "# ==============================================================================\n",
        "print(\"Starting model training...\")\n",
        "trainer.train()\n",
        "print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# Cell 10: UPDATED Training Setup - Early Stopping & Optimized Checkpoints\n",
        "# ==============================================================================\n",
        "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "\n",
        "# Define training arguments with early stopping and frequent evaluation\n",
        "training_args_2 = TrainingArguments(\n",
        "    output_dir=Config.OUTPUT_DIR,\n",
        "    num_train_epochs=6,  # Extended training\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=8,  # Effective batch size = 32\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    learning_rate=1e-4,  # Lower learning rate for continued training\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.05,  # Reduced warmup for continued training\n",
        "    bf16=True,\n",
        "\n",
        "    # FREQUENT LOGGING, EVALUATION & SAVING\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=25,\n",
        "    eval_strategy=\"steps\",        # Evaluate every 25 steps\n",
        "    eval_steps=25,\n",
        "    save_strategy=\"steps\",       # Save every 25 steps\n",
        "    save_steps=25,\n",
        "    save_total_limit=2,          # Keep only 2 most recent checkpoints\n",
        "\n",
        "    # EARLY STOPPING CONFIGURATION\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"line_accuracy\",\n",
        "    greater_is_better=True,\n",
        "\n",
        "    # OTHER SETTINGS\n",
        "    report_to=\"none\",\n",
        "    save_safetensors=False,\n",
        "    label_names=[\"first_error_line\"]\n",
        ")\n",
        "\n",
        "# Instantiate the updated data collator\n",
        "data_collator_2 = DataCollatorForLineClassification(tokenizer=tokenizer)\n",
        "\n",
        "# Initialize early stopping callback\n",
        "early_stopping_callback = EarlyStoppingCallback(\n",
        "    early_stopping_patience=2,    # Stop after 2 evaluations (2 * 25 = 50 steps) without improvement\n",
        "    early_stopping_threshold=0.0  # Any improvement counts (even tiny ones)\n",
        ")\n",
        "\n",
        "# Initialize the Trainer with early stopping\n",
        "trainer_2 = Trainer(\n",
        "    model=model,\n",
        "    args=training_args_2,\n",
        "    train_dataset=final_dataset[\"train\"],\n",
        "    eval_dataset=final_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator_2,\n",
        "    compute_metrics=compute_metrics_for_line_detection,\n",
        "    callbacks=[early_stopping_callback]  # Add early stopping callback\n",
        ")\n",
        "\n",
        "print(\"--- Enhanced Trainer with Early Stopping initialized ---\")\n",
        "print(f\"📊 Configuration Summary:\")\n",
        "print(f\"   🔄 Evaluation every: {training_args.eval_steps} steps\")\n",
        "print(f\"   💾 Saving every: {training_args.save_steps} steps\")\n",
        "print(f\"   📈 Logging every: {training_args.logging_steps} steps\")\n",
        "# print(f\"   🛑 Early stopping: {early_stopping_callback.early_stopping_patience * training_args.eval_steps} steps without improvement\")\n",
        "print(f\"   📁 Max checkpoints: {training_args.save_total_limit}\")\n",
        "print(f\"   📚 Training samples: {len(final_dataset['train'])}\")\n",
        "print(f\"   🧪 Evaluation samples: {len(final_dataset['test'])}\")\n",
        "print(f\"   🎯 Total epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"   🏆 Best metric: {training_args.metric_for_best_model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "h3fFLP-B80w6",
        "outputId": "0bc555c7-7d6f-4a84-d825-2a7e0149d8ce"
      },
      "id": "h3fFLP-B80w6",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Enhanced Trainer with Early Stopping initialized ---\n",
            "📊 Configuration Summary:\n",
            "   🔄 Evaluation every: None steps\n",
            "   💾 Saving every: 500 steps\n",
            "   📈 Logging every: 25 steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-33-900272129.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_2 = Trainer(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for *: 'int' and 'NoneType'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-33-900272129.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   💾 Saving every: {training_args.save_steps} steps\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   📈 Logging every: {training_args.logging_steps} steps\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   🛑 Early stopping: {early_stopping_callback.early_stopping_patience * training_args.eval_steps} steps without improvement\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   📁 Max checkpoints: {training_args.save_total_limit}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   📚 Training samples: {len(final_dataset['train'])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'int' and 'NoneType'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_2.train()\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "DEIDQ6G09sBz",
        "outputId": "d4f41b15-d7df-464e-ecf8-252149eb2979"
      },
      "id": "DEIDQ6G09sBz",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/528 08:00 < 26:13, 0.26 it/s, Epoch 1/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Line Accuracy</th>\n",
              "      <th>Correct Predictions</th>\n",
              "      <th>Total Samples</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>3.336100</td>\n",
              "      <td>0.485392</td>\n",
              "      <td>0.348138</td>\n",
              "      <td>243</td>\n",
              "      <td>698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.416800</td>\n",
              "      <td>0.482614</td>\n",
              "      <td>0.355301</td>\n",
              "      <td>248</td>\n",
              "      <td>698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>3.393700</td>\n",
              "      <td>0.491674</td>\n",
              "      <td>0.381089</td>\n",
              "      <td>266</td>\n",
              "      <td>698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.172100</td>\n",
              "      <td>0.487001</td>\n",
              "      <td>0.355301</td>\n",
              "      <td>248</td>\n",
              "      <td>698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>3.255500</td>\n",
              "      <td>0.483073</td>\n",
              "      <td>0.365330</td>\n",
              "      <td>255</td>\n",
              "      <td>698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were unexpected keys in the checkpoint model loaded: ['base.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.0.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.0.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.0.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.0.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.0.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.0.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.1.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.1.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.1.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.1.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.1.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.1.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.2.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.2.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.2.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.2.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.2.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.2.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.3.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.3.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.3.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.3.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.3.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.3.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.4.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.4.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.4.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.4.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.4.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.4.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.5.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.5.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.5.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.5.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.5.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.5.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.6.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.6.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.6.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.6.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.6.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.6.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.7.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.7.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.7.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.7.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.7.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.7.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.8.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.8.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.8.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.8.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.8.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.8.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.9.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.9.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.9.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.9.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.9.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.9.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.10.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.10.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.10.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.10.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.10.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.10.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.11.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.11.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.11.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.11.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.11.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.11.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.12.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.12.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.12.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.12.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.12.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.12.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.13.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.13.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.13.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.13.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.13.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.13.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.14.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.14.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.14.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.14.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.14.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.14.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.15.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.15.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.15.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.15.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.15.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.15.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.16.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.16.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.16.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.16.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.16.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.16.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.16.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.16.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.16.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.17.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.17.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.17.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.17.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.17.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.17.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.17.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.17.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.17.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.18.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.18.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.18.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.18.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.18.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.18.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.18.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.18.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.18.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.19.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.19.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.19.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.19.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.19.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.19.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.19.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.19.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.19.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.20.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.20.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.20.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.20.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.20.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.20.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.20.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.20.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.20.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.21.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.21.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.21.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.21.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.21.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.21.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.21.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.21.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.21.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.22.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.22.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.22.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.22.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.22.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.22.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.22.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.22.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.22.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.23.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.23.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.23.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.23.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.23.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.23.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.23.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.23.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.23.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.24.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.24.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.24.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.24.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.24.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.24.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.24.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.24.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.24.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.25.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.25.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.25.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.25.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.25.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.25.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.25.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.25.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.25.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.26.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.26.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.26.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.26.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.26.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.26.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.26.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.26.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.26.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.27.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.27.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.27.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.27.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.27.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.27.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.27.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.27.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.27.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.28.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.28.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.28.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.28.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.28.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.28.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.28.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.28.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.28.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.29.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.29.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.29.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.29.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.29.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.29.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.29.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.29.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.29.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.30.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.30.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.30.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.30.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.30.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.30.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.30.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.30.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.30.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.31.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.31.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.31.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.31.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.31.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.31.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.31.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.31.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.31.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b1e559d",
      "metadata": {
        "id": "0b1e559d"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Cell 12: Evaluation and Saving\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Evaluating on the test set ---\")\n",
        "# test_results = trainer.evaluate()\n",
        "# print(\"Test set performance:\")\n",
        "# print(test_results)\n",
        "\n",
        "print(f\"\\nSaving final model adapter to {Config.OUTPUT_DIR}...\")\n",
        "# trainer.save_model(Config.OUTPUT_DIR)\n",
        "print(\"Model saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "448a6c97",
      "metadata": {
        "id": "448a6c97"
      },
      "outputs": [],
      "source": [
        "# # ==============================================================================\n",
        "# # TESTING SUITE: Comprehensive Pipeline Validation\n",
        "# # ==============================================================================\n",
        "\n",
        "# def run_comprehensive_test_suite():\n",
        "#     \"\"\"Run all tests in sequence\"\"\"\n",
        "#     print(\"🚀 RUNNING COMPREHENSIVE TEST SUITE\")\n",
        "#     print(\"=\" * 80)\n",
        "\n",
        "#     # Load dataset first\n",
        "#     dataset_path = Config.DATASET_PATH\n",
        "#     df = pd.read_csv(dataset_path)\n",
        "\n",
        "#     # Initialize tokenizer\n",
        "#     tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_ID, trust_remote_code=True)\n",
        "#     if tokenizer.pad_token is None:\n",
        "#         tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "#     # Initialize data collator\n",
        "#     data_collator = DataCollatorForLineClassification(tokenizer=tokenizer)\n",
        "\n",
        "#     test_results = {}\n",
        "\n",
        "#     # Run tests\n",
        "#     test_results['dataset_loading'] = test_dataset_loading_and_format()\n",
        "#     test_results['line_labels'] = test_line_labels_validation(df)\n",
        "\n",
        "#     # Prepare sample texts for tokenization test\n",
        "#     sample_texts = [\n",
        "#         f\"Problem: {row['question']}\\n\\nSolution: {row['solution']}\"\n",
        "#         for _, row in df.sample(3, random_state=42).iterrows()\n",
        "#     ]\n",
        "#     test_results['tokenization'] = test_tokenization_and_line_detection(tokenizer, sample_texts)\n",
        "\n",
        "#     test_results['preprocessing'] = test_preprocessing_function(df, tokenizer)\n",
        "\n",
        "#     # Create processed dataset for remaining tests\n",
        "#     small_df = df.sample(5, random_state=42)\n",
        "#     small_dataset = Dataset.from_pandas(small_df)\n",
        "#     processed_dataset = small_dataset.map(preprocess_for_line_detection, batched=True)\n",
        "\n",
        "#     test_results['data_collator'] = test_data_collator(data_collator, processed_dataset)\n",
        "\n",
        "#     # Skip model tests for now (will be added when model is loaded)\n",
        "#     test_results['solution_alignment'] = test_solution_line_alignment(df)\n",
        "\n",
        "#     # Print summary\n",
        "#     print(\"\\n\" + \"=\" * 80)\n",
        "#     print(\"🏁 TEST SUITE SUMMARY\")\n",
        "#     print(\"=\" * 80)\n",
        "\n",
        "#     for test_name, result in test_results.items():\n",
        "#         status = \"✅ PASS\" if result else \"❌ FAIL\"\n",
        "#         print(f\"{status} {test_name}\")\n",
        "\n",
        "#     overall_success = all(test_results.values())\n",
        "#     print(f\"\\n🎯 Overall Status: {'✅ ALL TESTS PASSED' if overall_success else '❌ SOME TESTS FAILED'}\")\n",
        "\n",
        "#     return test_results\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5345485697384a0cb1fb254eba560d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f181a3a88f50467b8aa486bc6d3f4fa7",
              "IPY_MODEL_1e9f78c47b08446f87eb8236b6b20513",
              "IPY_MODEL_a9d7f4dbb0b3471fb833dfdeb986e4fc"
            ],
            "layout": "IPY_MODEL_892fa056882c4156863f77febfa46447"
          }
        },
        "f181a3a88f50467b8aa486bc6d3f4fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_767d432ff15e4beea76a59cc428f3821",
            "placeholder": "​",
            "style": "IPY_MODEL_c268190cbce5481ca9c2ada012e90d10",
            "value": "tokenizer_config.json: "
          }
        },
        "1e9f78c47b08446f87eb8236b6b20513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73fdc693931947c58b5bd82cff34622d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_681264275aa84c118a6bcbcc852e7ab4",
            "value": 1
          }
        },
        "a9d7f4dbb0b3471fb833dfdeb986e4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f91168ebc4f744289b973dacac92e751",
            "placeholder": "​",
            "style": "IPY_MODEL_10cb1a4196394f28b391c723995e7c7a",
            "value": " 2.93k/? [00:00&lt;00:00, 307kB/s]"
          }
        },
        "892fa056882c4156863f77febfa46447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "767d432ff15e4beea76a59cc428f3821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c268190cbce5481ca9c2ada012e90d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73fdc693931947c58b5bd82cff34622d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "681264275aa84c118a6bcbcc852e7ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f91168ebc4f744289b973dacac92e751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10cb1a4196394f28b391c723995e7c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ada7ee8aa25416da67f3d1ae5cb5f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df43fe620a394acbb711c843a78b7bb2",
              "IPY_MODEL_a9a62cd6bd08403691b5a672ec19f702",
              "IPY_MODEL_e4f59a41189d46789d282d707338947c"
            ],
            "layout": "IPY_MODEL_636ed92805fa4259bd66947339fcfdb7"
          }
        },
        "df43fe620a394acbb711c843a78b7bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91db3e1c69e6429d9ab13a59da49ba94",
            "placeholder": "​",
            "style": "IPY_MODEL_7303fc38bee24bae91a8404c7216f562",
            "value": "vocab.json: "
          }
        },
        "a9a62cd6bd08403691b5a672ec19f702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ea29820a969433d996995543edec5e9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_141c358145f7419b9d5d1d6bca2b5157",
            "value": 1
          }
        },
        "e4f59a41189d46789d282d707338947c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed882864d8994a0ea5f9540c3b4635df",
            "placeholder": "​",
            "style": "IPY_MODEL_69613cebf069406f8c0bd69e7d26cbd6",
            "value": " 3.91M/? [00:00&lt;00:00, 13.4MB/s]"
          }
        },
        "636ed92805fa4259bd66947339fcfdb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91db3e1c69e6429d9ab13a59da49ba94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7303fc38bee24bae91a8404c7216f562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ea29820a969433d996995543edec5e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "141c358145f7419b9d5d1d6bca2b5157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed882864d8994a0ea5f9540c3b4635df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69613cebf069406f8c0bd69e7d26cbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b227276cec014ba5a0a598540828782a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4009405334ed4ebdad424a010586c14e",
              "IPY_MODEL_173bb135f2614d3a8e08a6e83c68499f",
              "IPY_MODEL_3faca1e2431c4c0fa79b8cac1056819b"
            ],
            "layout": "IPY_MODEL_9d155d3bffa44518a0e8ac440ef9d1d1"
          }
        },
        "4009405334ed4ebdad424a010586c14e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63b70b6d41bd412ab2674a764f2deba3",
            "placeholder": "​",
            "style": "IPY_MODEL_3c8b807d9ad5489483e90595db672341",
            "value": "merges.txt: "
          }
        },
        "173bb135f2614d3a8e08a6e83c68499f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8545b77e4e754f029de549188dc1c882",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56357a846de340f1884425f854e08487",
            "value": 1
          }
        },
        "3faca1e2431c4c0fa79b8cac1056819b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88c54bedf15c4175a9fc2c58584f5ccb",
            "placeholder": "​",
            "style": "IPY_MODEL_ceff28e2dd554f298c096a9e30f7331f",
            "value": " 2.42M/? [00:00&lt;00:00, 50.3MB/s]"
          }
        },
        "9d155d3bffa44518a0e8ac440ef9d1d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63b70b6d41bd412ab2674a764f2deba3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c8b807d9ad5489483e90595db672341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8545b77e4e754f029de549188dc1c882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "56357a846de340f1884425f854e08487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88c54bedf15c4175a9fc2c58584f5ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceff28e2dd554f298c096a9e30f7331f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5820698fa1fb4e3c9b2acd994fb6cc2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68461ecb7e8a44c2be24fe63a84a8ed7",
              "IPY_MODEL_005822a9ba214e3eae82f2bd9d1404cb",
              "IPY_MODEL_6c4b6597cec84ca896a97fc0d8979c85"
            ],
            "layout": "IPY_MODEL_8ed5be5c78674e20b8c8521e2b0e2c93"
          }
        },
        "68461ecb7e8a44c2be24fe63a84a8ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5ef733dc84d4aef9dee3da5d87811cc",
            "placeholder": "​",
            "style": "IPY_MODEL_a32d4062b51a46fcb1d7a23cc22624c7",
            "value": "tokenizer.json: 100%"
          }
        },
        "005822a9ba214e3eae82f2bd9d1404cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a4a89e761cb461182f779fdfbf0414f",
            "max": 15524095,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b348901da7c04d59ab3503b00c7fb5f7",
            "value": 15524095
          }
        },
        "6c4b6597cec84ca896a97fc0d8979c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_417d37d999f34180bcc5f0ad52eecebb",
            "placeholder": "​",
            "style": "IPY_MODEL_3b9df550493049379a4ae9aee7780d8d",
            "value": " 15.5M/15.5M [00:00&lt;00:00, 25.3MB/s]"
          }
        },
        "8ed5be5c78674e20b8c8521e2b0e2c93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ef733dc84d4aef9dee3da5d87811cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a32d4062b51a46fcb1d7a23cc22624c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a4a89e761cb461182f779fdfbf0414f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b348901da7c04d59ab3503b00c7fb5f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "417d37d999f34180bcc5f0ad52eecebb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b9df550493049379a4ae9aee7780d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4cbdb2b9c444b6fb2ff811990c2660b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_402834dece9649838b67d4236ff30f08",
              "IPY_MODEL_9b94586ef9bd4c46bd40be8feba48d45",
              "IPY_MODEL_45dade88e03c4892b5d27412b2ed4047"
            ],
            "layout": "IPY_MODEL_6ee2645025fe4eda892cb13d758d37bb"
          }
        },
        "402834dece9649838b67d4236ff30f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7959b16302a6493dad9dba9dfd7f517f",
            "placeholder": "​",
            "style": "IPY_MODEL_aa6530ab0c2943c381bb4b002caf1607",
            "value": "added_tokens.json: 100%"
          }
        },
        "9b94586ef9bd4c46bd40be8feba48d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f4249f2897344569c3ca10e1b9d385e",
            "max": 249,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30f74c3a46664e24809f5deacea69c87",
            "value": 249
          }
        },
        "45dade88e03c4892b5d27412b2ed4047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddab4a7a340742bcb6c8e21bae1f0782",
            "placeholder": "​",
            "style": "IPY_MODEL_87a80bd857384d648fb5b200d206f9b6",
            "value": " 249/249 [00:00&lt;00:00, 32.1kB/s]"
          }
        },
        "6ee2645025fe4eda892cb13d758d37bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7959b16302a6493dad9dba9dfd7f517f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa6530ab0c2943c381bb4b002caf1607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f4249f2897344569c3ca10e1b9d385e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30f74c3a46664e24809f5deacea69c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddab4a7a340742bcb6c8e21bae1f0782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a80bd857384d648fb5b200d206f9b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4303dd97984847a5a7783872ab0e7177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b5b11efb28d4cae9b9e6d1eb3f07ec5",
              "IPY_MODEL_22100073caf646689ab90c4277a486ed",
              "IPY_MODEL_9ff6f97b428e4f848a3a491fae6ac0f4"
            ],
            "layout": "IPY_MODEL_590ec88fb86149a0b128d1d6f23e2ace"
          }
        },
        "9b5b11efb28d4cae9b9e6d1eb3f07ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab5b6e9c6d14482299cd28199a0c61c6",
            "placeholder": "​",
            "style": "IPY_MODEL_519aa06a41134a2ab68da0f09a3d884d",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "22100073caf646689ab90c4277a486ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1721ca7d9d1e4f428a3b43fbf1856e45",
            "max": 587,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be311bcce96742db8ca4a3da040a2b77",
            "value": 587
          }
        },
        "9ff6f97b428e4f848a3a491fae6ac0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82043032f2134f32860a208b04eb8ff1",
            "placeholder": "​",
            "style": "IPY_MODEL_bdc96ac7a3004a05bac5382c502dc38e",
            "value": " 587/587 [00:00&lt;00:00, 77.9kB/s]"
          }
        },
        "590ec88fb86149a0b128d1d6f23e2ace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab5b6e9c6d14482299cd28199a0c61c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "519aa06a41134a2ab68da0f09a3d884d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1721ca7d9d1e4f428a3b43fbf1856e45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be311bcce96742db8ca4a3da040a2b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82043032f2134f32860a208b04eb8ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdc96ac7a3004a05bac5382c502dc38e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20cf9c9f2f154f41b8b73d914ec1947b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6ed981dad4d4457b44774f0bf3420bb",
              "IPY_MODEL_d73e0d510071416bb700693e7bcb44b4",
              "IPY_MODEL_b72617a255ae4f8fb8d309c3bcdaac52"
            ],
            "layout": "IPY_MODEL_735d1a316bfa4ba4952cba70c6ccf58d"
          }
        },
        "e6ed981dad4d4457b44774f0bf3420bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8003d111502452a8016cfcee1a96dea",
            "placeholder": "​",
            "style": "IPY_MODEL_c50d65f51301471f9df4ec1560b4f21e",
            "value": "Map: 100%"
          }
        },
        "d73e0d510071416bb700693e7bcb44b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2372b7004a1e477fafa700b3e3741599",
            "max": 2789,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10a7f527ead346dfbef7beaa373f6ae4",
            "value": 2789
          }
        },
        "b72617a255ae4f8fb8d309c3bcdaac52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ced3afa7419b4a29b76302dfba88aa95",
            "placeholder": "​",
            "style": "IPY_MODEL_c71c150bd1514bdc9766e45acf2c3078",
            "value": " 2789/2789 [00:00&lt;00:00, 4365.15 examples/s]"
          }
        },
        "735d1a316bfa4ba4952cba70c6ccf58d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8003d111502452a8016cfcee1a96dea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c50d65f51301471f9df4ec1560b4f21e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2372b7004a1e477fafa700b3e3741599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10a7f527ead346dfbef7beaa373f6ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ced3afa7419b4a29b76302dfba88aa95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c71c150bd1514bdc9766e45acf2c3078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e07fed6cdd7f4c9684486d122f562f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc68a5650bb34b0cae21ad0a4f6747a4",
              "IPY_MODEL_f3d94dae5812486eb6d7de1215a1dde4",
              "IPY_MODEL_7c026b5de4a74d2a913ceb1e6222186e"
            ],
            "layout": "IPY_MODEL_31fb695829224d12a203d65432f7cab6"
          }
        },
        "bc68a5650bb34b0cae21ad0a4f6747a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69dda00401de4255b19fac7b886caf6b",
            "placeholder": "​",
            "style": "IPY_MODEL_01e05a2fac294dc3b762f0f866628fa3",
            "value": "Map: 100%"
          }
        },
        "f3d94dae5812486eb6d7de1215a1dde4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10cf529e3b8d49c0bdcbab4167fb1db4",
            "max": 698,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_642c30c9bf5f46aabd96e2b0ab5f4eaa",
            "value": 698
          }
        },
        "7c026b5de4a74d2a913ceb1e6222186e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31ecb8654eb24f979d12256c00d9d119",
            "placeholder": "​",
            "style": "IPY_MODEL_9bc6acc7ae6f4600a0432868dcd53468",
            "value": " 698/698 [00:00&lt;00:00, 5326.17 examples/s]"
          }
        },
        "31fb695829224d12a203d65432f7cab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69dda00401de4255b19fac7b886caf6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01e05a2fac294dc3b762f0f866628fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10cf529e3b8d49c0bdcbab4167fb1db4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "642c30c9bf5f46aabd96e2b0ab5f4eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31ecb8654eb24f979d12256c00d9d119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bc6acc7ae6f4600a0432868dcd53468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f417866f02f41378a3bd2a6c2c461d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2db862f6fbd34662b5cd367b529dd6bd",
              "IPY_MODEL_66d8f685f51844a3b3a30a1ecdd9b5b5",
              "IPY_MODEL_5f6b9e7fcf0445f7b7bcc7d600ba4d2b"
            ],
            "layout": "IPY_MODEL_6055cf94bd894096b58307e4c6a37194"
          }
        },
        "2db862f6fbd34662b5cd367b529dd6bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b36bc4b3f7e430cb207e4aae05e2aee",
            "placeholder": "​",
            "style": "IPY_MODEL_e811179cefa846b59b54981ec8ca1a1d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "66d8f685f51844a3b3a30a1ecdd9b5b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6afee8670a3449ff84f69167e3081fd4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_754d7b2c931341218427573d8fce2fbc",
            "value": 2
          }
        },
        "5f6b9e7fcf0445f7b7bcc7d600ba4d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f12babf129e4b988307a136a0ce2a07",
            "placeholder": "​",
            "style": "IPY_MODEL_e84c5eec69e340e684951503d80a2dab",
            "value": " 2/2 [00:07&lt;00:00,  3.71s/it]"
          }
        },
        "6055cf94bd894096b58307e4c6a37194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b36bc4b3f7e430cb207e4aae05e2aee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e811179cefa846b59b54981ec8ca1a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6afee8670a3449ff84f69167e3081fd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "754d7b2c931341218427573d8fce2fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f12babf129e4b988307a136a0ce2a07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e84c5eec69e340e684951503d80a2dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e91be68e7b134fa2a680a35e68a34935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc94d6b002444e0d958398402a3fb3d0",
              "IPY_MODEL_785ecd7e4c234485b009e9e84536e43a",
              "IPY_MODEL_f926db3da1d34cfba3b968baf0105f1a"
            ],
            "layout": "IPY_MODEL_6d5cf285e2e141b4b3421d87eb7fec0c"
          }
        },
        "cc94d6b002444e0d958398402a3fb3d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d347e4415c6435990690bdf3c10806a",
            "placeholder": "​",
            "style": "IPY_MODEL_e8bc20da2ef64c0a98342d51d93da7ab",
            "value": "Map: 100%"
          }
        },
        "785ecd7e4c234485b009e9e84536e43a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d127b43fbc9846bf9199d169d50440db",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8dcefdbf6d5b4591ac6432ed52e26f7c",
            "value": 5
          }
        },
        "f926db3da1d34cfba3b968baf0105f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df809a3560d64d39b98f52fceebc26d7",
            "placeholder": "​",
            "style": "IPY_MODEL_144b5d94bdee40ed99ba6f5659aba622",
            "value": " 5/5 [00:00&lt;00:00, 228.40 examples/s]"
          }
        },
        "6d5cf285e2e141b4b3421d87eb7fec0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d347e4415c6435990690bdf3c10806a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8bc20da2ef64c0a98342d51d93da7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d127b43fbc9846bf9199d169d50440db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dcefdbf6d5b4591ac6432ed52e26f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df809a3560d64d39b98f52fceebc26d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "144b5d94bdee40ed99ba6f5659aba622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}