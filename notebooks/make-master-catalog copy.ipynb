{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "151049e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/manually_generated_errors_final.csv\n",
      "computational: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/computational-errors-generated/computational_error_catalog.csv\n",
      "conceptual_ali: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_ali.csv\n",
      "conceptual_arvind: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_arvind.csv\n",
      "conceptual_mauro: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_mauro.csv\n",
      "conceptual_ling: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_ling.csv\n",
      "conceptual_yewei: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_yewei.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Set, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- Path and Directory Definitions ---\n",
    "\n",
    "def find_project_root(marker: str = \".git\") -> Path:\n",
    "    \"\"\"Traverse upwards to find the project root, marked by the git repository.\"\"\"\n",
    "    current_path = Path.cwd().resolve()\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / marker).exists():\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    raise FileNotFoundError(f\"Could not find project root. Marker '{marker}' not found.\")\n",
    "\n",
    "VALIDATORS = [\"ali\", \"arvind\", \"mauro\", \"ling\", \"yewei\"]\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "CONCEPTUAL_ERRORS_DIR = DATA_DIR / 'conceptual-errors-accepted'\n",
    "COMPUTATIONAL_ERRORS_DIR = DATA_DIR / 'computational-errors-generated'\n",
    "CONCEPTUAL_CATALOG_DIR = DATA_DIR / 'conceptual-error-candidates'\n",
    "\n",
    "# load all catalog filepaths into a dict\n",
    "CATALOG_FILEPATH_DICT = {\n",
    "    \"manual\": DATA_DIR / 'manually_generated_errors_final.csv',\n",
    "    \"computational\": COMPUTATIONAL_ERRORS_DIR / 'computational_error_catalog.csv'\n",
    "}\n",
    "for name in VALIDATORS:\n",
    "    CATALOG_FILEPATH_DICT[f\"conceptual_{name}\"] = CONCEPTUAL_CATALOG_DIR / f'validation_catalog_{name}.csv'\n",
    "\n",
    "# Display the filepaths\n",
    "for name, path in CATALOG_FILEPATH_DICT.items():\n",
    "    print(f\"{name}: {path}\")\n",
    "\n",
    "# make dictionary with all catalogs\n",
    "CATALOG_DICT = {key: pd.read_csv(path) for key, path in CATALOG_FILEPATH_DICT.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7a0c34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual: 1963 rows\n",
      "columns: ['answer', 'erroneous_line_number', 'error_type', 'explanation', 'filepath', 'index', 'question', 'wrong_answer']\n",
      "computational: 22623 rows\n",
      "columns: ['index', 'tier', 'model', 'erroneous_line_number', 'explanation', 'wrong_answer', 'correct_trace_generated', 'target_variable', 'error_type', 'correct_value', 'flawed_value', 'repro_seed', 'date_utc', 'time_utc', 'filepath']\n",
      "conceptual_ali: 398 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n",
      "conceptual_arvind: 394 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n",
      "conceptual_mauro: 381 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n",
      "conceptual_ling: 388 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n",
      "conceptual_yewei: 381 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n"
     ]
    }
   ],
   "source": [
    "for key, df in CATALOG_DICT.items():\n",
    "    print(f\"{key}: {len(df)} rows\")\n",
    "    print(\"columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bdb057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSM8K_TRAIN = load_dataset(\"gsm8k\", \"main\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebb8c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Tier Definition Functions (copied from arvind-july-25.ipynb) ---\n",
    "\n",
    "def has_computational_division(solution_text: str):\n",
    "    \"\"\"Checks if a solution text contains a division operation.\"\"\"\n",
    "    pattern = re.compile(r'/\\s*\\d')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def has_float(solution_text: str):\n",
    "    \"\"\"Checks if a solution text contains a float value.\"\"\"\n",
    "    pattern = re.compile(r'(?<!\\d)\\.\\d+|\\d+\\.\\d+')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def is_symbolic(solution_text: str):\n",
    "    \"\"\"Checks if a solution text uses symbolic algebra (e.g., 'Let x...').\"\"\"\n",
    "    pattern = re.compile(r'^Let [a-zA-Z] ', re.MULTILINE)\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def mutually_disjoint_tiers(dataset):\n",
    "    \"\"\"\n",
    "    Categorizes all problems in the dataset into mutually disjoint tiers\n",
    "    based on the mathematical operations present in their solution text.\n",
    "    \"\"\"\n",
    "    tiers = {}\n",
    "    symbolic_set = {idx for idx, sample in enumerate(dataset) if is_symbolic(sample.get(\"answer\", \"\"))}\n",
    "    non_symbolic_indices = [idx for idx in range(len(dataset)) if idx not in symbolic_set]\n",
    "    \n",
    "    tiers[\"tier1\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier2\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier3\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier4\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier5\"] = sorted(list(symbolic_set))\n",
    "    return tiers\n",
    "\n",
    "def sanitize_commas(text: str) -> str:\n",
    "    \"\"\"Removes comma separators from numbers to prevent model artifacts.\"\"\"\n",
    "    return re.sub(r'(\\d),(\\d)', r'\\1\\2', text)\n",
    "\n",
    "def sanitize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Replaces a comprehensive set of problematic Unicode characters with their\n",
    "    ASCII equivalents to prevent model generation and string parsing errors.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "        \n",
    "    replacements = {\n",
    "        \"\\u2212\": \"-\",    # Minus Sign\n",
    "        \"\\u00d7\": \"*\",    # Multiplication Sign\n",
    "        \"\\u00f7\": \"/\",    # Division Sign\n",
    "        \"\\u22c5\": \"*\",    # Dot Operator\n",
    "        \"\\u201c\": '\"',    # Left Double Quotation Mark\n",
    "        \"\\u201d\": '\"',    # Right Double Quotation Mark\n",
    "        \"\\u2018\": \"'\",    # Left Single Quotation Mark\n",
    "        \"\\u2019\": \"'\",    # Right Single Quotation Mark\n",
    "        \"\\u2014\": \"-\",    # Em Dash\n",
    "        \"\\u2013\": \"-\",    # En Dash\n",
    "        \"\\u2026\": \"...\",  # Horizontal Ellipsis\n",
    "        \"\\u00a0\": \" \",    # No-Break Space\n",
    "        \"\\u00f1\": \"n\",    # Spanish ñ -> n\n",
    "        # NEW: Currency and problematic characters\n",
    "        \"\\u00a2\": \"cents\", # ¢ -> cents\n",
    "        \"\\u00a3\": \"pounds\", # £ -> pounds  \n",
    "        \"\\u20ac\": \"euros\",  # € -> euros\n",
    "        \"\\u00e9\": \"e\",      # é -> e\n",
    "        \"\\u200b\": \"\",       # Zero Width Space -> remove completely\n",
    "    }\n",
    "    for uni, ascii_char in replacements.items():\n",
    "        text = text.replace(uni, ascii_char)\n",
    "    return text\n",
    "\n",
    "# --- Updated Solution Analysis Functions with Preprocessing ---\n",
    "\n",
    "def preprocess_solution_for_analysis(solution_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Apply the same preprocessing that will be used in dataset creation.\n",
    "    This ensures solution_length and relative_line_position are calculated \n",
    "    from the same text that will be tokenized.\n",
    "    \"\"\"\n",
    "    if not isinstance(solution_text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Step 1: Convert literal \\n to actual newlines\n",
    "    processed = solution_text.replace('\\\\n', '\\n')\n",
    "    \n",
    "    # Step 2: Remove calculator annotations (THIS is critical!)\n",
    "    processed = re.sub(r'<<.*?>>', '', processed)\n",
    "    \n",
    "    # Step 3: Sanitize Unicode characters (use existing function)\n",
    "    processed = sanitize_text(processed)\n",
    "    \n",
    "    # Step 4: Remove comma separators from numbers (use existing function)\n",
    "    processed = sanitize_commas(processed)\n",
    "    \n",
    "    return processed\n",
    "\n",
    "def clean_and_split_solution_preprocessed(raw_text: str) -> Tuple[str, str | None]:\n",
    "    \"\"\"\n",
    "    UPDATED VERSION: Takes a raw solution text, applies FULL preprocessing including\n",
    "    calculator annotation removal, then separates reasoning from final answer.\n",
    "    \n",
    "    This ensures consistency with dataset creation preprocessing.\n",
    "    \"\"\"\n",
    "    if not isinstance(raw_text, str):\n",
    "        return \"\", None\n",
    "    \n",
    "    # Apply the same preprocessing as dataset creation\n",
    "    processed_text = preprocess_solution_for_analysis(raw_text)\n",
    "    \n",
    "    lines = processed_text.split('\\n')\n",
    "    final_answer = None\n",
    "    \n",
    "    if lines and re.match(r'^\\s*####\\s*.*$', lines[-1]):\n",
    "        final_answer_line = lines.pop().strip()\n",
    "        match = re.search(r'####\\s*(.*)', final_answer_line)\n",
    "        if match:\n",
    "            final_answer = match.group(1).strip()\n",
    "\n",
    "    cleaned_lines = [line.strip() for line in lines if line.strip()]\n",
    "    reasoning_text = '\\n'.join(cleaned_lines)\n",
    "    \n",
    "    return reasoning_text, final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e803b036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier distribution in GSM8K:\n",
      "  tier1: 2767 problems\n",
      "  tier2: 837 problems\n",
      "  tier3: 3113 problems\n",
      "  tier4: 544 problems\n",
      "  tier5: 212 problems\n"
     ]
    }
   ],
   "source": [
    "# --- Create Tier Mappings ---\n",
    "\n",
    "def add_tier_column(df, tier_lists):\n",
    "    \"\"\"\n",
    "    Adds a 'tier' column to the dataframe based on the TIER_LISTS dictionary.\n",
    "    Maps each GSM8K index to its corresponding tier.\n",
    "    \"\"\"\n",
    "    index_to_tier = {}\n",
    "    for tier_name, indices in tier_lists.items():\n",
    "        for idx in indices:\n",
    "            index_to_tier[idx] = tier_name\n",
    "    \n",
    "    df['tier'] = df['index'].map(index_to_tier)\n",
    "    \n",
    "    missing_tiers = df['tier'].isna().sum()\n",
    "    if missing_tiers > 0:\n",
    "        print(f\"Warning: {missing_tiers} indices could not be mapped to tiers\")\n",
    "        df['tier'] = df['tier'].fillna('unknown')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate tier mappings for the entire GSM8K dataset\n",
    "TIER_LISTS = mutually_disjoint_tiers(GSM8K_TRAIN)\n",
    "print(\"Tier distribution in GSM8K:\")\n",
    "for tier, indices in TIER_LISTS.items():\n",
    "    print(f\"  {tier}: {len(indices)} problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b122d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ UPDATED solution analysis functions with preprocessing loaded successfully\n"
     ]
    }
   ],
   "source": [
    "def validate_line_number_preprocessed(erroneous_line_number: str, gsm8k_answer: str) -> bool:\n",
    "    \"\"\"\n",
    "    UPDATED: Validates line number using preprocessed solution text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reasoning, final_answer = clean_and_split_solution_preprocessed(gsm8k_answer)\n",
    "        lines = [line for line in reasoning.split('\\n') if line.strip()]\n",
    "        \n",
    "        if erroneous_line_number == \"FA\":\n",
    "            return final_answer is not None\n",
    "        elif erroneous_line_number.startswith(\"L\"):\n",
    "            line_num = int(erroneous_line_number[1:])\n",
    "            return 1 <= line_num <= len(lines)\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def calculate_solution_metrics_preprocessed(gsm8k_answer: str) -> Tuple[int, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    UPDATED: Calculates solution metrics using preprocessed text.\n",
    "    This ensures the solution_length matches what will be used in dataset creation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reasoning, final_answer = clean_and_split_solution_preprocessed(gsm8k_answer)\n",
    "        lines = [line for line in reasoning.split('\\n') if line.strip()]\n",
    "        \n",
    "        solution_length = len(lines)\n",
    "        if final_answer is not None:\n",
    "            solution_length += 1  # Include FA in count\n",
    "            \n",
    "        line_mapping = {f\"L{i+1}\": line for i, line in enumerate(lines)}\n",
    "        if final_answer is not None:\n",
    "            line_mapping[\"FA\"] = final_answer\n",
    "            \n",
    "        return solution_length, line_mapping\n",
    "    except:\n",
    "        return 0, {}\n",
    "\n",
    "def calculate_relative_line_position_preprocessed(erroneous_line_number: str, gsm8k_answer: str) -> float:\n",
    "    \"\"\"\n",
    "    UPDATED: Calculates relative position using preprocessed solution text.\n",
    "    This ensures consistency with dataset creation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reasoning, final_answer = clean_and_split_solution_preprocessed(gsm8k_answer)\n",
    "        lines = [line for line in reasoning.split('\\n') if line.strip()]\n",
    "        total_lines = len(lines)\n",
    "        \n",
    "        if final_answer is not None:\n",
    "            total_lines += 1\n",
    "            \n",
    "        if total_lines == 0:\n",
    "            return 0.5  # Fallback for empty solutions\n",
    "            \n",
    "        if erroneous_line_number == \"FA\":\n",
    "            return 1.0\n",
    "        elif erroneous_line_number.startswith(\"L\"):\n",
    "            line_num = int(erroneous_line_number[1:])\n",
    "            # Use max(1, total_lines) to avoid division by zero\n",
    "            return (line_num - 1) / max(1, total_lines - 1) if total_lines > 1 else 0.0\n",
    "        else:\n",
    "            return 0.5  # Default fallback\n",
    "    except:\n",
    "        return 0.5\n",
    "\n",
    "def preprocess_question_text(question_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Apply preprocessing to question text for consistency.\n",
    "    \"\"\"\n",
    "    if not isinstance(question_text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Apply Unicode sanitization and comma removal\n",
    "    processed = sanitize_text(question_text)\n",
    "    processed = sanitize_commas(processed)\n",
    "    \n",
    "    return processed\n",
    "\n",
    "print(\"✓ UPDATED solution analysis functions with preprocessing loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec4b2c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 SOLUTION LENGTH COMPUTATION CHECK\n",
      "==================================================\n",
      "\n",
      "--- INDEX 143 ---\n",
      "RAW ANSWER:\n",
      "'There are 60 goldfish because 15 / .25 = <<15/.25=60>>60\\n75% of the fish are below the surface because 100 - 25 = <<100-25=75>>75\\nThere are 45 goldfish below the surface because 60 x .75 = <<60*.75=45>>45\\n#### 45'\n",
      "\n",
      "AFTER PREPROCESSING:\n",
      "'There are 60 goldfish because 15 / .25 = 60\\n75% of the fish are below the surface because 100 - 25 = 75\\nThere are 45 goldfish below the surface because 60 x .75 = 45\\n#### 45'\n",
      "\n",
      "COMPUTED SOLUTION_LENGTH: 4\n",
      "MANUAL COUNT: 4\n",
      "MATCH: True\n",
      "\n",
      "LINE MAPPING:\n",
      "  L1: 'There are 60 goldfish because 15 / .25 = 60'\n",
      "  L2: '75% of the fish are below the surface because 100 - 25 = 75'\n",
      "  L3: 'There are 45 goldfish below the surface because 60 x .75 = 45'\n",
      "  FA: '45'\n",
      "\n",
      "--- INDEX 140 ---\n",
      "RAW ANSWER:\n",
      "'First find how many kids from Riverside High are rejected: 20% * 120 kids = <<20*.01*120=24>>24 kids\\nThen find how many kids from West Side High are rejected: 70% * 90 kids = <<70*.01*90=63>>63 kids\\nThen find how many kids from Mountaintop High are rejected: 50 kids / 2 = <<50/2=25>>25 kids\\nThen add the number of kids from each school to find the total number of kids: 120 kids + 90 kids + 50 kids = <<120+90+50=260>>260 kids\\nThen subtract all the kids who were rejected from the total number of kids to find the number who got in: 260 kids - 24 kids - 63 kids - 25 kids = <<260-24-63-25=148>>148 kids\\n#### 148'\n",
      "\n",
      "AFTER PREPROCESSING:\n",
      "'First find how many kids from Riverside High are rejected: 20% * 120 kids = 24 kids\\nThen find how many kids from West Side High are rejected: 70% * 90 kids = 63 kids\\nThen find how many kids from Mountaintop High are rejected: 50 kids / 2 = 25 kids\\nThen add the number of kids from each school to find the total number of kids: 120 kids + 90 kids + 50 kids = 260 kids\\nThen subtract all the kids who were rejected from the total number of kids to find the number who got in: 260 kids - 24 kids - 63 kids - 25 kids = 148 kids\\n#### 148'\n",
      "\n",
      "COMPUTED SOLUTION_LENGTH: 6\n",
      "MANUAL COUNT: 6\n",
      "MATCH: True\n",
      "\n",
      "LINE MAPPING:\n",
      "  L1: 'First find how many kids from Riverside High are rejected: 20% * 120 kids = 24 kids'\n",
      "  L2: 'Then find how many kids from West Side High are rejected: 70% * 90 kids = 63 kids'\n",
      "  L3: 'Then find how many kids from Mountaintop High are rejected: 50 kids / 2 = 25 kids'\n",
      "  L4: 'Then add the number of kids from each school to find the total number of kids: 120 kids + 90 kids + 50 kids = 260 kids'\n",
      "  L5: 'Then subtract all the kids who were rejected from the total number of kids to find the number who got in: 260 kids - 24 kids - 63 kids - 25 kids = 148 kids'\n",
      "  FA: '148'\n",
      "\n",
      "--- INDEX 145 ---\n",
      "RAW ANSWER:\n",
      "'He watched 2*20=<<2*20=40>>40 minutes of Jeopardy.\\nWheel of Fortune is 2*20=<<2*20=40>>40 minutes each.\\nSo he watched it for 40*2=<<40*2=80>>80 minutes.\\nSo he watched 40+80=<<40+80=120>>120 minutes of TV.\\nThat means he watched 120/60=<<120/60=2>>2 hours of TV.\\n#### 2'\n",
      "\n",
      "AFTER PREPROCESSING:\n",
      "'He watched 2*20=40 minutes of Jeopardy.\\nWheel of Fortune is 2*20=40 minutes each.\\nSo he watched it for 40*2=80 minutes.\\nSo he watched 40+80=120 minutes of TV.\\nThat means he watched 120/60=2 hours of TV.\\n#### 2'\n",
      "\n",
      "COMPUTED SOLUTION_LENGTH: 6\n",
      "MANUAL COUNT: 6\n",
      "MATCH: True\n",
      "\n",
      "LINE MAPPING:\n",
      "  L1: 'He watched 2*20=40 minutes of Jeopardy.'\n",
      "  L2: 'Wheel of Fortune is 2*20=40 minutes each.'\n",
      "  L3: 'So he watched it for 40*2=80 minutes.'\n",
      "  L4: 'So he watched 40+80=120 minutes of TV.'\n",
      "  L5: 'That means he watched 120/60=2 hours of TV.'\n",
      "  FA: '2'\n"
     ]
    }
   ],
   "source": [
    "# Simple check of solution length computation\n",
    "print(\"🔍 SOLUTION LENGTH COMPUTATION CHECK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get a few GSM8K samples to test\n",
    "test_indices = [143, 140, 145]\n",
    "\n",
    "for idx in test_indices:\n",
    "    if idx < len(GSM8K_TRAIN):\n",
    "        gsm8k_problem = GSM8K_TRAIN[idx]\n",
    "        \n",
    "        print(f\"\\n--- INDEX {idx} ---\")\n",
    "        \n",
    "        # Raw GSM8K answer\n",
    "        raw_answer = gsm8k_problem['answer']\n",
    "        print(f\"RAW ANSWER:\")\n",
    "        print(repr(raw_answer))\n",
    "        \n",
    "        # After preprocessing\n",
    "        preprocessed = preprocess_solution_for_analysis(raw_answer)\n",
    "        print(f\"\\nAFTER PREPROCESSING:\")\n",
    "        print(repr(preprocessed))\n",
    "        \n",
    "        # Calculate solution length using your function\n",
    "        solution_length, line_mapping = calculate_solution_metrics_preprocessed(raw_answer)\n",
    "        print(f\"\\nCOMPUTED SOLUTION_LENGTH: {solution_length}\")\n",
    "        \n",
    "        # Manual count for verification\n",
    "        reasoning, final_answer = clean_and_split_solution_preprocessed(raw_answer)\n",
    "        manual_lines = [line for line in reasoning.split('\\n') if line.strip()]\n",
    "        manual_count = len(manual_lines)\n",
    "        if final_answer is not None:\n",
    "            manual_count += 1\n",
    "        \n",
    "        print(f\"MANUAL COUNT: {manual_count}\")\n",
    "        print(f\"MATCH: {solution_length == manual_count}\")\n",
    "        \n",
    "        print(f\"\\nLINE MAPPING:\")\n",
    "        for key, line in line_mapping.items():\n",
    "            print(f\"  {key}: {repr(line)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3d04ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_manual_catalog_with_preprocessing(catalog_dict, gsm8k_train, tier_lists) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    UPDATED: Processes manual catalog with proper preprocessing for consistency.\n",
    "    FIXED: Now calculates solution_length from wrong_answer instead of correct answer.\n",
    "    \"\"\"\n",
    "    print(\"=== Processing Manual Catalog with Preprocessing ===\")\n",
    "    \n",
    "    df = catalog_dict['manual'].copy()\n",
    "    print(f\"Initial rows: {len(df)}\")\n",
    "    \n",
    "    clean_rows = []\n",
    "    problematic_rows = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing manual catalog\"):\n",
    "        try:\n",
    "            problem_index = int(row['index'])\n",
    "            \n",
    "            # Check if erroneous_line_number is missing\n",
    "            if pd.isna(row['erroneous_line_number']):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': 'Missing erroneous_line_number',\n",
    "                    'source_catalog': 'manual'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Get GSM8K data\n",
    "            if problem_index >= len(gsm8k_train):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': f'Index {problem_index} out of range',\n",
    "                    'source_catalog': 'manual'\n",
    "                })\n",
    "                continue\n",
    "                \n",
    "            gsm8k_problem = gsm8k_train[problem_index]\n",
    "            \n",
    "            # Validate line number using PREPROCESSED solution\n",
    "            if not validate_line_number_preprocessed(row['erroneous_line_number'], gsm8k_problem['answer']):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': f'Invalid line number: {row[\"erroneous_line_number\"]}',\n",
    "                    'source_catalog': 'manual'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # FIXED: Calculate metrics using WRONG ANSWER instead of correct answer\n",
    "            solution_length, _ = calculate_solution_metrics_preprocessed(row['wrong_answer'])\n",
    "            relative_position = calculate_relative_line_position_preprocessed(row['erroneous_line_number'], row['wrong_answer'])\n",
    "            \n",
    "            # Preprocess question and answer texts\n",
    "            preprocessed_question = preprocess_question_text(gsm8k_problem['question'])\n",
    "            preprocessed_correct_answer = preprocess_solution_for_analysis(gsm8k_problem['answer'])\n",
    "            preprocessed_wrong_answer = preprocess_solution_for_analysis(row['wrong_answer'])\n",
    "            \n",
    "            # Create standardized row\n",
    "            clean_row = {\n",
    "                'index': problem_index,\n",
    "                'tier': None,  # Will be added later\n",
    "                'question': preprocessed_question,\n",
    "                'correct_answer': preprocessed_correct_answer,\n",
    "                'wrong_answer': preprocessed_wrong_answer,\n",
    "                'error_type': row['error_type'] + '_error',\n",
    "                'erroneous_line_number': row['erroneous_line_number'],\n",
    "                'explanation': row['explanation'],\n",
    "                'error_subtype': 'NA',\n",
    "                'source': 'manual',\n",
    "                'solution_length': solution_length,\n",
    "                'relative_line_position': relative_position\n",
    "            }\n",
    "            \n",
    "            clean_rows.append(clean_row)\n",
    "            \n",
    "        except Exception as e:\n",
    "            problematic_rows.append({\n",
    "                **row.to_dict(),\n",
    "                'error_reason': f'Processing error: {str(e)}',\n",
    "                'source_catalog': 'manual'\n",
    "            })\n",
    "    \n",
    "    clean_df = pd.DataFrame(clean_rows)\n",
    "    problematic_df = pd.DataFrame(problematic_rows)\n",
    "    \n",
    "    # Add tier information\n",
    "    if not clean_df.empty:\n",
    "        clean_df = add_tier_column(clean_df, tier_lists)\n",
    "    \n",
    "    print(f\"Clean rows: {len(clean_df)}\")\n",
    "    print(f\"Problematic rows: {len(problematic_df)}\")\n",
    "    \n",
    "    return clean_df, problematic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a2c09fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Manual Catalog with Preprocessing ===\n",
      "Initial rows: 1963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8df91eb7058404081d66a8700dfb585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing manual catalog:   0%|          | 0/1963 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean rows: 1740\n",
      "Problematic rows: 223\n"
     ]
    }
   ],
   "source": [
    "manual_clean, manual_problematic = process_manual_catalog_with_preprocessing(CATALOG_DICT, GSM8K_TRAIN, TIER_LISTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d33aa5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_computational_catalog_with_preprocessing(catalog_dict, gsm8k_train, tier_lists) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    UPDATED: Processes computational catalog with proper preprocessing.\n",
    "    FIXED: Now calculates solution_length from wrong_answer instead of correct answer.\n",
    "    \"\"\"\n",
    "    print(\"=== Processing Computational Catalog with Preprocessing ===\")\n",
    "    \n",
    "    df = catalog_dict['computational'].copy()\n",
    "    print(f\"Initial rows: {len(df)}\")\n",
    "    \n",
    "    clean_rows = []\n",
    "    problematic_rows = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing computational catalog\"):\n",
    "        try:\n",
    "            problem_index = int(row['index'])\n",
    "            \n",
    "            # Check if erroneous_line_number is missing\n",
    "            if pd.isna(row['erroneous_line_number']):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': 'Missing erroneous_line_number',\n",
    "                    'source_catalog': 'computational'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Get GSM8K data\n",
    "            if problem_index >= len(gsm8k_train):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': f'Index {problem_index} out of range',\n",
    "                    'source_catalog': 'computational'\n",
    "                })\n",
    "                continue\n",
    "                \n",
    "            gsm8k_problem = gsm8k_train[problem_index]\n",
    "            \n",
    "            # Check if this is tier5 and exclude it\n",
    "            problem_tier = None\n",
    "            for tier_name, indices in tier_lists.items():\n",
    "                if problem_index in indices:\n",
    "                    problem_tier = tier_name\n",
    "                    break\n",
    "            \n",
    "            if problem_tier == 'tier5':\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': 'Excluded tier5 problem',\n",
    "                    'source_catalog': 'computational'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Validate line number using PREPROCESSED solution\n",
    "            if not validate_line_number_preprocessed(row['erroneous_line_number'], gsm8k_problem['answer']):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': f'Invalid line number: {row[\"erroneous_line_number\"]}',\n",
    "                    'source_catalog': 'computational'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # FIXED: Calculate metrics using WRONG ANSWER instead of correct answer\n",
    "            solution_length, _ = calculate_solution_metrics_preprocessed(row['wrong_answer'])\n",
    "            relative_position = calculate_relative_line_position_preprocessed(row['erroneous_line_number'], row['wrong_answer'])\n",
    "            \n",
    "            # Preprocess texts\n",
    "            preprocessed_question = preprocess_question_text(gsm8k_problem['question'])\n",
    "            preprocessed_correct_answer = preprocess_solution_for_analysis(gsm8k_problem['answer'])\n",
    "            preprocessed_wrong_answer = preprocess_solution_for_analysis(row['wrong_answer'])\n",
    "            \n",
    "            # Create standardized row\n",
    "            clean_row = {\n",
    "                'index': problem_index,\n",
    "                'tier': problem_tier,\n",
    "                'question': preprocessed_question,\n",
    "                'correct_answer': preprocessed_correct_answer,\n",
    "                'wrong_answer': preprocessed_wrong_answer,\n",
    "                'error_type': 'computational_error',\n",
    "                'erroneous_line_number': row['erroneous_line_number'],\n",
    "                'explanation': row['explanation'],\n",
    "                'error_subtype': row['error_type'],\n",
    "                'source': 'programmatic',\n",
    "                'solution_length': solution_length,\n",
    "                'relative_line_position': relative_position\n",
    "            }\n",
    "            \n",
    "            clean_rows.append(clean_row)\n",
    "            \n",
    "        except Exception as e:\n",
    "            problematic_rows.append({\n",
    "                **row.to_dict(),\n",
    "                'error_reason': f'Processing error: {str(e)}',\n",
    "                'source_catalog': 'computational'\n",
    "            })\n",
    "    \n",
    "    clean_df = pd.DataFrame(clean_rows)\n",
    "    problematic_df = pd.DataFrame(problematic_rows)\n",
    "    \n",
    "    print(f\"Clean rows: {len(clean_df)}\")\n",
    "    print(f\"Problematic rows: {len(problematic_df)}\")\n",
    "    \n",
    "    return clean_df, problematic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d51729de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Computational Catalog with Preprocessing ===\n",
      "Initial rows: 22623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8933ba8e88438bab78a1936948aa08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing computational catalog:   0%|          | 0/22623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean rows: 21768\n",
      "Problematic rows: 855\n"
     ]
    }
   ],
   "source": [
    "computational_clean, computational_problematic = process_computational_catalog_with_preprocessing(CATALOG_DICT, GSM8K_TRAIN, TIER_LISTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68722700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_validator_catalogs_with_preprocessing(catalog_dict, gsm8k_train, tier_lists, validators, project_root) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    UPDATED: Processes all validator catalogs with proper preprocessing for consistency.\n",
    "    Only includes accepted samples and excludes tier5 problems.\n",
    "    Uses proper cross-platform path handling and fixes answer formatting.\n",
    "    FIXED: Now calculates solution_length from wrong_answer instead of correct answer.\n",
    "    Returns (clean_rows_df, problematic_rows_df).\n",
    "    \"\"\"\n",
    "    print(\"=== Processing Validator Catalogs with Preprocessing ===\")\n",
    "    \n",
    "    all_clean_rows = []\n",
    "    all_problematic_rows = []\n",
    "    \n",
    "    def check_file_exists_and_get_path(filepath, base_dir=None):\n",
    "        \"\"\"\n",
    "        Check if a file exists and return the correct path, handling cross-platform path issues.\n",
    "        Based on logic from july-26-merging-repairing-accepted.ipynb\n",
    "        \"\"\"\n",
    "        if pd.isna(filepath) or filepath == \"\":\n",
    "            return None, False\n",
    "        \n",
    "        # Convert to Path object and normalize path separators\n",
    "        # Replace Windows backslashes with forward slashes for cross-platform compatibility\n",
    "        normalized_filepath = str(filepath).replace('\\\\', '/')\n",
    "        file_path = Path(normalized_filepath)\n",
    "        \n",
    "        # If it's a relative path, make it relative to the project root\n",
    "        if not file_path.is_absolute():\n",
    "            full_path = project_root / file_path\n",
    "        else:\n",
    "            full_path = file_path\n",
    "        \n",
    "        return full_path, full_path.exists()\n",
    "    \n",
    "    def fix_answer_formatting(wrong_answer: str) -> str:\n",
    "        \"\"\"\n",
    "        Fixes the formatting of wrong answers by moving the final answer line\n",
    "        from the beginning to the end if it's misplaced.\n",
    "        \"\"\"\n",
    "        if not isinstance(wrong_answer, str):\n",
    "            return wrong_answer\n",
    "        \n",
    "        lines = wrong_answer.strip().split('\\n')\n",
    "        final_answer_line = None\n",
    "        other_lines = []\n",
    "        \n",
    "        # Find and extract the final answer line\n",
    "        for line in lines:\n",
    "            if re.match(r'^\\s*####\\s*.*$', line.strip()):\n",
    "                final_answer_line = line.strip()\n",
    "            elif line.strip():  # Skip empty lines\n",
    "                other_lines.append(line)\n",
    "        \n",
    "        # Reconstruct with final answer at the end\n",
    "        if final_answer_line and other_lines:\n",
    "            return '\\n'.join(other_lines) + '\\n' + final_answer_line\n",
    "        elif final_answer_line:\n",
    "            return final_answer_line\n",
    "        else:\n",
    "            return wrong_answer\n",
    "    \n",
    "    for validator in validators:\n",
    "        print(f\"\\nProcessing validator: {validator}\")\n",
    "        df = catalog_dict[f'conceptual_{validator}'].copy()\n",
    "        \n",
    "        # Filter to only accepted samples\n",
    "        df = df[df['status'] == 'accepted']\n",
    "        print(f\"Accepted rows for {validator}: {len(df)}\")\n",
    "        \n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Processing {validator}\"):\n",
    "            try:\n",
    "                problem_index = int(row['index'])\n",
    "                \n",
    "                # Get GSM8K data\n",
    "                if problem_index >= len(gsm8k_train):\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'Index {problem_index} out of range',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                    \n",
    "                gsm8k_problem = gsm8k_train[problem_index]\n",
    "                \n",
    "                # Check if this is tier5 and exclude it\n",
    "                problem_tier = None\n",
    "                for tier_name, indices in tier_lists.items():\n",
    "                    if problem_index in indices:\n",
    "                        problem_tier = tier_name\n",
    "                        break\n",
    "                \n",
    "                if problem_tier == 'tier5':\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': 'Excluded tier5 problem',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Load JSON file with proper path handling\n",
    "                try:\n",
    "                    filepath, file_exists = check_file_exists_and_get_path(row['filepath'])\n",
    "                    \n",
    "                    if not file_exists or filepath is None:\n",
    "                        all_problematic_rows.append({\n",
    "                            **row.to_dict(),\n",
    "                            'error_reason': f'JSON file not found: {row[\"filepath\"]}',\n",
    "                            'source_catalog': f'conceptual_{validator}'\n",
    "                        })\n",
    "                        continue\n",
    "                    \n",
    "                    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                        json_data = json.load(f)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'JSON loading error: {str(e)}',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Extract data from JSON\n",
    "                try:\n",
    "                    raw_wrong_answer = json_data['context']['flawed_solution']\n",
    "                    explanation = json_data['error_details']['explanation']\n",
    "                    erroneous_line_number = json_data['error_details']['erroneous_line_number']\n",
    "                    error_subtype = json_data['error_details']['error_type']\n",
    "                except KeyError as e:\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'Missing JSON field: {str(e)}',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Fix the answer formatting\n",
    "                wrong_answer = fix_answer_formatting(raw_wrong_answer)\n",
    "                \n",
    "                # Check for null erroneous_line_number (from the repair logic in the notebook)\n",
    "                if erroneous_line_number is None or erroneous_line_number == \"null\":\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'Null erroneous_line_number in JSON',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Validate line number using PREPROCESSED solution\n",
    "                if not validate_line_number_preprocessed(erroneous_line_number, gsm8k_problem['answer']):\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'Invalid line number: {erroneous_line_number}',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # FIXED: Calculate metrics using WRONG ANSWER instead of correct answer\n",
    "                solution_length, _ = calculate_solution_metrics_preprocessed(wrong_answer)\n",
    "                relative_position = calculate_relative_line_position_preprocessed(erroneous_line_number, wrong_answer)\n",
    "                \n",
    "                # Preprocess texts for consistency\n",
    "                preprocessed_question = preprocess_question_text(gsm8k_problem['question'])\n",
    "                preprocessed_correct_answer = preprocess_solution_for_analysis(gsm8k_problem['answer'])\n",
    "                preprocessed_wrong_answer = preprocess_solution_for_analysis(wrong_answer)\n",
    "                \n",
    "                # Create standardized row\n",
    "                clean_row = {\n",
    "                    'index': problem_index,\n",
    "                    'tier': problem_tier,\n",
    "                    'question': preprocessed_question,\n",
    "                    'correct_answer': preprocessed_correct_answer,\n",
    "                    'wrong_answer': preprocessed_wrong_answer,  # Now properly formatted AND preprocessed\n",
    "                    'error_type': 'conceptual_error',\n",
    "                    'erroneous_line_number': erroneous_line_number,\n",
    "                    'explanation': explanation,\n",
    "                    'error_subtype': error_subtype,\n",
    "                    'source': 'programmatic',\n",
    "                    'solution_length': solution_length,\n",
    "                    'relative_line_position': relative_position\n",
    "                }\n",
    "                \n",
    "                all_clean_rows.append(clean_row)\n",
    "                \n",
    "            except Exception as e:\n",
    "                all_problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': f'Processing error: {str(e)}',\n",
    "                    'source_catalog': f'conceptual_{validator}'\n",
    "                })\n",
    "    \n",
    "    clean_df = pd.DataFrame(all_clean_rows)\n",
    "    problematic_df = pd.DataFrame(all_problematic_rows)\n",
    "    \n",
    "    print(f\"\\nTotal clean rows: {len(clean_df)}\")\n",
    "    print(f\"Total problematic rows: {len(problematic_df)}\")\n",
    "    \n",
    "    return clean_df, problematic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95c39568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Validator Catalogs with Preprocessing ===\n",
      "\n",
      "Processing validator: ali\n",
      "Accepted rows for ali: 341\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35452e04ad044306bf04e3376c3caf99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ali:   0%|          | 0/341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validator: arvind\n",
      "Accepted rows for arvind: 91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79332e068b2943cfbf4bde190b06a92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing arvind:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validator: mauro\n",
      "Accepted rows for mauro: 312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3837226af4d047128e17d6890471aaa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing mauro:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validator: ling\n",
      "Accepted rows for ling: 110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476ec3a4df724fa7b83c2f5236d30434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ling:   0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validator: yewei\n",
      "Accepted rows for yewei: 290\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abe298c0b6946ca92c19c79f63084a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing yewei:   0%|          | 0/290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total clean rows: 1144\n",
      "Total problematic rows: 0\n"
     ]
    }
   ],
   "source": [
    "validator_clean, validator_problematic = process_validator_catalogs_with_preprocessing(\n",
    "    CATALOG_DICT, GSM8K_TRAIN, TIER_LISTS, VALIDATORS, PROJECT_ROOT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72d5d7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Creating Master Catalogs ===\n",
      "Master catalog rows: 24652\n",
      "Problematic rows: 1078\n",
      "✓ Master catalogs created successfully\n"
     ]
    }
   ],
   "source": [
    "# --- Combine All Catalogs ---\n",
    "\n",
    "def create_master_catalogs(manual_clean, computational_clean, validator_clean, \n",
    "                          manual_problematic, computational_problematic, validator_problematic):\n",
    "    \"\"\"\n",
    "    Combines all clean and problematic dataframes into final master catalogs.\n",
    "    Returns (master_catalog, catalog_problematic).\n",
    "    \"\"\"\n",
    "    print(\"=== Creating Master Catalogs ===\")\n",
    "    \n",
    "    # Combine all clean dataframes\n",
    "    all_clean_dfs = []\n",
    "    if not manual_clean.empty:\n",
    "        all_clean_dfs.append(manual_clean)\n",
    "    if not computational_clean.empty:\n",
    "        all_clean_dfs.append(computational_clean)\n",
    "    if not validator_clean.empty:\n",
    "        all_clean_dfs.append(validator_clean)\n",
    "    \n",
    "    master_catalog = pd.concat(all_clean_dfs, ignore_index=True) if all_clean_dfs else pd.DataFrame()\n",
    "    \n",
    "    # Combine all problematic dataframes\n",
    "    all_problematic_dfs = []\n",
    "    if not manual_problematic.empty:\n",
    "        all_problematic_dfs.append(manual_problematic)\n",
    "    if not computational_problematic.empty:\n",
    "        all_problematic_dfs.append(computational_problematic)\n",
    "    if not validator_problematic.empty:\n",
    "        all_problematic_dfs.append(validator_problematic)\n",
    "    \n",
    "    catalog_problematic = pd.concat(all_problematic_dfs, ignore_index=True) if all_problematic_dfs else pd.DataFrame()\n",
    "    \n",
    "    # Ensure consistent column order for master catalog\n",
    "    if not master_catalog.empty:\n",
    "        column_order = [\n",
    "            'index', 'tier', 'question', 'correct_answer', 'wrong_answer', \n",
    "            'error_type', 'erroneous_line_number', 'explanation', 'error_subtype',\n",
    "            'source', 'solution_length', 'relative_line_position'\n",
    "        ]\n",
    "        master_catalog = master_catalog[column_order]\n",
    "    \n",
    "    print(f\"Master catalog rows: {len(master_catalog)}\")\n",
    "    print(f\"Problematic rows: {len(catalog_problematic)}\")\n",
    "    \n",
    "    return master_catalog, catalog_problematic\n",
    "\n",
    "master_catalog, catalog_problematic = create_master_catalogs(\n",
    "    manual_clean, \n",
    "    computational_clean, \n",
    "    validator_clean,\n",
    "    manual_problematic, \n",
    "    computational_problematic, \n",
    "    validator_problematic\n",
    ")\n",
    "\n",
    "print(\"✓ Master catalogs created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e97872cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MASTER CATALOG SUMMARY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "📊 BASIC STATISTICS\n",
      "Total rows: 24,652\n",
      "Unique GSM8K indices: 6,777\n",
      "Average entries per index: 3.64\n",
      "\n",
      "🔧 SOURCE DISTRIBUTION\n",
      "  programmatic: 22,912 (92.9%)\n",
      "  manual: 1,740 (7.1%)\n",
      "\n",
      "🐛 ERROR TYPE DISTRIBUTION\n",
      "  computational_error: 22,542 (91.4%)\n",
      "  conceptual_error: 2,110 (8.6%)\n",
      "\n",
      "🎯 TIER DISTRIBUTION\n",
      "  tier1: 11,188 (45.4%)\n",
      "  tier2: 3,458 (14.0%)\n",
      "  tier3: 8,288 (33.6%)\n",
      "  tier4: 1,662 (6.7%)\n",
      "  tier5: 56 (0.2%)\n",
      "\n",
      "🔍 ERROR SUBTYPE DISTRIBUTION\n",
      "Total unique subtypes: 15\n",
      "  generate_digit_transposition_error: 9,505 (38.6%)\n",
      "  generate_off_by_n_error: 7,083 (28.7%)\n",
      "  generate_off_by_factor_of_10_error: 2,561 (10.4%)\n",
      "  NA: 1,740 (7.1%)\n",
      "  generate_stem_off_by_n_error: 1,512 (6.1%)\n",
      "  generate_multiplication_by_reciprocal_error: 696 (2.8%)\n",
      "  incorrect_final_answer_selection: 340 (1.4%)\n",
      "  generate_decimal_shift_error: 284 (1.2%)\n",
      "  operator_swap: 222 (0.9%)\n",
      "  incomplete_calculation: 222 (0.9%)\n",
      "  ... and 5 more\n",
      "\n",
      "📏 SOLUTION LENGTH STATISTICS\n",
      "  Mean: 4.8 lines\n",
      "  Median: 5.0 lines\n",
      "  Min: 2 lines\n",
      "  Max: 10 lines\n",
      "  Std: 1.5 lines\n",
      "\n",
      "📍 RELATIVE LINE POSITION STATISTICS\n",
      "  Mean: 0.418\n",
      "  Median: 0.500\n",
      "  Min: 0.000\n",
      "  Max: 3.500\n",
      "  Std: 0.306\n",
      "\n",
      "📊 CROSS-TABULATION: ERROR TYPE vs TIER\n",
      "error_type  computational_error  conceptual_error    All\n",
      "tier                                                    \n",
      "tier1                     10481               707  11188\n",
      "tier2                      3132               326   3458\n",
      "tier3                      7475               813   8288\n",
      "tier4                      1427               235   1662\n",
      "tier5                        27                29     56\n",
      "All                       22542              2110  24652\n",
      "\n",
      "📊 CROSS-TABULATION: SOURCE vs ERROR TYPE\n",
      "error_type    computational_error  conceptual_error    All\n",
      "source                                                    \n",
      "manual                        774               966   1740\n",
      "programmatic                21768              1144  22912\n",
      "All                         22542              2110  24652\n",
      "\n",
      "================================================================================\n",
      "PROBLEMATIC ENTRIES SUMMARY\n",
      "================================================================================\n",
      "Total problematic rows: 1,078\n",
      "\n",
      "❌ ERROR REASONS\n",
      "  Missing erroneous_line_number: 894 (82.9%)\n",
      "  Excluded tier5 problem: 184 (17.1%)\n",
      "\n",
      "📁 PROBLEMATIC BY SOURCE CATALOG\n",
      "  computational: 855 (79.3%)\n",
      "  manual: 223 (20.7%)\n"
     ]
    }
   ],
   "source": [
    "# --- Generate Summary Statistics ---\n",
    "\n",
    "def print_catalog_summary(master_catalog, catalog_problematic):\n",
    "    \"\"\"\n",
    "    Prints comprehensive summary statistics for the master catalog and problematic entries.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"MASTER CATALOG SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if master_catalog.empty:\n",
    "        print(\"❌ Master catalog is empty!\")\n",
    "        return\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"\\n📊 BASIC STATISTICS\")\n",
    "    print(f\"Total rows: {len(master_catalog):,}\")\n",
    "    print(f\"Unique GSM8K indices: {master_catalog['index'].nunique():,}\")\n",
    "    print(f\"Average entries per index: {len(master_catalog) / master_catalog['index'].nunique():.2f}\")\n",
    "    \n",
    "    # Source distribution\n",
    "    print(f\"\\n🔧 SOURCE DISTRIBUTION\")\n",
    "    source_counts = master_catalog['source'].value_counts()\n",
    "    for source, count in source_counts.items():\n",
    "        pct = (count / len(master_catalog)) * 100\n",
    "        print(f\"  {source}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Error type distribution\n",
    "    print(f\"\\n🐛 ERROR TYPE DISTRIBUTION\")\n",
    "    error_type_counts = master_catalog['error_type'].value_counts()\n",
    "    for error_type, count in error_type_counts.items():\n",
    "        pct = (count / len(master_catalog)) * 100\n",
    "        print(f\"  {error_type}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Tier distribution\n",
    "    print(f\"\\n🎯 TIER DISTRIBUTION\")\n",
    "    tier_counts = master_catalog['tier'].value_counts().sort_index()\n",
    "    for tier, count in tier_counts.items():\n",
    "        pct = (count / len(master_catalog)) * 100\n",
    "        print(f\"  {tier}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Error subtype distribution\n",
    "    print(f\"\\n🔍 ERROR SUBTYPE DISTRIBUTION\")\n",
    "    subtype_counts = master_catalog['error_subtype'].value_counts()\n",
    "    print(f\"Total unique subtypes: {len(subtype_counts)}\")\n",
    "    for subtype, count in subtype_counts.head(10).items():\n",
    "        pct = (count / len(master_catalog)) * 100\n",
    "        print(f\"  {subtype}: {count:,} ({pct:.1f}%)\")\n",
    "    if len(subtype_counts) > 10:\n",
    "        print(f\"  ... and {len(subtype_counts) - 10} more\")\n",
    "    \n",
    "    # Solution length statistics\n",
    "    print(f\"\\n📏 SOLUTION LENGTH STATISTICS\")\n",
    "    print(f\"  Mean: {master_catalog['solution_length'].mean():.1f} lines\")\n",
    "    print(f\"  Median: {master_catalog['solution_length'].median():.1f} lines\")\n",
    "    print(f\"  Min: {master_catalog['solution_length'].min()} lines\")\n",
    "    print(f\"  Max: {master_catalog['solution_length'].max()} lines\")\n",
    "    print(f\"  Std: {master_catalog['solution_length'].std():.1f} lines\")\n",
    "    \n",
    "    # Relative line position statistics\n",
    "    print(f\"\\n📍 RELATIVE LINE POSITION STATISTICS\")\n",
    "    print(f\"  Mean: {master_catalog['relative_line_position'].mean():.3f}\")\n",
    "    print(f\"  Median: {master_catalog['relative_line_position'].median():.3f}\")\n",
    "    print(f\"  Min: {master_catalog['relative_line_position'].min():.3f}\")\n",
    "    print(f\"  Max: {master_catalog['relative_line_position'].max():.3f}\")\n",
    "    print(f\"  Std: {master_catalog['relative_line_position'].std():.3f}\")\n",
    "    \n",
    "    # Cross-tabulation: Error Type vs Tier\n",
    "    print(f\"\\n📊 CROSS-TABULATION: ERROR TYPE vs TIER\")\n",
    "    crosstab = pd.crosstab(master_catalog['tier'], master_catalog['error_type'], margins=True)\n",
    "    print(crosstab)\n",
    "    \n",
    "    # Cross-tabulation: Source vs Error Type\n",
    "    print(f\"\\n📊 CROSS-TABULATION: SOURCE vs ERROR TYPE\")\n",
    "    crosstab_source = pd.crosstab(master_catalog['source'], master_catalog['error_type'], margins=True)\n",
    "    print(crosstab_source)\n",
    "    \n",
    "    # Problematic entries summary\n",
    "    print(f\"\\n\" + \"=\" * 80)\n",
    "    print(\"PROBLEMATIC ENTRIES SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if catalog_problematic.empty:\n",
    "        print(\"✅ No problematic entries found!\")\n",
    "    else:\n",
    "        print(f\"Total problematic rows: {len(catalog_problematic):,}\")\n",
    "        \n",
    "        # Error reasons\n",
    "        if 'error_reason' in catalog_problematic.columns:\n",
    "            print(f\"\\n❌ ERROR REASONS\")\n",
    "            error_reasons = catalog_problematic['error_reason'].value_counts()\n",
    "            for reason, count in error_reasons.items():\n",
    "                pct = (count / len(catalog_problematic)) * 100\n",
    "                print(f\"  {reason}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        # Source catalog distribution\n",
    "        if 'source_catalog' in catalog_problematic.columns:\n",
    "            print(f\"\\n📁 PROBLEMATIC BY SOURCE CATALOG\")\n",
    "            source_prob_counts = catalog_problematic['source_catalog'].value_counts()\n",
    "            for source, count in source_prob_counts.items():\n",
    "                pct = (count / len(catalog_problematic)) * 100\n",
    "                print(f\"  {source}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Generate the summary\n",
    "print_catalog_summary(master_catalog, catalog_problematic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d366a370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "SAMPLE ROWS BY ERROR TYPE AND SOURCE\n",
      "====================================================================================================\n",
      "\n",
      "==================== COMPUTATIONAL_ERROR + MANUAL ====================\n",
      "Total samples: 774\n",
      "--------------------------------------------------------------------------------\n",
      "📍 INDEX: 1000\n",
      "🎯 TIER: tier3\n",
      "🔧 ERROR SUBTYPE: NA\n",
      "📏 SOLUTION LENGTH: 3 lines\n",
      "📍 ERROR LINE: L1 (relative position: 0.000)\n",
      "\n",
      "❓ QUESTION:\n",
      "   John buys a heating pad for $30.  He uses it 3 times a week for 2 weeks.  How much does he spend on each use?\n",
      "\n",
      "✅ CORRECT ANSWER:\n",
      "   He uses it 3*2=6 times\n",
      "   So he pays 30/6=$5\n",
      "   #### 5\n",
      "\n",
      "❌ WRONG ANSWER:\n",
      "   He uses it 3*2=5 times\n",
      "   So he pays 30/5=$6\n",
      "   #### 6\n",
      "\n",
      "💡 EXPLANATION:\n",
      "   computational error: John uses it 3*2=<<3*2=6>>6 times.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "==================== COMPUTATIONAL_ERROR + PROGRAMMATIC ====================\n",
      "Total samples: 21,768\n",
      "--------------------------------------------------------------------------------\n",
      "📍 INDEX: 4\n",
      "🎯 TIER: tier1\n",
      "🔧 ERROR SUBTYPE: generate_digit_transposition_error\n",
      "📏 SOLUTION LENGTH: 4 lines\n",
      "📍 ERROR LINE: L2 (relative position: 0.333)\n",
      "\n",
      "❓ QUESTION:\n",
      "   James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\n",
      "\n",
      "✅ CORRECT ANSWER:\n",
      "   He writes each friend 3*2=6 pages a week\n",
      "   So he writes 6*2=12 pages every week\n",
      "   That means he writes 12*52=624 pages a year\n",
      "   #### 624\n",
      "\n",
      "❌ WRONG ANSWER:\n",
      "   He writes each friend 3*2=6 pages a week\n",
      "   So he writes 6*2=21 pages every week\n",
      "   That means he writes 21*52=1092 pages a year\n",
      "   #### 1092\n",
      "\n",
      "💡 EXPLANATION:\n",
      "   The result of this computation should be 12, not 21. It appears two adjacent digits were swapped.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "==================== CONCEPTUAL_ERROR + MANUAL ====================\n",
      "Total samples: 966\n",
      "--------------------------------------------------------------------------------\n",
      "📍 INDEX: 1000\n",
      "🎯 TIER: tier3\n",
      "🔧 ERROR SUBTYPE: NA\n",
      "📏 SOLUTION LENGTH: 3 lines\n",
      "📍 ERROR LINE: L1 (relative position: 0.000)\n",
      "\n",
      "❓ QUESTION:\n",
      "   John buys a heating pad for $30.  He uses it 3 times a week for 2 weeks.  How much does he spend on each use?\n",
      "\n",
      "✅ CORRECT ANSWER:\n",
      "   He uses it 3*2=6 times\n",
      "   So he pays 30/6=$5\n",
      "   #### 5\n",
      "\n",
      "❌ WRONG ANSWER:\n",
      "   He uses it for 2 weeks.\n",
      "   So he pays 30/2=$15\n",
      "   #### 15\n",
      "\n",
      "💡 EXPLANATION:\n",
      "   incorrect divisor: The cost should be divided by the total number of uses (3 times/week * 2 weeks = 6 uses), not just the number of weeks. The calculation should be 30/6 = $5.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "==================== CONCEPTUAL_ERROR + PROGRAMMATIC ====================\n",
      "Total samples: 1,144\n",
      "--------------------------------------------------------------------------------\n",
      "📍 INDEX: 978\n",
      "🎯 TIER: tier4\n",
      "🔧 ERROR SUBTYPE: operator_swap\n",
      "📏 SOLUTION LENGTH: 4 lines\n",
      "📍 ERROR LINE: L1 (relative position: 0.000)\n",
      "\n",
      "❓ QUESTION:\n",
      "   Stephen has 110 ants in his ant farm.  Half of the ants are worker ants, 20 percent of the worker ants are male.  How many female worker ants are there?\n",
      "\n",
      "✅ CORRECT ANSWER:\n",
      "   Worker ants:110/2=55 ants\n",
      "   Male worker ants:55(.20)=11\n",
      "   Female worker ants:55-11=44 ants\n",
      "   #### 44\n",
      "\n",
      "❌ WRONG ANSWER:\n",
      "   Worker ants:110*2=220 ants\n",
      "   Male worker ants:220(0.2)=44\n",
      "   Female worker ants:220-44=176 ants\n",
      "   #### 176\n",
      "\n",
      "💡 EXPLANATION:\n",
      "   Incorrect operation. The calculation should use '/' but used '*' instead.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Pretty Print Sample Rows by Error Type and Source ---\n",
    "\n",
    "def pretty_print_sample_rows(master_catalog):\n",
    "    \"\"\"\n",
    "    Pretty prints one sample row from each combination of error_type and source.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 100)\n",
    "    print(\"SAMPLE ROWS BY ERROR TYPE AND SOURCE\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Get all combinations of error_type and source\n",
    "    combinations = master_catalog.groupby(['error_type', 'source']).size().reset_index()\n",
    "    \n",
    "    for _, combo in combinations.iterrows():\n",
    "        error_type = combo['error_type']\n",
    "        source = combo['source']\n",
    "        count = combo[0]\n",
    "        \n",
    "        print(f\"\\n{'='*20} {error_type.upper()} + {source.upper()} {'='*20}\")\n",
    "        print(f\"Total samples: {count:,}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Get one sample from this combination\n",
    "        sample_df = master_catalog[\n",
    "            (master_catalog['error_type'] == error_type) & \n",
    "            (master_catalog['source'] == source)\n",
    "        ]\n",
    "        \n",
    "        if len(sample_df) > 0:\n",
    "            sample = sample_df.iloc[0]\n",
    "            \n",
    "            print(f\"📍 INDEX: {sample['index']}\")\n",
    "            print(f\"🎯 TIER: {sample['tier']}\")\n",
    "            print(f\"🔧 ERROR SUBTYPE: {sample['error_subtype']}\")\n",
    "            print(f\"📏 SOLUTION LENGTH: {sample['solution_length']} lines\")\n",
    "            print(f\"📍 ERROR LINE: {sample['erroneous_line_number']} (relative position: {sample['relative_line_position']:.3f})\")\n",
    "            print()\n",
    "            \n",
    "            print(\"❓ QUESTION:\")\n",
    "            print(f\"   {sample['question']}\")\n",
    "            print()\n",
    "            \n",
    "            print(\"✅ CORRECT ANSWER:\")\n",
    "            correct_lines = sample['correct_answer'].split('\\n')\n",
    "            for i, line in enumerate(correct_lines, 1):\n",
    "                if line.strip():\n",
    "                    print(f\"   {line}\")\n",
    "            print()\n",
    "            \n",
    "            print(\"❌ WRONG ANSWER:\")\n",
    "            wrong_lines = sample['wrong_answer'].split('\\n')\n",
    "            for i, line in enumerate(wrong_lines, 1):\n",
    "                if line.strip():\n",
    "                    print(f\"   {line}\")\n",
    "            print()\n",
    "            \n",
    "            print(\"💡 EXPLANATION:\")\n",
    "            print(f\"   {sample['explanation']}\")\n",
    "            print()\n",
    "        else:\n",
    "            print(\"No samples found for this combination.\")\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "\n",
    "# Run the pretty printer\n",
    "pretty_print_sample_rows(master_catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cfc5b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv in the data folder\n",
    "master_catalog.to_csv(DATA_DIR / 'master_catalog_sanitized.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87573dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the problematic catalog to csv in the data folder\n",
    "catalog_problematic.to_csv(DATA_DIR / 'catalog_problematic_sanitized.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04fa19c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
