{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21c64eb4",
   "metadata": {},
   "source": [
    "### Cell 1: Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4bd7d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math\n",
      "Input (Processed Templates): /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/template-generated-processed\n",
      "Output (Generated Errors): /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/computational-errors-generated\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import ast\n",
    "import inspect\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "from types import ModuleType\n",
    "from typing import Callable, Any, Dict, List\n",
    "from fractions import Fraction as BuiltinFraction\n",
    "import datetime\n",
    "import functools\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# --- Path and Directory Definitions ---\n",
    "def find_project_root(marker: str = \".git\") -> Path:\n",
    "    current_path = Path.cwd().resolve()\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / marker).exists():\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    raise FileNotFoundError(f\"Could not find project root. Marker '{marker}' not found.\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "\n",
    "PROCESSED_TEMPLATE_DIR = DATA_DIR / \"template-generated-processed\"\n",
    "GENERATED_ERRORS_DIR = DATA_DIR / \"computational-errors-generated\"\n",
    "\n",
    "MODELS = ['openai_gpt-4.1', 'google_gemini-2.5-flash']\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Input (Processed Templates): {PROCESSED_TEMPLATE_DIR}\")\n",
    "print(f\"Output (Generated Errors): {GENERATED_ERRORS_DIR}\")\n",
    "\n",
    "# --- Ensure Directories Exist ---\n",
    "PROCESSED_TEMPLATE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "GENERATED_ERRORS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895a0273",
   "metadata": {},
   "source": [
    "### Cell 2: Load dataset and define the tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64a3923a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier definitions loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Load GSM8K Dataset ---\n",
    "GSM8K_TRAIN: Dataset = load_dataset(\"gsm8k\", \"main\")[\"train\"] #type: ignore\n",
    "\n",
    "# --- Tier Definition Functions ---\n",
    "def has_computational_division(solution_text: str) -> bool:\n",
    "    pattern = re.compile(r'/\\s*\\d')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def has_float(solution_text: str) -> bool:\n",
    "    pattern = re.compile(r'(?<!\\d)\\.\\d+|\\d+\\.\\d+')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def is_symbolic(solution_text: str) -> bool:\n",
    "    pattern = re.compile(r'^Let [a-zA-Z] ', re.MULTILINE)\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def mutually_disjoint_tiers(dataset: Dataset) -> dict[str, list[int]]:\n",
    "    tiers = {}\n",
    "    symbolic_set = set(idx for idx, sample in enumerate(dataset) if is_symbolic(sample.get(\"answer\", \"\")))\n",
    "    non_symbolic_indices = [idx for idx in range(len(dataset)) if idx not in symbolic_set]\n",
    "    tiers[\"tier1\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier2\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier3\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier4\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier5\"] = sorted(list(symbolic_set))\n",
    "    return tiers\n",
    "\n",
    "TIER_LISTS = mutually_disjoint_tiers(GSM8K_TRAIN)\n",
    "print(\"Tier definitions loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd9ef9f",
   "metadata": {},
   "source": [
    "### Cell 3: Template Loading Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc79ee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template loading functions defined.\n"
     ]
    }
   ],
   "source": [
    "def load_function_module(tier: str, index: int, model_name: str) -> ModuleType | None:\n",
    "    \"\"\"Dynamically loads the '{model_name}.py' file for a given template.\"\"\"\n",
    "    py_file_path = PROCESSED_TEMPLATE_DIR / tier / str(index) / f\"{model_name}.py\"\n",
    "    if not py_file_path.exists():\n",
    "        return None\n",
    "    module_name = f\"templates.t{tier}.i{index}.m_{model_name.replace('.', '_')}.solve\"\n",
    "    spec = importlib.util.spec_from_file_location(module_name, py_file_path)\n",
    "    if spec and spec.loader:\n",
    "        module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(module)\n",
    "        return module\n",
    "    return None\n",
    "\n",
    "def load_logical_steps(tier: str, index: int, model_name: str) -> list[dict] | None:\n",
    "    \"\"\"Loads the '{model_name}.json' file for a given template.\"\"\"\n",
    "    json_file_path = PROCESSED_TEMPLATE_DIR / tier / str(index) / f\"{model_name}.json\"\n",
    "    try:\n",
    "        return json.loads(json_file_path.read_text(encoding='utf-8'))\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        return None\n",
    "\n",
    "print(\"Template loading functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c9901c",
   "metadata": {},
   "source": [
    "### Cell 4: Core Pipeline Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be2a61a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core pipeline utilities defined.\n"
     ]
    }
   ],
   "source": [
    "# --- ADD THIS CLASS ---\n",
    "class FormattingTrace(dict):\n",
    "    \"\"\"A dictionary subclass that formats numbers for clean reconstruction.\"\"\"\n",
    "    def __getitem__(self, key):\n",
    "        val = super().__getitem__(key)\n",
    "        if isinstance(val, float) and val.is_integer():\n",
    "            return str(int(val))\n",
    "        if isinstance(val, float):\n",
    "            # Round to 2 decimal places, but remove trailing .0 if it exists\n",
    "            rounded_val = round(val, 2)\n",
    "            if rounded_val == int(rounded_val):\n",
    "                 return str(int(rounded_val))\n",
    "            return str(rounded_val)\n",
    "        return str(val)\n",
    "\n",
    "class NonSimplifyingFraction(BuiltinFraction):\n",
    "    \"\"\"\n",
    "    A subclass of fractions.Fraction that does NOT simplify when converted\n",
    "    to a string, preserving the original representation from the template.\n",
    "    \"\"\"\n",
    "    def __new__(cls, numerator=0, denominator=None):\n",
    "        self = super().__new__(cls, numerator, denominator)\n",
    "        if denominator is not None:\n",
    "            self._original_denominator = denominator\n",
    "            self._original_numerator = numerator\n",
    "        else:\n",
    "            self._original_numerator, self._original_denominator = self.as_integer_ratio()\n",
    "        return self\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self._original_numerator}/{self._original_denominator}\"\n",
    "\n",
    "def normalize_value(value: Any) -> Any:\n",
    "    \"\"\"Normalizes a numeric value by casting integer-like floats to int.\"\"\"\n",
    "    if isinstance(value, float) and value.is_integer():\n",
    "        return int(value)\n",
    "    return value\n",
    "\n",
    "def get_sign(n) -> int:\n",
    "    \"\"\"Returns the sign of a number (1 for positive, -1 for negative, 0 for zero).\"\"\"\n",
    "    if n > 0: return 1\n",
    "    if n < 0: return -1\n",
    "    return 0\n",
    "\n",
    "def has_distinct_adjacent_digits(n: int) -> bool:\n",
    "    \"\"\"Checks if an integer is suitable for digit transposition.\"\"\"\n",
    "    s = str(abs(n))\n",
    "    return len(s) >= 2 and any(s[i] != s[i+1] for i in range(len(s) - 1))\n",
    "\n",
    "def execution_trace(func: Callable[[], Any]) -> dict[str, Any] | None:\n",
    "    \"\"\"\n",
    "    Executes a function's source code line by line to build a variable trace,\n",
    "    using NonSimplifyingFraction to preserve fraction representations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "        func_def = tree.body[0]\n",
    "        global_namespace = {'Fraction': NonSimplifyingFraction}\n",
    "        local_env = {}\n",
    "        for stmt in func_def.body:\n",
    "            if isinstance(stmt, ast.Assign):\n",
    "                module_node = ast.Module([stmt], type_ignores=[])\n",
    "                code_obj = compile(module_node, '<string>', 'exec')\n",
    "                exec(code_obj, global_namespace, local_env)\n",
    "        return local_env\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def generate_flawed_trace(func: Callable, error_details: dict[str, Any]) -> dict[str, Any] | None:\n",
    "    \"\"\"\n",
    "    Creates a flawed execution trace by modifying an assignment in the function's\n",
    "    AST and re-executing it, using NonSimplifyingFraction.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "        func_def = tree.body[0]\n",
    "        variable_to_change = error_details[\"variable\"]\n",
    "        flawed_value = error_details[\"flawed_value\"]\n",
    "        modified_body = copy.deepcopy(func_def.body)\n",
    "        node_found_and_modified = False\n",
    "        for node in modified_body:\n",
    "            if isinstance(node, ast.Assign) and any(t.id == variable_to_change for t in node.targets if isinstance(t, ast.Name)):\n",
    "                if isinstance(flawed_value, BuiltinFraction):\n",
    "                    new_value_node = ast.Call(\n",
    "                        func=ast.Name(id='Fraction', ctx=ast.Load()),\n",
    "                        args=[ast.Constant(value=flawed_value._original_numerator), ast.Constant(value=flawed_value._original_denominator)],\n",
    "                        keywords=[]\n",
    "                    )\n",
    "                else:\n",
    "                    new_value_node = ast.Constant(value=flawed_value)\n",
    "                ast.copy_location(new_value_node, node.value)\n",
    "                ast.fix_missing_locations(new_value_node)\n",
    "                node.value = new_value_node\n",
    "                node_found_and_modified = True\n",
    "                break\n",
    "        if not node_found_and_modified: return None\n",
    "\n",
    "        global_namespace = {'Fraction': NonSimplifyingFraction}\n",
    "        env = {}\n",
    "        for stmt in modified_body:\n",
    "            if isinstance(stmt, ast.Assign):\n",
    "                code_obj = compile(ast.Module([stmt], type_ignores=[]), '<string>', 'exec')\n",
    "                exec(code_obj, global_namespace, env)\n",
    "        return env\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def reconstruct_solution_lines(logical_steps: list[dict], eval_trace: dict[str, Any]) -> dict[str, str] | None:\n",
    "    \"\"\"Reconstructs natural language solution lines from templates and a variable trace.\"\"\"\n",
    "    reconstructed_mapping = {}\n",
    "    # --- MODIFICATION: Wrap eval_trace with FormattingTrace ---\n",
    "    formatted_trace = FormattingTrace(eval_trace)\n",
    "    for step in logical_steps:\n",
    "        ln, template = step.get(\"line_number\"), step.get(\"solution_line_template\")\n",
    "        if not (ln and template): continue\n",
    "        try:\n",
    "            reconstructed_mapping[ln] = template.format_map(formatted_trace)\n",
    "        except (KeyError, ValueError):\n",
    "            return None\n",
    "    return reconstructed_mapping\n",
    "\n",
    "def is_trace_valid(flawed_trace: dict[str, Any], correct_trace: dict[str, Any]) -> bool:\n",
    "    \"\"\"Validates a flawed trace for type integrity and sign integrity.\"\"\"\n",
    "    for var_name, correct_val in correct_trace.items():\n",
    "        flawed_val = flawed_trace.get(var_name)\n",
    "        if flawed_val is None: continue\n",
    "        is_correct_int_like = isinstance(normalize_value(correct_val), int)\n",
    "        is_flawed_int_like = isinstance(normalize_value(flawed_val), int)\n",
    "        if is_correct_int_like and not is_flawed_int_like: return False\n",
    "        \n",
    "        processed_correct = normalize_value(correct_val)\n",
    "        processed_flawed = normalize_value(flawed_val)\n",
    "        if isinstance(processed_correct, (int, float)) and processed_correct != 0:\n",
    "            if get_sign(processed_correct) != get_sign(processed_flawed): return False\n",
    "    return True\n",
    "\n",
    "print(\"Core pipeline utilities defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab744ab5",
   "metadata": {},
   "source": [
    "### Cell 5: Error Generator Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "073243e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generator functions defined.\n"
     ]
    }
   ],
   "source": [
    "def generate_off_by_n_error(correct_value: int, offset_range: tuple[int, int] = (1, 5)):\n",
    "    offset = random.randint(offset_range[0], offset_range[1]) * random.choice([-1, 1])\n",
    "    flawed_value = correct_value + offset\n",
    "    if get_sign(correct_value) != get_sign(flawed_value) and correct_value != 0: flawed_value = correct_value - offset\n",
    "    if flawed_value == correct_value: flawed_value += 1 if correct_value >= 0 else -1\n",
    "    return {\"flawed_value\": flawed_value, \"explanation_type\": \"This appears to be a minor miscalculation.\"}\n",
    "\n",
    "def generate_off_by_factor_of_10_error(correct_value: int):\n",
    "    if random.random() < 0.5:\n",
    "        return {\"flawed_value\": correct_value // 10, \"explanation_type\": \"It appears a zero was dropped from the number.\"}\n",
    "    else:\n",
    "        return {\"flawed_value\": correct_value * 10, \"explanation_type\": \"It appears an extra zero was added to the number.\"}\n",
    "\n",
    "def generate_digit_transposition_error(correct_value: int) -> dict[str, Any] | None:\n",
    "    s_val = str(abs(correct_value))\n",
    "    if len(s_val) < 2: return None\n",
    "    valid_indices = [i for i in range(len(s_val) - 1) if s_val[i] != s_val[i+1] and not (i == 0 and s_val[i+1] == '0')]\n",
    "    if not valid_indices: return None\n",
    "    idx_to_swap = random.choice(valid_indices)\n",
    "    s_list = list(s_val)\n",
    "    s_list[idx_to_swap], s_list[idx_to_swap+1] = s_list[idx_to_swap+1], s_list[idx_to_swap]\n",
    "    flawed_value = int(\"\".join(s_list))\n",
    "    if correct_value < 0: flawed_value = -flawed_value\n",
    "    return {\"flawed_value\": flawed_value, \"explanation_type\": \"It appears two adjacent digits were swapped.\"}\n",
    "\n",
    "def generate_stem_off_by_n_error(correct_value: int, offset_range: tuple[int, int] = (1, 3)):\n",
    "    stem = correct_value // 10\n",
    "    offset = random.randint(offset_range[0], offset_range[1]) * random.choice([-1, 1])\n",
    "    flawed_stem = stem + offset\n",
    "    if flawed_stem == stem: flawed_stem += 1\n",
    "    return {\"flawed_value\": flawed_stem * 10, \"explanation_type\": \"It appears there was a miscalculation with the digits before the final zero.\"}\n",
    "\n",
    "def generate_decimal_shift_error(correct_value: float):\n",
    "    flawed_value = correct_value * 10 if random.random() < 0.5 else correct_value / 10\n",
    "    return {\"flawed_value\": round(flawed_value, 10), \"explanation_type\": \"It appears the decimal point was misplaced.\"}\n",
    "\n",
    "def generate_float_off_by_n_error(correct_value: float):\n",
    "    magnitude = abs(correct_value)\n",
    "    offset = random.uniform(magnitude * 0.1, magnitude * 0.2) * random.choice([-1, 1])\n",
    "    return {\"flawed_value\": round(correct_value + offset, 10), \"explanation_type\": \"This appears to be a minor miscalculation.\"}\n",
    "\n",
    "def generate_reciprocal_error(correct_value: NonSimplifyingFraction):\n",
    "    if correct_value.denominator == 0: return None\n",
    "    return {\"flawed_value\": NonSimplifyingFraction(correct_value.denominator, correct_value.numerator), \"explanation_type\": \"It appears the numerator and denominator were swapped.\"}\n",
    "\n",
    "def generate_off_by_one_in_fraction_part_error(correct_value: NonSimplifyingFraction):\n",
    "    offset = random.choice([-1, 1])\n",
    "    if random.random() < 0.5:\n",
    "        new_num, new_den = correct_value.numerator + offset, correct_value.denominator\n",
    "    else:\n",
    "        new_num, new_den = correct_value.numerator, correct_value.denominator + offset\n",
    "        if new_den == 0: new_den = correct_value.denominator + (offset * 2)\n",
    "    return {\"flawed_value\": NonSimplifyingFraction(new_num, new_den), \"explanation_type\": \"It appears there was an off-by-one error in the fraction.\"}\n",
    "\n",
    "def generate_multiplication_by_reciprocal_error(numeric_val: Any, fraction_val: NonSimplifyingFraction):\n",
    "    if fraction_val.numerator == 0: return None\n",
    "    numeric_as_frac = BuiltinFraction(numeric_val)\n",
    "    new_num = numeric_as_frac.numerator * fraction_val.denominator\n",
    "    new_den = numeric_as_frac.denominator * fraction_val.numerator\n",
    "    return {\"flawed_value\": NonSimplifyingFraction(new_num, new_den), \"explanation_type\": \"It appears the value was multiplied by the reciprocal of the intended fraction.\"}\n",
    "\n",
    "print(\"Error generator functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59336d75",
   "metadata": {},
   "source": [
    "### Cell 6: Error Applicability Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43280bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error applicability logic defined.\n"
     ]
    }
   ],
   "source": [
    "def get_target_variables(logical_steps: list[dict]) -> list[str]:\n",
    "    \"\"\"Extracts all 'output_variable' names from the logical steps.\"\"\"\n",
    "    return [step['output_variable'] for step in logical_steps if 'output_variable' in step]\n",
    "\n",
    "def get_operator_for_variable(func: Callable, variable_name: str) -> str | None:\n",
    "    \"\"\"Inspects the AST to find the operator used to compute a variable.\"\"\"\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "    except (TypeError, FileNotFoundError, SyntaxError): return None\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Assign) and any(t.id == variable_name for t in node.targets if isinstance(t, ast.Name)):\n",
    "            if isinstance(node.value, ast.BinOp):\n",
    "                op = node.value.op\n",
    "                if isinstance(op, ast.Add): return \"add\"\n",
    "                if isinstance(op, ast.Sub): return \"sub\"\n",
    "                if isinstance(op, ast.Mult): return \"mult\"\n",
    "                if isinstance(op, ast.Div): return \"div\"\n",
    "            return \"other\"\n",
    "    return None\n",
    "\n",
    "def get_operand_names_for_variable(func: Callable, variable_name: str) -> list[str]:\n",
    "    \"\"\"Finds the names of variables used as operands for a target variable.\"\"\"\n",
    "    operand_names = []\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "    except (TypeError, FileNotFoundError, SyntaxError): return []\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Assign) and any(t.id == variable_name for t in node.targets if isinstance(t, ast.Name)):\n",
    "            for sub_node in ast.walk(node.value):\n",
    "                if isinstance(sub_node, ast.Name): operand_names.append(sub_node.id)\n",
    "            return list(set(operand_names))\n",
    "    return []\n",
    "\n",
    "def _get_applicable_integer_errors(correct_value: int, operator: str, operand_values: list):\n",
    "    \"\"\"Returns a list of applicable error generator functions for an integer.\"\"\"\n",
    "    applicable_generators = []\n",
    "    if operator in [\"add\", \"sub\"]:\n",
    "        if all(isinstance(v, int) and v % 10 == 0 for v in operand_values) and correct_value % 10 == 0 and correct_value != 0:\n",
    "            applicable_generators.append(generate_stem_off_by_n_error)\n",
    "        else:\n",
    "            applicable_generators.append(generate_off_by_n_error)\n",
    "    if correct_value % 100 == 0 and correct_value != 0:\n",
    "        applicable_generators.append(generate_off_by_factor_of_10_error)\n",
    "    if has_distinct_adjacent_digits(correct_value):\n",
    "        applicable_generators.append(generate_digit_transposition_error)\n",
    "    return applicable_generators\n",
    "\n",
    "def get_applicable_generators(func: Callable, correct_trace: dict[str, Any], variable_name: str):\n",
    "    \"\"\"Identifies and partially instantiates all applicable error generators for a variable.\"\"\"\n",
    "    applicable_generators = []\n",
    "    correct_value = correct_trace.get(variable_name)\n",
    "    if not isinstance(correct_value, (int, float, BuiltinFraction)): return []\n",
    "\n",
    "    def add_generator(gen_func, value_to_pass):\n",
    "        partial_gen = functools.partial(gen_func, value_to_pass)\n",
    "        partial_gen.__name__ = gen_func.__name__\n",
    "        applicable_generators.append(partial_gen)\n",
    "\n",
    "    if isinstance(correct_value, int) or (isinstance(correct_value, float) and correct_value.is_integer()):\n",
    "        int_val, op = int(correct_value), get_operator_for_variable(func, variable_name)\n",
    "        op_names = get_operand_names_for_variable(func, variable_name)\n",
    "        op_vals = [correct_trace.get(name) for name in op_names if name in correct_trace]\n",
    "        for gen_func in _get_applicable_integer_errors(int_val, op, op_vals):\n",
    "            add_generator(gen_func, int_val)\n",
    "    elif isinstance(correct_value, float):\n",
    "        add_generator(generate_float_off_by_n_error, correct_value)\n",
    "        if correct_value != 0: add_generator(generate_decimal_shift_error, correct_value)\n",
    "    elif isinstance(correct_value, NonSimplifyingFraction) and correct_value.denominator != 1:\n",
    "        add_generator(generate_off_by_one_in_fraction_part_error, correct_value)\n",
    "        if correct_value.numerator != 0: add_generator(generate_reciprocal_error, correct_value)\n",
    "\n",
    "    if get_operator_for_variable(func, variable_name) == \"mult\":\n",
    "        op_names = get_operand_names_for_variable(func, variable_name)\n",
    "        op_vals = [correct_trace.get(name) for name in op_names if name in correct_trace]\n",
    "        if len(op_vals) == 2:\n",
    "            num_op = next((op for op in op_vals if isinstance(op, (int, float))), None)\n",
    "            frac_op = next((op for op in op_vals if isinstance(op, NonSimplifyingFraction)), None)\n",
    "            if num_op is not None and frac_op is not None and frac_op.denominator != 1:\n",
    "                gen = functools.partial(generate_multiplication_by_reciprocal_error, numeric_val=num_op, fraction_val=frac_op)\n",
    "                gen.__name__ = 'generate_multiplication_by_reciprocal_error'\n",
    "                applicable_generators.append(gen)\n",
    "    return list(dict.fromkeys(applicable_generators))\n",
    "\n",
    "print(\"Error applicability logic defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944280d0",
   "metadata": {},
   "source": [
    "### Cell 7: Orchestrator and Artifact Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6e49368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orchestration and artifact generation functions defined.\n"
     ]
    }
   ],
   "source": [
    "def find_error_line_number(variable_name: str, logical_steps: list[dict]) -> str | None:\n",
    "    \"\"\"Finds the line number corresponding to a given output variable.\"\"\"\n",
    "    for step in logical_steps:\n",
    "        if step.get(\"output_variable\") == variable_name:\n",
    "            return step.get(\"line_number\")\n",
    "    return None\n",
    "\n",
    "def generate_training_artifacts(\n",
    "    logical_steps: list[dict], # <- 'func' argument removed\n",
    "    error_details: dict[str, Any],\n",
    "    flawed_trace: dict[str, Any]\n",
    "):\n",
    "    \"\"\"Generates the final training data: a flawed NL solution and a JSON label.\"\"\"\n",
    "    flawed_solution_map = reconstruct_solution_lines(logical_steps, flawed_trace)\n",
    "    if not flawed_solution_map: return None\n",
    "    \n",
    "    sorted_lines = sorted(flawed_solution_map.items(), key=lambda item: int(item[0][1:]))\n",
    "    flawed_nl_solution = \"\\n\".join([line for _, line in sorted_lines])\n",
    "    \n",
    "    # --- START OF SIMPLIFIED LOGIC ---\n",
    "    # The return variable is always 'answer'.\n",
    "    return_variable = \"answer\"\n",
    "    \n",
    "    if return_variable in flawed_trace:\n",
    "        final_answer = normalize_value(flawed_trace[return_variable])\n",
    "        flawed_nl_solution += f\"\\n#### {final_answer}\"\n",
    "    # --- END OF SIMPLIFIED LOGIC ---\n",
    "\n",
    "    erroneous_line = find_error_line_number(error_details[\"variable\"], logical_steps)\n",
    "    if not erroneous_line: return None\n",
    "\n",
    "    correct_val_str = str(normalize_value(error_details['correct_value']))\n",
    "    flawed_val_str = str(normalize_value(error_details['flawed_value']))\n",
    "    \n",
    "    base_explanation = f\"The result of this computation should be {correct_val_str}, not {flawed_val_str}.\"\n",
    "    type_explanation = error_details[\"explanation_type\"]\n",
    "    \n",
    "    target_json = {\n",
    "        \"verdict\": \"Flawed\",\n",
    "        \"error_details\": {\n",
    "            \"error_type\": \"computational_error\",\n",
    "            \"erroneous_line_number\": erroneous_line,\n",
    "            \"explanation\": f\"{base_explanation} {type_explanation}\",\n",
    "        }\n",
    "    }\n",
    "    return flawed_nl_solution, target_json\n",
    "\n",
    "def generate_all_valid_errors(\n",
    "    func: Callable,\n",
    "    logical_steps: list[dict],\n",
    "    correct_trace: dict[str, Any],\n",
    "    max_attempts: int = 10\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Deterministically generates and validates all possible computational errors.\n",
    "    \"\"\"\n",
    "    all_generated_examples = []\n",
    "    target_variables = get_target_variables(logical_steps)\n",
    "    \n",
    "    for variable_name in target_variables:\n",
    "        correct_value = correct_trace.get(variable_name)\n",
    "        base_seed = hash(f\"{variable_name}\")\n",
    "        applicable_generators = get_applicable_generators(func, correct_trace, variable_name)\n",
    "\n",
    "        for generator_func in applicable_generators:\n",
    "            for attempt in range(max_attempts):\n",
    "                repro_seed = base_seed + hash(generator_func.__name__) + attempt\n",
    "                random.seed(repro_seed)\n",
    "                \n",
    "                error_result = generator_func()\n",
    "                if not error_result: continue\n",
    "\n",
    "                error_details = {\"variable\": variable_name, \"correct_value\": correct_value, **error_result}\n",
    "                if isinstance(correct_value, float) and correct_value.is_integer():\n",
    "                    error_details['flawed_value'] = float(error_details['flawed_value'])\n",
    "\n",
    "                flawed_trace = generate_flawed_trace(func, error_details)\n",
    "                \n",
    "                if flawed_trace and is_trace_valid(flawed_trace, correct_trace):\n",
    "                    # --- MODIFICATION: The call no longer needs 'func' ---\n",
    "                    artifacts = generate_training_artifacts(logical_steps, error_details, flawed_trace)\n",
    "                    if artifacts:\n",
    "                        all_generated_examples.append({\n",
    "                            \"variable\": variable_name, \"error_type\": generator_func.__name__,\n",
    "                            \"flawed_nl_solution\": artifacts[0], \"target_json\": artifacts[1],\n",
    "                            \"correct_value\": error_details['correct_value'],\n",
    "                            \"flawed_value\": error_details['flawed_value'], \"repro_seed\": repro_seed,\n",
    "                        })\n",
    "                        break\n",
    "    return all_generated_examples\n",
    "\n",
    "def save_error_artifacts(tier: str, index: int, model_name: str, valid_errors: list[dict]):\n",
    "    \"\"\"Saves all valid error artifacts to disk and returns a list of metadata records.\"\"\"\n",
    "    output_dir = GENERATED_ERRORS_DIR / tier / str(index)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    metadata_records = []\n",
    "    now_utc = datetime.datetime.now(datetime.timezone.utc)\n",
    "    for error_example in valid_errors:\n",
    "        variable, error_type = error_example['variable'], error_example['error_type']\n",
    "        filename = f\"{model_name}_{variable}_{error_type}.json\"\n",
    "        filepath = output_dir / filename\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\"flawed_nl_solution\": error_example[\"flawed_nl_solution\"], \"target_json\": error_example[\"target_json\"]}, f, indent=2)\n",
    "        record = {\n",
    "            \"index\": index, \"tier\": tier, \"model\": model_name, \"target_variable\": variable,\n",
    "            \"error_type\": error_type, \"correct_value\": normalize_value(error_example['correct_value']),\n",
    "            \"flawed_value\": normalize_value(error_example['flawed_value']), \"repro_seed\": error_example['repro_seed'],\n",
    "            \"date_utc\": now_utc.strftime('%Y-%m-%d'), \"time_utc\": now_utc.strftime('%H:%M:%S'),\n",
    "            \"filepath\": str(filepath.relative_to(PROJECT_ROOT))\n",
    "        }\n",
    "        metadata_records.append(record)\n",
    "    return metadata_records\n",
    "\n",
    "print(\"Orchestration and artifact generation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364dc64d",
   "metadata": {},
   "source": [
    "### Cell 8: Parallel worker function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6eaa0a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel worker function defined.\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def process_single_template(tier: str, index: int, model_name: str, project_root: Path, processed_dir: Path, output_dir: Path) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Worker function to process a single template. This function is designed to be\n",
    "    called in parallel by joblib. It includes comprehensive error handling.\n",
    "    \"\"\"\n",
    "    # --- START OF MODIFICATION: Add try...except block ---\n",
    "    try:\n",
    "        solve_module = load_function_module(tier, index, model_name)\n",
    "        logical_steps = load_logical_steps(tier, index, model_name)\n",
    "        \n",
    "        if not (solve_module and logical_steps):\n",
    "            return [{\"index\": index, \"tier\": tier, \"model\": model_name, \"correct_trace_generated\": False, \"error_type\": \"TemplateFilesMissing\"}]\n",
    "\n",
    "        solve_function = solve_module.solve\n",
    "        correct_trace = execution_trace(solve_function)\n",
    "\n",
    "        if not correct_trace:\n",
    "            return [{\"index\": index, \"tier\": tier, \"model\": model_name, \"correct_trace_generated\": False}]\n",
    "\n",
    "        valid_errors = generate_all_valid_errors(solve_function, logical_steps, correct_trace)\n",
    "        \n",
    "        if valid_errors:\n",
    "            records = save_error_artifacts(tier, index, model_name, valid_errors)\n",
    "            for record in records:\n",
    "                record['correct_trace_generated'] = True\n",
    "            return records\n",
    "        \n",
    "        return [{\"index\": index, \"tier\": tier, \"model\": model_name, \"correct_trace_generated\": True, \"error_type\": \"NoValidErrorsFound\"}]\n",
    "    \n",
    "    except Exception as e:\n",
    "        # If any unexpected error occurs, print a diagnostic message and return\n",
    "        # an empty list so the main process does not crash.\n",
    "        print(f\"\\n---\")\n",
    "        print(f\"WARNING: A critical error occurred while processing template (tier={tier}, index={index}, model={model_name}).\")\n",
    "        print(f\"Error Type: {type(e).__name__}\")\n",
    "        print(f\"Error Details: {e}\")\n",
    "        print(f\"This template will be skipped. The pipeline will continue.\")\n",
    "        print(f\"---\")\n",
    "        return []\n",
    "    # --- END OF MODIFICATION ---\n",
    "\n",
    "print(\"Parallel worker function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15465673",
   "metadata": {},
   "source": [
    "### Cell 9: Main Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6536bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_errors_for_all_templates_parallel():\n",
    "    \"\"\"\n",
    "    Drives the error generation pipeline in parallel using joblib.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Parallel Error Generation for All Processed Templates ---\")\n",
    "\n",
    "    # 1. Prepare the list of all tasks to be executed.\n",
    "    tasks = []\n",
    "    tier_dirs = sorted([d for d in PROCESSED_TEMPLATE_DIR.iterdir() if d.is_dir() and d.name.startswith('tier')])\n",
    "    for tier_dir in tier_dirs:\n",
    "        index_dirs = sorted([d for d in tier_dir.iterdir() if d.is_dir() and d.name.isdigit()], key=lambda p: int(p.name))\n",
    "        for index_dir in index_dirs:\n",
    "            index = int(index_dir.name)\n",
    "            for model_name in MODELS:\n",
    "                tasks.append((tier_dir.name, index, model_name, PROJECT_ROOT, PROCESSED_TEMPLATE_DIR, GENERATED_ERRORS_DIR))\n",
    "    \n",
    "    print(f\"Found {len(tasks)} total templates to process across all models.\")\n",
    "\n",
    "    # 2. Execute all tasks in parallel.\n",
    "    # n_jobs=-1 uses all available CPU cores.\n",
    "    # The 'loky' backend is more robust for complex Python objects.\n",
    "    results = Parallel(n_jobs=-1, backend=\"loky\")(\n",
    "        delayed(process_single_template)(*task_args) for task_args in tqdm(tasks, desc=\"Generating Errors\")\n",
    "    )\n",
    "\n",
    "    # 3. Flatten the list of lists into a single list of metadata records.\n",
    "    all_metadata = [record for sublist in results for record in sublist]\n",
    "\n",
    "    # 4. Save the final catalog CSV file.\n",
    "    if all_metadata:\n",
    "        catalog_df = pd.DataFrame(all_metadata)\n",
    "        cols = ['index', 'tier', 'model', 'correct_trace_generated', 'target_variable', 'error_type', 'correct_value', 'flawed_value', 'repro_seed', 'date_utc', 'time_utc', 'filepath']\n",
    "        catalog_df = catalog_df.reindex(columns=cols).sort_values(by=['tier', 'index', 'model']).reset_index(drop=True)\n",
    "        catalog_path = GENERATED_ERRORS_DIR / \"computational_error_catalog.csv\"\n",
    "        catalog_df.to_csv(catalog_path, index=False)\n",
    "        print(f\"\\nCatalog with {len(catalog_df)} records saved to: {catalog_path}\")\n",
    "    else:\n",
    "        print(\"\\nNo templates were found to process or no metadata was returned.\")\n",
    "    print(\"--- Parallel Error Generation Pipeline Complete ---\")\n",
    "\n",
    "# Note: Your old \"Cell 9: Execute the Pipeline\" is now Cell 10.\n",
    "# It simply calls this new function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98bb2f0",
   "metadata": {},
   "source": [
    "### Cell 10: Execute the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0724fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Parallel Error Generation for All Processed Templates ---\n",
      "Found 5832 total templates to process across all models.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3713b3d25f674db3851a7efceadfd139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Errors:   0%|          | 0/5832 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "WARNING: A critical error occurred while processing template (tier=tier3, index=400, model=openai_gpt-4.1).\n",
      "Error Type: AttributeError\n",
      "Error Details: 'str' object has no attribute 'denominator'\n",
      "This template will be skipped. The pipeline will continue.\n",
      "---\n",
      "\n",
      "Catalog with 16506 records saved to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/computational-errors-generated/computational_error_catalog.csv\n",
      "--- Parallel Error Generation Pipeline Complete ---\n"
     ]
    }
   ],
   "source": [
    "generate_errors_for_all_templates_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87632169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Error Type Counts ---\n",
      "error_type\n",
      "generate_digit_transposition_error             6632\n",
      "generate_off_by_n_error                        4972\n",
      "generate_off_by_factor_of_10_error             1781\n",
      "generate_stem_off_by_n_error                   1105\n",
      "TemplateFilesMissing                           1037\n",
      "NoValidErrorsFound                              358\n",
      "generate_multiplication_by_reciprocal_error     333\n",
      "generate_decimal_shift_error                    195\n",
      "generate_float_off_by_n_error                    70\n",
      "generate_off_by_one_in_fraction_part_error       11\n",
      "generate_reciprocal_error                         8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "catalog_df = pd.read_csv(GENERATED_ERRORS_DIR / \"computational_error_catalog.csv\")\n",
    "error_type_counts = catalog_df['error_type'].value_counts()\n",
    "print(\"\\n--- Error Type Counts ---\")\n",
    "print(error_type_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
