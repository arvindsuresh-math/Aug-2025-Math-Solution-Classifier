{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151049e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/manually_generated_errors_final.csv\n",
      "computational: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/computational-errors-generated/computational_error_catalog.csv\n",
      "conceptual_ali: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_ali.csv\n",
      "conceptual_arvind: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_arvind.csv\n",
      "conceptual_mauro: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_mauro.csv\n",
      "conceptual_ling: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_ling.csv\n",
      "conceptual_yewei: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_yewei.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Set, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- Path and Directory Definitions ---\n",
    "\n",
    "def find_project_root(marker: str = \".git\") -> Path:\n",
    "    \"\"\"Traverse upwards to find the project root, marked by the git repository.\"\"\"\n",
    "    current_path = Path.cwd().resolve()\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / marker).exists():\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    raise FileNotFoundError(f\"Could not find project root. Marker '{marker}' not found.\")\n",
    "\n",
    "VALIDATORS = [\"ali\", \"arvind\", \"mauro\", \"ling\", \"yewei\"]\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "CONCEPTUAL_ERRORS_DIR = DATA_DIR / 'conceptual-errors-accepted'\n",
    "COMPUTATIONAL_ERRORS_DIR = DATA_DIR / 'computational-errors-generated'\n",
    "CONCEPTUAL_CATALOG_DIR = DATA_DIR / 'conceptual-error-candidates'\n",
    "\n",
    "# load all catalog filepaths into a dict\n",
    "CATALOG_FILEPATH_DICT = {\n",
    "    \"manual\": DATA_DIR / 'manually_generated_errors_final.csv',\n",
    "    \"computational\": COMPUTATIONAL_ERRORS_DIR / 'computational_error_catalog.csv'\n",
    "}\n",
    "for name in VALIDATORS:\n",
    "    CATALOG_FILEPATH_DICT[f\"conceptual_{name}\"] = CONCEPTUAL_CATALOG_DIR / f'validation_catalog_{name}.csv'\n",
    "\n",
    "# Display the filepaths\n",
    "for name, path in CATALOG_FILEPATH_DICT.items():\n",
    "    print(f\"{name}: {path}\")\n",
    "\n",
    "# make dictionary with all catalogs\n",
    "CATALOG_DICT = {key: pd.read_csv(path) for key, path in CATALOG_FILEPATH_DICT.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a0c34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual: 1963 rows\n",
      "columns: ['answer', 'erroneous_line_number', 'error_type', 'explanation', 'filepath', 'index', 'question', 'wrong_answer']\n",
      "computational: 22623 rows\n",
      "columns: ['index', 'tier', 'model', 'erroneous_line_number', 'explanation', 'wrong_answer', 'correct_trace_generated', 'target_variable', 'error_type', 'correct_value', 'flawed_value', 'repro_seed', 'date_utc', 'time_utc', 'filepath']\n",
      "conceptual_ali: 398 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n",
      "conceptual_arvind: 394 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n",
      "conceptual_mauro: 381 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n",
      "conceptual_ling: 388 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n",
      "conceptual_yewei: 381 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n"
     ]
    }
   ],
   "source": [
    "for key, df in CATALOG_DICT.items():\n",
    "    print(f\"{key}: {len(df)} rows\")\n",
    "    print(\"columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bdb057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSM8K_TRAIN = load_dataset(\"gsm8k\", \"main\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebb8c55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper functions loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# --- Tier Definition Functions (copied from arvind-july-25.ipynb) ---\n",
    "\n",
    "def has_computational_division(solution_text: str):\n",
    "    \"\"\"Checks if a solution text contains a division operation.\"\"\"\n",
    "    pattern = re.compile(r'/\\s*\\d')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def has_float(solution_text: str):\n",
    "    \"\"\"Checks if a solution text contains a float value.\"\"\"\n",
    "    pattern = re.compile(r'(?<!\\d)\\.\\d+|\\d+\\.\\d+')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def is_symbolic(solution_text: str):\n",
    "    \"\"\"Checks if a solution text uses symbolic algebra (e.g., 'Let x...').\"\"\"\n",
    "    pattern = re.compile(r'^Let [a-zA-Z] ', re.MULTILINE)\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def mutually_disjoint_tiers(dataset):\n",
    "    \"\"\"\n",
    "    Categorizes all problems in the dataset into mutually disjoint tiers\n",
    "    based on the mathematical operations present in their solution text.\n",
    "    \"\"\"\n",
    "    tiers = {}\n",
    "    symbolic_set = {idx for idx, sample in enumerate(dataset) if is_symbolic(sample.get(\"answer\", \"\"))}\n",
    "    non_symbolic_indices = [idx for idx in range(len(dataset)) if idx not in symbolic_set]\n",
    "    \n",
    "    tiers[\"tier1\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier2\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier3\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier4\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier5\"] = sorted(list(symbolic_set))\n",
    "    return tiers\n",
    "\n",
    "def sanitize_commas(text: str) -> str:\n",
    "    \"\"\"Removes comma separators from numbers to prevent model artifacts.\"\"\"\n",
    "    return re.sub(r'(\\d),(\\d)', r'\\1\\2', text)\n",
    "\n",
    "def sanitize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Replaces a comprehensive set of problematic Unicode characters with their\n",
    "    ASCII equivalents to prevent model generation and string parsing errors.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "        \n",
    "    replacements = {\n",
    "        \"\\u2212\": \"-\",  # Minus Sign\n",
    "        \"\\u00d7\": \"*\",  # Multiplication Sign\n",
    "        \"\\u00f7\": \"/\",  # Division Sign\n",
    "        \"\\u22c5\": \"*\",  # Dot Operator\n",
    "        \"\\u201c\": '\"',  # Left Double Quotation Mark\n",
    "        \"\\u201d\": '\"',  # Right Double Quotation Mark\n",
    "        \"\\u2018\": \"'\",  # Left Single Quotation Mark\n",
    "        \"\\u2019\": \"'\",  # Right Single Quotation Mark\n",
    "        \"\\u2014\": \"-\",  # Em Dash\n",
    "        \"\\u2013\": \"-\",  # En Dash\n",
    "        \"\\u2026\": \"...\",# Horizontal Ellipsis\n",
    "        \"\\u00a0\": \" \",  # No-Break Space\n",
    "    }\n",
    "    for uni, ascii_char in replacements.items():\n",
    "        text = text.replace(uni, ascii_char)\n",
    "    return text\n",
    "\n",
    "def clean_and_split_solution(raw_text: str) -> Tuple[str, str | None]:\n",
    "    \"\"\"\n",
    "    Takes a raw solution text, sanitizes it, and separates the reasoning\n",
    "    lines from the final answer line. Returns a tuple containing \n",
    "    (cleaned_reasoning_text, final_answer_string).\n",
    "    \"\"\"\n",
    "    if not isinstance(raw_text, str):\n",
    "        return \"\", None\n",
    "        \n",
    "    sanitized_text = sanitize_text(raw_text)\n",
    "    text_no_annotations = re.sub(r'<<.*?>>', '', sanitized_text)\n",
    "    text_no_commas = sanitize_commas(text_no_annotations)\n",
    "    \n",
    "    lines = text_no_commas.split('\\n')\n",
    "    final_answer = None\n",
    "    \n",
    "    if lines and re.match(r'^\\s*####\\s*.*$', lines[-1]):\n",
    "        final_answer_line = lines.pop().strip()\n",
    "        match = re.search(r'####\\s*(.*)', final_answer_line)\n",
    "        if match:\n",
    "            final_answer = match.group(1).strip()\n",
    "\n",
    "    cleaned_lines = [line.strip() for line in lines if line.strip()]\n",
    "    reasoning_text = '\\n'.join(cleaned_lines)\n",
    "    \n",
    "    return reasoning_text, final_answer\n",
    "\n",
    "print(\"✓ Helper functions loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e803b036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier distribution in GSM8K:\n",
      "  tier1: 2767 problems\n",
      "  tier2: 837 problems\n",
      "  tier3: 3113 problems\n",
      "  tier4: 544 problems\n",
      "  tier5: 212 problems\n"
     ]
    }
   ],
   "source": [
    "# --- Create Tier Mappings ---\n",
    "\n",
    "def add_tier_column(df, tier_lists):\n",
    "    \"\"\"\n",
    "    Adds a 'tier' column to the dataframe based on the TIER_LISTS dictionary.\n",
    "    Maps each GSM8K index to its corresponding tier.\n",
    "    \"\"\"\n",
    "    index_to_tier = {}\n",
    "    for tier_name, indices in tier_lists.items():\n",
    "        for idx in indices:\n",
    "            index_to_tier[idx] = tier_name\n",
    "    \n",
    "    df['tier'] = df['index'].map(index_to_tier)\n",
    "    \n",
    "    missing_tiers = df['tier'].isna().sum()\n",
    "    if missing_tiers > 0:\n",
    "        print(f\"Warning: {missing_tiers} indices could not be mapped to tiers\")\n",
    "        df['tier'] = df['tier'].fillna('unknown')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate tier mappings for the entire GSM8K dataset\n",
    "TIER_LISTS = mutually_disjoint_tiers(GSM8K_TRAIN)\n",
    "print(\"Tier distribution in GSM8K:\")\n",
    "for tier, indices in TIER_LISTS.items():\n",
    "    print(f\"  {tier}: {len(indices)} problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b122d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Solution analysis functions loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# --- Solution Analysis Functions ---\n",
    "\n",
    "def validate_line_number(erroneous_line_number: str, gsm8k_answer: str) -> bool:\n",
    "    \"\"\"\n",
    "    Validates that the erroneous_line_number exists in the parsed GSM8K solution.\n",
    "    Returns True if the line number is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reasoning, final_answer = clean_and_split_solution(gsm8k_answer)\n",
    "        lines = [line for line in reasoning.split('\\n') if line.strip()]\n",
    "        \n",
    "        if erroneous_line_number == \"FA\":\n",
    "            return final_answer is not None\n",
    "        elif erroneous_line_number.startswith(\"L\"):\n",
    "            line_num = int(erroneous_line_number[1:])\n",
    "            return 1 <= line_num <= len(lines)\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def calculate_solution_metrics(gsm8k_answer: str) -> Tuple[int, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Calculates solution metrics including total line count and creates a mapping\n",
    "    of line numbers to content. Returns (solution_length, line_mapping).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reasoning, final_answer = clean_and_split_solution(gsm8k_answer)\n",
    "        lines = [line for line in reasoning.split('\\n') if line.strip()]\n",
    "        \n",
    "        solution_length = len(lines)\n",
    "        if final_answer is not None:\n",
    "            solution_length += 1  # Include FA in count\n",
    "            \n",
    "        line_mapping = {f\"L{i+1}\": line for i, line in enumerate(lines)}\n",
    "        if final_answer is not None:\n",
    "            line_mapping[\"FA\"] = final_answer\n",
    "            \n",
    "        return solution_length, line_mapping\n",
    "    except:\n",
    "        return 0, {}\n",
    "\n",
    "def calculate_relative_line_position(erroneous_line_number: str, gsm8k_answer: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the relative position of the erroneous line within the solution.\n",
    "    Returns a value between 0 and 1, where 0 is the first line and 1 is the last line.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reasoning, final_answer = clean_and_split_solution(gsm8k_answer)\n",
    "        lines = [line for line in reasoning.split('\\n') if line.strip()]\n",
    "        total_lines = len(lines)\n",
    "        \n",
    "        if final_answer is not None:\n",
    "            total_lines += 1\n",
    "            \n",
    "        if erroneous_line_number == \"FA\":\n",
    "            return 1.0\n",
    "        elif erroneous_line_number.startswith(\"L\"):\n",
    "            line_num = int(erroneous_line_number[1:])\n",
    "            return line_num / total_lines\n",
    "        else:\n",
    "            return 0.5  # Default fallback\n",
    "    except:\n",
    "        return 0.5\n",
    "\n",
    "print(\"✓ Solution analysis functions loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3d04ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Process Manual Catalog ---\n",
    "\n",
    "def process_manual_catalog(catalog_dict, gsm8k_train, tier_lists) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Processes the manual catalog to extract standardized error data.\n",
    "    Returns (clean_rows_df, problematic_rows_df).\n",
    "    \"\"\"\n",
    "    print(\"=== Processing Manual Catalog ===\")\n",
    "    \n",
    "    df = catalog_dict['manual'].copy()\n",
    "    print(f\"Initial rows: {len(df)}\")\n",
    "    \n",
    "    clean_rows = []\n",
    "    problematic_rows = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing manual catalog\"):\n",
    "        try:\n",
    "            problem_index = int(row['index'])\n",
    "            \n",
    "            # Check if erroneous_line_number is missing\n",
    "            if pd.isna(row['erroneous_line_number']):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': 'Missing erroneous_line_number',\n",
    "                    'source_catalog': 'manual'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Get GSM8K data\n",
    "            if problem_index >= len(gsm8k_train):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': f'Index {problem_index} out of range',\n",
    "                    'source_catalog': 'manual'\n",
    "                })\n",
    "                continue\n",
    "                \n",
    "            gsm8k_problem = gsm8k_train[problem_index]\n",
    "            \n",
    "            # Validate line number\n",
    "            if not validate_line_number(row['erroneous_line_number'], gsm8k_problem['answer']):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': f'Invalid line number: {row[\"erroneous_line_number\"]}',\n",
    "                    'source_catalog': 'manual'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Calculate metrics\n",
    "            solution_length, _ = calculate_solution_metrics(gsm8k_problem['answer'])\n",
    "            relative_position = calculate_relative_line_position(row['erroneous_line_number'], gsm8k_problem['answer'])\n",
    "            \n",
    "            # Create standardized row\n",
    "            clean_row = {\n",
    "                'index': problem_index,\n",
    "                'tier': None,  # Will be added later\n",
    "                'question': gsm8k_problem['question'],\n",
    "                'correct_answer': gsm8k_problem['answer'],\n",
    "                'wrong_answer': row['wrong_answer'],\n",
    "                'error_type': row['error_type'] + '_error',\n",
    "                'erroneous_line_number': row['erroneous_line_number'],\n",
    "                'explanation': row['explanation'],\n",
    "                'error_subtype': 'NA',\n",
    "                'source': 'manual',\n",
    "                'solution_length': solution_length,\n",
    "                'relative_line_position': relative_position\n",
    "            }\n",
    "            \n",
    "            clean_rows.append(clean_row)\n",
    "            \n",
    "        except Exception as e:\n",
    "            problematic_rows.append({\n",
    "                **row.to_dict(),\n",
    "                'error_reason': f'Processing error: {str(e)}',\n",
    "                'source_catalog': 'manual'\n",
    "            })\n",
    "    \n",
    "    clean_df = pd.DataFrame(clean_rows)\n",
    "    problematic_df = pd.DataFrame(problematic_rows)\n",
    "    \n",
    "    # Add tier information\n",
    "    if not clean_df.empty:\n",
    "        clean_df = add_tier_column(clean_df, tier_lists)\n",
    "        # Keep all tiers for manual catalog (including tier5)\n",
    "    \n",
    "    print(f\"Clean rows: {len(clean_df)}\")\n",
    "    print(f\"Problematic rows: {len(problematic_df)}\")\n",
    "    \n",
    "    return clean_df, problematic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a2c09fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Manual Catalog ===\n",
      "Initial rows: 1963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02da26d58d3e4a93a575847c12e823d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing manual catalog:   0%|          | 0/1963 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean rows: 1740\n",
      "Problematic rows: 223\n"
     ]
    }
   ],
   "source": [
    "manual_clean, manual_problematic = process_manual_catalog(CATALOG_DICT, GSM8K_TRAIN, TIER_LISTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d33aa5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Process Computational Catalog ---\n",
    "\n",
    "def process_computational_catalog(catalog_dict, gsm8k_train, tier_lists) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Processes the computational catalog to extract standardized error data.\n",
    "    Excludes tier5 problems. Returns (clean_rows_df, problematic_rows_df).\n",
    "    \"\"\"\n",
    "    print(\"=== Processing Computational Catalog ===\")\n",
    "    \n",
    "    df = catalog_dict['computational'].copy()\n",
    "    print(f\"Initial rows: {len(df)}\")\n",
    "    \n",
    "    clean_rows = []\n",
    "    problematic_rows = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing computational catalog\"):\n",
    "        try:\n",
    "            problem_index = int(row['index'])\n",
    "            \n",
    "            # Check if erroneous_line_number is missing\n",
    "            if pd.isna(row['erroneous_line_number']):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': 'Missing erroneous_line_number',\n",
    "                    'source_catalog': 'computational'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Get GSM8K data\n",
    "            if problem_index >= len(gsm8k_train):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': f'Index {problem_index} out of range',\n",
    "                    'source_catalog': 'computational'\n",
    "                })\n",
    "                continue\n",
    "                \n",
    "            gsm8k_problem = gsm8k_train[problem_index]\n",
    "            \n",
    "            # Check if this is tier5 and exclude it\n",
    "            problem_tier = None\n",
    "            for tier_name, indices in tier_lists.items():\n",
    "                if problem_index in indices:\n",
    "                    problem_tier = tier_name\n",
    "                    break\n",
    "            \n",
    "            if problem_tier == 'tier5':\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': 'Excluded tier5 problem',\n",
    "                    'source_catalog': 'computational'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Validate line number\n",
    "            if not validate_line_number(row['erroneous_line_number'], gsm8k_problem['answer']):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': f'Invalid line number: {row[\"erroneous_line_number\"]}',\n",
    "                    'source_catalog': 'computational'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Calculate metrics\n",
    "            solution_length, _ = calculate_solution_metrics(gsm8k_problem['answer'])\n",
    "            relative_position = calculate_relative_line_position(row['erroneous_line_number'], gsm8k_problem['answer'])\n",
    "            \n",
    "            # Create standardized row\n",
    "            clean_row = {\n",
    "                'index': problem_index,\n",
    "                'tier': problem_tier,\n",
    "                'question': gsm8k_problem['question'],\n",
    "                'correct_answer': gsm8k_problem['answer'],\n",
    "                'wrong_answer': row['wrong_answer'],\n",
    "                'error_type': 'computational_error',\n",
    "                'erroneous_line_number': row['erroneous_line_number'],\n",
    "                'explanation': row['explanation'],\n",
    "                'error_subtype': row['error_type'],  # Use original error_type as subtype\n",
    "                'source': 'programmatic',\n",
    "                'solution_length': solution_length,\n",
    "                'relative_line_position': relative_position\n",
    "            }\n",
    "            \n",
    "            clean_rows.append(clean_row)\n",
    "            \n",
    "        except Exception as e:\n",
    "            problematic_rows.append({\n",
    "                **row.to_dict(),\n",
    "                'error_reason': f'Processing error: {str(e)}',\n",
    "                'source_catalog': 'computational'\n",
    "            })\n",
    "    \n",
    "    clean_df = pd.DataFrame(clean_rows)\n",
    "    problematic_df = pd.DataFrame(problematic_rows)\n",
    "    \n",
    "    print(f\"Clean rows: {len(clean_df)}\")\n",
    "    print(f\"Problematic rows: {len(problematic_df)}\")\n",
    "    \n",
    "    return clean_df, problematic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d51729de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Computational Catalog ===\n",
      "Initial rows: 22623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f32bf0b36094ec28dc0e46ba25210b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing computational catalog:   0%|          | 0/22623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean rows: 21768\n",
      "Problematic rows: 855\n"
     ]
    }
   ],
   "source": [
    "computational_clean, computational_problematic = process_computational_catalog(CATALOG_DICT, GSM8K_TRAIN, TIER_LISTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68722700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Process Validator Catalogs (Updated with Fixed Path Handling and Answer Formatting) ---\n",
    "\n",
    "def process_validator_catalogs(catalog_dict, gsm8k_train, tier_lists, validators, project_root) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Processes all validator catalogs to extract standardized error data from JSON files.\n",
    "    Only includes accepted samples and excludes tier5 problems.\n",
    "    Uses proper cross-platform path handling and fixes answer formatting.\n",
    "    Returns (clean_rows_df, problematic_rows_df).\n",
    "    \"\"\"\n",
    "    print(\"=== Processing Validator Catalogs ===\")\n",
    "    \n",
    "    all_clean_rows = []\n",
    "    all_problematic_rows = []\n",
    "    \n",
    "    def check_file_exists_and_get_path(filepath, base_dir=None):\n",
    "        \"\"\"\n",
    "        Check if a file exists and return the correct path, handling cross-platform path issues.\n",
    "        Based on logic from july-26-merging-repairing-accepted.ipynb\n",
    "        \"\"\"\n",
    "        if pd.isna(filepath) or filepath == \"\":\n",
    "            return None, False\n",
    "        \n",
    "        # Convert to Path object and normalize path separators\n",
    "        # Replace Windows backslashes with forward slashes for cross-platform compatibility\n",
    "        normalized_filepath = str(filepath).replace('\\\\', '/')\n",
    "        file_path = Path(normalized_filepath)\n",
    "        \n",
    "        # If it's a relative path, make it relative to the project root\n",
    "        if not file_path.is_absolute():\n",
    "            full_path = project_root / file_path\n",
    "        else:\n",
    "            full_path = file_path\n",
    "        \n",
    "        return full_path, full_path.exists()\n",
    "    \n",
    "    def fix_answer_formatting(wrong_answer: str) -> str:\n",
    "        \"\"\"\n",
    "        Fixes the formatting of wrong answers by moving the final answer line\n",
    "        from the beginning to the end if it's misplaced.\n",
    "        \"\"\"\n",
    "        if not isinstance(wrong_answer, str):\n",
    "            return wrong_answer\n",
    "        \n",
    "        lines = wrong_answer.strip().split('\\n')\n",
    "        final_answer_line = None\n",
    "        other_lines = []\n",
    "        \n",
    "        # Find and extract the final answer line\n",
    "        for line in lines:\n",
    "            if re.match(r'^\\s*####\\s*.*$', line.strip()):\n",
    "                final_answer_line = line.strip()\n",
    "            elif line.strip():  # Skip empty lines\n",
    "                other_lines.append(line)\n",
    "        \n",
    "        # Reconstruct with final answer at the end\n",
    "        if final_answer_line and other_lines:\n",
    "            return '\\n'.join(other_lines) + '\\n' + final_answer_line\n",
    "        elif final_answer_line:\n",
    "            return final_answer_line\n",
    "        else:\n",
    "            return wrong_answer\n",
    "    \n",
    "    for validator in validators:\n",
    "        print(f\"\\nProcessing validator: {validator}\")\n",
    "        df = catalog_dict[f'conceptual_{validator}'].copy()\n",
    "        \n",
    "        # Filter to only accepted samples\n",
    "        df = df[df['status'] == 'accepted']\n",
    "        print(f\"Accepted rows for {validator}: {len(df)}\")\n",
    "        \n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Processing {validator}\"):\n",
    "            try:\n",
    "                problem_index = int(row['index'])\n",
    "                \n",
    "                # Get GSM8K data\n",
    "                if problem_index >= len(gsm8k_train):\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'Index {problem_index} out of range',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                    \n",
    "                gsm8k_problem = gsm8k_train[problem_index]\n",
    "                \n",
    "                # Check if this is tier5 and exclude it\n",
    "                problem_tier = None\n",
    "                for tier_name, indices in tier_lists.items():\n",
    "                    if problem_index in indices:\n",
    "                        problem_tier = tier_name\n",
    "                        break\n",
    "                \n",
    "                if problem_tier == 'tier5':\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': 'Excluded tier5 problem',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Load JSON file with proper path handling\n",
    "                try:\n",
    "                    filepath, file_exists = check_file_exists_and_get_path(row['filepath'])\n",
    "                    \n",
    "                    if not file_exists or filepath is None:\n",
    "                        all_problematic_rows.append({\n",
    "                            **row.to_dict(),\n",
    "                            'error_reason': f'JSON file not found: {row[\"filepath\"]}',\n",
    "                            'source_catalog': f'conceptual_{validator}'\n",
    "                        })\n",
    "                        continue\n",
    "                    \n",
    "                    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                        json_data = json.load(f)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'JSON loading error: {str(e)}',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Extract data from JSON\n",
    "                try:\n",
    "                    raw_wrong_answer = json_data['context']['flawed_solution']\n",
    "                    explanation = json_data['error_details']['explanation']\n",
    "                    erroneous_line_number = json_data['error_details']['erroneous_line_number']\n",
    "                    error_subtype = json_data['error_details']['error_type']\n",
    "                except KeyError as e:\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'Missing JSON field: {str(e)}',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Fix the answer formatting\n",
    "                wrong_answer = fix_answer_formatting(raw_wrong_answer)\n",
    "                \n",
    "                # Check for null erroneous_line_number (from the repair logic in the notebook)\n",
    "                if erroneous_line_number is None or erroneous_line_number == \"null\":\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'Null erroneous_line_number in JSON',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Validate line number\n",
    "                if not validate_line_number(erroneous_line_number, gsm8k_problem['answer']):\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'Invalid line number: {erroneous_line_number}',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Calculate metrics\n",
    "                solution_length, _ = calculate_solution_metrics(gsm8k_problem['answer'])\n",
    "                relative_position = calculate_relative_line_position(erroneous_line_number, gsm8k_problem['answer'])\n",
    "                \n",
    "                # Create standardized row\n",
    "                clean_row = {\n",
    "                    'index': problem_index,\n",
    "                    'tier': problem_tier,\n",
    "                    'question': gsm8k_problem['question'],\n",
    "                    'correct_answer': gsm8k_problem['answer'],\n",
    "                    'wrong_answer': wrong_answer,  # Now properly formatted\n",
    "                    'error_type': 'conceptual_error',\n",
    "                    'erroneous_line_number': erroneous_line_number,\n",
    "                    'explanation': explanation,\n",
    "                    'error_subtype': error_subtype,\n",
    "                    'source': 'programmatic',\n",
    "                    'solution_length': solution_length,\n",
    "                    'relative_line_position': relative_position\n",
    "                }\n",
    "                \n",
    "                all_clean_rows.append(clean_row)\n",
    "                \n",
    "            except Exception as e:\n",
    "                all_problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': f'Processing error: {str(e)}',\n",
    "                    'source_catalog': f'conceptual_{validator}'\n",
    "                })\n",
    "    \n",
    "    clean_df = pd.DataFrame(all_clean_rows)\n",
    "    problematic_df = pd.DataFrame(all_problematic_rows)\n",
    "    \n",
    "    print(f\"\\nTotal clean rows: {len(clean_df)}\")\n",
    "    print(f\"Total problematic rows: {len(problematic_df)}\")\n",
    "    \n",
    "    return clean_df, problematic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95c39568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Validator Catalogs ===\n",
      "\n",
      "Processing validator: ali\n",
      "Accepted rows for ali: 341\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d797d0e801d43d2a6284d578ec8a77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ali:   0%|          | 0/341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validator: arvind\n",
      "Accepted rows for arvind: 91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c6b767417a48b28eceba6664563631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing arvind:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validator: mauro\n",
      "Accepted rows for mauro: 312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed095befe5e4f5c92b009113a4ba6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing mauro:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validator: ling\n",
      "Accepted rows for ling: 110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f86f778b844170a900a4434dd6654a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ling:   0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validator: yewei\n",
      "Accepted rows for yewei: 290\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfcecb0f6a3a457fa55bed9f3ffe4eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing yewei:   0%|          | 0/290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total clean rows: 1144\n",
      "Total problematic rows: 0\n"
     ]
    }
   ],
   "source": [
    "validator_clean, validator_problematic = process_validator_catalogs(\n",
    "    CATALOG_DICT, GSM8K_TRAIN, TIER_LISTS, VALIDATORS, PROJECT_ROOT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72d5d7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Creating Master Catalogs ===\n",
      "Master catalog rows: 24652\n",
      "Problematic rows: 1078\n",
      "✓ Master catalogs created successfully\n"
     ]
    }
   ],
   "source": [
    "# --- Combine All Catalogs ---\n",
    "\n",
    "def create_master_catalogs(manual_clean, computational_clean, validator_clean, \n",
    "                          manual_problematic, computational_problematic, validator_problematic):\n",
    "    \"\"\"\n",
    "    Combines all clean and problematic dataframes into final master catalogs.\n",
    "    Returns (master_catalog, catalog_problematic).\n",
    "    \"\"\"\n",
    "    print(\"=== Creating Master Catalogs ===\")\n",
    "    \n",
    "    # Combine all clean dataframes\n",
    "    all_clean_dfs = []\n",
    "    if not manual_clean.empty:\n",
    "        all_clean_dfs.append(manual_clean)\n",
    "    if not computational_clean.empty:\n",
    "        all_clean_dfs.append(computational_clean)\n",
    "    if not validator_clean.empty:\n",
    "        all_clean_dfs.append(validator_clean)\n",
    "    \n",
    "    master_catalog = pd.concat(all_clean_dfs, ignore_index=True) if all_clean_dfs else pd.DataFrame()\n",
    "    \n",
    "    # Combine all problematic dataframes\n",
    "    all_problematic_dfs = []\n",
    "    if not manual_problematic.empty:\n",
    "        all_problematic_dfs.append(manual_problematic)\n",
    "    if not computational_problematic.empty:\n",
    "        all_problematic_dfs.append(computational_problematic)\n",
    "    if not validator_problematic.empty:\n",
    "        all_problematic_dfs.append(validator_problematic)\n",
    "    \n",
    "    catalog_problematic = pd.concat(all_problematic_dfs, ignore_index=True) if all_problematic_dfs else pd.DataFrame()\n",
    "    \n",
    "    # Ensure consistent column order for master catalog\n",
    "    if not master_catalog.empty:\n",
    "        column_order = [\n",
    "            'index', 'tier', 'question', 'correct_answer', 'wrong_answer', \n",
    "            'error_type', 'erroneous_line_number', 'explanation', 'error_subtype',\n",
    "            'source', 'solution_length', 'relative_line_position'\n",
    "        ]\n",
    "        master_catalog = master_catalog[column_order]\n",
    "    \n",
    "    print(f\"Master catalog rows: {len(master_catalog)}\")\n",
    "    print(f\"Problematic rows: {len(catalog_problematic)}\")\n",
    "    \n",
    "    return master_catalog, catalog_problematic\n",
    "\n",
    "master_catalog, catalog_problematic = create_master_catalogs(\n",
    "    manual_clean, \n",
    "    computational_clean, \n",
    "    validator_clean,\n",
    "    manual_problematic, \n",
    "    computational_problematic, \n",
    "    validator_problematic\n",
    ")\n",
    "\n",
    "print(\"✓ Master catalogs created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e97872cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MASTER CATALOG SUMMARY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "📊 BASIC STATISTICS\n",
      "Total rows: 24,652\n",
      "Unique GSM8K indices: 6,777\n",
      "Average entries per index: 3.64\n",
      "\n",
      "🔧 SOURCE DISTRIBUTION\n",
      "  programmatic: 22,912 (92.9%)\n",
      "  manual: 1,740 (7.1%)\n",
      "\n",
      "🐛 ERROR TYPE DISTRIBUTION\n",
      "  computational_error: 22,542 (91.4%)\n",
      "  conceptual_error: 2,110 (8.6%)\n",
      "\n",
      "🎯 TIER DISTRIBUTION\n",
      "  tier1: 11,188 (45.4%)\n",
      "  tier2: 3,458 (14.0%)\n",
      "  tier3: 8,288 (33.6%)\n",
      "  tier4: 1,662 (6.7%)\n",
      "  tier5: 56 (0.2%)\n",
      "\n",
      "🔍 ERROR SUBTYPE DISTRIBUTION\n",
      "Total unique subtypes: 15\n",
      "  generate_digit_transposition_error: 9,505 (38.6%)\n",
      "  generate_off_by_n_error: 7,083 (28.7%)\n",
      "  generate_off_by_factor_of_10_error: 2,561 (10.4%)\n",
      "  NA: 1,740 (7.1%)\n",
      "  generate_stem_off_by_n_error: 1,512 (6.1%)\n",
      "  generate_multiplication_by_reciprocal_error: 696 (2.8%)\n",
      "  incorrect_final_answer_selection: 340 (1.4%)\n",
      "  generate_decimal_shift_error: 284 (1.2%)\n",
      "  operator_swap: 222 (0.9%)\n",
      "  incomplete_calculation: 222 (0.9%)\n",
      "  ... and 5 more\n",
      "\n",
      "📏 SOLUTION LENGTH STATISTICS\n",
      "  Mean: 4.9 lines\n",
      "  Median: 5.0 lines\n",
      "  Min: 3 lines\n",
      "  Max: 10 lines\n",
      "  Std: 1.5 lines\n",
      "\n",
      "📍 RELATIVE LINE POSITION STATISTICS\n",
      "  Mean: 0.545\n",
      "  Median: 0.600\n",
      "  Min: 0.100\n",
      "  Max: 1.000\n",
      "  Std: 0.222\n",
      "\n",
      "📊 CROSS-TABULATION: ERROR TYPE vs TIER\n",
      "error_type  computational_error  conceptual_error    All\n",
      "tier                                                    \n",
      "tier1                     10481               707  11188\n",
      "tier2                      3132               326   3458\n",
      "tier3                      7475               813   8288\n",
      "tier4                      1427               235   1662\n",
      "tier5                        27                29     56\n",
      "All                       22542              2110  24652\n",
      "\n",
      "📊 CROSS-TABULATION: SOURCE vs ERROR TYPE\n",
      "error_type    computational_error  conceptual_error    All\n",
      "source                                                    \n",
      "manual                        774               966   1740\n",
      "programmatic                21768              1144  22912\n",
      "All                         22542              2110  24652\n",
      "\n",
      "================================================================================\n",
      "PROBLEMATIC ENTRIES SUMMARY\n",
      "================================================================================\n",
      "Total problematic rows: 1,078\n",
      "\n",
      "❌ ERROR REASONS\n",
      "  Missing erroneous_line_number: 894 (82.9%)\n",
      "  Excluded tier5 problem: 184 (17.1%)\n",
      "\n",
      "📁 PROBLEMATIC BY SOURCE CATALOG\n",
      "  computational: 855 (79.3%)\n",
      "  manual: 223 (20.7%)\n"
     ]
    }
   ],
   "source": [
    "# --- Generate Summary Statistics ---\n",
    "\n",
    "def print_catalog_summary(master_catalog, catalog_problematic):\n",
    "    \"\"\"\n",
    "    Prints comprehensive summary statistics for the master catalog and problematic entries.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"MASTER CATALOG SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if master_catalog.empty:\n",
    "        print(\"❌ Master catalog is empty!\")\n",
    "        return\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"\\n📊 BASIC STATISTICS\")\n",
    "    print(f\"Total rows: {len(master_catalog):,}\")\n",
    "    print(f\"Unique GSM8K indices: {master_catalog['index'].nunique():,}\")\n",
    "    print(f\"Average entries per index: {len(master_catalog) / master_catalog['index'].nunique():.2f}\")\n",
    "    \n",
    "    # Source distribution\n",
    "    print(f\"\\n🔧 SOURCE DISTRIBUTION\")\n",
    "    source_counts = master_catalog['source'].value_counts()\n",
    "    for source, count in source_counts.items():\n",
    "        pct = (count / len(master_catalog)) * 100\n",
    "        print(f\"  {source}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Error type distribution\n",
    "    print(f\"\\n🐛 ERROR TYPE DISTRIBUTION\")\n",
    "    error_type_counts = master_catalog['error_type'].value_counts()\n",
    "    for error_type, count in error_type_counts.items():\n",
    "        pct = (count / len(master_catalog)) * 100\n",
    "        print(f\"  {error_type}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Tier distribution\n",
    "    print(f\"\\n🎯 TIER DISTRIBUTION\")\n",
    "    tier_counts = master_catalog['tier'].value_counts().sort_index()\n",
    "    for tier, count in tier_counts.items():\n",
    "        pct = (count / len(master_catalog)) * 100\n",
    "        print(f\"  {tier}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Error subtype distribution\n",
    "    print(f\"\\n🔍 ERROR SUBTYPE DISTRIBUTION\")\n",
    "    subtype_counts = master_catalog['error_subtype'].value_counts()\n",
    "    print(f\"Total unique subtypes: {len(subtype_counts)}\")\n",
    "    for subtype, count in subtype_counts.head(10).items():\n",
    "        pct = (count / len(master_catalog)) * 100\n",
    "        print(f\"  {subtype}: {count:,} ({pct:.1f}%)\")\n",
    "    if len(subtype_counts) > 10:\n",
    "        print(f\"  ... and {len(subtype_counts) - 10} more\")\n",
    "    \n",
    "    # Solution length statistics\n",
    "    print(f\"\\n📏 SOLUTION LENGTH STATISTICS\")\n",
    "    print(f\"  Mean: {master_catalog['solution_length'].mean():.1f} lines\")\n",
    "    print(f\"  Median: {master_catalog['solution_length'].median():.1f} lines\")\n",
    "    print(f\"  Min: {master_catalog['solution_length'].min()} lines\")\n",
    "    print(f\"  Max: {master_catalog['solution_length'].max()} lines\")\n",
    "    print(f\"  Std: {master_catalog['solution_length'].std():.1f} lines\")\n",
    "    \n",
    "    # Relative line position statistics\n",
    "    print(f\"\\n📍 RELATIVE LINE POSITION STATISTICS\")\n",
    "    print(f\"  Mean: {master_catalog['relative_line_position'].mean():.3f}\")\n",
    "    print(f\"  Median: {master_catalog['relative_line_position'].median():.3f}\")\n",
    "    print(f\"  Min: {master_catalog['relative_line_position'].min():.3f}\")\n",
    "    print(f\"  Max: {master_catalog['relative_line_position'].max():.3f}\")\n",
    "    print(f\"  Std: {master_catalog['relative_line_position'].std():.3f}\")\n",
    "    \n",
    "    # Cross-tabulation: Error Type vs Tier\n",
    "    print(f\"\\n📊 CROSS-TABULATION: ERROR TYPE vs TIER\")\n",
    "    crosstab = pd.crosstab(master_catalog['tier'], master_catalog['error_type'], margins=True)\n",
    "    print(crosstab)\n",
    "    \n",
    "    # Cross-tabulation: Source vs Error Type\n",
    "    print(f\"\\n📊 CROSS-TABULATION: SOURCE vs ERROR TYPE\")\n",
    "    crosstab_source = pd.crosstab(master_catalog['source'], master_catalog['error_type'], margins=True)\n",
    "    print(crosstab_source)\n",
    "    \n",
    "    # Problematic entries summary\n",
    "    print(f\"\\n\" + \"=\" * 80)\n",
    "    print(\"PROBLEMATIC ENTRIES SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if catalog_problematic.empty:\n",
    "        print(\"✅ No problematic entries found!\")\n",
    "    else:\n",
    "        print(f\"Total problematic rows: {len(catalog_problematic):,}\")\n",
    "        \n",
    "        # Error reasons\n",
    "        if 'error_reason' in catalog_problematic.columns:\n",
    "            print(f\"\\n❌ ERROR REASONS\")\n",
    "            error_reasons = catalog_problematic['error_reason'].value_counts()\n",
    "            for reason, count in error_reasons.items():\n",
    "                pct = (count / len(catalog_problematic)) * 100\n",
    "                print(f\"  {reason}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        # Source catalog distribution\n",
    "        if 'source_catalog' in catalog_problematic.columns:\n",
    "            print(f\"\\n📁 PROBLEMATIC BY SOURCE CATALOG\")\n",
    "            source_prob_counts = catalog_problematic['source_catalog'].value_counts()\n",
    "            for source, count in source_prob_counts.items():\n",
    "                pct = (count / len(catalog_problematic)) * 100\n",
    "                print(f\"  {source}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Generate the summary\n",
    "print_catalog_summary(master_catalog, catalog_problematic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d366a370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "SAMPLE ROWS BY ERROR TYPE AND SOURCE\n",
      "====================================================================================================\n",
      "\n",
      "==================== COMPUTATIONAL_ERROR + MANUAL ====================\n",
      "Total samples: 774\n",
      "--------------------------------------------------------------------------------\n",
      "📍 INDEX: 1000\n",
      "🎯 TIER: tier3\n",
      "🔧 ERROR SUBTYPE: NA\n",
      "📏 SOLUTION LENGTH: 3 lines\n",
      "📍 ERROR LINE: L1 (relative position: 0.333)\n",
      "\n",
      "❓ QUESTION:\n",
      "   John buys a heating pad for $30.  He uses it 3 times a week for 2 weeks.  How much does he spend on each use?\n",
      "\n",
      "✅ CORRECT ANSWER:\n",
      "   He uses it 3*2=<<3*2=6>>6 times\n",
      "   So he pays 30/6=$<<30/6=5>>5\n",
      "   #### 5\n",
      "\n",
      "❌ WRONG ANSWER:\n",
      "   He uses it 3*2=<<3*2=5>>5 times\n",
      "   So he pays 30/5=$<<30/5=6>>6\n",
      "   #### 6\n",
      "\n",
      "💡 EXPLANATION:\n",
      "   computational error: John uses it 3*2=<<3*2=6>>6 times.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "==================== COMPUTATIONAL_ERROR + PROGRAMMATIC ====================\n",
      "Total samples: 21,768\n",
      "--------------------------------------------------------------------------------\n",
      "📍 INDEX: 4\n",
      "🎯 TIER: tier1\n",
      "🔧 ERROR SUBTYPE: generate_digit_transposition_error\n",
      "📏 SOLUTION LENGTH: 4 lines\n",
      "📍 ERROR LINE: L2 (relative position: 0.500)\n",
      "\n",
      "❓ QUESTION:\n",
      "   James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\n",
      "\n",
      "✅ CORRECT ANSWER:\n",
      "   He writes each friend 3*2=<<3*2=6>>6 pages a week\n",
      "   So he writes 6*2=<<6*2=12>>12 pages every week\n",
      "   That means he writes 12*52=<<12*52=624>>624 pages a year\n",
      "   #### 624\n",
      "\n",
      "❌ WRONG ANSWER:\n",
      "   He writes each friend 3*2=<<3*2=6>>6 pages a week\n",
      "   So he writes 6*2=<<6*2=21>>21 pages every week\n",
      "   That means he writes 21*52=<<21*52=1092>>1092 pages a year\n",
      "   #### 1092\n",
      "\n",
      "💡 EXPLANATION:\n",
      "   The result of this computation should be 12, not 21. It appears two adjacent digits were swapped.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "==================== CONCEPTUAL_ERROR + MANUAL ====================\n",
      "Total samples: 966\n",
      "--------------------------------------------------------------------------------\n",
      "📍 INDEX: 1000\n",
      "🎯 TIER: tier3\n",
      "🔧 ERROR SUBTYPE: NA\n",
      "📏 SOLUTION LENGTH: 3 lines\n",
      "📍 ERROR LINE: L1 (relative position: 0.333)\n",
      "\n",
      "❓ QUESTION:\n",
      "   John buys a heating pad for $30.  He uses it 3 times a week for 2 weeks.  How much does he spend on each use?\n",
      "\n",
      "✅ CORRECT ANSWER:\n",
      "   He uses it 3*2=<<3*2=6>>6 times\n",
      "   So he pays 30/6=$<<30/6=5>>5\n",
      "   #### 5\n",
      "\n",
      "❌ WRONG ANSWER:\n",
      "   He uses it for 2 weeks.\n",
      "   So he pays 30/2=$<<30/2=15>>15\n",
      "   #### 15\n",
      "\n",
      "💡 EXPLANATION:\n",
      "   incorrect divisor: The cost should be divided by the total number of uses (3 times/week * 2 weeks = 6 uses), not just the number of weeks. The calculation should be 30/6 = $5.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "==================== CONCEPTUAL_ERROR + PROGRAMMATIC ====================\n",
      "Total samples: 1,144\n",
      "--------------------------------------------------------------------------------\n",
      "📍 INDEX: 978\n",
      "🎯 TIER: tier4\n",
      "🔧 ERROR SUBTYPE: operator_swap\n",
      "📏 SOLUTION LENGTH: 4 lines\n",
      "📍 ERROR LINE: L1 (relative position: 0.250)\n",
      "\n",
      "❓ QUESTION:\n",
      "   Stephen has 110 ants in his ant farm.  Half of the ants are worker ants, 20 percent of the worker ants are male.  How many female worker ants are there?\n",
      "\n",
      "✅ CORRECT ANSWER:\n",
      "   Worker ants:110/2=<<110/2=55>>55 ants\n",
      "   Male worker ants:55(.20)=11\n",
      "   Female worker ants:55-11=<<55-11=44>>44 ants\n",
      "   #### 44\n",
      "\n",
      "❌ WRONG ANSWER:\n",
      "   Worker ants:110*2=<<110*2=220>>220 ants\n",
      "   Male worker ants:220(0.2)=44\n",
      "   Female worker ants:220-44=<<220-44=176>>176 ants\n",
      "   #### 176\n",
      "\n",
      "💡 EXPLANATION:\n",
      "   Incorrect operation. The calculation should use '/' but used '*' instead.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Pretty Print Sample Rows by Error Type and Source ---\n",
    "\n",
    "def pretty_print_sample_rows(master_catalog):\n",
    "    \"\"\"\n",
    "    Pretty prints one sample row from each combination of error_type and source.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 100)\n",
    "    print(\"SAMPLE ROWS BY ERROR TYPE AND SOURCE\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Get all combinations of error_type and source\n",
    "    combinations = master_catalog.groupby(['error_type', 'source']).size().reset_index()\n",
    "    \n",
    "    for _, combo in combinations.iterrows():\n",
    "        error_type = combo['error_type']\n",
    "        source = combo['source']\n",
    "        count = combo[0]\n",
    "        \n",
    "        print(f\"\\n{'='*20} {error_type.upper()} + {source.upper()} {'='*20}\")\n",
    "        print(f\"Total samples: {count:,}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Get one sample from this combination\n",
    "        sample_df = master_catalog[\n",
    "            (master_catalog['error_type'] == error_type) & \n",
    "            (master_catalog['source'] == source)\n",
    "        ]\n",
    "        \n",
    "        if len(sample_df) > 0:\n",
    "            sample = sample_df.iloc[0]\n",
    "            \n",
    "            print(f\"📍 INDEX: {sample['index']}\")\n",
    "            print(f\"🎯 TIER: {sample['tier']}\")\n",
    "            print(f\"🔧 ERROR SUBTYPE: {sample['error_subtype']}\")\n",
    "            print(f\"📏 SOLUTION LENGTH: {sample['solution_length']} lines\")\n",
    "            print(f\"📍 ERROR LINE: {sample['erroneous_line_number']} (relative position: {sample['relative_line_position']:.3f})\")\n",
    "            print()\n",
    "            \n",
    "            print(\"❓ QUESTION:\")\n",
    "            print(f\"   {sample['question']}\")\n",
    "            print()\n",
    "            \n",
    "            print(\"✅ CORRECT ANSWER:\")\n",
    "            correct_lines = sample['correct_answer'].split('\\n')\n",
    "            for i, line in enumerate(correct_lines, 1):\n",
    "                if line.strip():\n",
    "                    print(f\"   {line}\")\n",
    "            print()\n",
    "            \n",
    "            print(\"❌ WRONG ANSWER:\")\n",
    "            wrong_lines = sample['wrong_answer'].split('\\n')\n",
    "            for i, line in enumerate(wrong_lines, 1):\n",
    "                if line.strip():\n",
    "                    print(f\"   {line}\")\n",
    "            print()\n",
    "            \n",
    "            print(\"💡 EXPLANATION:\")\n",
    "            print(f\"   {sample['explanation']}\")\n",
    "            print()\n",
    "        else:\n",
    "            print(\"No samples found for this combination.\")\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "\n",
    "# Run the pretty printer\n",
    "pretty_print_sample_rows(master_catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cfc5b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv in the data folder\n",
    "master_catalog.to_csv(DATA_DIR / 'master_catalog.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87573dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the problematic catalog to csv in the data folder\n",
    "catalog_problematic.to_csv(DATA_DIR / 'catalog_problematic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04fa19c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
