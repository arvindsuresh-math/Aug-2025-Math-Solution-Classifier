{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69138661",
   "metadata": {},
   "source": [
    "#### Cell 1: Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5a72283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root found at: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math\n",
      "Data directory found at: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data\n",
      "Raw template output directory set to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/template-generated-raw\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def find_project_root():\n",
    "    \"\"\"Traverse upwards to find the project root, marked by the .git folder.\"\"\"\n",
    "    current_path = Path.cwd()\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / \".git\").is_dir():\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    raise FileNotFoundError(\"Could not find project root. Is this a git repository?\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "\n",
    "# To contain generated template txt files\n",
    "TEMPLATE_OUTPUT_DIR = DATA_DIR / \"template-generated-raw\" \n",
    "\n",
    "# Contains sample template json files, questions answers, and user prompt prefixes\n",
    "TEMPLATE_EXAMPLE_DIR = DATA_DIR / \"template-examples-raw\"\n",
    "\n",
    "TIER_OUTPUT_DIRS = {f\"tier{i}\": TEMPLATE_OUTPUT_DIR / f\"tier{i}\" for i in range(1, 6)}\n",
    "TIER_EXAMPLES_DIRS = {f\"tier{i}\": TEMPLATE_EXAMPLE_DIR / f\"tier{i}\" for i in range(1, 6)}\n",
    "\n",
    "# Make the directory for the tier if it doesn't exist\n",
    "for tier_dir in TIER_OUTPUT_DIRS.values():\n",
    "    tier_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for tier_dir in TIER_EXAMPLES_DIRS.values():\n",
    "    tier_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root found at: {PROJECT_ROOT}\")\n",
    "print(f\"Data directory found at: {DATA_DIR}\")\n",
    "print(f\"Raw template output directory set to: {TEMPLATE_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2789a77f",
   "metadata": {},
   "source": [
    "#### Cell 2: Dataset and tier definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c14957c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier definitions loaded.\n",
      "tier1     : 2767 samples\n",
      "tier2     : 837 samples\n",
      "tier3     : 3113 samples\n",
      "tier4     : 544 samples\n",
      "tier5     : 212 samples\n",
      "Total     : 7473 samples\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from datasets import load_dataset \n",
    "import re\n",
    "\n",
    "# --- Load GSM8K Dataset ---\n",
    "GSM8K_TRAIN: Dataset = load_dataset(\"gsm8k\", \"main\")[\"train\"]\n",
    "\n",
    "# --- Tier Definition Functions ---\n",
    "def has_computational_division(solution_text: str) -> bool:\n",
    "    pattern = re.compile(r'/\\s*\\d')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def has_float(solution_text: str) -> bool:\n",
    "    pattern = re.compile(r'(?<!\\d)\\.\\d+|\\d+\\.\\d+')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def is_symbolic(solution_text: str) -> bool:\n",
    "    pattern = re.compile(r'^Let [a-zA-Z] ', re.MULTILINE)\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def mutually_disjoint_tiers(dataset: Dataset) -> dict[str, list[int]]:\n",
    "    tiers = {}\n",
    "\n",
    "    symbolic_set = set(idx for idx, sample in enumerate(dataset) if is_symbolic(sample.get(\"answer\", \"\")))\n",
    "\n",
    "    non_symbolic_indices = [idx for idx in range(len(dataset)) if idx not in symbolic_set]\n",
    "\n",
    "    tiers[\"tier1\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "\n",
    "    tiers[\"tier2\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "\n",
    "    tiers[\"tier3\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "\n",
    "    tiers[\"tier4\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    \n",
    "    tiers[\"tier5\"] = sorted(list(symbolic_set))\n",
    "    return tiers\n",
    "\n",
    "TIER_LISTS = mutually_disjoint_tiers(GSM8K_TRAIN)\n",
    "print(\"Tier definitions loaded.\")\n",
    "\n",
    "# Display the number of samples in each tier\n",
    "for tier, indices in TIER_LISTS.items():\n",
    "    print(f\"{tier:<10}: {len(indices)} samples\")\n",
    "print(f\"{'Total':<10}: {len(GSM8K_TRAIN)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31607ee",
   "metadata": {},
   "source": [
    "#### **Selecting the current tier for this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60720481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier for this notebook: tier4\n",
      "Number of samples in tier4: 544\n",
      "Output directory for tier4: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/template-generated-raw/tier4\n",
      "Examples directory for tier4: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/template-examples-raw/tier4\n"
     ]
    }
   ],
   "source": [
    "### --- Select the tier ONCE for this notebook --- ###\n",
    "CURRENT_TIER = \"tier4\"\n",
    "\n",
    "CURRENT_INDICES = TIER_LISTS[CURRENT_TIER]\n",
    "CURRENT_TIER_OUTPUT_DIR = TIER_OUTPUT_DIRS[CURRENT_TIER]\n",
    "CURRENT_TIER_EXAMPLES_DIR = TIER_EXAMPLES_DIRS[CURRENT_TIER]\n",
    "\n",
    "print(f\"Tier for this notebook: {CURRENT_TIER}\")\n",
    "print(f\"Number of samples in {CURRENT_TIER}: {len(CURRENT_INDICES)}\")\n",
    "print(f\"Output directory for {CURRENT_TIER}: {CURRENT_TIER_OUTPUT_DIR}\")\n",
    "print(f\"Examples directory for {CURRENT_TIER}: {CURRENT_TIER_EXAMPLES_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a653ef",
   "metadata": {},
   "source": [
    "#### Cell 3: Prompt creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0bf0dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User prompt for index 1 in tier4 has 22581 characters:\n",
      "--------------------------------------------------------------------------------\n",
      "In the TASK below, you will be given a math problem and its corresponding step-by-step solution. Each step in the solution is numbered (e.g. \"L1\", \"L2\" and so on), and many of the steps include calculator annotations (e.g. \"<<20*0.1=2>>\"). Your goal is to convert this information into a structured JSON object according to the following detialed instructions.\n",
      "\n",
      "# Detailed Field Instructions\n",
      "\n",
      "## 1. \"function_code\"\n",
      "\n",
      "This string must contain a Python function with the following characteristics:\n",
      "\n",
      "*   **1.A. Handling Imports:** The `function_code` should have no imports **unless** your formalization requires the `Fraction` object.\n",
      "    *   If your code uses the `Fraction()` constructor, the very first line of the string MUST be `from fractions import Fraction`.\n",
      "    *   If your code does **not** use the `Fraction()` constructor (e.g., it only uses integers, floats, or standard division `/`), the function definition `def solve():` MUST be the very first line.\n",
      "*   **1.B. Function Naming & Docstring:** The function must be named `solve`, and it should not have any args. It must begin with a docstring that has exactly two lines:\n",
      "    *   **1.B.i.** The first line must be: \"Index: [Index].\" using the index from the task header.\n",
      "    *   **1.B.ii.** The second line must be a succinct, one-sentence description of what the function returns (e.g., \"Returns: the total cost of wages and taxes.\").\n",
      "*   **1.C. Line comments:** For each solution line that is used to compute the final answer, include a comment of the form `# L1`, `# L2` and so on, which references the line number.\n",
      "    *   **1.C.i.** Such a comment must immediately be followed by a code block that precisely formalizes the corresponding solution line. More details about code blocks are provided in 1.D below.\n",
      "    *   **1.C.ii.** If a solution line does not contain any computation relevant to the final answer, then omit it completely from the function code and do NOT add a corresponding line comment.\n",
      "*   **1.D. Code blocks:** Each code block constitutes a complete formalization of its corresponding solution line. It must consist of the following:\n",
      "    *   **1.D.i. Input Variables** First, define any NEW variables needed for the computation, i.e. that will be used for the first time in the solution. Each input variable MUST be followed by a comment (`#`) in the same line. These variables fall into two categories:\n",
      "        *   \"question_inputs\": These are variables whose values are stated in or can be extracted from the question text (only the question text, NOT the answer text). The comment for these variables should quote or refer to the phrase in the question text from which it is extracted.\n",
      "        *   \"WK_inputs\": These are variables drawn from common-sense \"World Knowledge\" (e.g. `minutes_per_hour = 60`, `dozen = 12`). The comment for these variables MUST simply say `# WK`.\n",
      "    *   **1.D.ii. Output Variables** Second, there should be EXACTLY ONE line of code which formalizes the computation in the solution line and assigns the resulting value to a new variable (this is the \"output_variable\" field).\n",
      "*   **1.E. The Direct Substitution Rule:** This is the MOST IMPORTANT RULE, which ensures that the \"solution_line_template\" is purely identical to the original solution line except that numerical values in computations have been replaced with variable placeholders: You MUST define variables in such a way that they can be DIRECTLY SUBSTITUTED into the solution line without changing any operators or surrounding text in the line.\n",
      "*   **1.F. Final Answer:** The line that assigns the final result to the `answer` variable must be immediately preceded by a line containing only the comment `# FA`. The last line of the function must always return the `answer` variable.\n",
      "\n",
      "## 2. \"solution_line_template\"\n",
      "\n",
      "*   **2.A.** The template should be EXACTLY identical to the original solution line, with the ONLY CHANGES being that every NUMERICAL value used in a computation is replaced by its corresponding `{variable_name}` placeholder. This applies to the entire content of the solution line, including the inside and outside of the calculator annotations.\n",
      "*   **2.B.** In particular, EVERY SINGLE numerical value appearing inside the calculator annotation (`<<..>>`) MUST be replaced with a `{variable_name}` placeholder.\n",
      "*   **2.C.** Note: some quantities may appear as words in the solution line (e.g. \"twice as many\"). Do NOT attempt to replace these with variable name placeholders.\n",
      "*   **2.D.** The Direct Substitution Rule will ensure that for correctly defined variables, it will be possible to replace the numerical values with variable name placeholders while leaving all surrounding text, symbols, and operators unchanged. Thus, in a correct \"solution_line_template\", the calculator annotation will not contain any numerical values, and moreover, replacing each `{variable_name}` by its value should exactly recover the original solution line, including the original calculator annotation.\n",
      "\n",
      "# Examples\n",
      "\n",
      "Given below are three examples that illustrate what a perfect formalization will look like. For each example, you are given the following:\n",
      "\n",
      "*   Input: consisting of an index, question, and solution mapping.\n",
      "*   Output: complete output, wrapped inside ```json .. ```\n",
      "\n",
      "In all examples, you will observe the following:\n",
      "\n",
      "*   **A rigid adherence to the Direct Substitution Rule (1.E)**. This is the most important principle. The `solution_line_template` must be an exact copy of the original solution line, with only computational numbers replaced by `{variable}` placeholders. Every other point follows from this rule.\n",
      "\n",
      "*   **How to formalize a rational number depends entirely on how it appears in the solution text.** It is crucial to distinguish between `floats`, `Fractions`, and the division operation (`/`).\n",
      "    *   **Use `float` for decimals:** In **Example 1**, \"half\" is used in the calculation as `0.5`, so it is formalized as `kevin_nice_fraction = 0.5`. In **Example 3**, \"30 percent\" is used as `.30`, formalized as `third_night_stolen_percent = 0.30`.\n",
      "    *   **Use `fractions.Fraction` for fractional quantities:** If \"/\" acts as a separator within a single fractional quantity, use `Fraction`. In **Example 1**, \"three-fourths\" appears as `(3/4)`, so it is formalized as `Fraction(3, 4)`. This requires the `from fractions import Fraction` import.\n",
      "    *   **Use the `/` operator for division operations:** If \"/\" represents the operation of dividing two values, use the standard operator. In **Example 2**, the solution `300/100` is a division operation, formalized using `/`: `total_dollars = total_cents / cents_per_dollar`. This does **not** require an import.\n",
      "\n",
      "*   **A single template can require multiple formalizations.** **Example 1** shows a problem using both `float` (`0.5`) and `Fraction` (`3/4`). **Example 4** shows a mix of percentages (decomposed into floats) and division (`/`). The model must adapt to each line.\n",
      "\n",
      "*   **Decomposition is sometimes needed to follow the rules.** This is a critical and advanced point. In **Example 4**, the solution for L1 is `80% * 20 votes = <<80*0.01*20=16>>16 votes`. To satisfy the Direct Substitution Rule for the calculator annotation, this must be decomposed into two variables: `taotd_discard_percent_num = 80` and `percent_factor = 0.01`.\n",
      "\n",
      "*   **Strict adherence to defining only NEW variables** in each step's `question_inputs` and `WK_inputs` lists. For instance, in **Example 3**, `initial_ducks` is defined in L1 and then simply re-used in the computation for L2 without being listed as an input again.\n",
      "\n",
      "*   Comments for `question_inputs` must cite the question text only, **NEVER** the solution text. Note how `cents_per_dollar = 100` in **Example 2** is correctly labeled `# WK` because that fact constitutes common-sense World Knowledge and is not present in the question text.\n",
      "\n",
      "## Example 1\n",
      "\n",
      "### Input\n",
      "\n",
      "**Index:**\n",
      "3847\n",
      "\n",
      "**Question:**\n",
      "All people named Barry are nice, while only half of the people named Kevin are nice.  Three-fourths of people named Julie are nice, while 10% of people named Joe are nice.  If a crowd contains 24 people named Barry, 20 people named Kevin, 80 people named Julie, and 50 people named Joe, how many nice people are in the crowd?\n",
      "\n",
      "**Solution mapping:**\n",
      "{\n",
      "  \"L1\": \"If all people named Barry are nice, and the crowd contains 24 people named Barry, then 1*24=<<24*1=24>>24 of these people are nice.\",\n",
      "  \"L2\": \"If only half of people named Kevin are nice, and the crowd contains 20 people named Kevin, then 0.5*20=<<0.5*20=10>>10 of these people are nice.\",\n",
      "  \"L3\": \"If three-fourths of people named Julie are nice, and the crowd contains 80 people named Julie, then (3/4)*80=<<3/4*80=60>>60 of these people are nice.\",\n",
      "  \"L4\": \"If 10% of people named Joe are nice, and the crowd contains 50 people named Joe, then 0.1*50=<<0.1*50=5>>5 of these people are nice.\",\n",
      "  \"L5\": \"In total, the crowd contains 24+10+60+5=<<24+10+60+5=99>>99 people who are nice.\"\n",
      "}\n",
      "\n",
      "### Output\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"function_code\": \"from fractions import Fraction\\n\\ndef solve():\\n    \\\"\\\"\\\"Index: 3847.\\n    Returns: the number of nice people in the crowd.\\n    \\\"\\\"\\\"\\n    # L1\\n    num_barry = 24 # 24 people named Barry\\n    barry_nice_fraction = 1 # All people named Barry are nice\\n    nice_barry = barry_nice_fraction * num_barry\\n\\n    # L2\\n    num_kevin = 20 # 20 people named Kevin\\n    kevin_nice_fraction = 0.5 # half of the people named Kevin are nice\\n    nice_kevin = kevin_nice_fraction * num_kevin\\n\\n    # L3\\n    num_julie = 80 # 80 people named Julie\\n    julie_nice_fraction = Fraction(3, 4) # Three-fourths of people named Julie are nice\\n    nice_julie = julie_nice_fraction * num_julie\\n\\n    # L4\\n    num_joe = 50 # 50 people named Joe\\n    joe_nice_fraction = 0.1 # 10% of people named Joe are nice\\n    nice_joe = joe_nice_fraction * num_joe\\n\\n    # L5\\n    total_nice_people = nice_barry + nice_kevin + nice_julie + nice_joe\\n\\n    # FA\\n    answer = total_nice_people\\n    return answer\",\n",
      "  \"logical_steps\": [\n",
      "    {\n",
      "      \"line_number\": \"L1\",\n",
      "      \"question_inputs\": [\"num_barry\", \"barry_nice_fraction\"],\n",
      "      \"WK_inputs\": [],\n",
      "      \"output_variable\": \"nice_barry\",\n",
      "      \"solution_line_template\": \"If all people named Barry are nice, and the crowd contains {num_barry} people named Barry, then {barry_nice_fraction}*{num_barry}=<<{num_barry}*{barry_nice_fraction}={nice_barry}>>{nice_barry} of these people are nice.\"\n",
      "    },\n",
      "    {\n",
      "      \"line_number\": \"L2\",\n",
      "      \"question_inputs\": [\"num_kevin\", \"kevin_nice_fraction\"],\n",
      "      \"WK_inputs\": [],\n",
      "      \"output_variable\": \"nice_kevin\",\n",
      "      \"solution_line_template\": \"If only half of people named Kevin are nice, and the crowd contains {num_kevin} people named Kevin, then {kevin_nice_fraction}*{num_kevin}=<<{kevin_nice_fraction}*{num_kevin}={nice_kevin}>>{nice_kevin} of these people are nice.\"\n",
      "    },\n",
      "    {\n",
      "      \"line_number\": \"L3\",\n",
      "      \"question_inputs\": [\"num_julie\", \"julie_nice_fraction\"],\n",
      "      \"WK_inputs\": [],\n",
      "      \"output_variable\": \"nice_julie\",\n",
      "      \"solution_line_template\": \"If three-fourths of people named Julie are nice, and the crowd contains {num_julie} people named Julie, then ({julie_nice_fraction})*{num_julie}=<<{julie_nice_fraction}*{num_julie}={nice_julie}>>{nice_julie} of these people are nice.\"\n",
      "    },\n",
      "    {\n",
      "      \"line_number\": \"L4\",\n",
      "      \"question_inputs\": [\"num_joe\", \"joe_nice_fraction\"],\n",
      "      \"WK_inputs\": [],\n",
      "      \"output_variable\": \"nice_joe\",\n",
      "      \"solution_line_template\": \"If 10% of people named Joe are nice, and the crowd contains {num_joe} people named Joe, then {joe_nice_fraction}*{num_joe}=<<{joe_nice_fraction}*{num_joe}={nice_joe}>>{nice_joe} of these people are nice.\"\n",
      "    },\n",
      "    {\n",
      "      \"line_number\": \"L5\",\n",
      "      \"question_inputs\": [],\n",
      "      \"WK_inputs\": [],\n",
      "      \"output_variable\": \"total_nice_people\",\n",
      "      \"solution_line_template\": \"In total, the crowd contains {nice_barry}+{nice_kevin}+{nice_julie}+{nice_joe}=<<{nice_barry}+{nice_kevin}+{nice_julie}+{nice_joe}={total_nice_people}>>{total_nice_people} people who are nice.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "## Example 2\n",
      "\n",
      "### Input\n",
      "\n",
      "**Index:**\n",
      "4847\n",
      "\n",
      "**Question:**\n",
      "Lucy plans to purchase potato chips for a party. Ten people will be at the party, including Lucy. The potato chips cost 25 cents per pound. How much will Lucy pay (in dollars) for the potato chips if she wants each person to get 1.2 pounds?\n",
      "\n",
      "**Solution mapping:**\n",
      "{\n",
      "  \"L1\": \"Lucy needs to purchase 10 x 1.2 = <<10*1.2=12>>12 pounds of potato chips.\",\n",
      "  \"L2\": \"So, Lucy will pay 12 x 25 = <<12*25=300>>300 cents for it.\",\n",
      "  \"L3\": \"Since there are 100 cents in $1, thus, Lucy will pay 300/100 = <<300/100=3>>3 dollars.\"\n",
      "}\n",
      "\n",
      "### Output\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"function_code\": \"def solve():\\n    \\\"\\\"\\\"Index: 4847.\\n    Returns: the amount Lucy will pay in dollars.\\n    \\\"\\\"\\\"\\n    # L1\\n    num_people = 10 # Ten people will be at the party\\n    chips_per_person = 1.2 # each person to get 1.2 pounds\\n    total_pounds = num_people * chips_per_person\\n\\n    # L2\\n    cents_per_pound = 25 # 25 cents per pound\\n    total_cents = total_pounds * cents_per_pound\\n\\n    # L3\\n    cents_per_dollar = 100 # WK\\n    total_dollars = total_cents / cents_per_dollar\\n\\n    # FA\\n    answer = total_dollars\\n    return answer\",\n",
      "  \"logical_steps\": [\n",
      "    {\n",
      "      \"line_number\": \"L1\",\n",
      "      \"question_inputs\": [\"num_people\", \"chips_per_person\"],\n",
      "      \"WK_inputs\": [],\n",
      "      \"output_variable\": \"total_pounds\",\n",
      "      \"solution_line_template\": \"Lucy needs to purchase {num_people} x {chips_per_person} = <<{num_people}*{chips_per_person}={total_pounds}>>{total_pounds} pounds of potato chips.\"\n",
      "    },\n",
      "    {\n",
      "      \"line_number\": \"L2\",\n",
      "      \"question_inputs\": [\"cents_per_pound\"],\n",
      "      \"WK_inputs\": [],\n",
      "      \"output_variable\": \"total_cents\",\n",
      "      \"solution_line_template\": \"So, Lucy will pay {total_pounds} x {cents_per_pound} = <<{total_pounds}*{cents_per_pound}={total_cents}>>{total_cents} cents for it.\"\n",
      "    },\n",
      "    {\n",
      "      \"line_number\": \"L3\",\n",
      "      \"question_inputs\": [],\n",
      "      \"WK_inputs\": [\"cents_per_dollar\"],\n",
      "      \"output_variable\": \"total_dollars\",\n",
      "      \"solution_line_template\": \"Since there are 100 cents in $1, thus, Lucy will pay {total_cents}/{cents_per_dollar} = <<{total_cents}/{cents_per_dollar}={total_dollars}>>{total_dollars} dollars.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "## Example 3\n",
      "\n",
      "### Input\n",
      "\n",
      "**Index:**\n",
      "5040\n",
      "\n",
      "**Question:**\n",
      "There are 320 ducks in a pond.  On the first night 1/4 of them get eaten by a fox.  On the second night 1/6 of the remaining ducks fly away, and on the third night 30 percent are stolen.  How many ducks remain after the three nights?\n",
      "\n",
      "**Solution mapping:**\n",
      "{\n",
      "  \"L1\": \"First night:320(1/4)=80\",\n",
      "  \"L2\": \"320-80=<<320-80=240>>240\",\n",
      "  \"L3\": \"Second night:240(1/6)=40\",\n",
      "  \"L4\": \"240-40=<<240-40=200>>200\",\n",
      "  \"L5\": \"Third night:200(.30)=60\",\n",
      "  \"L6\": \"200-60=<<200-60=140>>140 ducks remain\"\n",
      "}\n",
      "\n",
      "### Output\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"function_code\": \"from fractions import Fraction\\n\\ndef solve():\\n    \\\"\\\"\\\"Index: 5040.\\n    Returns: the number of ducks remaining after three nights.\\n    \\\"\\\"\\\"\\n    # L1\\n    initial_ducks = 320 # 320 ducks in a pond\\n    first_night_eaten_fraction = Fraction(1, 4) # 1/4 of them get eaten\\n    first_night_eaten = initial_ducks * first_night_eaten_fraction\\n\\n    # L2\\n    ducks_after_night1 = initial_ducks - first_night_eaten\\n\\n    # L3\\n    second_night_flew_fraction = Fraction(1, 6) # 1/6 of the remaining ducks fly away\\n    second_night_flew = ducks_after_night1 * second_night_flew_fraction\\n\\n    # L4\\n    ducks_after_night2 = ducks_after_night1 - second_night_flew\\n\\n    # L5\\n    third_night_stolen_percent = 0.30 # 30 percent are stolen\\n    third_night_stolen = ducks_after_night2 * third_night_stolen_percent\\n\\n    # L6\\n    ducks_after_night3 = ducks_after_night2 - third_night_stolen\\n\\n    # FA\\n    answer = ducks_after_night3\\n    return answer\",\n",
      "  \"logical_steps\": [\n",
      "    {\n",
      "      \"line_number\": \"L1\",\n",
      "      \"question_inputs\": [\"initial_ducks\", \"first_night_eaten_fraction\"],\n",
      "      \"WK_inputs\": [],\n",
      "      \"output_variable\": \"first_night_eaten\",\n",
      "      \"solution_line_template\": \"First night:{initial_ducks}({first_night_eaten_fraction})={first_night_eaten}\"\n",
      "    },\n",
      "    {\n",
      "      \"line_number\": \"L2\",\n",
      "      \"question_inputs\": [],\n",
      "      \"WK_inputs\": [],\n",
      "      \"output_variable\": \"ducks_after_night1\",\n",
      "      \"solution_line_template\": \"{initial_ducks}-{first_night_eaten}=<<{initial_ducks}-{first_night_eaten}={ducks_after_night1}>>{ducks_after_night1}\"\n",
      "    },\n",
      "    {\n",
      "      \"line_number\": \"L3\",\n",
      "      \"question_inputs\": [\"second_night_flew_fraction\"],\n",
      "      \"WK_inputs\": [],\n",
      "      \"output_variable\": \"second_night_flew\",\n",
      "      \"solution_line_template\": \"Second night:{ducks_after_night1}({second_night_flew_fraction})={second_night_flew}\"\n",
      "    },\n",
      "    {\n",
      "      \"line_number\": \"L4\",\n",
      "      \"question_inputs\": [],\n",
      "      \"WK_inputs\": [],\n",
      "      \"output_variable\": \"ducks_after_night2\",\n",
      "      \"solution_line_template\": \"{ducks_after_night1}-{second_night_flew}=<<{ducks_after_night1}-{second_night_flew}={ducks_after_night2}>>{ducks_after_night2}\"\n",
      "    },\n",
      "    {\n",
      "      \"line_number\": \"L5\",\n",
      "      \"question_inputs\": [\"third_night_stolen_percent\"],\n",
      "      \"WK_inputs\": [],\n",
      "      \"output_variable\": \"third_night_stolen\",\n",
      "      \"solution_line_template\": \"Third night:{ducks_after_night2}({third_night_stolen_percent})={third_night_stolen}\"\n",
      "    },\n",
      "    {\n",
      "      \"line_number\": \"L6\",\n",
      "      \"question_inputs\": [],\n",
      "      \"WK_inputs\": [],\n",
      "      \"output_variable\": \"ducks_after_night3\",\n",
      "      \"solution_line_template\": \"{ducks_after_night2}-{third_night_stolen}=<<{ducks_after_night2}-{third_night_stolen}={ducks_after_night3}>>{ducks_after_night3} ducks remain\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "## Example 4\n",
      "\n",
      "### Input\n",
      "\n",
      "**Index:**\n",
      "7037\n",
      "\n",
      "**Question:**\n",
      "At a book burning, Fran counts 20 votes for The Art of the Deal, 12 votes for Twilight, and 10 votes for Game of Thrones.  She decides to alter the results by throwing away 80% of the votes for The Art of the Deal and half the votes for Twilight. What percentage of the altered votes are for Game of Thrones?\n",
      "\n",
      "**Solution mapping:**\n",
      "{\n",
      "  \"L1\": \"First find the total number of The Art of the Deal votes Fran throws away: 80% * 20 votes = <<80*0.01*20=16>>16 votes\",\n",
      "  \"L2\": \"Then subtract these votes from the total number of The Art of the Deal votes to find the altered number: 20 votes - 16 votes = <<20-16=4>>4 votes\",\n",
      "  \"L3\": \"Then divide the total number Twilight votes by 2 to find the altered number of votes: 12 votes / 2 = <<12/2=6>>6 votes\",\n",
      "  \"L4\": \"Then add the altered number of votes for each book to find the total altered number of votes: 6 votes + 4 votes + 10 votes = <<6+4+10=20>>20 votes\",\n",
      "  \"L5\": \"Then divide the number of votes for Game of Thrones by the total altered number of votes and multiply by 100% to express the answer as a percentage: 10 votes / 20 votes * 100% = 50%\"\n",
      "}\n",
      "\n",
      "### Output\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"function_code\": \"def solve():\\n    \\\"\\\"\\\"Index: 7037.\\n    Returns: the percentage of altered votes for Game of Thrones.\\n    \\\"\\\"\\\"\\n    # L1\\n    taotd_initial_votes = 20 # 20 votes for The Art of the Deal\\n    taotd_discard_percent_num = 80 # throws away 80% of the votes\\n    percent_factor = 0.01 # WK\\n    taotd_discarded_votes = taotd_discard_percent_num * percent_factor * taotd_initial_votes\\n\\n    # L2\\n    taotd_altered_votes = taotd_initial_votes - taotd_discarded_votes\\n\\n    # L3\\n    twilight_initial_votes = 12 # 12 votes for Twilight\\n    twilight_discard_divisor = 2 # half the votes for Twilight\\n    twilight_altered_votes = twilight_initial_votes / twilight_discard_divisor\\n\\n    # L4\\n    got_initial_votes = 10 # 10 votes for Game of Thrones\\n    total_altered_votes = twilight_altered_votes + taotd_altered_votes + got_initial_votes\\n\\n    # L5\\n    percent_multiplier = 100 # WK\\n    got_percentage = got_initial_votes / total_altered_votes * percent_multiplier\\n\\n    # FA\\n    answer = got_percentage\\n    return answer\",\n",
      "  \"logical_steps\": [\n",
      "    {\n",
      "      \"line_number\": \"L1\",\n",
      "      \"question_inputs\": [\"taotd_discard_percent_num\", \"taotd_initial_votes\"],\n",
      "      \"WK_inputs\": [\"percent_factor\"],\n",
      "      \"output_variable\": \"taotd_discarded_votes\",\n",
      "      \"solution_line_template\": \"First find the total number of The Art of the Deal votes Fran throws away: 80% * {taotd_initial_votes} votes = <<{taotd_discard_percent_num}*{percent_factor}*{taotd_initial_votes}={taotd_discarded_votes}>>{taotd_discarded_votes} votes\"\n",
      "    },\n",
      "    {\n",
      "      \"line_number\": \"L2\",\n",
      "      \"question_inputs\": [],\n",
      "      \"WK_inputs\": [],\n",
      "      \"output_variable\": \"taotd_altered_votes\",\n",
      "      \"solution_line_template\": \"Then subtract these votes from the total number of The Art of the Deal votes to find the altered number: {taotd_initial_votes} - {taotd_discarded_votes} votes = <<{taotd_initial_votes}-{taotd_discarded_votes}={taotd_altered_votes}>>{taotd_altered_votes} votes\"\n",
      "    },\n",
      "    {\n",
      "      \"line_number\": \"L3\",\n",
      "      \"question_inputs\": [\"twilight_initial_votes\", \"twilight_discard_divisor\"],\n",
      "      \"WK_inputs\": [],\n",
      "      \"output_variable\": \"twilight_altered_votes\",\n",
      "      \"solution_line_template\": \"Then divide the total number Twilight votes by {twilight_discard_divisor} to find the altered number of votes: {twilight_initial_votes} votes / {twilight_discard_divisor} = <<{twilight_initial_votes}/{twilight_discard_divisor}={twilight_altered_votes}>>{twilight_altered_votes} votes\"\n",
      "    },\n",
      "    {\n",
      "      \"line_number\": \"L4\",\n",
      "      \"question_inputs\": [\"got_initial_votes\"],\n",
      "      \"WK_inputs\": [],\n",
      "      \"output_variable\": \"total_altered_votes\",\n",
      "      \"solution_line_template\": \"Then add the altered number of votes for each book to find the total altered number of votes: {twilight_altered_votes} votes + {taotd_altered_votes} votes + {got_initial_votes} votes = <<{twilight_altered_votes}+{taotd_altered_votes}+{got_initial_votes}={total_altered_votes}>>{total_altered_votes} votes\"\n",
      "    },\n",
      "    {\n",
      "      \"line_number\": \"L5\",\n",
      "      \"question_inputs\": [],\n",
      "      \"WK_inputs\": [\"percent_multiplier\"],\n",
      "      \"output_variable\": \"got_percentage\",\n",
      "      \"solution_line_template\": \"Then divide the number of votes for Game of Thrones by the total altered number of votes and multiply by {percent_multiplier}% to express the answer as a percentage: {got_initial_votes} votes / {total_altered_votes} votes * {percent_multiplier}% = {got_percentage}%\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "## Input\n",
      "\n",
      "**Index:**:\n",
      "1\n",
      "\n",
      "**Question:**:\n",
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
      "\n",
      "**Solution mapping:**:\n",
      "{\n",
      "  \"L1\": \"Weng earns 12/60 = $<<12/60=0.2>>0.2 per minute.\",\n",
      "  \"L2\": \"Working 50 minutes, she earned 0.2 x 50 = $<<0.2*50=10>>10.\"\n",
      "}\n",
      "\n",
      "## Output\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def sanitize_text(text: str):\n",
    "    \"\"\"\n",
    "    Replaces a comprehensive set of problematic Unicode characters with their\n",
    "    ASCII equivalents to prevent model generation and string parsing errors.\n",
    "    \"\"\"\n",
    "    replacements = {\n",
    "        # Mathematical Operators\n",
    "        \"\\u2212\": \"-\",  # Minus Sign\n",
    "        \"\\u00d7\": \"*\",  # Multiplication Sign\n",
    "        \"\\u00f7\": \"/\",  # Division Sign\n",
    "        \"\\u22c5\": \"*\",  # Dot Operator\n",
    "        \n",
    "        # Typographic Quotes\n",
    "        \"\\u201c\": '\"',  # Left Double Quotation Mark\n",
    "        \"\\u201d\": '\"',  # Right Double Quotation Mark\n",
    "        \"\\u2018\": \"'\",  # Left Single Quotation Mark\n",
    "        \"\\u2019\": \"'\",  # Right Single Quotation Mark\n",
    "        \n",
    "        # Typographic Dashes\n",
    "        \"\\u2014\": \"-\",  # Em Dash\n",
    "        \"\\u2013\": \"-\",  # En Dash\n",
    "        \n",
    "        # Other\n",
    "        \"\\u2026\": \"...\", # Horizontal Ellipsis\n",
    "        \"\\u00a0\": \" \",  # Non-breaking Space\n",
    "    }\n",
    "    for uni, ascii_char in replacements.items():\n",
    "        text = text.replace(uni, ascii_char)\n",
    "    return text\n",
    "\n",
    "\n",
    "def build_solution_mapping(\n",
    "        index: int, \n",
    "        dataset: 'datasets.Dataset' = GSM8K_TRAIN,\n",
    "        exclude_FA: bool = True\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Extracts the natural language solution, sanitizes it, and structures\n",
    "    it into a line-numbered dictionary.\n",
    "    \"\"\"\n",
    "    solution_mapping = {}\n",
    "    solution_text = dataset[index][\"answer\"]\n",
    "    sanitized_solution_text = sanitize_text(solution_text)\n",
    "    \n",
    "    # --- CORRECTION: Use the sanitized variable ---\n",
    "    lines = [ln.strip() for ln in sanitized_solution_text.splitlines() if ln.strip()]\n",
    "\n",
    "    if lines and re.match(r\"^####\\s*[\\d\\.,]+$\", lines[-1]):\n",
    "        solution_mapping[\"FA\"] = lines.pop(-1).strip()\n",
    "\n",
    "    for i, line in enumerate(lines, 1):\n",
    "        solution_mapping[f\"L{i}\"] = line\n",
    "\n",
    "    if exclude_FA and \"FA\" in solution_mapping:\n",
    "        del solution_mapping[\"FA\"]\n",
    "\n",
    "    return solution_mapping\n",
    "\n",
    "\n",
    "BASE_TEMPLATE_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"function_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"A single string containing a complete, self-contained Python function that constitutes an end-to-end formalization of the solution.\"\n",
    "        },\n",
    "        \"logical_steps\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"line_number\": {\"type\": \"string\"},\n",
    "                    \"question_inputs\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "                    \"WK_inputs\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "                    \"output_variable\": {\"type\": \"string\"},\n",
    "                    \"solution_line_template\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"line_number\", \"question_inputs\", \"WK_inputs\", \"output_variable\", \"solution_line_template\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"function_code\", \"logical_steps\"]\n",
    "}\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a data formalization expert who excels in mathematical reasoning and writing python code. You will be presented with a math word problem accompanied by a step-by-step natural language solution. You goal is to carefully and meticulously analyze the given question and solution, and formalize it by converting it into a structured json object that deconstructs the logic of the solution.\n",
    "\n",
    "You MUST follow all rules and formatting instructions provided in the user prompt without deviation. Your entire output MUST be a single JSON object wrapped in ```json ... ```. Do not include any text or explanation before or after the JSON object.\"\"\"\n",
    "\n",
    "STATIC_PREFIXES = {}\n",
    "for tier in TIER_LISTS.keys():\n",
    "    prefix_file = TIER_EXAMPLES_DIRS[tier] / f\"{tier}_user_prompt_prefix.txt\"\n",
    "    with open(prefix_file, 'r', encoding='utf-8') as f:\n",
    "        STATIC_PREFIXES[tier] = f.read()\n",
    "\n",
    "\n",
    "def append_sample_to_user_prompt(\n",
    "        tier: str, \n",
    "        index: int, \n",
    "        dataset: 'datasets.Dataset' = GSM8K_TRAIN\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Appends a chosen sample from the GSM8K dataset to the user prompt for a specific tier. Returns the complete user prompt, ready to be sent to the LLM for template generation.\n",
    "    \"\"\"\n",
    "    if tier not in TIER_LISTS:\n",
    "        raise ValueError(f\"Invalid tier: {tier}. Must be one of {list(TIER_LISTS.keys())}.\")\n",
    "\n",
    "    sample = dataset[index]\n",
    "    question = sample['question']\n",
    "    answer = build_solution_mapping(index, dataset)\n",
    "\n",
    "    task_block = f\"\"\"## Input\n",
    "\n",
    "**Index:**:\n",
    "{index}\n",
    "\n",
    "**Question:**:\n",
    "{question}\n",
    "\n",
    "**Solution mapping:**:\n",
    "{json.dumps(answer, indent=2)}\n",
    "\n",
    "## Output\n",
    "\n",
    "\"\"\"\n",
    "    return STATIC_PREFIXES[tier] + task_block\n",
    "\n",
    "\n",
    "# Example usage\n",
    "idx = CURRENT_INDICES[0]\n",
    "user_prompt = append_sample_to_user_prompt(CURRENT_TIER, idx, GSM8K_TRAIN)\n",
    "print(f\"User prompt for index {idx} in {CURRENT_TIER} has {len(user_prompt)} characters:\")\n",
    "print(\"-\"*80)\n",
    "print(user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4d0856",
   "metadata": {},
   "source": [
    "#### Cell 4: API clients, concurrency limits, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3216c711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables from .env file.\n",
      "API clients initialized successfully.\n",
      "API concurrency limits set to: {'google': 30, 'anthropic': 2, 'openai': 2}\n",
      "Available models: ['openai_gpt-4.1', 'google_gemini-2.5-flash']\n"
     ]
    }
   ],
   "source": [
    "# Imports for API clients and related functionality\n",
    "import os\n",
    "import openai\n",
    "import google.generativeai as genai\n",
    "import anthropic\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from openai import AsyncOpenAI\n",
    "from anthropic import AsyncClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# This must be done once per kernel to allow asyncio to run in a Jupyter notebook..\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load API Keys from .env file\n",
    "load_dotenv()\n",
    "print(\"Loaded environment variables from .env file.\")\n",
    "\n",
    "# Initialize Asynchronous API Clients\n",
    "try:\n",
    "    openai_client_async = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    anthropic_client_async = AsyncClient(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "    genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "    print(\"API clients initialized successfully.\")\n",
    "except TypeError:\n",
    "    print(\"API key not found for one or more services. Please check your .env file.\")\n",
    "    # Assign None to prevent errors in subsequent cells\n",
    "    openai_client_async = None\n",
    "    anthropic_client_async = None\n",
    "\n",
    "# Define API Concurrency Limits to prevent 429 \"Too Many Requests\" errors.\n",
    "API_CONCURRENCY_LIMITS = {\n",
    "    \"google\": 30,    \n",
    "    \"anthropic\": 2, \n",
    "    \"openai\": 2,    \n",
    "}\n",
    "print(f\"API concurrency limits set to: {API_CONCURRENCY_LIMITS}\")\n",
    "\n",
    "MODEL_DICT = {\n",
    "  \"openai\": \"gpt-4.1\",\n",
    "  \"google\": \"gemini-2.5-flash\"\n",
    "}\n",
    "\n",
    "MODELS = [f\"{provider}_{model}\" for provider, model in MODEL_DICT.items()]\n",
    "print(f\"Available models: {MODELS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe2d695",
   "metadata": {},
   "source": [
    "#### Cell 5: Helper functions to avoid rate limits in API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cb47255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "import threading\n",
    "import datetime\n",
    "\n",
    "_log_lock = threading.Lock()\n",
    "def log_event(\n",
    "        level: str, \n",
    "        index: int, \n",
    "        model: str, \n",
    "        message: str\n",
    "    ):\n",
    "    \"\"\"A thread-safe logger for concurrent operations.\"\"\"\n",
    "    with _log_lock:\n",
    "        ts = datetime.datetime.now(datetime.timezone.utc).isoformat(timespec=\"milliseconds\")\n",
    "        task_id = asyncio.current_task().get_name()\n",
    "        print(f\"{ts} [{level:^7s}] [Idx {index:<4}] [Mdl: {model:<15}] [Task {task_id:<8}] {message}\")\n",
    " \n",
    "\n",
    "async def with_api_retries(\n",
    "        send_coroutine_factory,\n",
    "        *,\n",
    "        model_info: str,  # For informative logging\n",
    "        max_attempts: int = 10,\n",
    "        base_wait_seconds: int = 10\n",
    "    ):\n",
    "    \"\"\"A wrapper to handle API retries with exponential backoff.\"\"\"\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            return await send_coroutine_factory()\n",
    "        except (openai.RateLimitError, anthropic.RateLimitError, Exception) as e:\n",
    "            # Check for specific rate limit error types or a 429 status code in the error string\n",
    "            if isinstance(e, (openai.RateLimitError, anthropic.RateLimitError)) or \"429\" in str(e):\n",
    "                if attempt == max_attempts - 1:\n",
    "                    print(f\"❌ Final attempt failed for {model_info}. Giving up.\")\n",
    "                    raise\n",
    "                \n",
    "                # Exponential backoff with jitter\n",
    "                wait_time = base_wait_seconds * (2 ** attempt) + random.uniform(0, 1)\n",
    "                \n",
    "                # More informative error message\n",
    "                print(f\"🕒 Rate limit on {model_info}. Retrying in {wait_time:.2f}s... (Attempt {attempt + 1}/{max_attempts})\")\n",
    "                await asyncio.sleep(wait_time)\n",
    "            else:\n",
    "                # If it's not a rate limit error, re-raise immediately\n",
    "                raise\n",
    "    return None\n",
    "\n",
    "\n",
    "class RateLimitCoordinator:\n",
    "    def __init__(self, refill_rate_per_sec: float, max_tokens: int):\n",
    "        self.refill_rate_per_sec = refill_rate_per_sec\n",
    "        self.max_tokens = float(max_tokens)\n",
    "        self.tokens = self.max_tokens\n",
    "        self._lock = asyncio.Lock()\n",
    "        self._refill_task = None\n",
    "        \n",
    "    async def _refill(self):\n",
    "        \"\"\"The background task that refills the token bucket at 1-second intervals.\"\"\"\n",
    "        while True:\n",
    "            await asyncio.sleep(1)\n",
    "            async with self._lock:\n",
    "                self.tokens = min(self.max_tokens, self.tokens + self.refill_rate_per_sec)\n",
    "                if int(time.time()) % 10 == 0:\n",
    "                    log_event(\"REFILL\", -1, \"Coordinator\", f\"Bucket budget at {int(self.tokens)} / {int(self.max_tokens)}\")\n",
    "\n",
    "    async def start(self):\n",
    "        if self._refill_task is None:\n",
    "            self._refill_task = asyncio.create_task(self._refill())\n",
    "\n",
    "    async def stop(self):\n",
    "        if self._refill_task:\n",
    "            self._refill_task.cancel()\n",
    "            self._refill_task = None\n",
    "\n",
    "    async def get_tokens(self, index: int, model: str, tokens_needed: int):\n",
    "        while True:\n",
    "            async with self._lock:\n",
    "                if self.tokens >= tokens_needed:\n",
    "                    self.tokens -= tokens_needed\n",
    "                    log_event(\"GRANT\", index, model, f\"Permission granted. Budget: {int(self.tokens + tokens_needed)} -> {int(self.tokens)}\")\n",
    "                    return\n",
    "            \n",
    "            deficit = tokens_needed - self.tokens\n",
    "            wait_time = max(0.1, deficit / self.refill_rate_per_sec) # Ensure at least a small wait\n",
    "            \n",
    "            log_event(\"WAIT\", index, model, f\"Budget low. Needed: {tokens_needed}, Have: {int(self.tokens)}. Waiting ~{wait_time:.2f}s...\")\n",
    "            await asyncio.sleep(wait_time)\n",
    "\n",
    "    async def return_tokens(self, index: int, model: str, tokens_returned: int):\n",
    "        async with self._lock:\n",
    "            self.tokens += tokens_returned\n",
    "            log_event(\"RETURN\", index, model, f\"Tokens returned on failure. Budget restored to {int(self.tokens)}.\")\n",
    "\n",
    "    async def refund_tokens(self, index: int, model: str, tokens_refunded: int):\n",
    "        \"\"\"Refunds tokens to the budget after a successful call, correcting our estimate.\"\"\"\n",
    "        async with self._lock:\n",
    "            self.tokens += tokens_refunded\n",
    "            log_event(\"REFUND\", index, model, f\"Correcting estimate. Budget restored by {tokens_refunded} -> {int(self.tokens)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96c463c",
   "metadata": {},
   "source": [
    "#### Cell 6: Provider-specific API calling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd962c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "\n",
    "async def call_openai_async(\n",
    "        model: str,\n",
    "        system_prompt: str,\n",
    "        user_prompt: str,\n",
    "        index: int,\n",
    "        json_schema: dict,\n",
    "        openai_max_tokens: int \n",
    "    ) -> tuple[str, dict, dict]:\n",
    "    \"\"\"\n",
    "    Prepares a provider-specific schema and handles an API call to OpenAI.\n",
    "    \"\"\"\n",
    "    \n",
    "    openai_schema = copy.deepcopy(json_schema)\n",
    "\n",
    "    def add_additional_properties(schema_part):\n",
    "        if isinstance(schema_part, dict):\n",
    "            if schema_part.get(\"type\") == \"object\":\n",
    "                schema_part[\"additionalProperties\"] = False\n",
    "            for value in schema_part.values():\n",
    "                add_additional_properties(value)\n",
    "        elif isinstance(schema_part, list):\n",
    "            for item in schema_part:\n",
    "                add_additional_properties(item)\n",
    "\n",
    "    add_additional_properties(openai_schema)\n",
    "    openai_schema_wrapper = {\n",
    "        \"name\": \"template_formalization\", \n",
    "        \"strict\": True, \n",
    "        \"schema\": openai_schema\n",
    "    }\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}, \n",
    "                {\"role\": \"user\", \"content\": user_prompt}]\n",
    "    \n",
    "    model_info = f\"{model} (Index {index})\"\n",
    "    \n",
    "    response_with_headers = await with_api_retries(\n",
    "        lambda: openai_client_async.chat.completions.with_raw_response.create(\n",
    "            model=model, \n",
    "            messages=messages, \n",
    "            temperature=0, \n",
    "            max_tokens=openai_max_tokens, \n",
    "            response_format={\"type\": \"json_schema\", \"json_schema\": openai_schema_wrapper} # type: ignore\n",
    "        ),\n",
    "        model_info=model_info\n",
    "    )\n",
    "    \n",
    "    response = response_with_headers.parse()\n",
    "    text_response = response.choices[0].message.content\n",
    "    \n",
    "    usage = {\"input_tokens\": 0, \"output_tokens\": 0, \"cached_tokens\": 0}\n",
    "    if response.usage:\n",
    "        usage[\"input_tokens\"] = response.usage.prompt_tokens\n",
    "        usage[\"output_tokens\"] = response.usage.completion_tokens\n",
    "        if hasattr(response.usage, 'prompt_tokens_details') and response.usage.prompt_tokens_details:\n",
    "             usage[\"cached_tokens\"] = response.usage.prompt_tokens_details.get(\"cached_tokens\", 0)\n",
    "\n",
    "    headers = response_with_headers.headers\n",
    "    rate_limit_info = {\n",
    "        \"limit_requests\": headers.get(\"x-ratelimit-limit-requests\"),\n",
    "        \"limit_tokens\": headers.get(\"x-ratelimit-limit-tokens\"),\n",
    "        \"remaining_requests\": headers.get(\"x-ratelimit-remaining-requests\"),\n",
    "        \"remaining_tokens\": headers.get(\"x-ratelimit-remaining-tokens\"),\n",
    "        \"reset_requests\": headers.get(\"x-ratelimit-reset-requests\"),\n",
    "        \"reset_tokens\": headers.get(\"x-ratelimit-reset-tokens\"),\n",
    "    }\n",
    "             \n",
    "    return text_response, usage, rate_limit_info\n",
    "\n",
    "\n",
    "async def call_google_async(\n",
    "        model: str,\n",
    "        system_prompt: str,\n",
    "        user_prompt: str,\n",
    "        index: int,\n",
    "        json_schema: dict\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Handles a Google API call with schema enforcement and a safe\n",
    "    upper bound on output tokens to prevent runaway generation.\n",
    "    \"\"\"\n",
    "    \n",
    "    safety_settings = {\n",
    "        \"HARM_CATEGORY_HARASSMENT\": \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_HATE_SPEECH\": \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_SEXUALLY_EXPLICIT\": \"BLOCK_NONE\",\n",
    "        \"HARM_CATEGORY_DANGEROUS_CONTENT\": \"BLOCK_NONE\",\n",
    "    }\n",
    "    \n",
    "    gemini = genai.GenerativeModel(\n",
    "        model_name=model,\n",
    "        system_instruction=system_prompt,\n",
    "        safety_settings=safety_settings\n",
    "    )\n",
    "    \n",
    "    cfg = genai.types.GenerationConfig(\n",
    "        temperature=0, \n",
    "        max_output_tokens=8192, # Safe upper bound\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=json_schema\n",
    "    )\n",
    "    \n",
    "    model_info = f\"{model} (Index {index})\"\n",
    "\n",
    "    response = await with_api_retries(\n",
    "        lambda: gemini.generate_content_async(user_prompt, generation_config=cfg),\n",
    "        model_info=model_info\n",
    "    )\n",
    "\n",
    "    if not response.parts:\n",
    "        raise ValueError(f\"Google API returned an empty response for Index {index}.\")\n",
    "\n",
    "    text_response = response.text\n",
    "    usage = {\"input_tokens\": 0, \"output_tokens\": 0, \"cached_tokens\": 0}\n",
    "    if response.usage_metadata:\n",
    "        usage[\"input_tokens\"] = response.usage_metadata.prompt_token_count\n",
    "        usage[\"output_tokens\"] = response.usage_metadata.candidates_token_count\n",
    "        \n",
    "    return text_response, usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61236607",
   "metadata": {},
   "source": [
    "#### Cell 7: Single API call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdba26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "async def run_single_api_call(\n",
    "    provider: str,\n",
    "    model: str,\n",
    "    index: int,\n",
    "    tier: str,\n",
    "    dataset: 'datasets.Dataset',\n",
    "    system_prompt: str,\n",
    "    output_dir: Path,\n",
    "    provider_sem: asyncio.Semaphore,\n",
    "    json_schema: dict,\n",
    "    coordinator: RateLimitCoordinator,\n",
    "    openai_max_tokens: int,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Runs a single API call, but first checks if the output file already\n",
    "    exists to avoid re-generating completed work.\n",
    "    \"\"\"\n",
    "\n",
    "    output_path = output_dir / str(index) / f\"{provider}_{model}.txt\"\n",
    "    if output_path.exists() and output_path.stat().st_size > 0:\n",
    "        log_event(\"SKIPPED\", index, model, \"Output file already exists.\")\n",
    "        return {\n",
    "            \"provider\": provider, \"model\": model, \"index\": index,\n",
    "            \"status\": \"Skipped\", \"time_s\": 0,\n",
    "            \"input_tokens\": 0, \"output_tokens\": 0, \"cached_tokens\": 0,\n",
    "            \"utc_completed\": datetime.datetime.now(datetime.timezone.utc).isoformat(timespec=\"seconds\")\n",
    "        }\n",
    "        \n",
    "    async with provider_sem:\n",
    "        user_prompt = append_sample_to_user_prompt(tier=tier, index=index, dataset=dataset)\n",
    "\n",
    "        tokens_needed = 0\n",
    "        if provider == \"openai\":\n",
    "            estimated_prompt_tokens = len(user_prompt.split()) * 1.25\n",
    "            tokens_needed = int(estimated_prompt_tokens + openai_max_tokens)\n",
    "            await coordinator.get_tokens(index, model, tokens_needed)\n",
    "\n",
    "        start_time = time.time()\n",
    "        status = \"Failed\"\n",
    "        usage = {\"input_tokens\": 0, \"output_tokens\": 0, \"cached_tokens\": 0}\n",
    "\n",
    "        try:\n",
    "            if provider == \"openai\":\n",
    "                text_response, usage, _ = await call_openai_async(\n",
    "                    model, system_prompt, user_prompt, index, json_schema, openai_max_tokens\n",
    "                )\n",
    "                log_event(\"SUCCESS\", index, model, f\"Call OK. Usage: {json.dumps(usage)}\")\n",
    "                \n",
    "                true_cost = usage['input_tokens'] + usage['output_tokens']\n",
    "                refund_amount = tokens_needed - true_cost\n",
    "                if refund_amount > 0:\n",
    "                    await coordinator.refund_tokens(index, model, refund_amount)\n",
    "                    \n",
    "            elif provider == \"google\":\n",
    "                text_response, usage = await call_google_async(\n",
    "                    model, system_prompt, user_prompt, index, json_schema\n",
    "                )\n",
    "                log_event(\"SUCCESS\", index, model, f\"Call OK. Usage: {json.dumps(usage)}\")\n",
    "            \n",
    "            status = \"Success\"\n",
    "\n",
    "        except Exception as e:\n",
    "            log_event(\"ERROR\", index, model, f\"{type(e).__name__}: {str(e).splitlines()[0]}\")\n",
    "            text_response = f\"--- ERROR ---\\nIndex: {index}, Model: {model}\\n{type(e).__name__}: {e}\"\n",
    "            \n",
    "        finally:\n",
    "            if status == \"Failed\" and provider == \"openai\" and tokens_needed > 0:\n",
    "                await coordinator.return_tokens(index, model, tokens_needed)\n",
    "\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        output_path.write_text(text_response, encoding='utf-8')\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        return {\n",
    "            \"provider\": provider, \"model\": model, \"index\": index,\n",
    "            \"status\": status, \"time_s\": round(elapsed, 2),\n",
    "            \"input_tokens\": usage[\"input_tokens\"], \"output_tokens\": usage[\"output_tokens\"],\n",
    "            \"cached_tokens\": usage[\"cached_tokens\"],\n",
    "            \"utc_completed\": datetime.datetime.now(datetime.timezone.utc).isoformat(timespec=\"seconds\")\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9593e58",
   "metadata": {},
   "source": [
    "#### Cell 8: Main template generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4cf464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "async def generate_templates_parallel_fixed(\n",
    "    indices_to_generate: list[int],\n",
    "    tier: str = CURRENT_TIER,\n",
    "    dataset: 'datasets.Dataset' = GSM8K_TRAIN,\n",
    "    model_dict: dict[str, str] = MODEL_DICT,\n",
    "    system_prompt: str = SYSTEM_PROMPT,\n",
    "    concurrency_limits: dict[str, int] = API_CONCURRENCY_LIMITS,\n",
    "    json_schema: dict = BASE_TEMPLATE_SCHEMA,\n",
    "    openai_max_tokens: int = 4000\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Fully parallel version with a robust token bucket coordinator for OpenAI.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Template Generation (Token Bucket) ---\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    openai_coordinator = RateLimitCoordinator(refill_rate_per_sec=800, max_tokens=30000)\n",
    "    await openai_coordinator.start()\n",
    "    \n",
    "    provider_semaphores = {prov: asyncio.Semaphore(limit) for prov, limit in concurrency_limits.items()}\n",
    "    output_dir = TIER_OUTPUT_DIRS[tier]\n",
    "    \n",
    "    all_tasks = []\n",
    "    for index in indices_to_generate:\n",
    "        for provider, model in model_dict.items():\n",
    "            task = asyncio.create_task(\n",
    "                run_single_api_call(\n",
    "                    provider=provider, model=model, index=index,\n",
    "                    tier=tier, dataset=dataset, system_prompt=system_prompt,\n",
    "                    output_dir=output_dir, provider_sem=provider_semaphores[provider],\n",
    "                    json_schema=json_schema,\n",
    "                    coordinator=openai_coordinator,\n",
    "                    openai_max_tokens=openai_max_tokens\n",
    "                )\n",
    "            )\n",
    "            all_tasks.append(task)\n",
    "    \n",
    "    print(f\"Created {len(all_tasks)} total API call tasks\")\n",
    "    \n",
    "    results = []\n",
    "    try:\n",
    "        with tqdm(total=len(all_tasks), desc=\"API Calls\") as pbar:\n",
    "            for task in asyncio.as_completed(all_tasks):\n",
    "                result = await task\n",
    "                results.append(result)\n",
    "                pbar.update(1)\n",
    "    finally:\n",
    "        await openai_coordinator.stop()\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    run_ts = datetime.datetime.now(datetime.timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n",
    "    csv_path = output_dir / f\"generation_performance_{run_ts}.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"\\n--- Template Generation Complete ---\")\n",
    "    print(f\"Processed {len(indices_to_generate)} indices in {end_time - start_time:.2f} seconds.\")\n",
    "    print(f\"Performance log saved to: {csv_path}\")\n",
    "    \n",
    "    success_count = len(df[df['status'] == 'Success'])\n",
    "    total_calls = len(df)\n",
    "    if total_calls > 0:\n",
    "      print(f\"Success rate: {success_count}/{total_calls} ({100*success_count/total_calls:.1f}%)\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219062ef",
   "metadata": {},
   "source": [
    "#### Cell 9: Running the main Template generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "350c5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWER_LIMIT = 0\n",
    "UPPER_LIMIT = 3000\n",
    "INDICES_TO_GENERATE = [idx for idx in CURRENT_INDICES if idx <= UPPER_LIMIT and idx >= LOWER_LIMIT]\n",
    "\n",
    "# print(f\"Starting generation for {len(INDICES_TO_GENERATE)} indices in {CURRENT_TIER} between {LOWER_LIMIT} and {UPPER_LIMIT}.\")\n",
    "\n",
    "# perf_df = await generate_templates_parallel_fixed(indices_to_generate=INDICES_TO_GENERATE)\n",
    "\n",
    "# print(\"\\n--- Generation Performance Summary ---\")\n",
    "# perf_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
