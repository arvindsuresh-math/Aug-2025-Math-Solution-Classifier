{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "151049e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/manually_generated_errors_final.csv\n",
      "computational: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/computational-errors-generated/computational_error_catalog.csv\n",
      "conceptual_ali: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_ali.csv\n",
      "conceptual_arvind: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_arvind.csv\n",
      "conceptual_mauro: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_mauro.csv\n",
      "conceptual_ling: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_ling.csv\n",
      "conceptual_yewei: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_yewei.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Set, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- Path and Directory Definitions ---\n",
    "\n",
    "def find_project_root(marker: str = \".git\") -> Path:\n",
    "    \"\"\"Traverse upwards to find the project root, marked by the git repository.\"\"\"\n",
    "    current_path = Path.cwd().resolve()\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / marker).exists():\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    raise FileNotFoundError(f\"Could not find project root. Marker '{marker}' not found.\")\n",
    "\n",
    "VALIDATORS = [\"ali\", \"arvind\", \"mauro\", \"ling\", \"yewei\"]\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "CONCEPTUAL_ERRORS_DIR = DATA_DIR / 'conceptual-errors-accepted'\n",
    "COMPUTATIONAL_ERRORS_DIR = DATA_DIR / 'computational-errors-generated'\n",
    "CONCEPTUAL_CATALOG_DIR = DATA_DIR / 'conceptual-error-candidates'\n",
    "\n",
    "# load all catalog filepaths into a dict\n",
    "CATALOG_FILEPATH_DICT = {\n",
    "    \"manual\": DATA_DIR / 'manually_generated_errors_final.csv',\n",
    "    \"computational\": COMPUTATIONAL_ERRORS_DIR / 'computational_error_catalog.csv'\n",
    "}\n",
    "for name in VALIDATORS:\n",
    "    CATALOG_FILEPATH_DICT[f\"conceptual_{name}\"] = CONCEPTUAL_CATALOG_DIR / f'validation_catalog_{name}.csv'\n",
    "\n",
    "# Display the filepaths\n",
    "for name, path in CATALOG_FILEPATH_DICT.items():\n",
    "    print(f\"{name}: {path}\")\n",
    "\n",
    "# make dictionary with all catalogs\n",
    "CATALOG_DICT = {key: pd.read_csv(path) for key, path in CATALOG_FILEPATH_DICT.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7a0c34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual: 1963 rows\n",
      "columns: ['answer', 'erroneous_line_number', 'error_type', 'explanation', 'filepath', 'index', 'question', 'wrong_answer']\n",
      "computational: 22623 rows\n",
      "columns: ['index', 'tier', 'model', 'erroneous_line_number', 'explanation', 'wrong_answer', 'correct_trace_generated', 'target_variable', 'error_type', 'correct_value', 'flawed_value', 'repro_seed', 'date_utc', 'time_utc', 'filepath']\n",
      "conceptual_ali: 398 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n",
      "conceptual_arvind: 394 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n",
      "conceptual_mauro: 381 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n",
      "conceptual_ling: 388 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n",
      "conceptual_yewei: 381 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n"
     ]
    }
   ],
   "source": [
    "for key, df in CATALOG_DICT.items():\n",
    "    print(f\"{key}: {len(df)} rows\")\n",
    "    print(\"columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6bdb057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSM8K_TRAIN = load_dataset(\"gsm8k\", \"main\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ebb8c55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier distribution in GSM8K:\n",
      "  tier1: 2767 problems\n",
      "  tier2: 837 problems\n",
      "  tier3: 3113 problems\n",
      "  tier4: 544 problems\n",
      "  tier5: 212 problems\n"
     ]
    }
   ],
   "source": [
    "# --- Tier Definition Functions (copied from arvind-july-25.ipynb) ---\n",
    "\n",
    "def has_computational_division(solution_text: str):\n",
    "    \"\"\"Checks if a solution text contains a division operation.\"\"\"\n",
    "    pattern = re.compile(r'/\\s*\\d')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def has_float(solution_text: str):\n",
    "    \"\"\"Checks if a solution text contains a float value.\"\"\"\n",
    "    pattern = re.compile(r'(?<!\\d)\\.\\d+|\\d+\\.\\d+')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def is_symbolic(solution_text: str):\n",
    "    \"\"\"Checks if a solution text uses symbolic algebra (e.g., 'Let x...').\"\"\"\n",
    "    pattern = re.compile(r'^Let [a-zA-Z] ', re.MULTILINE)\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def mutually_disjoint_tiers(dataset):\n",
    "    \"\"\"\n",
    "    Categorizes all problems in the dataset into mutually disjoint tiers\n",
    "    based on the mathematical operations present in their solution text.\n",
    "    \"\"\"\n",
    "    tiers = {}\n",
    "    symbolic_set = {idx for idx, sample in enumerate(dataset) if is_symbolic(sample.get(\"answer\", \"\"))}\n",
    "    non_symbolic_indices = [idx for idx in range(len(dataset)) if idx not in symbolic_set]\n",
    "    \n",
    "    tiers[\"tier1\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier2\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier3\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier4\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier5\"] = sorted(list(symbolic_set))\n",
    "    return tiers\n",
    "\n",
    "# --- Create Tier Mappings ---\n",
    "\n",
    "def add_tier_column(df, tier_lists):\n",
    "    \"\"\"\n",
    "    Adds a 'tier' column to the dataframe based on the TIER_LISTS dictionary.\n",
    "    Maps each GSM8K index to its corresponding tier.\n",
    "    \"\"\"\n",
    "    index_to_tier = {}\n",
    "    for tier_name, indices in tier_lists.items():\n",
    "        for idx in indices:\n",
    "            index_to_tier[idx] = tier_name\n",
    "    \n",
    "    df['tier'] = df['index'].map(index_to_tier)\n",
    "    \n",
    "    missing_tiers = df['tier'].isna().sum()\n",
    "    if missing_tiers > 0:\n",
    "        print(f\"Warning: {missing_tiers} indices could not be mapped to tiers\")\n",
    "        df['tier'] = df['tier'].fillna('unknown')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate tier mappings for the entire GSM8K dataset\n",
    "TIER_LISTS = mutually_disjoint_tiers(GSM8K_TRAIN)\n",
    "print(\"Tier distribution in GSM8K:\")\n",
    "for tier, indices in TIER_LISTS.items():\n",
    "    print(f\"  {tier}: {len(indices)} problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e803b036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Comprehensive text sanitization function that:\n",
    "    1. Converts literal \\n to actual newlines\n",
    "    2. Replaces problematic Unicode characters with ASCII equivalents\n",
    "    3. Removes comma separators from numbers\n",
    "    \n",
    "    This prevents model generation and string parsing errors.\n",
    "    \"\"\"\n",
    "    text = text.replace('\\\\n', '\\n')\n",
    "\n",
    "    replacements = {\n",
    "        \"\\u2212\": \"-\",    # Minus Sign\n",
    "        \"\\u00d7\": \"*\",    # Multiplication Sign\n",
    "        \"\\u00f7\": \"/\",    # Division Sign\n",
    "        \"\\u22c5\": \"*\",    # Dot Operator\n",
    "        \"\\u201c\": '\"',    # Left Double Quotation Mark\n",
    "        \"\\u201d\": '\"',    # Right Double Quotation Mark\n",
    "        \"\\u2018\": \"'\",    # Left Single Quotation Mark\n",
    "        \"\\u2019\": \"'\",    # Right Single Quotation Mark\n",
    "        \"\\u2014\": \"-\",    # Em Dash\n",
    "        \"\\u2013\": \"-\",    # En Dash\n",
    "        \"\\u2026\": \"...\",  # Horizontal Ellipsis\n",
    "        \"\\u00a0\": \" \",    # No-Break Space\n",
    "        \"\\u00f1\": \"n\",    # Spanish ñ -> n\n",
    "        \"\\u200b\": \"\",     # Zero Width Space -> remove completely\n",
    "    }\n",
    "    for uni, ascii_char in replacements.items():\n",
    "        text = text.replace(uni, ascii_char)\n",
    "\n",
    "    text = re.sub(r'(\\d),(\\d)', r'\\1\\2', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def make_answer_mapping(answer: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Create a mapping from line numbers to solution lines from sanitized answer text.\n",
    "    Returns a dict mapping line identifiers (\"L1\", \"L2\", ..., \"FA\") to solution lines\n",
    "    WITHOUT calculator annotations.\n",
    "    \"\"\"\n",
    "    lines = answer.split('\\n')\n",
    "    final_answer = None\n",
    "    answer_mapping = {}\n",
    "\n",
    "    if lines and re.match(r'^\\s*####\\s*.*$', lines[-1]):\n",
    "        final_answer_line = lines.pop().strip()\n",
    "        match = re.search(r'####\\s*(.*)', final_answer_line)\n",
    "        if match:\n",
    "            final_answer = match.group(1).strip()\n",
    "\n",
    "    cleaned_lines = [line.strip() for line in lines if line.strip()]\n",
    "    for i, line in enumerate(cleaned_lines):\n",
    "        # Remove calculator annotations from each line\n",
    "        clean_line = re.sub(r'<<.*?>>', '', line).strip()\n",
    "        answer_mapping[f\"L{i+1}\"] = clean_line\n",
    "    \n",
    "    if final_answer is not None:\n",
    "        answer_mapping[\"FA\"] = final_answer\n",
    "    \n",
    "    return answer_mapping\n",
    "\n",
    "def make_separate_mappings(answer: str) -> Tuple[Dict[str, str], Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Extract calculator equations and create clean answer mapping without annotations.\n",
    "    Takes the original answer text and returns both equation mapping and clean answer mapping.\n",
    "    \"\"\"\n",
    "    lines = answer.split('\\n')\n",
    "    final_answer = None\n",
    "    \n",
    "    # Handle final answer line\n",
    "    if lines and re.match(r'^\\s*####\\s*.*$', lines[-1]):\n",
    "        final_answer_line = lines.pop().strip()\n",
    "        match = re.search(r'####\\s*(.*)', final_answer_line)\n",
    "        if match:\n",
    "            final_answer = match.group(1).strip()\n",
    "\n",
    "    cleaned_lines = [line.strip() for line in lines if line.strip()]\n",
    "    \n",
    "    eqn_mapping = {}\n",
    "    clean_answer_mapping = {}\n",
    "    \n",
    "    for i, line in enumerate(cleaned_lines):\n",
    "        line_id = f\"L{i+1}\"\n",
    "        \n",
    "        # Extract calculator equations\n",
    "        calculator_matches = re.findall(r'<<(.*?)>>', line)\n",
    "        if calculator_matches:\n",
    "            eqn_mapping[line_id] = calculator_matches[0]\n",
    "        else:\n",
    "            eqn_mapping[line_id] = \"\"\n",
    "        \n",
    "        # Create clean text without calculator annotations\n",
    "        clean_text = re.sub(r'<<.*?>>', '', line).strip()\n",
    "        clean_answer_mapping[line_id] = clean_text\n",
    "    \n",
    "    # Handle final answer\n",
    "    if final_answer is not None:\n",
    "        clean_answer_mapping[\"FA\"] = final_answer\n",
    "        eqn_mapping[\"FA\"] = \"\"\n",
    "    \n",
    "    return eqn_mapping, clean_answer_mapping\n",
    "\n",
    "def reconstruct_answer_from_clean_mapping(clean_mapping: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Returns a reconstructed answer text from clean mapping with FINAL ANSWER: prefix.\n",
    "    \"\"\"\n",
    "    if not clean_mapping:\n",
    "        return \"\"\n",
    "    \n",
    "    lines = []\n",
    "    i = 1\n",
    "    while f\"L{i}\" in clean_mapping:\n",
    "        line_text = clean_mapping[f\"L{i}\"].strip()\n",
    "        if line_text:\n",
    "            lines.append(line_text)\n",
    "        i += 1\n",
    "    \n",
    "    if \"FA\" in clean_mapping and clean_mapping[\"FA\"].strip():\n",
    "        lines.append(f\"FINAL ANSWER: {clean_mapping['FA'].strip()}\")\n",
    "    \n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "def process_answer_with_full_mappings(\n",
    "        answer_text: str,\n",
    "        answer_prefix: str) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Process an answer text and extract all mappings and derived information.\n",
    "    \n",
    "    Args:\n",
    "        answer_text: Raw answer text\n",
    "        answer_prefix: \"correct\" or \"flawed\"\n",
    "    \n",
    "    Returns:\n",
    "        Dict containing all processed information or None if processing fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sanitized_text = sanitize_text(answer_text)\n",
    "        \n",
    "        # Extract equations and clean mappings from original text\n",
    "        eqn_mapping, clean_answer_mapping = make_separate_mappings(sanitized_text)\n",
    "        \n",
    "        if not clean_answer_mapping:\n",
    "            return None\n",
    "\n",
    "        # Reconstruct clean answer\n",
    "        reconstructed_answer = reconstruct_answer_from_clean_mapping(clean_answer_mapping)\n",
    "        \n",
    "        # Store the CLEAN mapping as the main answer mapping\n",
    "        answer_mapping_json = json.dumps(clean_answer_mapping, ensure_ascii=False, indent=2)\n",
    "        eqn_mapping_json = json.dumps(eqn_mapping, ensure_ascii=False, indent=2)\n",
    "\n",
    "        return {\n",
    "            answer_prefix + '_answer': reconstructed_answer,\n",
    "            answer_prefix + '_mapping': answer_mapping_json,  # Now clean\n",
    "            answer_prefix + '_eqn_mapping': eqn_mapping_json,\n",
    "            answer_prefix + '_answer_length': len(clean_answer_mapping)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Any processing error returns None, will be handled as problematic\n",
    "        return None\n",
    "\n",
    "def validate_line_number_with_mapping(erroneous_line_number: str, answer_mapping: Dict[str, str]) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the erroneous line number exists in the answer mapping, False otherwise.\n",
    "    \"\"\"\n",
    "    if not erroneous_line_number or not answer_mapping:\n",
    "        return False\n",
    "    return erroneous_line_number in answer_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25450664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_catalog_row(\n",
    "        gsm8k_problem: Dict, \n",
    "        wrong_answer_text: str,\n",
    "        erroneous_line_number: str, \n",
    "        explanation: str,\n",
    "        error_type: str, \n",
    "        error_subtype: str, \n",
    "        source: str,\n",
    "        tier_lists: Dict,\n",
    "        catalog_index: int) -> Tuple[Dict[str, any], bool]:\n",
    "    \"\"\"\n",
    "    Process a single catalog row and return all required columns.\n",
    "    \n",
    "    Args:\n",
    "        gsm8k_problem: GSM8K problem data\n",
    "        wrong_answer_text: Wrong answer text\n",
    "        erroneous_line_number: Line identifier with error\n",
    "        explanation: Error explanation\n",
    "        error_type: Type of error (computational_error/conceptual_error)\n",
    "        error_subtype: Subtype of error\n",
    "        source: Source of data (manual/programmatic)\n",
    "        tier_lists: Tier mapping dictionary\n",
    "        catalog_index: The GSM8K index from the source catalog\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (processed_row_dict, is_successful)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        problem_index = catalog_index\n",
    "        \n",
    "        # Determine tier\n",
    "        problem_tier = None\n",
    "        for tier_name, indices in tier_lists.items():\n",
    "            if problem_index in indices:\n",
    "                problem_tier = tier_name\n",
    "                break\n",
    "        \n",
    "        # Process question\n",
    "        cleaned_question = sanitize_text(gsm8k_problem['question'])\n",
    "        \n",
    "        # Process correct answer\n",
    "        correct_processed = process_answer_with_full_mappings(gsm8k_problem['answer'], \"correct\")\n",
    "        if not correct_processed:\n",
    "            return {}, False\n",
    "        \n",
    "        # Process wrong answer\n",
    "        wrong_processed = process_answer_with_full_mappings(wrong_answer_text, \"wrong\")\n",
    "        if not wrong_processed:\n",
    "            return {}, False\n",
    "        \n",
    "        # Parse the clean mappings for validation and line extraction\n",
    "        correct_mapping = json.loads(correct_processed['correct_mapping'])\n",
    "        wrong_mapping = json.loads(wrong_processed['wrong_mapping'])\n",
    "        wrong_eqn_mapping = json.loads(wrong_processed['wrong_eqn_mapping'])\n",
    "        \n",
    "        # Validate erroneous line number against correct answer\n",
    "        if not validate_line_number_with_mapping(erroneous_line_number, correct_mapping):\n",
    "            return {}, False\n",
    "        \n",
    "        # Extract erroneous line information from wrong answer (already clean)\n",
    "        if erroneous_line_number == \"FA\":\n",
    "            # For final answer, reconstruct with \"FINAL ANSWER:\" prefix\n",
    "            fa_content = wrong_mapping.get(\"FA\", \"\")\n",
    "            erroneous_line = f\"FINAL ANSWER: {fa_content}\" if fa_content else \"\"\n",
    "        else:\n",
    "            # For regular lines, use the clean version directly\n",
    "            erroneous_line = wrong_mapping.get(erroneous_line_number, \"\")\n",
    "\n",
    "        erroneous_line_eqn = wrong_eqn_mapping.get(erroneous_line_number, \"\")\n",
    "        \n",
    "        # Build the complete row\n",
    "        processed_row = {\n",
    "            'index': problem_index,\n",
    "            'tier': problem_tier,\n",
    "            'question': cleaned_question,\n",
    "            'correct_answer': correct_processed['correct_answer'],\n",
    "            'wrong_answer': wrong_processed['wrong_answer'],\n",
    "            'error_type': error_type,\n",
    "            'explanation': explanation,\n",
    "            'erroneous_line_number': erroneous_line_number,\n",
    "            'erroneous_line': erroneous_line,\n",
    "            'erroneous_line_eqn': erroneous_line_eqn,\n",
    "            'correct_answer_mapping': correct_processed['correct_mapping'],\n",
    "            'wrong_answer_mapping': wrong_processed['wrong_mapping'],\n",
    "            'correct_eqn_mapping': correct_processed['correct_eqn_mapping'],\n",
    "            'wrong_eqn_mapping': wrong_processed['wrong_eqn_mapping'],\n",
    "            'correct_answer_length': correct_processed['correct_answer_length'],\n",
    "            'wrong_answer_length': wrong_processed['wrong_answer_length'],\n",
    "            'source': source,\n",
    "            'error_subtype': error_subtype\n",
    "        }\n",
    "        \n",
    "        return processed_row, True\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {}, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b9f8c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_manual_catalog_with_new_pipeline(catalog_dict, gsm8k_train, tier_lists) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Process manual catalog using the new pipeline with full mappings.\n",
    "    \"\"\"\n",
    "    print(\"=== Processing Manual Catalog with New Pipeline ===\")\n",
    "    \n",
    "    df = catalog_dict['manual'].copy()\n",
    "    print(f\"Initial rows: {len(df)}\")\n",
    "    \n",
    "    clean_rows = []\n",
    "    problematic_rows = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing manual catalog\"):\n",
    "        try:\n",
    "            problem_index = int(row['index'])\n",
    "            \n",
    "            # Check if erroneous_line_number is missing\n",
    "            if pd.isna(row['erroneous_line_number']):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': 'Missing erroneous_line_number',\n",
    "                    'source_catalog': 'manual'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Get GSM8K data\n",
    "            if problem_index >= len(gsm8k_train):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': f'Index {problem_index} out of range',\n",
    "                    'source_catalog': 'manual'\n",
    "                })\n",
    "                continue\n",
    "                \n",
    "            gsm8k_problem = gsm8k_train[problem_index]\n",
    "            \n",
    "            # Process using the new pipeline\n",
    "            processed_row, success = process_single_catalog_row(\n",
    "                gsm8k_problem=gsm8k_problem,\n",
    "                wrong_answer_text=row['wrong_answer'],\n",
    "                erroneous_line_number=row['erroneous_line_number'],\n",
    "                explanation=row['explanation'],\n",
    "                error_type=row['error_type'] + '_error',\n",
    "                error_subtype='NA',\n",
    "                source='manual',\n",
    "                tier_lists=tier_lists,\n",
    "                catalog_index=problem_index  # Add this line\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                clean_rows.append(processed_row)\n",
    "            else:\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': 'Processing failed in pipeline',\n",
    "                    'source_catalog': 'manual'\n",
    "                })\n",
    "            \n",
    "        except Exception as e:\n",
    "            problematic_rows.append({\n",
    "                **row.to_dict(),\n",
    "                'error_reason': f'Processing error: {str(e)}',\n",
    "                'source_catalog': 'manual'\n",
    "            })\n",
    "    \n",
    "    clean_df = pd.DataFrame(clean_rows)\n",
    "    problematic_df = pd.DataFrame(problematic_rows)\n",
    "    \n",
    "    print(f\"Clean rows: {len(clean_df)}\")\n",
    "    print(f\"Problematic rows: {len(problematic_df)}\")\n",
    "    \n",
    "    return clean_df, problematic_df\n",
    "\n",
    "def process_computational_catalog_with_new_pipeline(catalog_dict, gsm8k_train, tier_lists) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Process computational catalog using the new pipeline with full mappings.\n",
    "    \"\"\"\n",
    "    print(\"=== Processing Computational Catalog with New Pipeline ===\")\n",
    "    \n",
    "    df = catalog_dict['computational'].copy()\n",
    "    print(f\"Initial rows: {len(df)}\")\n",
    "    \n",
    "    clean_rows = []\n",
    "    problematic_rows = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing computational catalog\"):\n",
    "        try:\n",
    "            problem_index = int(row['index'])\n",
    "            \n",
    "            # Check if erroneous_line_number is missing\n",
    "            if pd.isna(row['erroneous_line_number']):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': 'Missing erroneous_line_number',\n",
    "                    'source_catalog': 'computational'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Get GSM8K data\n",
    "            if problem_index >= len(gsm8k_train):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': f'Index {problem_index} out of range',\n",
    "                    'source_catalog': 'computational'\n",
    "                })\n",
    "                continue\n",
    "                \n",
    "            gsm8k_problem = gsm8k_train[problem_index]\n",
    "            \n",
    "            # Check if this is tier5 and exclude it\n",
    "            problem_tier = None\n",
    "            for tier_name, indices in tier_lists.items():\n",
    "                if problem_index in indices:\n",
    "                    problem_tier = tier_name\n",
    "                    break\n",
    "            \n",
    "            if problem_tier == 'tier5':\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': 'Excluded tier5 problem',\n",
    "                    'source_catalog': 'computational'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Process using the new pipeline\n",
    "            processed_row, success = process_single_catalog_row(\n",
    "                gsm8k_problem=gsm8k_problem,\n",
    "                wrong_answer_text=row['wrong_answer'],\n",
    "                erroneous_line_number=row['erroneous_line_number'],\n",
    "                explanation=row['explanation'],\n",
    "                error_type='computational_error',\n",
    "                error_subtype=row['error_type'],\n",
    "                source='programmatic',\n",
    "                tier_lists=tier_lists,\n",
    "                catalog_index=problem_index  # Add this line\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                clean_rows.append(processed_row)\n",
    "            else:\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': 'Processing failed in pipeline',\n",
    "                    'source_catalog': 'computational'\n",
    "                })\n",
    "            \n",
    "        except Exception as e:\n",
    "            problematic_rows.append({\n",
    "                **row.to_dict(),\n",
    "                'error_reason': f'Processing error: {str(e)}',\n",
    "                'source_catalog': 'computational'\n",
    "            })\n",
    "    \n",
    "    clean_df = pd.DataFrame(clean_rows)\n",
    "    problematic_df = pd.DataFrame(problematic_rows)\n",
    "    \n",
    "    print(f\"Clean rows: {len(clean_df)}\")\n",
    "    print(f\"Problematic rows: {len(problematic_df)}\")\n",
    "    \n",
    "    return clean_df, problematic_df\n",
    "\n",
    "def process_validator_catalogs_with_new_pipeline(catalog_dict, gsm8k_train, tier_lists, validators, project_root) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Process all validator catalogs using the new pipeline with full mappings.\n",
    "    \"\"\"\n",
    "    print(\"=== Processing Validator Catalogs with New Pipeline ===\")\n",
    "    \n",
    "    all_clean_rows = []\n",
    "    all_problematic_rows = []\n",
    "    \n",
    "    def check_file_exists_and_get_path(filepath, base_dir=None):\n",
    "        \"\"\"\n",
    "        Check if a file exists and return the correct path, handling cross-platform path issues.\n",
    "        \"\"\"\n",
    "        if pd.isna(filepath) or filepath == \"\":\n",
    "            return None, False\n",
    "        \n",
    "        normalized_filepath = str(filepath).replace('\\\\', '/')\n",
    "        file_path = Path(normalized_filepath)\n",
    "        \n",
    "        if not file_path.is_absolute():\n",
    "            full_path = project_root / file_path\n",
    "        else:\n",
    "            full_path = file_path\n",
    "        \n",
    "        return full_path, full_path.exists()\n",
    "    \n",
    "    def fix_answer_formatting(wrong_answer: str) -> str:\n",
    "        \"\"\"\n",
    "        Fixes the formatting of wrong answers by moving the final answer line\n",
    "        from the beginning to the end if it's misplaced.\n",
    "        \"\"\"\n",
    "        if not isinstance(wrong_answer, str):\n",
    "            return wrong_answer\n",
    "        \n",
    "        lines = wrong_answer.strip().split('\\n')\n",
    "        final_answer_line = None\n",
    "        other_lines = []\n",
    "        \n",
    "        for line in lines:\n",
    "            if re.match(r'^\\s*####\\s*.*$', line.strip()):\n",
    "                final_answer_line = line.strip()\n",
    "            elif line.strip():\n",
    "                other_lines.append(line)\n",
    "        \n",
    "        if final_answer_line and other_lines:\n",
    "            return '\\n'.join(other_lines) + '\\n' + final_answer_line\n",
    "        elif final_answer_line:\n",
    "            return final_answer_line\n",
    "        else:\n",
    "            return wrong_answer\n",
    "    \n",
    "    for validator in validators:\n",
    "        print(f\"\\nProcessing validator: {validator}\")\n",
    "        df = catalog_dict[f'conceptual_{validator}'].copy()\n",
    "        \n",
    "        # Filter to only accepted samples\n",
    "        df = df[df['status'] == 'accepted']\n",
    "        print(f\"Accepted rows for {validator}: {len(df)}\")\n",
    "        \n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Processing {validator}\"):\n",
    "            try:\n",
    "                problem_index = int(row['index'])\n",
    "                \n",
    "                # Get GSM8K data\n",
    "                if problem_index >= len(gsm8k_train):\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'Index {problem_index} out of range',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                    \n",
    "                gsm8k_problem = gsm8k_train[problem_index]\n",
    "                \n",
    "                # Check if this is tier5 and exclude it\n",
    "                problem_tier = None\n",
    "                for tier_name, indices in tier_lists.items():\n",
    "                    if problem_index in indices:\n",
    "                        problem_tier = tier_name\n",
    "                        break\n",
    "                \n",
    "                if problem_tier == 'tier5':\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': 'Excluded tier5 problem',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Load JSON file with proper path handling\n",
    "                try:\n",
    "                    filepath, file_exists = check_file_exists_and_get_path(row['filepath'])\n",
    "                    \n",
    "                    if not file_exists or filepath is None:\n",
    "                        all_problematic_rows.append({\n",
    "                            **row.to_dict(),\n",
    "                            'error_reason': f'JSON file not found: {row[\"filepath\"]}',\n",
    "                            'source_catalog': f'conceptual_{validator}'\n",
    "                        })\n",
    "                        continue\n",
    "                    \n",
    "                    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                        json_data = json.load(f)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'JSON loading error: {str(e)}',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Extract data from JSON\n",
    "                try:\n",
    "                    raw_wrong_answer = json_data['context']['flawed_solution']\n",
    "                    explanation = json_data['error_details']['explanation']\n",
    "                    erroneous_line_number = json_data['error_details']['erroneous_line_number']\n",
    "                    error_subtype = json_data['error_details']['error_type']\n",
    "                except KeyError as e:\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'Missing JSON field: {str(e)}',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Fix the answer formatting\n",
    "                wrong_answer = fix_answer_formatting(raw_wrong_answer)\n",
    "                \n",
    "                # Check for null erroneous_line_number\n",
    "                if erroneous_line_number is None or erroneous_line_number == \"null\":\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'Null erroneous_line_number in JSON',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Process using the new pipeline\n",
    "                processed_row, success = process_single_catalog_row(\n",
    "                    gsm8k_problem=gsm8k_problem,\n",
    "                    wrong_answer_text=wrong_answer,\n",
    "                    erroneous_line_number=erroneous_line_number,\n",
    "                    explanation=explanation,\n",
    "                    error_type='conceptual_error',\n",
    "                    error_subtype=error_subtype,\n",
    "                    source='programmatic',\n",
    "                    tier_lists=tier_lists,\n",
    "                    catalog_index=problem_index  # Add this line\n",
    "                )\n",
    "                \n",
    "                if success:\n",
    "                    all_clean_rows.append(processed_row)\n",
    "                else:\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': 'Processing failed in pipeline',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                \n",
    "            except Exception as e:\n",
    "                all_problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': f'Processing error: {str(e)}',\n",
    "                    'source_catalog': f'conceptual_{validator}'\n",
    "                })\n",
    "    \n",
    "    clean_df = pd.DataFrame(all_clean_rows)\n",
    "    problematic_df = pd.DataFrame(all_problematic_rows)\n",
    "    \n",
    "    print(f\"\\nTotal clean rows: {len(clean_df)}\")\n",
    "    print(f\"Total problematic rows: {len(problematic_df)}\")\n",
    "    \n",
    "    return clean_df, problematic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5739e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_CATALOG_COLUMNS = [\n",
    "    'index', \n",
    "    'tier', \n",
    "    'question', \n",
    "    'correct_answer', \n",
    "    'wrong_answer', \n",
    "    'error_type', \n",
    "    'explanation', \n",
    "    'erroneous_line_number', \n",
    "    'erroneous_line', \n",
    "    'erroneous_line_eqn', \n",
    "    'correct_answer_mapping', \n",
    "    'wrong_answer_mapping',\n",
    "    'correct_eqn_mapping', \n",
    "    'wrong_eqn_mapping', \n",
    "    'correct_answer_length',\n",
    "    'wrong_answer_length', \n",
    "    'source', \n",
    "    'error_subtype'\n",
    "]\n",
    "\n",
    "def create_master_catalogs_with_new_structure(manual_clean, computational_clean, validator_clean, \n",
    "                          manual_problematic, computational_problematic, validator_problematic):\n",
    "    \"\"\"\n",
    "    Combines all clean and problematic dataframes into final master catalogs with new structure.\n",
    "    \"\"\"\n",
    "    print(\"=== Creating Master Catalogs with New Structure ===\")\n",
    "    \n",
    "    # Combine all clean dataframes\n",
    "    all_clean_dfs = []\n",
    "    if not manual_clean.empty:\n",
    "        all_clean_dfs.append(manual_clean)\n",
    "    if not computational_clean.empty:\n",
    "        all_clean_dfs.append(computational_clean)\n",
    "    if not validator_clean.empty:\n",
    "        all_clean_dfs.append(validator_clean)\n",
    "    \n",
    "    master_catalog = pd.concat(all_clean_dfs, ignore_index=True) if all_clean_dfs else pd.DataFrame()\n",
    "    \n",
    "    # Combine all problematic dataframes\n",
    "    all_problematic_dfs = []\n",
    "    if not manual_problematic.empty:\n",
    "        all_problematic_dfs.append(manual_problematic)\n",
    "    if not computational_problematic.empty:\n",
    "        all_problematic_dfs.append(computational_problematic)\n",
    "    if not validator_problematic.empty:\n",
    "        all_problematic_dfs.append(validator_problematic)\n",
    "    \n",
    "    catalog_problematic = pd.concat(all_problematic_dfs, ignore_index=True) if all_problematic_dfs else pd.DataFrame()\n",
    "    \n",
    "    # Ensure consistent column order for master catalog\n",
    "    if not master_catalog.empty:\n",
    "        master_catalog = master_catalog[MASTER_CATALOG_COLUMNS]\n",
    "    \n",
    "    print(f\"Master catalog rows: {len(master_catalog)}\")\n",
    "    print(f\"Problematic rows: {len(catalog_problematic)}\")\n",
    "    \n",
    "    return master_catalog, catalog_problematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39977ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Full Pipeline Execution\n",
      "================================================================================\n",
      "=== Processing Manual Catalog with New Pipeline ===\n",
      "Initial rows: 1963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d723e6687db442c962db86467e85116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing manual catalog:   0%|          | 0/1963 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean rows: 1740\n",
      "Problematic rows: 223\n",
      "=== Processing Computational Catalog with New Pipeline ===\n",
      "Initial rows: 22623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7a9bad17a14cf2ae2e975628fe883b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing computational catalog:   0%|          | 0/22623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean rows: 21768\n",
      "Problematic rows: 855\n",
      "=== Processing Validator Catalogs with New Pipeline ===\n",
      "\n",
      "Processing validator: ali\n",
      "Accepted rows for ali: 341\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ebf906cdbd4ba4b1ea7d46492dd682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ali:   0%|          | 0/341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validator: arvind\n",
      "Accepted rows for arvind: 91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682a4e3ddd594a1aa6735dbe1ebb3129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing arvind:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validator: mauro\n",
      "Accepted rows for mauro: 312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0faa49fb2bbb45cd8b6f1e33dc4680c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing mauro:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validator: ling\n",
      "Accepted rows for ling: 110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd24f41078c43d7ba661e17934066e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ling:   0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validator: yewei\n",
      "Accepted rows for yewei: 290\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ba3500759241f3a765453e99ef4893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing yewei:   0%|          | 0/290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total clean rows: 1144\n",
      "Total problematic rows: 0\n",
      "=== Creating Master Catalogs with New Structure ===\n",
      "Master catalog rows: 24652\n",
      "Problematic rows: 1078\n",
      "\n",
      "🎉 Pipeline Execution Complete!\n",
      "✅ Master catalog: 24,652 rows\n",
      "❌ Problematic rows: 1,078 rows\n"
     ]
    }
   ],
   "source": [
    "# 1. Run the full pipeline\n",
    "print(\"🚀 Starting Full Pipeline Execution\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Process manual catalog\n",
    "manual_clean, manual_problematic = process_manual_catalog_with_new_pipeline(\n",
    "    CATALOG_DICT, GSM8K_TRAIN, TIER_LISTS\n",
    ")\n",
    "\n",
    "# Process computational catalog  \n",
    "computational_clean, computational_problematic = process_computational_catalog_with_new_pipeline(\n",
    "    CATALOG_DICT, GSM8K_TRAIN, TIER_LISTS\n",
    ")\n",
    "\n",
    "# Process validator catalogs\n",
    "validator_clean, validator_problematic = process_validator_catalogs_with_new_pipeline(\n",
    "    CATALOG_DICT, GSM8K_TRAIN, TIER_LISTS, VALIDATORS, PROJECT_ROOT\n",
    ")\n",
    "\n",
    "# Create master catalogs\n",
    "master_catalog, catalog_problematic = create_master_catalogs_with_new_structure(\n",
    "    manual_clean, computational_clean, validator_clean,\n",
    "    manual_problematic, computational_problematic, validator_problematic\n",
    ")\n",
    "\n",
    "print(\"\\n🎉 Pipeline Execution Complete!\")\n",
    "print(f\"✅ Master catalog: {len(master_catalog):,} rows\")\n",
    "print(f\"❌ Problematic rows: {len(catalog_problematic):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "73ed4200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎲 RANDOM SAMPLE FROM EACH SOURCE CATALOG\n",
      "================================================================================\n",
      "\n",
      "🔍 MANUAL CATALOG\n",
      "------------------------------------------------------------\n",
      "📋 Index: 1184 | Tier: tier1 | Error Type: computational_error\n",
      "📝 Error Subtype: NA\n",
      "🎯 Erroneous Line Number: L3\n",
      "🔴 Erroneous Line: A medium bed can hold 3 rows with 20 seeds sown per row, 3 * 20=50 seeds per medium bed.\n",
      "🧮 Erroneous Line Equation: 3*20=50\n",
      "\n",
      "❓ Question:\n",
      "Grace is looking to plant some lettuce in her raised bed garden. Her raised bed is comprised of 2 large beds on top with 2 medium beds on the bottom. The top bed can hold 4 rows of lettuce with 25 seeds being sown per row. The medium bed can house 3 rows with 20 seeds being sown per row. How many seeds can Grace plant in all four beds of her raised bed garden?\n",
      "\n",
      "✅ Correct Answer (Full):\n",
      "A large bed can hold 4 rows with 25 seeds per row, 4 * 25=100 seeds per large bed\n",
      "100 seeds per large bed and there are 2 beds, 100 * 2= 200 seeds needed in total for both large beds.\n",
      "A medium bed can hold 3 rows with 20 seeds sown per row, 3 * 20=60 seeds per medium bed.\n",
      "60 seeds per medium bed and there are 2 medium beds, 60 * 2=120 seeds needed in total for both medium beds.\n",
      "200 seeds needed for the large beds combined with 120 seeds needed for the medium beds comes to 200 +120= 320 seeds needed to plant all four beds of the raised garden bed.\n",
      "FINAL ANSWER: 320\n",
      "\n",
      "❌ Wrong Answer (Full):\n",
      "A large bed can hold 4 rows with 25 seeds per row, 4 * 25=100 seeds per large bed\n",
      "100 seeds per large bed and there are 2 beds, 100 * 2= 200 seeds needed in total for both large beds.\n",
      "A medium bed can hold 3 rows with 20 seeds sown per row, 3 * 20=50 seeds per medium bed.\n",
      "50 seeds per medium bed and there are 2 medium beds, 50 * 2=100 seeds needed in total for both medium beds.\n",
      "200 seeds needed for the large beds combined with 100 seeds needed for the medium beds comes to 200 +100= 300 seeds needed to plant all four beds of the raised garden bed.\n",
      "FINAL ANSWER: 300\n",
      "\n",
      "💡 Explanation:\n",
      "computational error: A medium bed can hold 3 rows with 20 seeds sown per row, 3 * 20 = 60 seeds per medium bed (the calculation of 3*20 was incorrect).\n",
      "\n",
      "📊 Answer Lengths:\n",
      "   Correct: 6 lines\n",
      "   Wrong: 6 lines\n",
      "\n",
      "🗂️ Correct Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"A large bed can hold 4 rows with 25 seeds per row, 4 * 25=100 seeds per large bed\",\n",
      "  \"L2\": \"100 seeds per large bed and there are 2 beds, 100 * 2= 200 seeds needed in total for both large beds.\",\n",
      "  \"L3\": \"A medium bed can hold 3 rows with 20 seeds sown per row, 3 * 20=60 seeds per medium bed.\",\n",
      "  \"L4\": \"60 seeds per medium bed and there are 2 medium beds, 60 * 2=120 seeds needed in total for both medium beds.\",\n",
      "  \"L5\": \"200 seeds needed for the large beds combined with 120 seeds needed for the medium beds comes to 200 +120= 320 seeds needed to plant all four beds of the raised garden bed.\",\n",
      "  \"FA\": \"320\"\n",
      "}\n",
      "\n",
      "🗂️ Wrong Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"A large bed can hold 4 rows with 25 seeds per row, 4 * 25=100 seeds per large bed\",\n",
      "  \"L2\": \"100 seeds per large bed and there are 2 beds, 100 * 2= 200 seeds needed in total for both large beds.\",\n",
      "  \"L3\": \"A medium bed can hold 3 rows with 20 seeds sown per row, 3 * 20=50 seeds per medium bed.\",\n",
      "  \"L4\": \"50 seeds per medium bed and there are 2 medium beds, 50 * 2=100 seeds needed in total for both medium beds.\",\n",
      "  \"L5\": \"200 seeds needed for the large beds combined with 100 seeds needed for the medium beds comes to 200 +100= 300 seeds needed to plant all four beds of the raised garden bed.\",\n",
      "  \"FA\": \"300\"\n",
      "}\n",
      "\n",
      "🧮 Correct Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"4*25=100\",\n",
      "  \"L2\": \"100*2=200\",\n",
      "  \"L3\": \"3*20=60\",\n",
      "  \"L4\": \"60*2=120\",\n",
      "  \"L5\": \"200+120=320\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "🧮 Wrong Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"4*25=100\",\n",
      "  \"L2\": \"100*2=200\",\n",
      "  \"L3\": \"3*20=50\",\n",
      "  \"L4\": \"50*2=100\",\n",
      "  \"L5\": \"200+100=300\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "🏷️ Source: manual\n",
      "================================================================================\n",
      "\n",
      "🔍 COMPUTATIONAL CATALOG\n",
      "------------------------------------------------------------\n",
      "📋 Index: 6725 | Tier: tier1 | Error Type: computational_error\n",
      "📝 Error Subtype: generate_digit_transposition_error\n",
      "🎯 Erroneous Line Number: L1\n",
      "🔴 Erroneous Line: Janice can earn $30 x 5 = $105 per week.\n",
      "🧮 Erroneous Line Equation: 30*5=105\n",
      "\n",
      "❓ Question:\n",
      "Janice has been working part-time at a convenience store 5 days a week. She can earn $30 per day and can earn $15 more when she works a 2 hour overtime shift. If she works three overtime shifts this week, how much will she earn this week?\n",
      "\n",
      "✅ Correct Answer (Full):\n",
      "Janice can earn $30 x 5 = $150 per week.\n",
      "She will earn $15 x 3 = $45 more if she works three overtime shifts.\n",
      "Therefore, Janice will earn $150 + $45 = $195 this week.\n",
      "FINAL ANSWER: 195\n",
      "\n",
      "❌ Wrong Answer (Full):\n",
      "Janice can earn $30 x 5 = $105 per week.\n",
      "She will earn $15 x 3 = $45 more if she works three overtime shifts.\n",
      "Therefore, Janice will earn $105 + $45 = $150 this week.\n",
      "FINAL ANSWER: 150\n",
      "\n",
      "💡 Explanation:\n",
      "The result of this computation should be 150, not 105. It appears two adjacent digits were swapped.\n",
      "\n",
      "📊 Answer Lengths:\n",
      "   Correct: 4 lines\n",
      "   Wrong: 4 lines\n",
      "\n",
      "🗂️ Correct Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"Janice can earn $30 x 5 = $150 per week.\",\n",
      "  \"L2\": \"She will earn $15 x 3 = $45 more if she works three overtime shifts.\",\n",
      "  \"L3\": \"Therefore, Janice will earn $150 + $45 = $195 this week.\",\n",
      "  \"FA\": \"195\"\n",
      "}\n",
      "\n",
      "🗂️ Wrong Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"Janice can earn $30 x 5 = $105 per week.\",\n",
      "  \"L2\": \"She will earn $15 x 3 = $45 more if she works three overtime shifts.\",\n",
      "  \"L3\": \"Therefore, Janice will earn $105 + $45 = $150 this week.\",\n",
      "  \"FA\": \"150\"\n",
      "}\n",
      "\n",
      "🧮 Correct Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"30*5=150\",\n",
      "  \"L2\": \"15*3=45\",\n",
      "  \"L3\": \"150+45=195\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "🧮 Wrong Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"30*5=105\",\n",
      "  \"L2\": \"15*3=45\",\n",
      "  \"L3\": \"105+45=150\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "🏷️ Source: programmatic\n",
      "================================================================================\n",
      "\n",
      "🔍 CONCEPTUAL VALIDATOR #1\n",
      "------------------------------------------------------------\n",
      "📋 Index: 3224 | Tier: tier4 | Error Type: conceptual_error\n",
      "📝 Error Subtype: operator_swap\n",
      "🎯 Erroneous Line Number: L2\n",
      "🔴 Erroneous Line: Traveling 15 minutes at 16 miles per hour, Stephen travels 16/0.25 = 64 miles.\n",
      "🧮 Erroneous Line Equation: \n",
      "\n",
      "❓ Question:\n",
      "Stephen rides his bicycle to church.  During the first third of his trip, he travels at a speed of 16 miles per hour. During the second third of his trip, riding uphill, he travels a speed of 12 miles per hour.  During the last third of his trip, he rides downhill at a speed of 20 miles per hour.  If each third of his trip takes 15 minutes, what is the distance Stephen rides his bicycle to church, in miles?\n",
      "\n",
      "✅ Correct Answer (Full):\n",
      "15 minutes is 15/60=0.25 hours.\n",
      "Traveling 15 minutes at 16 miles per hour, Stephen travels 16*0.25 = 4 miles.\n",
      "Traveling 15 minutes at 12 miles per hour, Stephen travels 12*0.25 = 3 miles.\n",
      "Traveling 15 minutes at 20 miles per hour, Stephen travels 20*0.25 = 5 miles.\n",
      "All together, Stephen travels 4+3+5=12 miles.\n",
      "FINAL ANSWER: 12\n",
      "\n",
      "❌ Wrong Answer (Full):\n",
      "15 minutes is 15/60=0.25 hours.\n",
      "Traveling 15 minutes at 16 miles per hour, Stephen travels 16/0.25 = 64 miles.\n",
      "Traveling 15 minutes at 12 miles per hour, Stephen travels 12*0.25 = 3 miles.\n",
      "Traveling 15 minutes at 20 miles per hour, Stephen travels 20*0.25 = 5 miles.\n",
      "All together, Stephen travels 64+3+5=72 miles.\n",
      "FINAL ANSWER: 72\n",
      "\n",
      "💡 Explanation:\n",
      "Incorrect operation. The calculation should use '*' but used '/' instead.\n",
      "\n",
      "📊 Answer Lengths:\n",
      "   Correct: 6 lines\n",
      "   Wrong: 6 lines\n",
      "\n",
      "🗂️ Correct Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"15 minutes is 15/60=0.25 hours.\",\n",
      "  \"L2\": \"Traveling 15 minutes at 16 miles per hour, Stephen travels 16*0.25 = 4 miles.\",\n",
      "  \"L3\": \"Traveling 15 minutes at 12 miles per hour, Stephen travels 12*0.25 = 3 miles.\",\n",
      "  \"L4\": \"Traveling 15 minutes at 20 miles per hour, Stephen travels 20*0.25 = 5 miles.\",\n",
      "  \"L5\": \"All together, Stephen travels 4+3+5=12 miles.\",\n",
      "  \"FA\": \"12\"\n",
      "}\n",
      "\n",
      "🗂️ Wrong Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"15 minutes is 15/60=0.25 hours.\",\n",
      "  \"L2\": \"Traveling 15 minutes at 16 miles per hour, Stephen travels 16/0.25 = 64 miles.\",\n",
      "  \"L3\": \"Traveling 15 minutes at 12 miles per hour, Stephen travels 12*0.25 = 3 miles.\",\n",
      "  \"L4\": \"Traveling 15 minutes at 20 miles per hour, Stephen travels 20*0.25 = 5 miles.\",\n",
      "  \"L5\": \"All together, Stephen travels 64+3+5=72 miles.\",\n",
      "  \"FA\": \"72\"\n",
      "}\n",
      "\n",
      "🧮 Correct Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"15/60=0.25\",\n",
      "  \"L2\": \"\",\n",
      "  \"L3\": \"\",\n",
      "  \"L4\": \"\",\n",
      "  \"L5\": \"4+3+5=12\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "🧮 Wrong Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"15/60=0.25\",\n",
      "  \"L2\": \"\",\n",
      "  \"L3\": \"\",\n",
      "  \"L4\": \"\",\n",
      "  \"L5\": \"64+3+5=72\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "🏷️ Source: programmatic\n",
      "================================================================================\n",
      "\n",
      "🔍 CONCEPTUAL VALIDATOR #2\n",
      "------------------------------------------------------------\n",
      "📋 Index: 4241 | Tier: tier3 | Error Type: conceptual_error\n",
      "📝 Error Subtype: operator_swap\n",
      "🎯 Erroneous Line Number: L2\n",
      "🔴 Erroneous Line: The total number of marbles that Ludo bought is 16 marbles + 4 marbles = 12 marbles\n",
      "🧮 Erroneous Line Equation: 16+4=12\n",
      "\n",
      "❓ Question:\n",
      "Three friends Wolfgang, Ludo, and Michael, went to Walmart and bought marbles. Wolfgang bought 16 marbles, Ludo bought 1/4 times more marbles than Wolfgang, and Michael bought 2/3 times as many marbles as the number of marbles both Wolfgang and Ludo bought. If they combined their marbles and decided to share them equally, how many marbles did each get?\n",
      "\n",
      "✅ Correct Answer (Full):\n",
      "Ludo bought 1/4 more marbles than Wolfgang, which is 1/4 * 16 marbles = 4 marbles\n",
      "The total number of marbles that Ludo bought is 16 marbles + 4 marbles = 20 marbles\n",
      "Wolfgang and Ludo purchased a total of 20 marbles + 16 marbles = 36 marbles.\n",
      "If Michael bought 2/3 times the total number of marbles bought by Wolfgang and Ludo, he bought 2/3 * 36 marbles = 24 marbles.\n",
      "The three friends purchased a total of 24 marbles + 36 marbles = 60 marbles.\n",
      "When they shared the marbles equally, each got 60 marbles / 3 people = 20 marbles/person.\n",
      "FINAL ANSWER: 20\n",
      "\n",
      "❌ Wrong Answer (Full):\n",
      "Ludo bought 1/4 more marbles than Wolfgang, which is 1/4 * 16 marbles = 4 marbles\n",
      "The total number of marbles that Ludo bought is 16 marbles + 4 marbles = 12 marbles\n",
      "Wolfgang and Ludo purchased a total of 12 marbles + 16 marbles = 28 marbles.\n",
      "If Michael bought 2/3 times the total number of marbles bought by Wolfgang and Ludo, he bought 2/3 * 28 marbles = 56/3 marbles.\n",
      "The three friends purchased a total of 56/3 marbles + 28 marbles = 140/3 marbles.\n",
      "When they shared the marbles equally, each got 140/3 marbles / 3 people = 140/9 marbles/person.\n",
      "FINAL ANSWER: 140/9\n",
      "\n",
      "💡 Explanation:\n",
      "Incorrect operation. The calculation should use '+' but used '-' instead.\n",
      "\n",
      "📊 Answer Lengths:\n",
      "   Correct: 7 lines\n",
      "   Wrong: 7 lines\n",
      "\n",
      "🗂️ Correct Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"Ludo bought 1/4 more marbles than Wolfgang, which is 1/4 * 16 marbles = 4 marbles\",\n",
      "  \"L2\": \"The total number of marbles that Ludo bought is 16 marbles + 4 marbles = 20 marbles\",\n",
      "  \"L3\": \"Wolfgang and Ludo purchased a total of 20 marbles + 16 marbles = 36 marbles.\",\n",
      "  \"L4\": \"If Michael bought 2/3 times the total number of marbles bought by Wolfgang and Ludo, he bought 2/3 * 36 marbles = 24 marbles.\",\n",
      "  \"L5\": \"The three friends purchased a total of 24 marbles + 36 marbles = 60 marbles.\",\n",
      "  \"L6\": \"When they shared the marbles equally, each got 60 marbles / 3 people = 20 marbles/person.\",\n",
      "  \"FA\": \"20\"\n",
      "}\n",
      "\n",
      "🗂️ Wrong Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"Ludo bought 1/4 more marbles than Wolfgang, which is 1/4 * 16 marbles = 4 marbles\",\n",
      "  \"L2\": \"The total number of marbles that Ludo bought is 16 marbles + 4 marbles = 12 marbles\",\n",
      "  \"L3\": \"Wolfgang and Ludo purchased a total of 12 marbles + 16 marbles = 28 marbles.\",\n",
      "  \"L4\": \"If Michael bought 2/3 times the total number of marbles bought by Wolfgang and Ludo, he bought 2/3 * 28 marbles = 56/3 marbles.\",\n",
      "  \"L5\": \"The three friends purchased a total of 56/3 marbles + 28 marbles = 140/3 marbles.\",\n",
      "  \"L6\": \"When they shared the marbles equally, each got 140/3 marbles / 3 people = 140/9 marbles/person.\",\n",
      "  \"FA\": \"140/9\"\n",
      "}\n",
      "\n",
      "🧮 Correct Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"1/4*16=4\",\n",
      "  \"L2\": \"16+4=20\",\n",
      "  \"L3\": \"20+16=36\",\n",
      "  \"L4\": \"2/3*36=24\",\n",
      "  \"L5\": \"24+36=60\",\n",
      "  \"L6\": \"60/3=20\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "🧮 Wrong Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"1/4*16=4\",\n",
      "  \"L2\": \"16+4=12\",\n",
      "  \"L3\": \"12+16=28\",\n",
      "  \"L4\": \"2/3*28=56/3\",\n",
      "  \"L5\": \"56/3+28=140/3\",\n",
      "  \"L6\": \"140/3/3=140/9\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "🏷️ Source: programmatic\n",
      "================================================================================\n",
      "\n",
      "🔍 CONCEPTUAL VALIDATOR #3\n",
      "------------------------------------------------------------\n",
      "📋 Index: 2135 | Tier: tier4 | Error Type: conceptual_error\n",
      "📝 Error Subtype: incomplete_calculation\n",
      "🎯 Erroneous Line Number: L1\n",
      "🔴 Erroneous Line: The four cats weigh 36 pounds in total because 12 plus 14.7 plus 9.3 equals 36.\n",
      "🧮 Erroneous Line Equation: 12+14.7+9.3=36\n",
      "\n",
      "❓ Question:\n",
      "Janele wants to figure out the average weight of her cats. She has 4 of them. The first two weigh 12 pounds each. The third weighs 14.7 pounds and the fourth weighs 9.3 pounds. What is their average weight?\n",
      "\n",
      "✅ Correct Answer (Full):\n",
      "The four cats weigh 48 pounds in total because 12 plus 12 plus 14.7 plus 9.3 equals 48.\n",
      "The average weight is 12 pounds because 48 divided by 4 is 12.\n",
      "FINAL ANSWER: 12\n",
      "\n",
      "❌ Wrong Answer (Full):\n",
      "The four cats weigh 36 pounds in total because 12 plus 14.7 plus 9.3 equals 36.\n",
      "The average weight is 9 pounds because 36 divided by 4 is 9.\n",
      "FINAL ANSWER: 9\n",
      "\n",
      "💡 Explanation:\n",
      "Incomplete calculation. The term 'cat2_weight' (value: 12.0) was omitted from the operation.\n",
      "\n",
      "📊 Answer Lengths:\n",
      "   Correct: 3 lines\n",
      "   Wrong: 3 lines\n",
      "\n",
      "🗂️ Correct Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"The four cats weigh 48 pounds in total because 12 plus 12 plus 14.7 plus 9.3 equals 48.\",\n",
      "  \"L2\": \"The average weight is 12 pounds because 48 divided by 4 is 12.\",\n",
      "  \"FA\": \"12\"\n",
      "}\n",
      "\n",
      "🗂️ Wrong Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"The four cats weigh 36 pounds in total because 12 plus 14.7 plus 9.3 equals 36.\",\n",
      "  \"L2\": \"The average weight is 9 pounds because 36 divided by 4 is 9.\",\n",
      "  \"FA\": \"9\"\n",
      "}\n",
      "\n",
      "🧮 Correct Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"12+12+14.7+9.3=48\",\n",
      "  \"L2\": \"48/4=12\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "🧮 Wrong Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"12+14.7+9.3=36\",\n",
      "  \"L2\": \"36/4=9\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "🏷️ Source: programmatic\n",
      "================================================================================\n",
      "\n",
      "🔍 CONCEPTUAL VALIDATOR #4\n",
      "------------------------------------------------------------\n",
      "📋 Index: 4809 | Tier: tier2 | Error Type: conceptual_error\n",
      "📝 Error Subtype: incomplete_calculation\n",
      "🎯 Erroneous Line Number: L3\n",
      "🔴 Erroneous Line: Now multiply the new total by 10% to find out how much Jerry owes the loan shark in interest the second month: $220 * 10% = $2200\n",
      "🧮 Erroneous Line Equation: 220*10=2200\n",
      "\n",
      "❓ Question:\n",
      "Jerry owes a loan shark $200. The loan shark charges Jerry 10% interest compounded monthly. (This means that every month the loan shark adds Jerry's interest amount to his loan, and the next month Jerry has to pay 10% on the new total). If Jerry doesn't make any payments, how much (in dollars) does the loan shark charge in interest the second month?\n",
      "\n",
      "✅ Correct Answer (Full):\n",
      "First calculate how much the loan shark charges in interest the first month by multiplying the loan amount by the interest rate: $200 * 10% = $20\n",
      "Now add the interest amount to the original amount of the loan to find Jerry's new total: $200 + $20 = $220\n",
      "Now multiply the new total by 10% to find out how much Jerry owes the loan shark in interest the second month: $220 * 10% = $22\n",
      "FINAL ANSWER: 22\n",
      "\n",
      "❌ Wrong Answer (Full):\n",
      "First calculate how much the loan shark charges in interest the first month by multiplying the loan amount by the interest rate: $200 * 10% = $20\n",
      "Now add the interest amount to the original amount of the loan to find Jerry's new total: $200 + $20 = $220\n",
      "Now multiply the new total by 10% to find out how much Jerry owes the loan shark in interest the second month: $220 * 10% = $2200\n",
      "FINAL ANSWER: 2200\n",
      "\n",
      "💡 Explanation:\n",
      "Incomplete calculation. The term 'percent_factor' (value: 0.01) was omitted from the operation.\n",
      "\n",
      "📊 Answer Lengths:\n",
      "   Correct: 4 lines\n",
      "   Wrong: 4 lines\n",
      "\n",
      "🗂️ Correct Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"First calculate how much the loan shark charges in interest the first month by multiplying the loan amount by the interest rate: $200 * 10% = $20\",\n",
      "  \"L2\": \"Now add the interest amount to the original amount of the loan to find Jerry's new total: $200 + $20 = $220\",\n",
      "  \"L3\": \"Now multiply the new total by 10% to find out how much Jerry owes the loan shark in interest the second month: $220 * 10% = $22\",\n",
      "  \"FA\": \"22\"\n",
      "}\n",
      "\n",
      "🗂️ Wrong Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"First calculate how much the loan shark charges in interest the first month by multiplying the loan amount by the interest rate: $200 * 10% = $20\",\n",
      "  \"L2\": \"Now add the interest amount to the original amount of the loan to find Jerry's new total: $200 + $20 = $220\",\n",
      "  \"L3\": \"Now multiply the new total by 10% to find out how much Jerry owes the loan shark in interest the second month: $220 * 10% = $2200\",\n",
      "  \"FA\": \"2200\"\n",
      "}\n",
      "\n",
      "🧮 Correct Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"200*10*.01=20\",\n",
      "  \"L2\": \"200+20=220\",\n",
      "  \"L3\": \"220*10*.01=22\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "🧮 Wrong Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"200*10*0.01=20\",\n",
      "  \"L2\": \"200+20=220\",\n",
      "  \"L3\": \"220*10=2200\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "🏷️ Source: programmatic\n",
      "================================================================================\n",
      "\n",
      "🔍 CONCEPTUAL VALIDATOR #5\n",
      "------------------------------------------------------------\n",
      "📋 Index: 5132 | Tier: tier1 | Error Type: conceptual_error\n",
      "📝 Error Subtype: incomplete_calculation\n",
      "🎯 Erroneous Line Number: L4\n",
      "🔴 Erroneous Line: Therefore, Cid earned a total of $$300 + $75 = $375.\n",
      "🧮 Erroneous Line Equation: 300+75=375\n",
      "\n",
      "❓ Question:\n",
      "Cid owns a mechanic shop, he charges $20 for an oil change, $30 for a repair, and $5 for a car wash. How much money did he earn if he changed the oil of 5 cars, repaired 10 cars, and washed 15 cars?\n",
      "\n",
      "✅ Correct Answer (Full):\n",
      "The money he earned from an oil change is $20 x 5 =$ 100.\n",
      "The money he earned from the repair is $30 x 10 = $300.\n",
      "The money he earned from the car wash is $15 x 5 = $75.\n",
      "Therefore, Cid earned a total of $100 + $300 + $75 = $475.\n",
      "FINAL ANSWER: 475\n",
      "\n",
      "❌ Wrong Answer (Full):\n",
      "The money he earned from an oil change is $20 x 5 =$ 100.\n",
      "The money he earned from the repair is $30 x 10 = $300.\n",
      "The money he earned from the car wash is $15 x 5 = $75.\n",
      "Therefore, Cid earned a total of $$300 + $75 = $375.\n",
      "FINAL ANSWER: 375\n",
      "\n",
      "💡 Explanation:\n",
      "Incomplete calculation. The term 'earned_from_oil_change' (value: 100) was omitted from the operation.\n",
      "\n",
      "📊 Answer Lengths:\n",
      "   Correct: 5 lines\n",
      "   Wrong: 5 lines\n",
      "\n",
      "🗂️ Correct Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"The money he earned from an oil change is $20 x 5 =$ 100.\",\n",
      "  \"L2\": \"The money he earned from the repair is $30 x 10 = $300.\",\n",
      "  \"L3\": \"The money he earned from the car wash is $15 x 5 = $75.\",\n",
      "  \"L4\": \"Therefore, Cid earned a total of $100 + $300 + $75 = $475.\",\n",
      "  \"FA\": \"475\"\n",
      "}\n",
      "\n",
      "🗂️ Wrong Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"The money he earned from an oil change is $20 x 5 =$ 100.\",\n",
      "  \"L2\": \"The money he earned from the repair is $30 x 10 = $300.\",\n",
      "  \"L3\": \"The money he earned from the car wash is $15 x 5 = $75.\",\n",
      "  \"L4\": \"Therefore, Cid earned a total of $$300 + $75 = $375.\",\n",
      "  \"FA\": \"375\"\n",
      "}\n",
      "\n",
      "🧮 Correct Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"20*5=100\",\n",
      "  \"L2\": \"30*10=300\",\n",
      "  \"L3\": \"15*5=75\",\n",
      "  \"L4\": \"100+300+75=475\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "🧮 Wrong Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"20*5=100\",\n",
      "  \"L2\": \"30*10=300\",\n",
      "  \"L3\": \"15*5=75\",\n",
      "  \"L4\": \"300+75=375\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "🏷️ Source: programmatic\n",
      "================================================================================\n",
      "\n",
      "📊 Summary: Displayed samples from 7 source categories\n"
     ]
    }
   ],
   "source": [
    "# 2. Pretty print one randomly chosen row from each catalog source\n",
    "import json\n",
    "\n",
    "def pretty_print_sample_rows_by_source(master_catalog):\n",
    "    \"\"\"\n",
    "    Pretty prints one randomly chosen row from each source catalog.\n",
    "    \"\"\"\n",
    "    print(\"🎲 RANDOM SAMPLE FROM EACH SOURCE CATALOG\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if master_catalog.empty:\n",
    "        print(\"❌ Master catalog is empty!\")\n",
    "        return\n",
    "    \n",
    "    # Define source mappings\n",
    "    source_mappings = {\n",
    "        'manual': 'Manual Catalog',\n",
    "        'computational': 'Computational Catalog', \n",
    "        'conceptual_ali': 'Conceptual Validator - Ali',\n",
    "        'conceptual_arvind': 'Conceptual Validator - Arvind',\n",
    "        'conceptual_mauro': 'Conceptual Validator - Mauro',\n",
    "        'conceptual_ling': 'Conceptual Validator - Ling',\n",
    "        'conceptual_yewei': 'Conceptual Validator - Yewei'\n",
    "    }\n",
    "    \n",
    "    # Get available sources in the data\n",
    "    available_sources = master_catalog['source'].unique()\n",
    "    error_types = master_catalog['error_type'].unique()\n",
    "    \n",
    "    # Sample one row from each available source/error_type combination\n",
    "    sampled_sources = set()\n",
    "    \n",
    "    # First priority: manual source\n",
    "    if 'manual' in available_sources:\n",
    "        manual_samples = master_catalog[master_catalog['source'] == 'manual']\n",
    "        if not manual_samples.empty:\n",
    "            sample = manual_samples.sample(1).iloc[0]\n",
    "            sampled_sources.add('manual')\n",
    "            print_sample_row(sample, 'Manual Catalog')\n",
    "    \n",
    "    # Second priority: computational (programmatic source + computational_error)\n",
    "    programmatic_computational = master_catalog[\n",
    "        (master_catalog['source'] == 'programmatic') & \n",
    "        (master_catalog['error_type'] == 'computational_error')\n",
    "    ]\n",
    "    if not programmatic_computational.empty:\n",
    "        sample = programmatic_computational.sample(1).iloc[0]\n",
    "        sampled_sources.add('computational')\n",
    "        print_sample_row(sample, 'Computational Catalog')\n",
    "    \n",
    "    # Third priority: conceptual validators (programmatic source + conceptual_error)\n",
    "    programmatic_conceptual = master_catalog[\n",
    "        (master_catalog['source'] == 'programmatic') & \n",
    "        (master_catalog['error_type'] == 'conceptual_error')\n",
    "    ]\n",
    "    \n",
    "    # Try to get one sample from each validator if possible\n",
    "    validators_sampled = set()\n",
    "    for _ in range(5):  # Try up to 5 times to get different validators\n",
    "        if not programmatic_conceptual.empty and len(validators_sampled) < 5:\n",
    "            sample = programmatic_conceptual.sample(1).iloc[0]\n",
    "            \n",
    "            # Determine which validator this likely came from based on patterns\n",
    "            # This is approximate since we don't store validator info directly\n",
    "            validator_name = f\"Conceptual Validator #{len(validators_sampled) + 1}\"\n",
    "            if validator_name not in validators_sampled:\n",
    "                validators_sampled.add(validator_name)\n",
    "                print_sample_row(sample, validator_name)\n",
    "    \n",
    "    print(f\"\\n📊 Summary: Displayed samples from {len(sampled_sources) + len(validators_sampled)} source categories\")\n",
    "\n",
    "def print_sample_row(sample, source_name):\n",
    "    \"\"\"Helper function to pretty print a single sample row with full content.\"\"\"\n",
    "    print(f\"\\n🔍 {source_name.upper()}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"📋 Index: {sample['index']} | Tier: {sample['tier']} | Error Type: {sample['error_type']}\")\n",
    "    print(f\"📝 Error Subtype: {sample['error_subtype']}\")\n",
    "    print(f\"🎯 Erroneous Line Number: {sample['erroneous_line_number']}\")\n",
    "    print(f\"🔴 Erroneous Line: {sample['erroneous_line']}\")\n",
    "    print(f\"🧮 Erroneous Line Equation: {sample['erroneous_line_eqn']}\")\n",
    "    \n",
    "    print(f\"\\n❓ Question:\")\n",
    "    print(f\"{sample['question']}\")\n",
    "    \n",
    "    print(f\"\\n✅ Correct Answer (Full):\")\n",
    "    print(f\"{sample['correct_answer']}\")\n",
    "    \n",
    "    print(f\"\\n❌ Wrong Answer (Full):\")\n",
    "    print(f\"{sample['wrong_answer']}\")\n",
    "    \n",
    "    print(f\"\\n💡 Explanation:\")\n",
    "    print(f\"{sample['explanation']}\")\n",
    "    \n",
    "    print(f\"\\n📊 Answer Lengths:\")\n",
    "    print(f\"   Correct: {sample['correct_answer_length']} lines\")\n",
    "    print(f\"   Wrong: {sample['wrong_answer_length']} lines\")\n",
    "    \n",
    "    print(f\"\\n🗂️ Correct Answer Mapping (JSON):\")\n",
    "    print(f\"{sample['correct_answer_mapping']}\")\n",
    "    \n",
    "    print(f\"\\n🗂️ Wrong Answer Mapping (JSON):\")\n",
    "    print(f\"{sample['wrong_answer_mapping']}\")\n",
    "    \n",
    "    print(f\"\\n🧮 Correct Equation Mapping (JSON):\")\n",
    "    print(f\"{sample['correct_eqn_mapping']}\")\n",
    "    \n",
    "    print(f\"\\n🧮 Wrong Equation Mapping (JSON):\")\n",
    "    print(f\"{sample['wrong_eqn_mapping']}\")\n",
    "    \n",
    "    print(f\"\\n🏷️ Source: {sample['source']}\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Run the pretty printer\n",
    "pretty_print_sample_rows_by_source(master_catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5f9c907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 SAVING MASTER CATALOG TO: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/aug-5-dataset\n",
      "================================================================================\n",
      "✅ Master catalog saved: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/aug-5-dataset/master_catalog.csv\n",
      "   📊 24,652 rows with 18 columns\n",
      "✅ Problematic catalog saved: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/aug-5-dataset/catalog_problematic.csv\n",
      "   📊 1,078 problematic rows\n",
      "✅ Summary statistics saved: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/aug-5-dataset/dataset_summary.txt\n",
      "✅ Column schema saved: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/aug-5-dataset/column_schema.json\n",
      "\n",
      "📁 FILES IN aug-5-dataset/:\n",
      "   📄 catalog_problematic.csv (0.4 MB)\n",
      "   📄 column_schema.json (0.0 MB)\n",
      "   📄 dataset_summary.txt (0.0 MB)\n",
      "   📄 manual_length_mismatch.csv (0.3 MB)\n",
      "   📄 master_catalog.csv (47.0 MB)\n",
      "\n",
      "🎉 Dataset successfully saved to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/aug-5-dataset\n",
      "✨ Ready for downstream processing and analysis!\n"
     ]
    }
   ],
   "source": [
    "# 3. Save the master catalog to a new folder \"../data/aug-5-dataset\"\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Create the new directory\n",
    "AUG_5_DATASET_DIR = DATA_DIR / \"aug-5-dataset\"\n",
    "AUG_5_DATASET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"💾 SAVING MASTER CATALOG TO: {AUG_5_DATASET_DIR}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save master catalog\n",
    "master_catalog_path = AUG_5_DATASET_DIR / \"master_catalog.csv\"\n",
    "master_catalog.to_csv(master_catalog_path, index=False)\n",
    "print(f\"✅ Master catalog saved: {master_catalog_path}\")\n",
    "print(f\"   📊 {len(master_catalog):,} rows with {len(MASTER_CATALOG_COLUMNS)} columns\")\n",
    "\n",
    "# Save problematic catalog\n",
    "problematic_catalog_path = AUG_5_DATASET_DIR / \"catalog_problematic.csv\"\n",
    "catalog_problematic.to_csv(problematic_catalog_path, index=False)\n",
    "print(f\"✅ Problematic catalog saved: {problematic_catalog_path}\")\n",
    "print(f\"   📊 {len(catalog_problematic):,} problematic rows\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_path = AUG_5_DATASET_DIR / \"dataset_summary.txt\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"AUG-5 DATASET SUMMARY\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    f.write(f\"Generated on: August 5, 2025\\n\")\n",
    "    f.write(f\"Total master catalog rows: {len(master_catalog):,}\\n\")\n",
    "    f.write(f\"Total problematic rows: {len(catalog_problematic):,}\\n\")\n",
    "    f.write(f\"Unique GSM8K indices: {master_catalog['index'].nunique():,}\\n\\n\")\n",
    "    \n",
    "    f.write(\"SOURCE DISTRIBUTION:\\n\")\n",
    "    source_counts = master_catalog['source'].value_counts()\n",
    "    for source, count in source_counts.items():\n",
    "        pct = (count / len(master_catalog)) * 100\n",
    "        f.write(f\"  {source}: {count:,} ({pct:.1f}%)\\n\")\n",
    "    \n",
    "    f.write(\"\\nERROR TYPE DISTRIBUTION:\\n\")\n",
    "    error_type_counts = master_catalog['error_type'].value_counts()\n",
    "    for error_type, count in error_type_counts.items():\n",
    "        pct = (count / len(master_catalog)) * 100\n",
    "        f.write(f\"  {error_type}: {count:,} ({pct:.1f}%)\\n\")\n",
    "    \n",
    "    f.write(\"\\nTIER DISTRIBUTION:\\n\")\n",
    "    tier_counts = master_catalog['tier'].value_counts().sort_index()\n",
    "    for tier, count in tier_counts.items():\n",
    "        pct = (count / len(master_catalog)) * 100\n",
    "        f.write(f\"  {tier}: {count:,} ({pct:.1f}%)\\n\")\n",
    "    \n",
    "    f.write(f\"\\nCOLUMNS ({len(MASTER_CATALOG_COLUMNS)}):\\n\")\n",
    "    for i, col in enumerate(MASTER_CATALOG_COLUMNS, 1):\n",
    "        f.write(f\"  {i:2d}. {col}\\n\")\n",
    "\n",
    "print(f\"✅ Summary statistics saved: {summary_path}\")\n",
    "\n",
    "def get_column_description(col_name):\n",
    "    \"\"\"Get description for each column.\"\"\"\n",
    "    descriptions = {\n",
    "        'index': 'GSM8K problem index',\n",
    "        'tier': 'Problem difficulty tier (tier1-tier5)',\n",
    "        'question': 'Math problem question text',\n",
    "        'correct_answer': 'Correct solution with FINAL ANSWER prefix',\n",
    "        'wrong_answer': 'Flawed solution with FINAL ANSWER prefix', \n",
    "        'error_type': 'Type of error (computational_error/conceptual_error)',\n",
    "        'explanation': 'Human explanation of the error',\n",
    "        'erroneous_line_number': 'Line identifier containing the error (L1, L2, FA)',\n",
    "        'erroneous_line': 'Text content of the erroneous line',\n",
    "        'erroneous_line_eqn': 'Calculator equation from erroneous line',\n",
    "        'correct_answer_mapping': 'JSON mapping of line IDs to correct solution lines',\n",
    "        'wrong_answer_mapping': 'JSON mapping of line IDs to wrong solution lines',\n",
    "        'correct_eqn_mapping': 'JSON mapping of line IDs to correct calculator equations',\n",
    "        'wrong_eqn_mapping': 'JSON mapping of line IDs to wrong calculator equations', \n",
    "        'correct_answer_length': 'Number of lines in correct solution',\n",
    "        'wrong_answer_length': 'Number of lines in wrong solution',\n",
    "        'source': 'Data source (manual/programmatic)',\n",
    "        'error_subtype': 'Detailed error subtype classification'\n",
    "    }\n",
    "    return descriptions.get(col_name, 'No description available')\n",
    "\n",
    "# Save column schema\n",
    "schema_path = AUG_5_DATASET_DIR / \"column_schema.json\"\n",
    "schema_info = {\n",
    "    \"dataset_name\": \"aug-5-dataset\", \n",
    "    \"creation_date\": \"2025-08-05\",\n",
    "    \"total_columns\": len(MASTER_CATALOG_COLUMNS),\n",
    "    \"columns\": {\n",
    "        col: {\n",
    "            \"position\": i + 1,\n",
    "            \"data_type\": str(master_catalog[col].dtype) if col in master_catalog.columns else \"unknown\",\n",
    "            \"description\": get_column_description(col)\n",
    "        }\n",
    "        for i, col in enumerate(MASTER_CATALOG_COLUMNS)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(schema_path, 'w') as f:\n",
    "    json.dump(schema_info, f, indent=2)\n",
    "\n",
    "print(f\"✅ Column schema saved: {schema_path}\")\n",
    "\n",
    "# List all files in the new directory\n",
    "print(f\"\\n📁 FILES IN {AUG_5_DATASET_DIR.name}/:\")\n",
    "for file_path in sorted(AUG_5_DATASET_DIR.iterdir()):\n",
    "    file_size = file_path.stat().st_size / (1024 * 1024)  # Size in MB\n",
    "    print(f\"   📄 {file_path.name} ({file_size:.1f} MB)\")\n",
    "\n",
    "print(f\"\\n🎉 Dataset successfully saved to: {AUG_5_DATASET_DIR}\")\n",
    "print(\"✨ Ready for downstream processing and analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "896d6a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 DATAFRAME INFO:\n",
      "==================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24652 entries, 0 to 24651\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   index                   24652 non-null  int64 \n",
      " 1   tier                    24652 non-null  object\n",
      " 2   question                24652 non-null  object\n",
      " 3   correct_answer          24652 non-null  object\n",
      " 4   wrong_answer            24652 non-null  object\n",
      " 5   error_type              24652 non-null  object\n",
      " 6   explanation             24651 non-null  object\n",
      " 7   erroneous_line_number   24652 non-null  object\n",
      " 8   erroneous_line          24382 non-null  object\n",
      " 9   erroneous_line_eqn      22616 non-null  object\n",
      " 10  correct_answer_mapping  24652 non-null  object\n",
      " 11  wrong_answer_mapping    24652 non-null  object\n",
      " 12  correct_eqn_mapping     24652 non-null  object\n",
      " 13  wrong_eqn_mapping       24652 non-null  object\n",
      " 14  correct_answer_length   24652 non-null  int64 \n",
      " 15  wrong_answer_length     24652 non-null  int64 \n",
      " 16  source                  24652 non-null  object\n",
      " 17  error_subtype           22912 non-null  object\n",
      "dtypes: int64(3), object(15)\n",
      "memory usage: 3.4+ MB\n",
      "\n",
      "📋 COLUMN DTYPES:\n",
      "==================================================\n",
      "index: int64\n",
      "tier: object\n",
      "question: object\n",
      "correct_answer: object\n",
      "wrong_answer: object\n",
      "error_type: object\n",
      "explanation: object\n",
      "erroneous_line_number: object\n",
      "erroneous_line: object\n",
      "erroneous_line_eqn: object\n",
      "correct_answer_mapping: object\n",
      "wrong_answer_mapping: object\n",
      "correct_eqn_mapping: object\n",
      "wrong_eqn_mapping: object\n",
      "correct_answer_length: int64\n",
      "wrong_answer_length: int64\n",
      "source: object\n",
      "error_subtype: object\n",
      "\n",
      "🔍 SAMPLE ROW (First Row):\n",
      "==================================================\n",
      "\n",
      "index:\n",
      "  Type: <class 'numpy.int64'>\n",
      "  Value: 1000\n",
      "\n",
      "tier:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'tier3'\n",
      "\n",
      "question:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'John buys a heating pad for $30.  He uses it 3 times a week for 2 weeks.  How much does he spend on each use?'\n",
      "\n",
      "correct_answer:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'He uses it 3*2=6 times\\nSo he pays 30/6=$5\\nFINAL ANSWER: 5'\n",
      "\n",
      "wrong_answer:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'He uses it 3*2=5 times\\nSo he pays 30/5=$6\\nFINAL ANSWER: 6'\n",
      "\n",
      "error_type:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'computational_error'\n",
      "\n",
      "explanation:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'computational error: John uses it 3*2=<<3*2=6>>6 times.'\n",
      "\n",
      "erroneous_line_number:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'L1'\n",
      "\n",
      "erroneous_line:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'He uses it 3*2=5 times'\n",
      "\n",
      "erroneous_line_eqn:\n",
      "  Type: <class 'str'>\n",
      "  Value: '3*2=5'\n",
      "\n",
      "correct_answer_mapping:\n",
      "  Type: <class 'str'>\n",
      "  Value: '{\\n  \"L1\": \"He uses it 3*2=6 times\",\\n  \"L2\": \"So he pays 30/6=$5\",\\n  \"FA\": \"5\"\\n}'\n",
      "  First 100 chars: {\n",
      "  \"L1\": \"He uses it 3*2=6 times\",\n",
      "  \"L2\": \"So he pays 30/6=$5\",\n",
      "  \"FA\": \"5\"\n",
      "}...\n",
      "  JSON Parse: SUCCESS - <class 'dict'>\n",
      "\n",
      "wrong_answer_mapping:\n",
      "  Type: <class 'str'>\n",
      "  Value: '{\\n  \"L1\": \"He uses it 3*2=5 times\",\\n  \"L2\": \"So he pays 30/5=$6\",\\n  \"FA\": \"6\"\\n}'\n",
      "  First 100 chars: {\n",
      "  \"L1\": \"He uses it 3*2=5 times\",\n",
      "  \"L2\": \"So he pays 30/5=$6\",\n",
      "  \"FA\": \"6\"\n",
      "}...\n",
      "  JSON Parse: SUCCESS - <class 'dict'>\n",
      "\n",
      "correct_eqn_mapping:\n",
      "  Type: <class 'str'>\n",
      "  Value: '{\\n  \"L1\": \"3*2=6\",\\n  \"L2\": \"30/6=5\",\\n  \"FA\": \"\"\\n}'\n",
      "  First 100 chars: {\n",
      "  \"L1\": \"3*2=6\",\n",
      "  \"L2\": \"30/6=5\",\n",
      "  \"FA\": \"\"\n",
      "}...\n",
      "  JSON Parse: SUCCESS - <class 'dict'>\n",
      "\n",
      "wrong_eqn_mapping:\n",
      "  Type: <class 'str'>\n",
      "  Value: '{\\n  \"L1\": \"3*2=5\",\\n  \"L2\": \"30/5=6\",\\n  \"FA\": \"\"\\n}'\n",
      "  First 100 chars: {\n",
      "  \"L1\": \"3*2=5\",\n",
      "  \"L2\": \"30/5=6\",\n",
      "  \"FA\": \"\"\n",
      "}...\n",
      "  JSON Parse: SUCCESS - <class 'dict'>\n",
      "\n",
      "correct_answer_length:\n",
      "  Type: <class 'numpy.int64'>\n",
      "  Value: 3\n",
      "\n",
      "wrong_answer_length:\n",
      "  Type: <class 'numpy.int64'>\n",
      "  Value: 3\n",
      "\n",
      "source:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'manual'\n",
      "\n",
      "error_subtype:\n",
      "  Type: <class 'float'>\n",
      "  Value: nan\n",
      "\n",
      "🧪 JSON PARSING TEST:\n",
      "==================================================\n",
      "\n",
      "Testing correct_answer_mapping:\n",
      "Raw value: '{\\n  \"L1\": \"He uses it 3*2=6 times\",\\n  \"L2\": \"So he pays 30/6=$5\",\\n  \"FA\": \"5\"\\n}'\n",
      "✅ Parsed successfully: <class 'dict'>\n",
      "   Sample content: ['L1', 'L2', 'FA']\n",
      "\n",
      "Testing wrong_answer_mapping:\n",
      "Raw value: '{\\n  \"L1\": \"He uses it 3*2=5 times\",\\n  \"L2\": \"So he pays 30/5=$6\",\\n  \"FA\": \"6\"\\n}'\n",
      "✅ Parsed successfully: <class 'dict'>\n",
      "   Sample content: ['L1', 'L2', 'FA']\n",
      "\n",
      "Testing correct_eqn_mapping:\n",
      "Raw value: '{\\n  \"L1\": \"3*2=6\",\\n  \"L2\": \"30/6=5\",\\n  \"FA\": \"\"\\n}'\n",
      "✅ Parsed successfully: <class 'dict'>\n",
      "   Sample content: ['L1', 'L2', 'FA']\n",
      "\n",
      "Testing wrong_eqn_mapping:\n",
      "Raw value: '{\\n  \"L1\": \"3*2=5\",\\n  \"L2\": \"30/5=6\",\\n  \"FA\": \"\"\\n}'\n",
      "✅ Parsed successfully: <class 'dict'>\n",
      "   Sample content: ['L1', 'L2', 'FA']\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV and examine the data types and a sample row\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Read the saved master catalog\n",
    "df = pd.read_csv(master_catalog_path)\n",
    "\n",
    "print(\"📊 DATAFRAME INFO:\")\n",
    "print(\"=\" * 50)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n📋 COLUMN DTYPES:\")\n",
    "print(\"=\" * 50)\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].dtype}\")\n",
    "\n",
    "print(\"\\n🔍 SAMPLE ROW (First Row):\")\n",
    "print(\"=\" * 50)\n",
    "sample_row = df.iloc[0]\n",
    "for col, value in sample_row.items():\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Type: {type(value)}\")\n",
    "    print(f\"  Value: {repr(value)}\")  # repr shows the actual string representation\n",
    "    \n",
    "    # Special handling for JSON columns\n",
    "    if col.endswith('_mapping'):\n",
    "        print(f\"  First 100 chars: {str(value)[:100]}...\")\n",
    "        try:\n",
    "            parsed = json.loads(value)\n",
    "            print(f\"  JSON Parse: SUCCESS - {type(parsed)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  JSON Parse: FAILED - {str(e)}\")\n",
    "\n",
    "print(\"\\n🧪 JSON PARSING TEST:\")\n",
    "print(\"=\" * 50)\n",
    "# Test parsing the JSON columns\n",
    "json_columns = ['correct_answer_mapping', 'wrong_answer_mapping', 'correct_eqn_mapping', 'wrong_eqn_mapping']\n",
    "\n",
    "for col in json_columns:\n",
    "    print(f\"\\nTesting {col}:\")\n",
    "    test_value = df.iloc[0][col]\n",
    "    print(f\"Raw value: {repr(test_value)}\")\n",
    "    \n",
    "    try:\n",
    "        parsed = json.loads(test_value)\n",
    "        print(f\"✅ Parsed successfully: {type(parsed)}\")\n",
    "        print(f\"   Sample content: {list(parsed.keys())[:3]}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"❌ JSON parsing failed: {e}\")\n",
    "        \n",
    "        # Try to fix the escaping issue\n",
    "        try:\n",
    "            fixed_value = test_value.replace('\"\"', '\"')\n",
    "            parsed = json.loads(fixed_value)\n",
    "            print(f\"✅ Fixed and parsed: {type(parsed)}\")\n",
    "        except Exception as e2:\n",
    "            print(f\"❌ Still failed after fixing: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3afa5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['erroneous_line', 'explanation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5639699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 CREATING ERROR DETECTION DATASET (SIMPLIFIED)\n",
      "======================================================================\n",
      "\n",
      "📋 Step 1: Processing CONCEPTUAL ERROR samples...\n",
      "   Found N = 2,067 conceptual error samples\n",
      "   ✅ Added 2,067 conceptual error samples\n",
      "\n",
      "📋 Step 2: Processing COMPUTATIONAL ERROR samples...\n",
      "   Target: 2,067 samples with distinct indices from conceptual samples\n",
      "   Available distinct computational candidates: 16,204\n",
      "   tier4: 500 selected (available: 787, limit: 500)\n",
      "   tier2: 500 selected (available: 2,051, limit: 500)\n",
      "   tier3: 500 selected (available: 5,505, limit: 500)\n",
      "   tier1: 500 selected (available: 7,851, limit: 500)\n",
      "   ✅ Added 2,000 computational error samples\n",
      "      Tier distribution: {'tier1': 500, 'tier2': 500, 'tier3': 500, 'tier4': 500}\n",
      "\n",
      "📋 Step 3: Processing CORRECT samples...\n",
      "   Target: 2000 randomly chosen correct samples (following tier priority)\n",
      "   Available correct candidates: 24,376\n",
      "   tier4: 500 selected (available: 1,637, limit: 500)\n",
      "   tier2: 500 selected (available: 3,436, limit: 500)\n",
      "   tier3: 500 selected (available: 8,198, limit: 500)\n",
      "   tier1: 500 selected (available: 11,050, limit: 500)\n",
      "   ✅ Added 2,000 correct samples\n",
      "      Tier distribution: {'tier1': 500, 'tier2': 500, 'tier3': 500, 'tier4': 500}\n",
      "      Unique indices in correct samples: 1,607 / 2,000\n",
      "      ⚠️  393 duplicate indices in correct samples\n",
      "\n",
      "📋 Adding train/test splits...\n",
      "\n",
      "🎯 FINAL DATASET SUMMARY\n",
      "==================================================\n",
      "Total samples: 6,067\n",
      "\n",
      "By Error Type:\n",
      "  correct: 2,000 (train: 1,600, test: 400, unique indices: 1,607)\n",
      "  conceptual_error: 2,067 (train: 1,653, test: 414, unique indices: 1,847)\n",
      "  computational_error: 2,000 (train: 1,600, test: 400, unique indices: 1,424)\n",
      "\n",
      "By Split:\n",
      "  train: 4,853 (80.0%)\n",
      "  test: 1,214 (20.0%)\n",
      "\n",
      "By Tier:\n",
      "  tier1: 1,690 (27.9%)\n",
      "  tier2: 1,321 (21.8%)\n",
      "  tier3: 1,794 (29.6%)\n",
      "  tier4: 1,234 (20.3%)\n",
      "  tier5: 28 (0.5%)\n",
      "\n",
      "By Source:\n",
      "  programmatic: 4,948 (81.6%)\n",
      "  manual: 1,119 (18.4%)\n",
      "\n",
      "Index Overlap Analysis:\n",
      "  Conceptual ∩ Computational: 0 indices\n",
      "  Conceptual ∩ Correct: 577 indices\n",
      "  Computational ∩ Correct: 467 indices\n",
      "\n",
      "💾 Dataset saved to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/aug-5-dataset/error_detection_dataset.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type int64 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[110]\u001b[39m\u001b[32m, line 249\u001b[39m\n\u001b[32m    247\u001b[39m     metadata_path = AUG_5_DATASET_DIR / \u001b[33m\"\u001b[39m\u001b[33merror_detection_metadata.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(metadata_path, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m         \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m💾 Metadata saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos-dl/lib/python3.12/json/__init__.py:179\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    173\u001b[39m     iterable = \u001b[38;5;28mcls\u001b[39m(skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n\u001b[32m    174\u001b[39m         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n\u001b[32m    175\u001b[39m         separators=separators,\n\u001b[32m    176\u001b[39m         default=default, sort_keys=sort_keys, **kw).iterencode(obj)\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos-dl/lib/python3.12/json/encoder.py:432\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    430\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos-dl/lib/python3.12/json/encoder.py:406\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    405\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    408\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos-dl/lib/python3.12/json/encoder.py:406\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    405\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    408\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos-dl/lib/python3.12/json/encoder.py:439\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    437\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCircular reference detected\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    438\u001b[39m     markers[markerid] = o\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m o = \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos-dl/lib/python3.12/json/encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type int64 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_error_detection_dataset_simplified(df):\n",
    "    \"\"\"\n",
    "    Create error detection dataset with simplified correct sample logic.\n",
    "    \"\"\"\n",
    "    print(\"🔧 CREATING ERROR DETECTION DATASET (SIMPLIFIED)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Tier priorities: tier4 (500), tier2 (500), tier3 (500), tier1 (500)\n",
    "    tier_priorities = [\n",
    "        ('tier4', 500),\n",
    "        ('tier2', 500), \n",
    "        ('tier3', 500),\n",
    "        ('tier1', 500)\n",
    "    ]\n",
    "    \n",
    "    used_indices = set()  # Track used GSM8K indices for conceptual/computational\n",
    "    selected_samples = []\n",
    "    \n",
    "    # Step 1: Get all conceptual error samples\n",
    "    print(f\"\\n📋 Step 1: Processing CONCEPTUAL ERROR samples...\")\n",
    "    conceptual_samples = df[df['error_type'] == 'conceptual_error'].copy()\n",
    "    N = len(conceptual_samples)\n",
    "    \n",
    "    print(f\"   Found N = {N:,} conceptual error samples\")\n",
    "    \n",
    "    # Track conceptual indices\n",
    "    conceptual_indices = set(conceptual_samples['index'].tolist())\n",
    "    used_indices.update(conceptual_indices)\n",
    "    \n",
    "    # Add split column (will assign later)\n",
    "    conceptual_samples['split'] = 'train'  # Default, will be reassigned\n",
    "    selected_samples.append(conceptual_samples)\n",
    "    \n",
    "    print(f\"   ✅ Added {len(conceptual_samples):,} conceptual error samples\")\n",
    "    \n",
    "    # Step 2: Add N computational error samples (distinct problem indices)\n",
    "    print(f\"\\n📋 Step 2: Processing COMPUTATIONAL ERROR samples...\")\n",
    "    print(f\"   Target: {N:,} samples with distinct indices from conceptual samples\")\n",
    "    \n",
    "    # Get computational candidates excluding conceptual indices\n",
    "    computational_candidates = df[\n",
    "        (df['error_type'] == 'computational_error') & \n",
    "        (~df['index'].isin(used_indices))\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"   Available distinct computational candidates: {len(computational_candidates):,}\")\n",
    "    \n",
    "    # Select computational samples by tier priority\n",
    "    selected_computational = []\n",
    "    remaining_slots = N\n",
    "    \n",
    "    for tier, tier_limit in tier_priorities:\n",
    "        if remaining_slots <= 0:\n",
    "            break\n",
    "            \n",
    "        tier_candidates = computational_candidates[computational_candidates['tier'] == tier]\n",
    "        available_count = len(tier_candidates)\n",
    "        actual_count = min(tier_limit, available_count, remaining_slots)\n",
    "        \n",
    "        if actual_count > 0:\n",
    "            # Randomly sample from this tier\n",
    "            tier_selected = tier_candidates.sample(n=actual_count, random_state=42).copy()\n",
    "            selected_computational.append(tier_selected)\n",
    "            remaining_slots -= actual_count\n",
    "            \n",
    "            # Track used indices\n",
    "            used_indices.update(tier_selected['index'].tolist())\n",
    "            \n",
    "            print(f\"   {tier}: {actual_count:,} selected (available: {available_count:,}, limit: {tier_limit:,})\")\n",
    "    \n",
    "    # Combine computational samples\n",
    "    if selected_computational:\n",
    "        computational_samples = pd.concat(selected_computational, ignore_index=True)\n",
    "        computational_samples['split'] = 'train'  # Default, will be reassigned\n",
    "        selected_samples.append(computational_samples)\n",
    "        \n",
    "        print(f\"   ✅ Added {len(computational_samples):,} computational error samples\")\n",
    "        \n",
    "        # Show tier distribution\n",
    "        tier_dist = computational_samples['tier'].value_counts().sort_index()\n",
    "        print(f\"      Tier distribution: {dict(tier_dist)}\")\n",
    "    else:\n",
    "        print(f\"   ❌ Could not select enough computational samples\")\n",
    "        computational_samples = pd.DataFrame()\n",
    "    \n",
    "    # Step 3: Add 2000 randomly chosen correct samples (following tier priority)\n",
    "    print(f\"\\n📋 Step 3: Processing CORRECT samples...\")\n",
    "    print(f\"   Target: 2000 randomly chosen correct samples (following tier priority)\")\n",
    "    \n",
    "    # Get all available candidates (don't worry about used indices)\n",
    "    correct_candidates = df.copy()\n",
    "    \n",
    "    print(f\"   Available correct candidates: {len(correct_candidates):,}\")\n",
    "    \n",
    "    # Select correct samples by tier priority\n",
    "    selected_correct = []\n",
    "    remaining_slots = 2000\n",
    "    \n",
    "    for tier, tier_limit in tier_priorities:\n",
    "        if remaining_slots <= 0:\n",
    "            break\n",
    "            \n",
    "        tier_candidates = correct_candidates[correct_candidates['tier'] == tier]\n",
    "        available_count = len(tier_candidates)\n",
    "        actual_count = min(tier_limit, available_count, remaining_slots)\n",
    "        \n",
    "        if actual_count > 0:\n",
    "            # Randomly sample from this tier\n",
    "            tier_selected = tier_candidates.sample(n=actual_count, random_state=45).copy()\n",
    "            selected_correct.append(tier_selected)\n",
    "            remaining_slots -= actual_count\n",
    "            \n",
    "            print(f\"   {tier}: {actual_count:,} selected (available: {available_count:,}, limit: {tier_limit:,})\")\n",
    "    \n",
    "    # Combine correct samples\n",
    "    if selected_correct:\n",
    "        correct_samples = pd.concat(selected_correct, ignore_index=True)\n",
    "        correct_samples['error_type'] = 'correct'\n",
    "        correct_samples['split'] = 'train'  # Default, will be reassigned\n",
    "        selected_samples.append(correct_samples)\n",
    "        \n",
    "        print(f\"   ✅ Added {len(correct_samples):,} correct samples\")\n",
    "        \n",
    "        # Show tier distribution\n",
    "        tier_dist = correct_samples['tier'].value_counts().sort_index()\n",
    "        print(f\"      Tier distribution: {dict(tier_dist)}\")\n",
    "        \n",
    "        # Check for distinctness within correct samples\n",
    "        unique_correct_indices = correct_samples['index'].nunique()\n",
    "        total_correct_samples = len(correct_samples)\n",
    "        print(f\"      Unique indices in correct samples: {unique_correct_indices:,} / {total_correct_samples:,}\")\n",
    "        if unique_correct_indices == total_correct_samples:\n",
    "            print(\"      ✅ All correct samples have distinct indices\")\n",
    "        else:\n",
    "            print(f\"      ⚠️  {total_correct_samples - unique_correct_indices} duplicate indices in correct samples\")\n",
    "    else:\n",
    "        print(f\"   ❌ Could not select correct samples\")\n",
    "    \n",
    "    # Combine all samples\n",
    "    if selected_samples:\n",
    "        final_dataset = pd.concat(selected_samples, ignore_index=True)\n",
    "        \n",
    "        # Add proper train/test split (4:1 ratio within each error type)\n",
    "        print(f\"\\n📋 Adding train/test splits...\")\n",
    "        \n",
    "        for error_type in ['correct', 'conceptual_error', 'computational_error']:\n",
    "            type_mask = final_dataset['error_type'] == error_type\n",
    "            type_indices = final_dataset[type_mask].index.tolist()\n",
    "            \n",
    "            if len(type_indices) > 0:\n",
    "                np.random.seed(44 + hash(error_type) % 100)  # Different seed per type\n",
    "                n_samples = len(type_indices)\n",
    "                n_train = int(0.8 * n_samples)  # 4:1 ratio\n",
    "                \n",
    "                shuffled_indices = np.random.permutation(type_indices)\n",
    "                train_indices = shuffled_indices[:n_train]\n",
    "                test_indices = shuffled_indices[n_train:]\n",
    "                \n",
    "                final_dataset.loc[train_indices, 'split'] = 'train'\n",
    "                final_dataset.loc[test_indices, 'split'] = 'test'\n",
    "        \n",
    "        print(f\"\\n🎯 FINAL DATASET SUMMARY\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Total samples: {len(final_dataset):,}\")\n",
    "        \n",
    "        # Summary by error type\n",
    "        print(f\"\\nBy Error Type:\")\n",
    "        for error_type in ['correct', 'conceptual_error', 'computational_error']:\n",
    "            type_data = final_dataset[final_dataset['error_type'] == error_type]\n",
    "            if len(type_data) > 0:\n",
    "                train_count = len(type_data[type_data['split'] == 'train'])\n",
    "                test_count = len(type_data[type_data['split'] == 'test'])\n",
    "                unique_indices = type_data['index'].nunique()\n",
    "                print(f\"  {error_type}: {len(type_data):,} (train: {train_count:,}, test: {test_count:,}, unique indices: {unique_indices:,})\")\n",
    "        \n",
    "        # Summary by split\n",
    "        print(f\"\\nBy Split:\")\n",
    "        split_counts = final_dataset['split'].value_counts()\n",
    "        for split, count in split_counts.items():\n",
    "            pct = (count / len(final_dataset)) * 100\n",
    "            print(f\"  {split}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        # Summary by tier\n",
    "        print(f\"\\nBy Tier:\")\n",
    "        tier_counts = final_dataset['tier'].value_counts().sort_index()\n",
    "        for tier, count in tier_counts.items():\n",
    "            pct = (count / len(final_dataset)) * 100\n",
    "            print(f\"  {tier}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        # Summary by source\n",
    "        print(f\"\\nBy Source:\")\n",
    "        source_counts = final_dataset['source'].value_counts()\n",
    "        for source, count in source_counts.items():\n",
    "            pct = (count / len(final_dataset)) * 100\n",
    "            print(f\"  {source}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        # Check overlap between error types\n",
    "        conceptual_idx = set(final_dataset[final_dataset['error_type'] == 'conceptual_error']['index'])\n",
    "        computational_idx = set(final_dataset[final_dataset['error_type'] == 'computational_error']['index'])\n",
    "        correct_idx = set(final_dataset[final_dataset['error_type'] == 'correct']['index'])\n",
    "        \n",
    "        print(f\"\\nIndex Overlap Analysis:\")\n",
    "        conceptual_computational_overlap = len(conceptual_idx & computational_idx)\n",
    "        conceptual_correct_overlap = len(conceptual_idx & correct_idx)\n",
    "        computational_correct_overlap = len(computational_idx & correct_idx)\n",
    "        \n",
    "        print(f\"  Conceptual ∩ Computational: {conceptual_computational_overlap:,} indices\")\n",
    "        print(f\"  Conceptual ∩ Correct: {conceptual_correct_overlap:,} indices\")\n",
    "        print(f\"  Computational ∩ Correct: {computational_correct_overlap:,} indices\")\n",
    "        \n",
    "        return final_dataset\n",
    "    else:\n",
    "        print(\"\\n❌ No samples could be selected!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Create the simplified error detection dataset\n",
    "error_detection_dataset = create_error_detection_dataset_simplified(df)\n",
    "\n",
    "# Save the dataset\n",
    "if not error_detection_dataset.empty:\n",
    "    output_path = AUG_5_DATASET_DIR / \"error_detection_dataset.csv\"\n",
    "    error_detection_dataset.to_csv(output_path, index=False)\n",
    "    print(f\"\\n💾 Dataset saved to: {output_path}\")\n",
    "else:\n",
    "    print(\"❌ Dataset creation failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e6496214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Calculator Annotation Coverage Analysis\n",
      "==================================================\n",
      "Total samples in dataset: 6,067\n",
      "Total samples missing coverage: 1,297\n",
      "Overall coverage rate: 78.6%\n",
      "\n",
      "By Error Type:\n",
      "  conceptual_error:\n",
      "    Total samples: 2,067\n",
      "    With complete coverage: 1,591\n",
      "    Missing coverage: 476\n",
      "    Coverage rate: 77.0%\n",
      "\n",
      "  computational_error:\n",
      "    Total samples: 2,000\n",
      "    With complete coverage: 1,571\n",
      "    Missing coverage: 429\n",
      "    Coverage rate: 78.5%\n",
      "\n",
      "  correct:\n",
      "    Total samples: 2,000\n",
      "    With complete coverage: 1,608\n",
      "    Missing coverage: 392\n",
      "    Coverage rate: 80.4%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_annotation_coverage(dataset_df, verbose=True):\n",
    "    \"\"\"\n",
    "    Check how many samples in the dataset are missing complete calculator annotation coverage.\n",
    "    \n",
    "    Args:\n",
    "        dataset_df: DataFrame containing the dataset to check\n",
    "        verbose: Whether to print detailed breakdown\n",
    "    \n",
    "    Returns:\n",
    "        dict: Summary of annotation coverage statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    def has_complete_annotation_coverage(row, eqn_mapping_col):\n",
    "        \"\"\"Check if all solution lines except FA have calculator annotations.\"\"\"\n",
    "        try:\n",
    "            eqn_mapping = json.loads(row[eqn_mapping_col])\n",
    "            \n",
    "            # Count total lines (excluding FA)\n",
    "            answer_length = row['correct_answer_length'] if 'correct' in eqn_mapping_col else row['wrong_answer_length']\n",
    "            expected_lines = answer_length - 1 if 'FA' in eqn_mapping else answer_length\n",
    "            \n",
    "            # Count non-empty equations (excluding FA)\n",
    "            non_empty_equations = sum(1 for key, value in eqn_mapping.items() \n",
    "                                    if key != 'FA' and value and str(value).strip())\n",
    "            \n",
    "            return non_empty_equations == expected_lines\n",
    "            \n",
    "        except (json.JSONDecodeError, KeyError, TypeError):\n",
    "            return False\n",
    "    \n",
    "    # Initialize results\n",
    "    results = {\n",
    "        'total_samples': len(dataset_df),\n",
    "        'by_error_type': {},\n",
    "        'missing_coverage': {\n",
    "            'total': 0,\n",
    "            'by_error_type': {}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Group by error_type for analysis\n",
    "    for error_type in dataset_df['error_type'].unique():\n",
    "        type_data = dataset_df[dataset_df['error_type'] == error_type]\n",
    "        \n",
    "        # Determine which equation mapping column to use\n",
    "        if error_type == 'correct':\n",
    "            eqn_col = 'correct_eqn_mapping'\n",
    "        else:\n",
    "            eqn_col = 'wrong_eqn_mapping'\n",
    "        \n",
    "        # Check coverage for this error type\n",
    "        has_coverage = type_data.apply(\n",
    "            lambda row: has_complete_annotation_coverage(row, eqn_col), axis=1\n",
    "        )\n",
    "        \n",
    "        # Count missing coverage\n",
    "        missing_count = (~has_coverage).sum()\n",
    "        total_count = len(type_data)\n",
    "        \n",
    "        results['by_error_type'][error_type] = {\n",
    "            'total': total_count,\n",
    "            'with_coverage': has_coverage.sum(),\n",
    "            'missing_coverage': missing_count,\n",
    "            'coverage_rate': has_coverage.sum() / total_count if total_count > 0 else 0\n",
    "        }\n",
    "        \n",
    "        results['missing_coverage']['by_error_type'][error_type] = missing_count\n",
    "        results['missing_coverage']['total'] += missing_count\n",
    "    \n",
    "    # Print results if verbose\n",
    "    if verbose:\n",
    "        print(\"🔍 Calculator Annotation Coverage Analysis\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Total samples in dataset: {results['total_samples']:,}\")\n",
    "        print(f\"Total samples missing coverage: {results['missing_coverage']['total']:,}\")\n",
    "        print(f\"Overall coverage rate: {((results['total_samples'] - results['missing_coverage']['total']) / results['total_samples'] * 100):.1f}%\")\n",
    "        print()\n",
    "        \n",
    "        print(\"By Error Type:\")\n",
    "        for error_type, stats in results['by_error_type'].items():\n",
    "            print(f\"  {error_type}:\")\n",
    "            print(f\"    Total samples: {stats['total']:,}\")\n",
    "            print(f\"    With complete coverage: {stats['with_coverage']:,}\")\n",
    "            print(f\"    Missing coverage: {stats['missing_coverage']:,}\")\n",
    "            print(f\"    Coverage rate: {stats['coverage_rate']:.1%}\")\n",
    "            print()\n",
    "    \n",
    "    return results\n",
    "\n",
    "coverage_results = check_annotation_coverage(error_detection_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6ea9ca4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'tier', 'question', 'correct_answer', 'wrong_answer',\n",
       "       'error_type', 'explanation', 'erroneous_line_number', 'erroneous_line',\n",
       "       'erroneous_line_eqn', 'correct_answer_mapping', 'wrong_answer_mapping',\n",
       "       'correct_eqn_mapping', 'wrong_eqn_mapping', 'correct_answer_length',\n",
       "       'wrong_answer_length', 'source', 'error_subtype', 'split'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_detection_dataset.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
