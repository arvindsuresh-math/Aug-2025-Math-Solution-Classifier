{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "151049e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/manually_generated_errors_final.csv\n",
      "computational: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/computational-errors-generated/computational_error_catalog.csv\n",
      "conceptual_ali: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_ali.csv\n",
      "conceptual_arvind: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_arvind.csv\n",
      "conceptual_mauro: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_mauro.csv\n",
      "conceptual_ling: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_ling.csv\n",
      "conceptual_yewei: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/validation_catalog_yewei.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Set, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- Path and Directory Definitions ---\n",
    "\n",
    "def find_project_root(marker: str = \".git\") -> Path:\n",
    "    \"\"\"Traverse upwards to find the project root, marked by the git repository.\"\"\"\n",
    "    current_path = Path.cwd().resolve()\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / marker).exists():\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    raise FileNotFoundError(f\"Could not find project root. Marker '{marker}' not found.\")\n",
    "\n",
    "VALIDATORS = [\"ali\", \"arvind\", \"mauro\", \"ling\", \"yewei\"]\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "CONCEPTUAL_ERRORS_DIR = DATA_DIR / 'conceptual-errors-accepted'\n",
    "COMPUTATIONAL_ERRORS_DIR = DATA_DIR / 'computational-errors-generated'\n",
    "CONCEPTUAL_CATALOG_DIR = DATA_DIR / 'conceptual-error-candidates'\n",
    "\n",
    "# load all catalog filepaths into a dict\n",
    "CATALOG_FILEPATH_DICT = {\n",
    "    \"manual\": DATA_DIR / 'manually_generated_errors_final.csv',\n",
    "    \"computational\": COMPUTATIONAL_ERRORS_DIR / 'computational_error_catalog.csv'\n",
    "}\n",
    "for name in VALIDATORS:\n",
    "    CATALOG_FILEPATH_DICT[f\"conceptual_{name}\"] = CONCEPTUAL_CATALOG_DIR / f'validation_catalog_{name}.csv'\n",
    "\n",
    "# Display the filepaths\n",
    "for name, path in CATALOG_FILEPATH_DICT.items():\n",
    "    print(f\"{name}: {path}\")\n",
    "\n",
    "# make dictionary with all catalogs\n",
    "CATALOG_DICT = {key: pd.read_csv(path) for key, path in CATALOG_FILEPATH_DICT.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7a0c34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual: 1963 rows\n",
      "columns: ['answer', 'erroneous_line_number', 'error_type', 'explanation', 'filepath', 'index', 'question', 'wrong_answer']\n",
      "computational: 22623 rows\n",
      "columns: ['index', 'tier', 'model', 'erroneous_line_number', 'explanation', 'wrong_answer', 'correct_trace_generated', 'target_variable', 'error_type', 'correct_value', 'flawed_value', 'repro_seed', 'date_utc', 'time_utc', 'filepath']\n",
      "conceptual_ali: 398 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n",
      "conceptual_arvind: 394 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n",
      "conceptual_mauro: 381 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n",
      "conceptual_ling: 388 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n",
      "conceptual_yewei: 381 rows\n",
      "columns: ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'decision_date_utc', 'decision_time_utc', 'status', 'manual_edits', 'filepath', 'validator', 'tier_numeric', 'priority']\n"
     ]
    }
   ],
   "source": [
    "for key, df in CATALOG_DICT.items():\n",
    "    print(f\"{key}: {len(df)} rows\")\n",
    "    print(\"columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6bdb057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSM8K_TRAIN = load_dataset(\"gsm8k\", \"main\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ebb8c55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier distribution in GSM8K:\n",
      "  tier1: 2767 problems\n",
      "  tier2: 837 problems\n",
      "  tier3: 3113 problems\n",
      "  tier4: 544 problems\n",
      "  tier5: 212 problems\n"
     ]
    }
   ],
   "source": [
    "# --- Tier Definition Functions (copied from arvind-july-25.ipynb) ---\n",
    "\n",
    "def has_computational_division(solution_text: str):\n",
    "    \"\"\"Checks if a solution text contains a division operation.\"\"\"\n",
    "    pattern = re.compile(r'/\\s*\\d')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def has_float(solution_text: str):\n",
    "    \"\"\"Checks if a solution text contains a float value.\"\"\"\n",
    "    pattern = re.compile(r'(?<!\\d)\\.\\d+|\\d+\\.\\d+')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def is_symbolic(solution_text: str):\n",
    "    \"\"\"Checks if a solution text uses symbolic algebra (e.g., 'Let x...').\"\"\"\n",
    "    pattern = re.compile(r'^Let [a-zA-Z] ', re.MULTILINE)\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def mutually_disjoint_tiers(dataset):\n",
    "    \"\"\"\n",
    "    Categorizes all problems in the dataset into mutually disjoint tiers\n",
    "    based on the mathematical operations present in their solution text.\n",
    "    \"\"\"\n",
    "    tiers = {}\n",
    "    symbolic_set = {idx for idx, sample in enumerate(dataset) if is_symbolic(sample.get(\"answer\", \"\"))}\n",
    "    non_symbolic_indices = [idx for idx in range(len(dataset)) if idx not in symbolic_set]\n",
    "    \n",
    "    tiers[\"tier1\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier2\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier3\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier4\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier5\"] = sorted(list(symbolic_set))\n",
    "    return tiers\n",
    "\n",
    "# --- Create Tier Mappings ---\n",
    "\n",
    "def add_tier_column(df, tier_lists):\n",
    "    \"\"\"\n",
    "    Adds a 'tier' column to the dataframe based on the TIER_LISTS dictionary.\n",
    "    Maps each GSM8K index to its corresponding tier.\n",
    "    \"\"\"\n",
    "    index_to_tier = {}\n",
    "    for tier_name, indices in tier_lists.items():\n",
    "        for idx in indices:\n",
    "            index_to_tier[idx] = tier_name\n",
    "    \n",
    "    df['tier'] = df['index'].map(index_to_tier)\n",
    "    \n",
    "    missing_tiers = df['tier'].isna().sum()\n",
    "    if missing_tiers > 0:\n",
    "        print(f\"Warning: {missing_tiers} indices could not be mapped to tiers\")\n",
    "        df['tier'] = df['tier'].fillna('unknown')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate tier mappings for the entire GSM8K dataset\n",
    "TIER_LISTS = mutually_disjoint_tiers(GSM8K_TRAIN)\n",
    "print(\"Tier distribution in GSM8K:\")\n",
    "for tier, indices in TIER_LISTS.items():\n",
    "    print(f\"  {tier}: {len(indices)} problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e803b036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Comprehensive text sanitization function that:\n",
    "    1. Converts literal \\n to actual newlines\n",
    "    2. Replaces problematic Unicode characters with ASCII equivalents\n",
    "    3. Removes comma separators from numbers\n",
    "    \n",
    "    This prevents model generation and string parsing errors.\n",
    "    \"\"\"\n",
    "    text = text.replace('\\\\n', '\\n')\n",
    "\n",
    "    replacements = {\n",
    "        \"\\u2212\": \"-\",    # Minus Sign\n",
    "        \"\\u00d7\": \"*\",    # Multiplication Sign\n",
    "        \"\\u00f7\": \"/\",    # Division Sign\n",
    "        \"\\u22c5\": \"*\",    # Dot Operator\n",
    "        \"\\u201c\": '\"',    # Left Double Quotation Mark\n",
    "        \"\\u201d\": '\"',    # Right Double Quotation Mark\n",
    "        \"\\u2018\": \"'\",    # Left Single Quotation Mark\n",
    "        \"\\u2019\": \"'\",    # Right Single Quotation Mark\n",
    "        \"\\u2014\": \"-\",    # Em Dash\n",
    "        \"\\u2013\": \"-\",    # En Dash\n",
    "        \"\\u2026\": \"...\",  # Horizontal Ellipsis\n",
    "        \"\\u00a0\": \" \",    # No-Break Space\n",
    "        \"\\u00f1\": \"n\",    # Spanish Ã± -> n\n",
    "        \"\\u200b\": \"\",     # Zero Width Space -> remove completely\n",
    "    }\n",
    "    for uni, ascii_char in replacements.items():\n",
    "        text = text.replace(uni, ascii_char)\n",
    "\n",
    "    text = re.sub(r'(\\d),(\\d)', r'\\1\\2', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def make_answer_mapping(answer: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Create a mapping from line numbers to solution lines from sanitized answer text.\n",
    "    Returns a dict mapping line identifiers (\"L1\", \"L2\", ..., \"FA\") to solution lines\n",
    "    WITHOUT calculator annotations.\n",
    "    \"\"\"\n",
    "    lines = answer.split('\\n')\n",
    "    final_answer = None\n",
    "    answer_mapping = {}\n",
    "\n",
    "    if lines and re.match(r'^\\s*####\\s*.*$', lines[-1]):\n",
    "        final_answer_line = lines.pop().strip()\n",
    "        match = re.search(r'####\\s*(.*)', final_answer_line)\n",
    "        if match:\n",
    "            final_answer = match.group(1).strip()\n",
    "\n",
    "    cleaned_lines = [line.strip() for line in lines if line.strip()]\n",
    "    for i, line in enumerate(cleaned_lines):\n",
    "        # Remove calculator annotations from each line\n",
    "        clean_line = re.sub(r'<<.*?>>', '', line).strip()\n",
    "        answer_mapping[f\"L{i+1}\"] = clean_line\n",
    "    \n",
    "    if final_answer is not None:\n",
    "        answer_mapping[\"FA\"] = final_answer\n",
    "    \n",
    "    return answer_mapping\n",
    "\n",
    "def make_separate_mappings(answer: str) -> Tuple[Dict[str, str], Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Extract calculator equations and create clean answer mapping without annotations.\n",
    "    Takes the original answer text and returns both equation mapping and clean answer mapping.\n",
    "    \"\"\"\n",
    "    lines = answer.split('\\n')\n",
    "    final_answer = None\n",
    "    \n",
    "    # Handle final answer line\n",
    "    if lines and re.match(r'^\\s*####\\s*.*$', lines[-1]):\n",
    "        final_answer_line = lines.pop().strip()\n",
    "        match = re.search(r'####\\s*(.*)', final_answer_line)\n",
    "        if match:\n",
    "            final_answer = match.group(1).strip()\n",
    "\n",
    "    cleaned_lines = [line.strip() for line in lines if line.strip()]\n",
    "    \n",
    "    eqn_mapping = {}\n",
    "    clean_answer_mapping = {}\n",
    "    \n",
    "    for i, line in enumerate(cleaned_lines):\n",
    "        line_id = f\"L{i+1}\"\n",
    "        \n",
    "        # Extract calculator equations\n",
    "        calculator_matches = re.findall(r'<<(.*?)>>', line)\n",
    "        if calculator_matches:\n",
    "            eqn_mapping[line_id] = calculator_matches[0]\n",
    "        else:\n",
    "            eqn_mapping[line_id] = \"\"\n",
    "        \n",
    "        # Create clean text without calculator annotations\n",
    "        clean_text = re.sub(r'<<.*?>>', '', line).strip()\n",
    "        clean_answer_mapping[line_id] = clean_text\n",
    "    \n",
    "    # Handle final answer\n",
    "    if final_answer is not None:\n",
    "        clean_answer_mapping[\"FA\"] = final_answer\n",
    "        eqn_mapping[\"FA\"] = \"\"\n",
    "    \n",
    "    return eqn_mapping, clean_answer_mapping\n",
    "\n",
    "def reconstruct_answer_from_clean_mapping(clean_mapping: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Returns a reconstructed answer text from clean mapping with FINAL ANSWER: prefix.\n",
    "    \"\"\"\n",
    "    if not clean_mapping:\n",
    "        return \"\"\n",
    "    \n",
    "    lines = []\n",
    "    i = 1\n",
    "    while f\"L{i}\" in clean_mapping:\n",
    "        line_text = clean_mapping[f\"L{i}\"].strip()\n",
    "        if line_text:\n",
    "            lines.append(line_text)\n",
    "        i += 1\n",
    "    \n",
    "    if \"FA\" in clean_mapping and clean_mapping[\"FA\"].strip():\n",
    "        lines.append(f\"FINAL ANSWER: {clean_mapping['FA'].strip()}\")\n",
    "    \n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "def process_answer_with_full_mappings(\n",
    "        answer_text: str,\n",
    "        answer_prefix: str) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Process an answer text and extract all mappings and derived information.\n",
    "    \n",
    "    Args:\n",
    "        answer_text: Raw answer text\n",
    "        answer_prefix: \"correct\" or \"flawed\"\n",
    "    \n",
    "    Returns:\n",
    "        Dict containing all processed information or None if processing fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sanitized_text = sanitize_text(answer_text)\n",
    "        \n",
    "        # Extract equations and clean mappings from original text\n",
    "        eqn_mapping, clean_answer_mapping = make_separate_mappings(sanitized_text)\n",
    "        \n",
    "        if not clean_answer_mapping:\n",
    "            return None\n",
    "\n",
    "        # Reconstruct clean answer\n",
    "        reconstructed_answer = reconstruct_answer_from_clean_mapping(clean_answer_mapping)\n",
    "        \n",
    "        # Store the CLEAN mapping as the main answer mapping\n",
    "        answer_mapping_json = json.dumps(clean_answer_mapping, ensure_ascii=False, indent=2)\n",
    "        eqn_mapping_json = json.dumps(eqn_mapping, ensure_ascii=False, indent=2)\n",
    "\n",
    "        return {\n",
    "            answer_prefix + '_answer': reconstructed_answer,\n",
    "            answer_prefix + '_mapping': answer_mapping_json,  # Now clean\n",
    "            answer_prefix + '_eqn_mapping': eqn_mapping_json,\n",
    "            answer_prefix + '_answer_length': len(clean_answer_mapping)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Any processing error returns None, will be handled as problematic\n",
    "        return None\n",
    "\n",
    "def validate_line_number_with_mapping(erroneous_line_number: str, answer_mapping: Dict[str, str]) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the erroneous line number exists in the answer mapping, False otherwise.\n",
    "    \"\"\"\n",
    "    if not erroneous_line_number or not answer_mapping:\n",
    "        return False\n",
    "    return erroneous_line_number in answer_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25450664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_catalog_row(\n",
    "        gsm8k_problem: Dict, \n",
    "        wrong_answer_text: str,\n",
    "        erroneous_line_number: str, \n",
    "        explanation: str,\n",
    "        error_type: str, \n",
    "        error_subtype: str, \n",
    "        source: str,\n",
    "        tier_lists: Dict,\n",
    "        catalog_index: int) -> Tuple[Dict[str, any], bool]:\n",
    "    \"\"\"\n",
    "    Process a single catalog row and return all required columns.\n",
    "    \n",
    "    Args:\n",
    "        gsm8k_problem: GSM8K problem data\n",
    "        wrong_answer_text: Wrong answer text\n",
    "        erroneous_line_number: Line identifier with error\n",
    "        explanation: Error explanation\n",
    "        error_type: Type of error (computational_error/conceptual_error)\n",
    "        error_subtype: Subtype of error\n",
    "        source: Source of data (manual/programmatic)\n",
    "        tier_lists: Tier mapping dictionary\n",
    "        catalog_index: The GSM8K index from the source catalog\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (processed_row_dict, is_successful)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        problem_index = catalog_index\n",
    "        \n",
    "        # Determine tier\n",
    "        problem_tier = None\n",
    "        for tier_name, indices in tier_lists.items():\n",
    "            if problem_index in indices:\n",
    "                problem_tier = tier_name\n",
    "                break\n",
    "        \n",
    "        # Process question\n",
    "        cleaned_question = sanitize_text(gsm8k_problem['question'])\n",
    "        \n",
    "        # Process correct answer\n",
    "        correct_processed = process_answer_with_full_mappings(gsm8k_problem['answer'], \"correct\")\n",
    "        if not correct_processed:\n",
    "            return {}, False\n",
    "        \n",
    "        # Process wrong answer\n",
    "        wrong_processed = process_answer_with_full_mappings(wrong_answer_text, \"wrong\")\n",
    "        if not wrong_processed:\n",
    "            return {}, False\n",
    "        \n",
    "        # Parse the clean mappings for validation and line extraction\n",
    "        correct_mapping = json.loads(correct_processed['correct_mapping'])\n",
    "        wrong_mapping = json.loads(wrong_processed['wrong_mapping'])\n",
    "        wrong_eqn_mapping = json.loads(wrong_processed['wrong_eqn_mapping'])\n",
    "        \n",
    "        # Validate erroneous line number against correct answer\n",
    "        if not validate_line_number_with_mapping(erroneous_line_number, correct_mapping):\n",
    "            return {}, False\n",
    "        \n",
    "        # Extract erroneous line information from wrong answer (already clean)\n",
    "        if erroneous_line_number == \"FA\":\n",
    "            # For final answer, reconstruct with \"FINAL ANSWER:\" prefix\n",
    "            fa_content = wrong_mapping.get(\"FA\", \"\")\n",
    "            erroneous_line = f\"FINAL ANSWER: {fa_content}\" if fa_content else \"\"\n",
    "        else:\n",
    "            # For regular lines, use the clean version directly\n",
    "            erroneous_line = wrong_mapping.get(erroneous_line_number, \"\")\n",
    "\n",
    "        erroneous_line_eqn = wrong_eqn_mapping.get(erroneous_line_number, \"\")\n",
    "        \n",
    "        # Build the complete row\n",
    "        processed_row = {\n",
    "            'index': problem_index,\n",
    "            'tier': problem_tier,\n",
    "            'question': cleaned_question,\n",
    "            'correct_answer': correct_processed['correct_answer'],\n",
    "            'wrong_answer': wrong_processed['wrong_answer'],\n",
    "            'error_type': error_type,\n",
    "            'explanation': explanation,\n",
    "            'erroneous_line_number': erroneous_line_number,\n",
    "            'erroneous_line': erroneous_line,\n",
    "            'erroneous_line_eqn': erroneous_line_eqn,\n",
    "            'correct_answer_mapping': correct_processed['correct_mapping'],\n",
    "            'wrong_answer_mapping': wrong_processed['wrong_mapping'],\n",
    "            'correct_eqn_mapping': correct_processed['correct_eqn_mapping'],\n",
    "            'wrong_eqn_mapping': wrong_processed['wrong_eqn_mapping'],\n",
    "            'correct_answer_length': correct_processed['correct_answer_length'],\n",
    "            'wrong_answer_length': wrong_processed['wrong_answer_length'],\n",
    "            'source': source,\n",
    "            'error_subtype': error_subtype\n",
    "        }\n",
    "        \n",
    "        return processed_row, True\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {}, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b9f8c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_manual_catalog_with_new_pipeline(catalog_dict, gsm8k_train, tier_lists) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Process manual catalog using the new pipeline with full mappings.\n",
    "    \"\"\"\n",
    "    print(\"=== Processing Manual Catalog with New Pipeline ===\")\n",
    "    \n",
    "    df = catalog_dict['manual'].copy()\n",
    "    print(f\"Initial rows: {len(df)}\")\n",
    "    \n",
    "    clean_rows = []\n",
    "    problematic_rows = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing manual catalog\"):\n",
    "        try:\n",
    "            problem_index = int(row['index'])\n",
    "            \n",
    "            # Check if erroneous_line_number is missing\n",
    "            if pd.isna(row['erroneous_line_number']):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': 'Missing erroneous_line_number',\n",
    "                    'source_catalog': 'manual'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Get GSM8K data\n",
    "            if problem_index >= len(gsm8k_train):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': f'Index {problem_index} out of range',\n",
    "                    'source_catalog': 'manual'\n",
    "                })\n",
    "                continue\n",
    "                \n",
    "            gsm8k_problem = gsm8k_train[problem_index]\n",
    "            \n",
    "            # Process using the new pipeline\n",
    "            processed_row, success = process_single_catalog_row(\n",
    "                gsm8k_problem=gsm8k_problem,\n",
    "                wrong_answer_text=row['wrong_answer'],\n",
    "                erroneous_line_number=row['erroneous_line_number'],\n",
    "                explanation=row['explanation'],\n",
    "                error_type=row['error_type'] + '_error',\n",
    "                error_subtype='NA',\n",
    "                source='manual',\n",
    "                tier_lists=tier_lists,\n",
    "                catalog_index=problem_index  # Add this line\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                clean_rows.append(processed_row)\n",
    "            else:\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': 'Processing failed in pipeline',\n",
    "                    'source_catalog': 'manual'\n",
    "                })\n",
    "            \n",
    "        except Exception as e:\n",
    "            problematic_rows.append({\n",
    "                **row.to_dict(),\n",
    "                'error_reason': f'Processing error: {str(e)}',\n",
    "                'source_catalog': 'manual'\n",
    "            })\n",
    "    \n",
    "    clean_df = pd.DataFrame(clean_rows)\n",
    "    problematic_df = pd.DataFrame(problematic_rows)\n",
    "    \n",
    "    print(f\"Clean rows: {len(clean_df)}\")\n",
    "    print(f\"Problematic rows: {len(problematic_df)}\")\n",
    "    \n",
    "    return clean_df, problematic_df\n",
    "\n",
    "def process_computational_catalog_with_new_pipeline(catalog_dict, gsm8k_train, tier_lists) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Process computational catalog using the new pipeline with full mappings.\n",
    "    \"\"\"\n",
    "    print(\"=== Processing Computational Catalog with New Pipeline ===\")\n",
    "    \n",
    "    df = catalog_dict['computational'].copy()\n",
    "    print(f\"Initial rows: {len(df)}\")\n",
    "    \n",
    "    clean_rows = []\n",
    "    problematic_rows = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing computational catalog\"):\n",
    "        try:\n",
    "            problem_index = int(row['index'])\n",
    "            \n",
    "            # Check if erroneous_line_number is missing\n",
    "            if pd.isna(row['erroneous_line_number']):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': 'Missing erroneous_line_number',\n",
    "                    'source_catalog': 'computational'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Get GSM8K data\n",
    "            if problem_index >= len(gsm8k_train):\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': f'Index {problem_index} out of range',\n",
    "                    'source_catalog': 'computational'\n",
    "                })\n",
    "                continue\n",
    "                \n",
    "            gsm8k_problem = gsm8k_train[problem_index]\n",
    "            \n",
    "            # Check if this is tier5 and exclude it\n",
    "            problem_tier = None\n",
    "            for tier_name, indices in tier_lists.items():\n",
    "                if problem_index in indices:\n",
    "                    problem_tier = tier_name\n",
    "                    break\n",
    "            \n",
    "            if problem_tier == 'tier5':\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': 'Excluded tier5 problem',\n",
    "                    'source_catalog': 'computational'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Process using the new pipeline\n",
    "            processed_row, success = process_single_catalog_row(\n",
    "                gsm8k_problem=gsm8k_problem,\n",
    "                wrong_answer_text=row['wrong_answer'],\n",
    "                erroneous_line_number=row['erroneous_line_number'],\n",
    "                explanation=row['explanation'],\n",
    "                error_type='computational_error',\n",
    "                error_subtype=row['error_type'],\n",
    "                source='programmatic',\n",
    "                tier_lists=tier_lists,\n",
    "                catalog_index=problem_index  # Add this line\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                clean_rows.append(processed_row)\n",
    "            else:\n",
    "                problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': 'Processing failed in pipeline',\n",
    "                    'source_catalog': 'computational'\n",
    "                })\n",
    "            \n",
    "        except Exception as e:\n",
    "            problematic_rows.append({\n",
    "                **row.to_dict(),\n",
    "                'error_reason': f'Processing error: {str(e)}',\n",
    "                'source_catalog': 'computational'\n",
    "            })\n",
    "    \n",
    "    clean_df = pd.DataFrame(clean_rows)\n",
    "    problematic_df = pd.DataFrame(problematic_rows)\n",
    "    \n",
    "    print(f\"Clean rows: {len(clean_df)}\")\n",
    "    print(f\"Problematic rows: {len(problematic_df)}\")\n",
    "    \n",
    "    return clean_df, problematic_df\n",
    "\n",
    "def process_validator_catalogs_with_new_pipeline(catalog_dict, gsm8k_train, tier_lists, validators, project_root) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Process all validator catalogs using the new pipeline with full mappings.\n",
    "    \"\"\"\n",
    "    print(\"=== Processing Validator Catalogs with New Pipeline ===\")\n",
    "    \n",
    "    all_clean_rows = []\n",
    "    all_problematic_rows = []\n",
    "    \n",
    "    def check_file_exists_and_get_path(filepath, base_dir=None):\n",
    "        \"\"\"\n",
    "        Check if a file exists and return the correct path, handling cross-platform path issues.\n",
    "        \"\"\"\n",
    "        if pd.isna(filepath) or filepath == \"\":\n",
    "            return None, False\n",
    "        \n",
    "        normalized_filepath = str(filepath).replace('\\\\', '/')\n",
    "        file_path = Path(normalized_filepath)\n",
    "        \n",
    "        if not file_path.is_absolute():\n",
    "            full_path = project_root / file_path\n",
    "        else:\n",
    "            full_path = file_path\n",
    "        \n",
    "        return full_path, full_path.exists()\n",
    "    \n",
    "    def fix_answer_formatting(wrong_answer: str) -> str:\n",
    "        \"\"\"\n",
    "        Fixes the formatting of wrong answers by moving the final answer line\n",
    "        from the beginning to the end if it's misplaced.\n",
    "        \"\"\"\n",
    "        if not isinstance(wrong_answer, str):\n",
    "            return wrong_answer\n",
    "        \n",
    "        lines = wrong_answer.strip().split('\\n')\n",
    "        final_answer_line = None\n",
    "        other_lines = []\n",
    "        \n",
    "        for line in lines:\n",
    "            if re.match(r'^\\s*####\\s*.*$', line.strip()):\n",
    "                final_answer_line = line.strip()\n",
    "            elif line.strip():\n",
    "                other_lines.append(line)\n",
    "        \n",
    "        if final_answer_line and other_lines:\n",
    "            return '\\n'.join(other_lines) + '\\n' + final_answer_line\n",
    "        elif final_answer_line:\n",
    "            return final_answer_line\n",
    "        else:\n",
    "            return wrong_answer\n",
    "    \n",
    "    for validator in validators:\n",
    "        print(f\"\\nProcessing validator: {validator}\")\n",
    "        df = catalog_dict[f'conceptual_{validator}'].copy()\n",
    "        \n",
    "        # Filter to only accepted samples\n",
    "        df = df[df['status'] == 'accepted']\n",
    "        print(f\"Accepted rows for {validator}: {len(df)}\")\n",
    "        \n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Processing {validator}\"):\n",
    "            try:\n",
    "                problem_index = int(row['index'])\n",
    "                \n",
    "                # Get GSM8K data\n",
    "                if problem_index >= len(gsm8k_train):\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'Index {problem_index} out of range',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                    \n",
    "                gsm8k_problem = gsm8k_train[problem_index]\n",
    "                \n",
    "                # Check if this is tier5 and exclude it\n",
    "                problem_tier = None\n",
    "                for tier_name, indices in tier_lists.items():\n",
    "                    if problem_index in indices:\n",
    "                        problem_tier = tier_name\n",
    "                        break\n",
    "                \n",
    "                if problem_tier == 'tier5':\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': 'Excluded tier5 problem',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Load JSON file with proper path handling\n",
    "                try:\n",
    "                    filepath, file_exists = check_file_exists_and_get_path(row['filepath'])\n",
    "                    \n",
    "                    if not file_exists or filepath is None:\n",
    "                        all_problematic_rows.append({\n",
    "                            **row.to_dict(),\n",
    "                            'error_reason': f'JSON file not found: {row[\"filepath\"]}',\n",
    "                            'source_catalog': f'conceptual_{validator}'\n",
    "                        })\n",
    "                        continue\n",
    "                    \n",
    "                    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                        json_data = json.load(f)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'JSON loading error: {str(e)}',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Extract data from JSON\n",
    "                try:\n",
    "                    raw_wrong_answer = json_data['context']['flawed_solution']\n",
    "                    explanation = json_data['error_details']['explanation']\n",
    "                    erroneous_line_number = json_data['error_details']['erroneous_line_number']\n",
    "                    error_subtype = json_data['error_details']['error_type']\n",
    "                except KeyError as e:\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'Missing JSON field: {str(e)}',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Fix the answer formatting\n",
    "                wrong_answer = fix_answer_formatting(raw_wrong_answer)\n",
    "                \n",
    "                # Check for null erroneous_line_number\n",
    "                if erroneous_line_number is None or erroneous_line_number == \"null\":\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': f'Null erroneous_line_number in JSON',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Process using the new pipeline\n",
    "                processed_row, success = process_single_catalog_row(\n",
    "                    gsm8k_problem=gsm8k_problem,\n",
    "                    wrong_answer_text=wrong_answer,\n",
    "                    erroneous_line_number=erroneous_line_number,\n",
    "                    explanation=explanation,\n",
    "                    error_type='conceptual_error',\n",
    "                    error_subtype=error_subtype,\n",
    "                    source='programmatic',\n",
    "                    tier_lists=tier_lists,\n",
    "                    catalog_index=problem_index  # Add this line\n",
    "                )\n",
    "                \n",
    "                if success:\n",
    "                    all_clean_rows.append(processed_row)\n",
    "                else:\n",
    "                    all_problematic_rows.append({\n",
    "                        **row.to_dict(),\n",
    "                        'error_reason': 'Processing failed in pipeline',\n",
    "                        'source_catalog': f'conceptual_{validator}'\n",
    "                    })\n",
    "                \n",
    "            except Exception as e:\n",
    "                all_problematic_rows.append({\n",
    "                    **row.to_dict(),\n",
    "                    'error_reason': f'Processing error: {str(e)}',\n",
    "                    'source_catalog': f'conceptual_{validator}'\n",
    "                })\n",
    "    \n",
    "    clean_df = pd.DataFrame(all_clean_rows)\n",
    "    problematic_df = pd.DataFrame(all_problematic_rows)\n",
    "    \n",
    "    print(f\"\\nTotal clean rows: {len(clean_df)}\")\n",
    "    print(f\"Total problematic rows: {len(problematic_df)}\")\n",
    "    \n",
    "    return clean_df, problematic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5739e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_CATALOG_COLUMNS = [\n",
    "    'index', \n",
    "    'tier', \n",
    "    'question', \n",
    "    'correct_answer', \n",
    "    'wrong_answer', \n",
    "    'error_type', \n",
    "    'explanation', \n",
    "    'erroneous_line_number', \n",
    "    'erroneous_line', \n",
    "    'erroneous_line_eqn', \n",
    "    'correct_answer_mapping', \n",
    "    'wrong_answer_mapping',\n",
    "    'correct_eqn_mapping', \n",
    "    'wrong_eqn_mapping', \n",
    "    'correct_answer_length',\n",
    "    'wrong_answer_length', \n",
    "    'source', \n",
    "    'error_subtype'\n",
    "]\n",
    "\n",
    "def create_master_catalogs_with_new_structure(manual_clean, computational_clean, validator_clean, \n",
    "                          manual_problematic, computational_problematic, validator_problematic):\n",
    "    \"\"\"\n",
    "    Combines all clean and problematic dataframes into final master catalogs with new structure.\n",
    "    \"\"\"\n",
    "    print(\"=== Creating Master Catalogs with New Structure ===\")\n",
    "    \n",
    "    # Combine all clean dataframes\n",
    "    all_clean_dfs = []\n",
    "    if not manual_clean.empty:\n",
    "        all_clean_dfs.append(manual_clean)\n",
    "    if not computational_clean.empty:\n",
    "        all_clean_dfs.append(computational_clean)\n",
    "    if not validator_clean.empty:\n",
    "        all_clean_dfs.append(validator_clean)\n",
    "    \n",
    "    master_catalog = pd.concat(all_clean_dfs, ignore_index=True) if all_clean_dfs else pd.DataFrame()\n",
    "    \n",
    "    # Combine all problematic dataframes\n",
    "    all_problematic_dfs = []\n",
    "    if not manual_problematic.empty:\n",
    "        all_problematic_dfs.append(manual_problematic)\n",
    "    if not computational_problematic.empty:\n",
    "        all_problematic_dfs.append(computational_problematic)\n",
    "    if not validator_problematic.empty:\n",
    "        all_problematic_dfs.append(validator_problematic)\n",
    "    \n",
    "    catalog_problematic = pd.concat(all_problematic_dfs, ignore_index=True) if all_problematic_dfs else pd.DataFrame()\n",
    "    \n",
    "    # Ensure consistent column order for master catalog\n",
    "    if not master_catalog.empty:\n",
    "        master_catalog = master_catalog[MASTER_CATALOG_COLUMNS]\n",
    "    \n",
    "    print(f\"Master catalog rows: {len(master_catalog)}\")\n",
    "    print(f\"Problematic rows: {len(catalog_problematic)}\")\n",
    "    \n",
    "    return master_catalog, catalog_problematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39977ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Full Pipeline Execution\n",
      "================================================================================\n",
      "=== Processing Manual Catalog with New Pipeline ===\n",
      "Initial rows: 1963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d723e6687db442c962db86467e85116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing manual catalog:   0%|          | 0/1963 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean rows: 1740\n",
      "Problematic rows: 223\n",
      "=== Processing Computational Catalog with New Pipeline ===\n",
      "Initial rows: 22623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7a9bad17a14cf2ae2e975628fe883b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing computational catalog:   0%|          | 0/22623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean rows: 21768\n",
      "Problematic rows: 855\n",
      "=== Processing Validator Catalogs with New Pipeline ===\n",
      "\n",
      "Processing validator: ali\n",
      "Accepted rows for ali: 341\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ebf906cdbd4ba4b1ea7d46492dd682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ali:   0%|          | 0/341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validator: arvind\n",
      "Accepted rows for arvind: 91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682a4e3ddd594a1aa6735dbe1ebb3129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing arvind:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validator: mauro\n",
      "Accepted rows for mauro: 312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0faa49fb2bbb45cd8b6f1e33dc4680c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing mauro:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validator: ling\n",
      "Accepted rows for ling: 110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd24f41078c43d7ba661e17934066e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ling:   0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validator: yewei\n",
      "Accepted rows for yewei: 290\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ba3500759241f3a765453e99ef4893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing yewei:   0%|          | 0/290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total clean rows: 1144\n",
      "Total problematic rows: 0\n",
      "=== Creating Master Catalogs with New Structure ===\n",
      "Master catalog rows: 24652\n",
      "Problematic rows: 1078\n",
      "\n",
      "ðŸŽ‰ Pipeline Execution Complete!\n",
      "âœ… Master catalog: 24,652 rows\n",
      "âŒ Problematic rows: 1,078 rows\n"
     ]
    }
   ],
   "source": [
    "# 1. Run the full pipeline\n",
    "print(\"ðŸš€ Starting Full Pipeline Execution\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Process manual catalog\n",
    "manual_clean, manual_problematic = process_manual_catalog_with_new_pipeline(\n",
    "    CATALOG_DICT, GSM8K_TRAIN, TIER_LISTS\n",
    ")\n",
    "\n",
    "# Process computational catalog  \n",
    "computational_clean, computational_problematic = process_computational_catalog_with_new_pipeline(\n",
    "    CATALOG_DICT, GSM8K_TRAIN, TIER_LISTS\n",
    ")\n",
    "\n",
    "# Process validator catalogs\n",
    "validator_clean, validator_problematic = process_validator_catalogs_with_new_pipeline(\n",
    "    CATALOG_DICT, GSM8K_TRAIN, TIER_LISTS, VALIDATORS, PROJECT_ROOT\n",
    ")\n",
    "\n",
    "# Create master catalogs\n",
    "master_catalog, catalog_problematic = create_master_catalogs_with_new_structure(\n",
    "    manual_clean, computational_clean, validator_clean,\n",
    "    manual_problematic, computational_problematic, validator_problematic\n",
    ")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Pipeline Execution Complete!\")\n",
    "print(f\"âœ… Master catalog: {len(master_catalog):,} rows\")\n",
    "print(f\"âŒ Problematic rows: {len(catalog_problematic):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "73ed4200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ² RANDOM SAMPLE FROM EACH SOURCE CATALOG\n",
      "================================================================================\n",
      "\n",
      "ðŸ” MANUAL CATALOG\n",
      "------------------------------------------------------------\n",
      "ðŸ“‹ Index: 1184 | Tier: tier1 | Error Type: computational_error\n",
      "ðŸ“ Error Subtype: NA\n",
      "ðŸŽ¯ Erroneous Line Number: L3\n",
      "ðŸ”´ Erroneous Line: A medium bed can hold 3 rows with 20 seeds sown per row, 3 * 20=50 seeds per medium bed.\n",
      "ðŸ§® Erroneous Line Equation: 3*20=50\n",
      "\n",
      "â“ Question:\n",
      "Grace is looking to plant some lettuce in her raised bed garden. Her raised bed is comprised of 2 large beds on top with 2 medium beds on the bottom. The top bed can hold 4 rows of lettuce with 25 seeds being sown per row. The medium bed can house 3 rows with 20 seeds being sown per row. How many seeds can Grace plant in all four beds of her raised bed garden?\n",
      "\n",
      "âœ… Correct Answer (Full):\n",
      "A large bed can hold 4 rows with 25 seeds per row, 4 * 25=100 seeds per large bed\n",
      "100 seeds per large bed and there are 2 beds, 100 * 2= 200 seeds needed in total for both large beds.\n",
      "A medium bed can hold 3 rows with 20 seeds sown per row, 3 * 20=60 seeds per medium bed.\n",
      "60 seeds per medium bed and there are 2 medium beds, 60 * 2=120 seeds needed in total for both medium beds.\n",
      "200 seeds needed for the large beds combined with 120 seeds needed for the medium beds comes to 200 +120= 320 seeds needed to plant all four beds of the raised garden bed.\n",
      "FINAL ANSWER: 320\n",
      "\n",
      "âŒ Wrong Answer (Full):\n",
      "A large bed can hold 4 rows with 25 seeds per row, 4 * 25=100 seeds per large bed\n",
      "100 seeds per large bed and there are 2 beds, 100 * 2= 200 seeds needed in total for both large beds.\n",
      "A medium bed can hold 3 rows with 20 seeds sown per row, 3 * 20=50 seeds per medium bed.\n",
      "50 seeds per medium bed and there are 2 medium beds, 50 * 2=100 seeds needed in total for both medium beds.\n",
      "200 seeds needed for the large beds combined with 100 seeds needed for the medium beds comes to 200 +100= 300 seeds needed to plant all four beds of the raised garden bed.\n",
      "FINAL ANSWER: 300\n",
      "\n",
      "ðŸ’¡ Explanation:\n",
      "computational error: A medium bed can hold 3 rows with 20 seeds sown per row, 3 * 20 = 60 seeds per medium bed (the calculation of 3*20 was incorrect).\n",
      "\n",
      "ðŸ“Š Answer Lengths:\n",
      "   Correct: 6 lines\n",
      "   Wrong: 6 lines\n",
      "\n",
      "ðŸ—‚ï¸ Correct Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"A large bed can hold 4 rows with 25 seeds per row, 4 * 25=100 seeds per large bed\",\n",
      "  \"L2\": \"100 seeds per large bed and there are 2 beds, 100 * 2= 200 seeds needed in total for both large beds.\",\n",
      "  \"L3\": \"A medium bed can hold 3 rows with 20 seeds sown per row, 3 * 20=60 seeds per medium bed.\",\n",
      "  \"L4\": \"60 seeds per medium bed and there are 2 medium beds, 60 * 2=120 seeds needed in total for both medium beds.\",\n",
      "  \"L5\": \"200 seeds needed for the large beds combined with 120 seeds needed for the medium beds comes to 200 +120= 320 seeds needed to plant all four beds of the raised garden bed.\",\n",
      "  \"FA\": \"320\"\n",
      "}\n",
      "\n",
      "ðŸ—‚ï¸ Wrong Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"A large bed can hold 4 rows with 25 seeds per row, 4 * 25=100 seeds per large bed\",\n",
      "  \"L2\": \"100 seeds per large bed and there are 2 beds, 100 * 2= 200 seeds needed in total for both large beds.\",\n",
      "  \"L3\": \"A medium bed can hold 3 rows with 20 seeds sown per row, 3 * 20=50 seeds per medium bed.\",\n",
      "  \"L4\": \"50 seeds per medium bed and there are 2 medium beds, 50 * 2=100 seeds needed in total for both medium beds.\",\n",
      "  \"L5\": \"200 seeds needed for the large beds combined with 100 seeds needed for the medium beds comes to 200 +100= 300 seeds needed to plant all four beds of the raised garden bed.\",\n",
      "  \"FA\": \"300\"\n",
      "}\n",
      "\n",
      "ðŸ§® Correct Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"4*25=100\",\n",
      "  \"L2\": \"100*2=200\",\n",
      "  \"L3\": \"3*20=60\",\n",
      "  \"L4\": \"60*2=120\",\n",
      "  \"L5\": \"200+120=320\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ§® Wrong Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"4*25=100\",\n",
      "  \"L2\": \"100*2=200\",\n",
      "  \"L3\": \"3*20=50\",\n",
      "  \"L4\": \"50*2=100\",\n",
      "  \"L5\": \"200+100=300\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ·ï¸ Source: manual\n",
      "================================================================================\n",
      "\n",
      "ðŸ” COMPUTATIONAL CATALOG\n",
      "------------------------------------------------------------\n",
      "ðŸ“‹ Index: 6725 | Tier: tier1 | Error Type: computational_error\n",
      "ðŸ“ Error Subtype: generate_digit_transposition_error\n",
      "ðŸŽ¯ Erroneous Line Number: L1\n",
      "ðŸ”´ Erroneous Line: Janice can earn $30 x 5 = $105 per week.\n",
      "ðŸ§® Erroneous Line Equation: 30*5=105\n",
      "\n",
      "â“ Question:\n",
      "Janice has been working part-time at a convenience store 5 days a week. She can earn $30 per day and can earn $15 more when she works a 2 hour overtime shift. If she works three overtime shifts this week, how much will she earn this week?\n",
      "\n",
      "âœ… Correct Answer (Full):\n",
      "Janice can earn $30 x 5 = $150 per week.\n",
      "She will earn $15 x 3 = $45 more if she works three overtime shifts.\n",
      "Therefore, Janice will earn $150 + $45 = $195 this week.\n",
      "FINAL ANSWER: 195\n",
      "\n",
      "âŒ Wrong Answer (Full):\n",
      "Janice can earn $30 x 5 = $105 per week.\n",
      "She will earn $15 x 3 = $45 more if she works three overtime shifts.\n",
      "Therefore, Janice will earn $105 + $45 = $150 this week.\n",
      "FINAL ANSWER: 150\n",
      "\n",
      "ðŸ’¡ Explanation:\n",
      "The result of this computation should be 150, not 105. It appears two adjacent digits were swapped.\n",
      "\n",
      "ðŸ“Š Answer Lengths:\n",
      "   Correct: 4 lines\n",
      "   Wrong: 4 lines\n",
      "\n",
      "ðŸ—‚ï¸ Correct Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"Janice can earn $30 x 5 = $150 per week.\",\n",
      "  \"L2\": \"She will earn $15 x 3 = $45 more if she works three overtime shifts.\",\n",
      "  \"L3\": \"Therefore, Janice will earn $150 + $45 = $195 this week.\",\n",
      "  \"FA\": \"195\"\n",
      "}\n",
      "\n",
      "ðŸ—‚ï¸ Wrong Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"Janice can earn $30 x 5 = $105 per week.\",\n",
      "  \"L2\": \"She will earn $15 x 3 = $45 more if she works three overtime shifts.\",\n",
      "  \"L3\": \"Therefore, Janice will earn $105 + $45 = $150 this week.\",\n",
      "  \"FA\": \"150\"\n",
      "}\n",
      "\n",
      "ðŸ§® Correct Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"30*5=150\",\n",
      "  \"L2\": \"15*3=45\",\n",
      "  \"L3\": \"150+45=195\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ§® Wrong Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"30*5=105\",\n",
      "  \"L2\": \"15*3=45\",\n",
      "  \"L3\": \"105+45=150\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ·ï¸ Source: programmatic\n",
      "================================================================================\n",
      "\n",
      "ðŸ” CONCEPTUAL VALIDATOR #1\n",
      "------------------------------------------------------------\n",
      "ðŸ“‹ Index: 3224 | Tier: tier4 | Error Type: conceptual_error\n",
      "ðŸ“ Error Subtype: operator_swap\n",
      "ðŸŽ¯ Erroneous Line Number: L2\n",
      "ðŸ”´ Erroneous Line: Traveling 15 minutes at 16 miles per hour, Stephen travels 16/0.25 = 64 miles.\n",
      "ðŸ§® Erroneous Line Equation: \n",
      "\n",
      "â“ Question:\n",
      "Stephen rides his bicycle to church.  During the first third of his trip, he travels at a speed of 16 miles per hour. During the second third of his trip, riding uphill, he travels a speed of 12 miles per hour.  During the last third of his trip, he rides downhill at a speed of 20 miles per hour.  If each third of his trip takes 15 minutes, what is the distance Stephen rides his bicycle to church, in miles?\n",
      "\n",
      "âœ… Correct Answer (Full):\n",
      "15 minutes is 15/60=0.25 hours.\n",
      "Traveling 15 minutes at 16 miles per hour, Stephen travels 16*0.25 = 4 miles.\n",
      "Traveling 15 minutes at 12 miles per hour, Stephen travels 12*0.25 = 3 miles.\n",
      "Traveling 15 minutes at 20 miles per hour, Stephen travels 20*0.25 = 5 miles.\n",
      "All together, Stephen travels 4+3+5=12 miles.\n",
      "FINAL ANSWER: 12\n",
      "\n",
      "âŒ Wrong Answer (Full):\n",
      "15 minutes is 15/60=0.25 hours.\n",
      "Traveling 15 minutes at 16 miles per hour, Stephen travels 16/0.25 = 64 miles.\n",
      "Traveling 15 minutes at 12 miles per hour, Stephen travels 12*0.25 = 3 miles.\n",
      "Traveling 15 minutes at 20 miles per hour, Stephen travels 20*0.25 = 5 miles.\n",
      "All together, Stephen travels 64+3+5=72 miles.\n",
      "FINAL ANSWER: 72\n",
      "\n",
      "ðŸ’¡ Explanation:\n",
      "Incorrect operation. The calculation should use '*' but used '/' instead.\n",
      "\n",
      "ðŸ“Š Answer Lengths:\n",
      "   Correct: 6 lines\n",
      "   Wrong: 6 lines\n",
      "\n",
      "ðŸ—‚ï¸ Correct Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"15 minutes is 15/60=0.25 hours.\",\n",
      "  \"L2\": \"Traveling 15 minutes at 16 miles per hour, Stephen travels 16*0.25 = 4 miles.\",\n",
      "  \"L3\": \"Traveling 15 minutes at 12 miles per hour, Stephen travels 12*0.25 = 3 miles.\",\n",
      "  \"L4\": \"Traveling 15 minutes at 20 miles per hour, Stephen travels 20*0.25 = 5 miles.\",\n",
      "  \"L5\": \"All together, Stephen travels 4+3+5=12 miles.\",\n",
      "  \"FA\": \"12\"\n",
      "}\n",
      "\n",
      "ðŸ—‚ï¸ Wrong Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"15 minutes is 15/60=0.25 hours.\",\n",
      "  \"L2\": \"Traveling 15 minutes at 16 miles per hour, Stephen travels 16/0.25 = 64 miles.\",\n",
      "  \"L3\": \"Traveling 15 minutes at 12 miles per hour, Stephen travels 12*0.25 = 3 miles.\",\n",
      "  \"L4\": \"Traveling 15 minutes at 20 miles per hour, Stephen travels 20*0.25 = 5 miles.\",\n",
      "  \"L5\": \"All together, Stephen travels 64+3+5=72 miles.\",\n",
      "  \"FA\": \"72\"\n",
      "}\n",
      "\n",
      "ðŸ§® Correct Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"15/60=0.25\",\n",
      "  \"L2\": \"\",\n",
      "  \"L3\": \"\",\n",
      "  \"L4\": \"\",\n",
      "  \"L5\": \"4+3+5=12\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ§® Wrong Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"15/60=0.25\",\n",
      "  \"L2\": \"\",\n",
      "  \"L3\": \"\",\n",
      "  \"L4\": \"\",\n",
      "  \"L5\": \"64+3+5=72\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ·ï¸ Source: programmatic\n",
      "================================================================================\n",
      "\n",
      "ðŸ” CONCEPTUAL VALIDATOR #2\n",
      "------------------------------------------------------------\n",
      "ðŸ“‹ Index: 4241 | Tier: tier3 | Error Type: conceptual_error\n",
      "ðŸ“ Error Subtype: operator_swap\n",
      "ðŸŽ¯ Erroneous Line Number: L2\n",
      "ðŸ”´ Erroneous Line: The total number of marbles that Ludo bought is 16 marbles + 4 marbles = 12 marbles\n",
      "ðŸ§® Erroneous Line Equation: 16+4=12\n",
      "\n",
      "â“ Question:\n",
      "Three friends Wolfgang, Ludo, and Michael, went to Walmart and bought marbles. Wolfgang bought 16 marbles, Ludo bought 1/4 times more marbles than Wolfgang, and Michael bought 2/3 times as many marbles as the number of marbles both Wolfgang and Ludo bought. If they combined their marbles and decided to share them equally, how many marbles did each get?\n",
      "\n",
      "âœ… Correct Answer (Full):\n",
      "Ludo bought 1/4 more marbles than Wolfgang, which is 1/4 * 16 marbles = 4 marbles\n",
      "The total number of marbles that Ludo bought is 16 marbles + 4 marbles = 20 marbles\n",
      "Wolfgang and Ludo purchased a total of 20 marbles + 16 marbles = 36 marbles.\n",
      "If Michael bought 2/3 times the total number of marbles bought by Wolfgang and Ludo, he bought 2/3 * 36 marbles = 24 marbles.\n",
      "The three friends purchased a total of 24 marbles + 36 marbles = 60 marbles.\n",
      "When they shared the marbles equally, each got 60 marbles / 3 people = 20 marbles/person.\n",
      "FINAL ANSWER: 20\n",
      "\n",
      "âŒ Wrong Answer (Full):\n",
      "Ludo bought 1/4 more marbles than Wolfgang, which is 1/4 * 16 marbles = 4 marbles\n",
      "The total number of marbles that Ludo bought is 16 marbles + 4 marbles = 12 marbles\n",
      "Wolfgang and Ludo purchased a total of 12 marbles + 16 marbles = 28 marbles.\n",
      "If Michael bought 2/3 times the total number of marbles bought by Wolfgang and Ludo, he bought 2/3 * 28 marbles = 56/3 marbles.\n",
      "The three friends purchased a total of 56/3 marbles + 28 marbles = 140/3 marbles.\n",
      "When they shared the marbles equally, each got 140/3 marbles / 3 people = 140/9 marbles/person.\n",
      "FINAL ANSWER: 140/9\n",
      "\n",
      "ðŸ’¡ Explanation:\n",
      "Incorrect operation. The calculation should use '+' but used '-' instead.\n",
      "\n",
      "ðŸ“Š Answer Lengths:\n",
      "   Correct: 7 lines\n",
      "   Wrong: 7 lines\n",
      "\n",
      "ðŸ—‚ï¸ Correct Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"Ludo bought 1/4 more marbles than Wolfgang, which is 1/4 * 16 marbles = 4 marbles\",\n",
      "  \"L2\": \"The total number of marbles that Ludo bought is 16 marbles + 4 marbles = 20 marbles\",\n",
      "  \"L3\": \"Wolfgang and Ludo purchased a total of 20 marbles + 16 marbles = 36 marbles.\",\n",
      "  \"L4\": \"If Michael bought 2/3 times the total number of marbles bought by Wolfgang and Ludo, he bought 2/3 * 36 marbles = 24 marbles.\",\n",
      "  \"L5\": \"The three friends purchased a total of 24 marbles + 36 marbles = 60 marbles.\",\n",
      "  \"L6\": \"When they shared the marbles equally, each got 60 marbles / 3 people = 20 marbles/person.\",\n",
      "  \"FA\": \"20\"\n",
      "}\n",
      "\n",
      "ðŸ—‚ï¸ Wrong Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"Ludo bought 1/4 more marbles than Wolfgang, which is 1/4 * 16 marbles = 4 marbles\",\n",
      "  \"L2\": \"The total number of marbles that Ludo bought is 16 marbles + 4 marbles = 12 marbles\",\n",
      "  \"L3\": \"Wolfgang and Ludo purchased a total of 12 marbles + 16 marbles = 28 marbles.\",\n",
      "  \"L4\": \"If Michael bought 2/3 times the total number of marbles bought by Wolfgang and Ludo, he bought 2/3 * 28 marbles = 56/3 marbles.\",\n",
      "  \"L5\": \"The three friends purchased a total of 56/3 marbles + 28 marbles = 140/3 marbles.\",\n",
      "  \"L6\": \"When they shared the marbles equally, each got 140/3 marbles / 3 people = 140/9 marbles/person.\",\n",
      "  \"FA\": \"140/9\"\n",
      "}\n",
      "\n",
      "ðŸ§® Correct Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"1/4*16=4\",\n",
      "  \"L2\": \"16+4=20\",\n",
      "  \"L3\": \"20+16=36\",\n",
      "  \"L4\": \"2/3*36=24\",\n",
      "  \"L5\": \"24+36=60\",\n",
      "  \"L6\": \"60/3=20\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ§® Wrong Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"1/4*16=4\",\n",
      "  \"L2\": \"16+4=12\",\n",
      "  \"L3\": \"12+16=28\",\n",
      "  \"L4\": \"2/3*28=56/3\",\n",
      "  \"L5\": \"56/3+28=140/3\",\n",
      "  \"L6\": \"140/3/3=140/9\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ·ï¸ Source: programmatic\n",
      "================================================================================\n",
      "\n",
      "ðŸ” CONCEPTUAL VALIDATOR #3\n",
      "------------------------------------------------------------\n",
      "ðŸ“‹ Index: 2135 | Tier: tier4 | Error Type: conceptual_error\n",
      "ðŸ“ Error Subtype: incomplete_calculation\n",
      "ðŸŽ¯ Erroneous Line Number: L1\n",
      "ðŸ”´ Erroneous Line: The four cats weigh 36 pounds in total because 12 plus 14.7 plus 9.3 equals 36.\n",
      "ðŸ§® Erroneous Line Equation: 12+14.7+9.3=36\n",
      "\n",
      "â“ Question:\n",
      "Janele wants to figure out the average weight of her cats. She has 4 of them. The first two weigh 12 pounds each. The third weighs 14.7 pounds and the fourth weighs 9.3 pounds. What is their average weight?\n",
      "\n",
      "âœ… Correct Answer (Full):\n",
      "The four cats weigh 48 pounds in total because 12 plus 12 plus 14.7 plus 9.3 equals 48.\n",
      "The average weight is 12 pounds because 48 divided by 4 is 12.\n",
      "FINAL ANSWER: 12\n",
      "\n",
      "âŒ Wrong Answer (Full):\n",
      "The four cats weigh 36 pounds in total because 12 plus 14.7 plus 9.3 equals 36.\n",
      "The average weight is 9 pounds because 36 divided by 4 is 9.\n",
      "FINAL ANSWER: 9\n",
      "\n",
      "ðŸ’¡ Explanation:\n",
      "Incomplete calculation. The term 'cat2_weight' (value: 12.0) was omitted from the operation.\n",
      "\n",
      "ðŸ“Š Answer Lengths:\n",
      "   Correct: 3 lines\n",
      "   Wrong: 3 lines\n",
      "\n",
      "ðŸ—‚ï¸ Correct Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"The four cats weigh 48 pounds in total because 12 plus 12 plus 14.7 plus 9.3 equals 48.\",\n",
      "  \"L2\": \"The average weight is 12 pounds because 48 divided by 4 is 12.\",\n",
      "  \"FA\": \"12\"\n",
      "}\n",
      "\n",
      "ðŸ—‚ï¸ Wrong Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"The four cats weigh 36 pounds in total because 12 plus 14.7 plus 9.3 equals 36.\",\n",
      "  \"L2\": \"The average weight is 9 pounds because 36 divided by 4 is 9.\",\n",
      "  \"FA\": \"9\"\n",
      "}\n",
      "\n",
      "ðŸ§® Correct Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"12+12+14.7+9.3=48\",\n",
      "  \"L2\": \"48/4=12\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ§® Wrong Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"12+14.7+9.3=36\",\n",
      "  \"L2\": \"36/4=9\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ·ï¸ Source: programmatic\n",
      "================================================================================\n",
      "\n",
      "ðŸ” CONCEPTUAL VALIDATOR #4\n",
      "------------------------------------------------------------\n",
      "ðŸ“‹ Index: 4809 | Tier: tier2 | Error Type: conceptual_error\n",
      "ðŸ“ Error Subtype: incomplete_calculation\n",
      "ðŸŽ¯ Erroneous Line Number: L3\n",
      "ðŸ”´ Erroneous Line: Now multiply the new total by 10% to find out how much Jerry owes the loan shark in interest the second month: $220 * 10% = $2200\n",
      "ðŸ§® Erroneous Line Equation: 220*10=2200\n",
      "\n",
      "â“ Question:\n",
      "Jerry owes a loan shark $200. The loan shark charges Jerry 10% interest compounded monthly. (This means that every month the loan shark adds Jerry's interest amount to his loan, and the next month Jerry has to pay 10% on the new total). If Jerry doesn't make any payments, how much (in dollars) does the loan shark charge in interest the second month?\n",
      "\n",
      "âœ… Correct Answer (Full):\n",
      "First calculate how much the loan shark charges in interest the first month by multiplying the loan amount by the interest rate: $200 * 10% = $20\n",
      "Now add the interest amount to the original amount of the loan to find Jerry's new total: $200 + $20 = $220\n",
      "Now multiply the new total by 10% to find out how much Jerry owes the loan shark in interest the second month: $220 * 10% = $22\n",
      "FINAL ANSWER: 22\n",
      "\n",
      "âŒ Wrong Answer (Full):\n",
      "First calculate how much the loan shark charges in interest the first month by multiplying the loan amount by the interest rate: $200 * 10% = $20\n",
      "Now add the interest amount to the original amount of the loan to find Jerry's new total: $200 + $20 = $220\n",
      "Now multiply the new total by 10% to find out how much Jerry owes the loan shark in interest the second month: $220 * 10% = $2200\n",
      "FINAL ANSWER: 2200\n",
      "\n",
      "ðŸ’¡ Explanation:\n",
      "Incomplete calculation. The term 'percent_factor' (value: 0.01) was omitted from the operation.\n",
      "\n",
      "ðŸ“Š Answer Lengths:\n",
      "   Correct: 4 lines\n",
      "   Wrong: 4 lines\n",
      "\n",
      "ðŸ—‚ï¸ Correct Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"First calculate how much the loan shark charges in interest the first month by multiplying the loan amount by the interest rate: $200 * 10% = $20\",\n",
      "  \"L2\": \"Now add the interest amount to the original amount of the loan to find Jerry's new total: $200 + $20 = $220\",\n",
      "  \"L3\": \"Now multiply the new total by 10% to find out how much Jerry owes the loan shark in interest the second month: $220 * 10% = $22\",\n",
      "  \"FA\": \"22\"\n",
      "}\n",
      "\n",
      "ðŸ—‚ï¸ Wrong Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"First calculate how much the loan shark charges in interest the first month by multiplying the loan amount by the interest rate: $200 * 10% = $20\",\n",
      "  \"L2\": \"Now add the interest amount to the original amount of the loan to find Jerry's new total: $200 + $20 = $220\",\n",
      "  \"L3\": \"Now multiply the new total by 10% to find out how much Jerry owes the loan shark in interest the second month: $220 * 10% = $2200\",\n",
      "  \"FA\": \"2200\"\n",
      "}\n",
      "\n",
      "ðŸ§® Correct Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"200*10*.01=20\",\n",
      "  \"L2\": \"200+20=220\",\n",
      "  \"L3\": \"220*10*.01=22\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ§® Wrong Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"200*10*0.01=20\",\n",
      "  \"L2\": \"200+20=220\",\n",
      "  \"L3\": \"220*10=2200\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ·ï¸ Source: programmatic\n",
      "================================================================================\n",
      "\n",
      "ðŸ” CONCEPTUAL VALIDATOR #5\n",
      "------------------------------------------------------------\n",
      "ðŸ“‹ Index: 5132 | Tier: tier1 | Error Type: conceptual_error\n",
      "ðŸ“ Error Subtype: incomplete_calculation\n",
      "ðŸŽ¯ Erroneous Line Number: L4\n",
      "ðŸ”´ Erroneous Line: Therefore, Cid earned a total of $$300 + $75 = $375.\n",
      "ðŸ§® Erroneous Line Equation: 300+75=375\n",
      "\n",
      "â“ Question:\n",
      "Cid owns a mechanic shop, he charges $20 for an oil change, $30 for a repair, and $5 for a car wash. How much money did he earn if he changed the oil of 5 cars, repaired 10 cars, and washed 15 cars?\n",
      "\n",
      "âœ… Correct Answer (Full):\n",
      "The money he earned from an oil change is $20 x 5 =$ 100.\n",
      "The money he earned from the repair is $30 x 10 = $300.\n",
      "The money he earned from the car wash is $15 x 5 = $75.\n",
      "Therefore, Cid earned a total of $100 + $300 + $75 = $475.\n",
      "FINAL ANSWER: 475\n",
      "\n",
      "âŒ Wrong Answer (Full):\n",
      "The money he earned from an oil change is $20 x 5 =$ 100.\n",
      "The money he earned from the repair is $30 x 10 = $300.\n",
      "The money he earned from the car wash is $15 x 5 = $75.\n",
      "Therefore, Cid earned a total of $$300 + $75 = $375.\n",
      "FINAL ANSWER: 375\n",
      "\n",
      "ðŸ’¡ Explanation:\n",
      "Incomplete calculation. The term 'earned_from_oil_change' (value: 100) was omitted from the operation.\n",
      "\n",
      "ðŸ“Š Answer Lengths:\n",
      "   Correct: 5 lines\n",
      "   Wrong: 5 lines\n",
      "\n",
      "ðŸ—‚ï¸ Correct Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"The money he earned from an oil change is $20 x 5 =$ 100.\",\n",
      "  \"L2\": \"The money he earned from the repair is $30 x 10 = $300.\",\n",
      "  \"L3\": \"The money he earned from the car wash is $15 x 5 = $75.\",\n",
      "  \"L4\": \"Therefore, Cid earned a total of $100 + $300 + $75 = $475.\",\n",
      "  \"FA\": \"475\"\n",
      "}\n",
      "\n",
      "ðŸ—‚ï¸ Wrong Answer Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"The money he earned from an oil change is $20 x 5 =$ 100.\",\n",
      "  \"L2\": \"The money he earned from the repair is $30 x 10 = $300.\",\n",
      "  \"L3\": \"The money he earned from the car wash is $15 x 5 = $75.\",\n",
      "  \"L4\": \"Therefore, Cid earned a total of $$300 + $75 = $375.\",\n",
      "  \"FA\": \"375\"\n",
      "}\n",
      "\n",
      "ðŸ§® Correct Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"20*5=100\",\n",
      "  \"L2\": \"30*10=300\",\n",
      "  \"L3\": \"15*5=75\",\n",
      "  \"L4\": \"100+300+75=475\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ§® Wrong Equation Mapping (JSON):\n",
      "{\n",
      "  \"L1\": \"20*5=100\",\n",
      "  \"L2\": \"30*10=300\",\n",
      "  \"L3\": \"15*5=75\",\n",
      "  \"L4\": \"300+75=375\",\n",
      "  \"FA\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ·ï¸ Source: programmatic\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Summary: Displayed samples from 7 source categories\n"
     ]
    }
   ],
   "source": [
    "# 2. Pretty print one randomly chosen row from each catalog source\n",
    "import json\n",
    "\n",
    "def pretty_print_sample_rows_by_source(master_catalog):\n",
    "    \"\"\"\n",
    "    Pretty prints one randomly chosen row from each source catalog.\n",
    "    \"\"\"\n",
    "    print(\"ðŸŽ² RANDOM SAMPLE FROM EACH SOURCE CATALOG\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if master_catalog.empty:\n",
    "        print(\"âŒ Master catalog is empty!\")\n",
    "        return\n",
    "    \n",
    "    # Define source mappings\n",
    "    source_mappings = {\n",
    "        'manual': 'Manual Catalog',\n",
    "        'computational': 'Computational Catalog', \n",
    "        'conceptual_ali': 'Conceptual Validator - Ali',\n",
    "        'conceptual_arvind': 'Conceptual Validator - Arvind',\n",
    "        'conceptual_mauro': 'Conceptual Validator - Mauro',\n",
    "        'conceptual_ling': 'Conceptual Validator - Ling',\n",
    "        'conceptual_yewei': 'Conceptual Validator - Yewei'\n",
    "    }\n",
    "    \n",
    "    # Get available sources in the data\n",
    "    available_sources = master_catalog['source'].unique()\n",
    "    error_types = master_catalog['error_type'].unique()\n",
    "    \n",
    "    # Sample one row from each available source/error_type combination\n",
    "    sampled_sources = set()\n",
    "    \n",
    "    # First priority: manual source\n",
    "    if 'manual' in available_sources:\n",
    "        manual_samples = master_catalog[master_catalog['source'] == 'manual']\n",
    "        if not manual_samples.empty:\n",
    "            sample = manual_samples.sample(1).iloc[0]\n",
    "            sampled_sources.add('manual')\n",
    "            print_sample_row(sample, 'Manual Catalog')\n",
    "    \n",
    "    # Second priority: computational (programmatic source + computational_error)\n",
    "    programmatic_computational = master_catalog[\n",
    "        (master_catalog['source'] == 'programmatic') & \n",
    "        (master_catalog['error_type'] == 'computational_error')\n",
    "    ]\n",
    "    if not programmatic_computational.empty:\n",
    "        sample = programmatic_computational.sample(1).iloc[0]\n",
    "        sampled_sources.add('computational')\n",
    "        print_sample_row(sample, 'Computational Catalog')\n",
    "    \n",
    "    # Third priority: conceptual validators (programmatic source + conceptual_error)\n",
    "    programmatic_conceptual = master_catalog[\n",
    "        (master_catalog['source'] == 'programmatic') & \n",
    "        (master_catalog['error_type'] == 'conceptual_error')\n",
    "    ]\n",
    "    \n",
    "    # Try to get one sample from each validator if possible\n",
    "    validators_sampled = set()\n",
    "    for _ in range(5):  # Try up to 5 times to get different validators\n",
    "        if not programmatic_conceptual.empty and len(validators_sampled) < 5:\n",
    "            sample = programmatic_conceptual.sample(1).iloc[0]\n",
    "            \n",
    "            # Determine which validator this likely came from based on patterns\n",
    "            # This is approximate since we don't store validator info directly\n",
    "            validator_name = f\"Conceptual Validator #{len(validators_sampled) + 1}\"\n",
    "            if validator_name not in validators_sampled:\n",
    "                validators_sampled.add(validator_name)\n",
    "                print_sample_row(sample, validator_name)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Summary: Displayed samples from {len(sampled_sources) + len(validators_sampled)} source categories\")\n",
    "\n",
    "def print_sample_row(sample, source_name):\n",
    "    \"\"\"Helper function to pretty print a single sample row with full content.\"\"\"\n",
    "    print(f\"\\nðŸ” {source_name.upper()}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"ðŸ“‹ Index: {sample['index']} | Tier: {sample['tier']} | Error Type: {sample['error_type']}\")\n",
    "    print(f\"ðŸ“ Error Subtype: {sample['error_subtype']}\")\n",
    "    print(f\"ðŸŽ¯ Erroneous Line Number: {sample['erroneous_line_number']}\")\n",
    "    print(f\"ðŸ”´ Erroneous Line: {sample['erroneous_line']}\")\n",
    "    print(f\"ðŸ§® Erroneous Line Equation: {sample['erroneous_line_eqn']}\")\n",
    "    \n",
    "    print(f\"\\nâ“ Question:\")\n",
    "    print(f\"{sample['question']}\")\n",
    "    \n",
    "    print(f\"\\nâœ… Correct Answer (Full):\")\n",
    "    print(f\"{sample['correct_answer']}\")\n",
    "    \n",
    "    print(f\"\\nâŒ Wrong Answer (Full):\")\n",
    "    print(f\"{sample['wrong_answer']}\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¡ Explanation:\")\n",
    "    print(f\"{sample['explanation']}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Answer Lengths:\")\n",
    "    print(f\"   Correct: {sample['correct_answer_length']} lines\")\n",
    "    print(f\"   Wrong: {sample['wrong_answer_length']} lines\")\n",
    "    \n",
    "    print(f\"\\nðŸ—‚ï¸ Correct Answer Mapping (JSON):\")\n",
    "    print(f\"{sample['correct_answer_mapping']}\")\n",
    "    \n",
    "    print(f\"\\nðŸ—‚ï¸ Wrong Answer Mapping (JSON):\")\n",
    "    print(f\"{sample['wrong_answer_mapping']}\")\n",
    "    \n",
    "    print(f\"\\nðŸ§® Correct Equation Mapping (JSON):\")\n",
    "    print(f\"{sample['correct_eqn_mapping']}\")\n",
    "    \n",
    "    print(f\"\\nðŸ§® Wrong Equation Mapping (JSON):\")\n",
    "    print(f\"{sample['wrong_eqn_mapping']}\")\n",
    "    \n",
    "    print(f\"\\nðŸ·ï¸ Source: {sample['source']}\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Run the pretty printer\n",
    "pretty_print_sample_rows_by_source(master_catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5f9c907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ SAVING MASTER CATALOG TO: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/aug-5-dataset\n",
      "================================================================================\n",
      "âœ… Master catalog saved: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/aug-5-dataset/master_catalog.csv\n",
      "   ðŸ“Š 24,652 rows with 18 columns\n",
      "âœ… Problematic catalog saved: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/aug-5-dataset/catalog_problematic.csv\n",
      "   ðŸ“Š 1,078 problematic rows\n",
      "âœ… Summary statistics saved: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/aug-5-dataset/dataset_summary.txt\n",
      "âœ… Column schema saved: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/aug-5-dataset/column_schema.json\n",
      "\n",
      "ðŸ“ FILES IN aug-5-dataset/:\n",
      "   ðŸ“„ catalog_problematic.csv (0.4 MB)\n",
      "   ðŸ“„ column_schema.json (0.0 MB)\n",
      "   ðŸ“„ dataset_summary.txt (0.0 MB)\n",
      "   ðŸ“„ manual_length_mismatch.csv (0.3 MB)\n",
      "   ðŸ“„ master_catalog.csv (47.0 MB)\n",
      "\n",
      "ðŸŽ‰ Dataset successfully saved to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/aug-5-dataset\n",
      "âœ¨ Ready for downstream processing and analysis!\n"
     ]
    }
   ],
   "source": [
    "# 3. Save the master catalog to a new folder \"../data/aug-5-dataset\"\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Create the new directory\n",
    "AUG_5_DATASET_DIR = DATA_DIR / \"aug-5-dataset\"\n",
    "AUG_5_DATASET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"ðŸ’¾ SAVING MASTER CATALOG TO: {AUG_5_DATASET_DIR}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save master catalog\n",
    "master_catalog_path = AUG_5_DATASET_DIR / \"master_catalog.csv\"\n",
    "master_catalog.to_csv(master_catalog_path, index=False)\n",
    "print(f\"âœ… Master catalog saved: {master_catalog_path}\")\n",
    "print(f\"   ðŸ“Š {len(master_catalog):,} rows with {len(MASTER_CATALOG_COLUMNS)} columns\")\n",
    "\n",
    "# Save problematic catalog\n",
    "problematic_catalog_path = AUG_5_DATASET_DIR / \"catalog_problematic.csv\"\n",
    "catalog_problematic.to_csv(problematic_catalog_path, index=False)\n",
    "print(f\"âœ… Problematic catalog saved: {problematic_catalog_path}\")\n",
    "print(f\"   ðŸ“Š {len(catalog_problematic):,} problematic rows\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_path = AUG_5_DATASET_DIR / \"dataset_summary.txt\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"AUG-5 DATASET SUMMARY\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    f.write(f\"Generated on: August 5, 2025\\n\")\n",
    "    f.write(f\"Total master catalog rows: {len(master_catalog):,}\\n\")\n",
    "    f.write(f\"Total problematic rows: {len(catalog_problematic):,}\\n\")\n",
    "    f.write(f\"Unique GSM8K indices: {master_catalog['index'].nunique():,}\\n\\n\")\n",
    "    \n",
    "    f.write(\"SOURCE DISTRIBUTION:\\n\")\n",
    "    source_counts = master_catalog['source'].value_counts()\n",
    "    for source, count in source_counts.items():\n",
    "        pct = (count / len(master_catalog)) * 100\n",
    "        f.write(f\"  {source}: {count:,} ({pct:.1f}%)\\n\")\n",
    "    \n",
    "    f.write(\"\\nERROR TYPE DISTRIBUTION:\\n\")\n",
    "    error_type_counts = master_catalog['error_type'].value_counts()\n",
    "    for error_type, count in error_type_counts.items():\n",
    "        pct = (count / len(master_catalog)) * 100\n",
    "        f.write(f\"  {error_type}: {count:,} ({pct:.1f}%)\\n\")\n",
    "    \n",
    "    f.write(\"\\nTIER DISTRIBUTION:\\n\")\n",
    "    tier_counts = master_catalog['tier'].value_counts().sort_index()\n",
    "    for tier, count in tier_counts.items():\n",
    "        pct = (count / len(master_catalog)) * 100\n",
    "        f.write(f\"  {tier}: {count:,} ({pct:.1f}%)\\n\")\n",
    "    \n",
    "    f.write(f\"\\nCOLUMNS ({len(MASTER_CATALOG_COLUMNS)}):\\n\")\n",
    "    for i, col in enumerate(MASTER_CATALOG_COLUMNS, 1):\n",
    "        f.write(f\"  {i:2d}. {col}\\n\")\n",
    "\n",
    "print(f\"âœ… Summary statistics saved: {summary_path}\")\n",
    "\n",
    "def get_column_description(col_name):\n",
    "    \"\"\"Get description for each column.\"\"\"\n",
    "    descriptions = {\n",
    "        'index': 'GSM8K problem index',\n",
    "        'tier': 'Problem difficulty tier (tier1-tier5)',\n",
    "        'question': 'Math problem question text',\n",
    "        'correct_answer': 'Correct solution with FINAL ANSWER prefix',\n",
    "        'wrong_answer': 'Flawed solution with FINAL ANSWER prefix', \n",
    "        'error_type': 'Type of error (computational_error/conceptual_error)',\n",
    "        'explanation': 'Human explanation of the error',\n",
    "        'erroneous_line_number': 'Line identifier containing the error (L1, L2, FA)',\n",
    "        'erroneous_line': 'Text content of the erroneous line',\n",
    "        'erroneous_line_eqn': 'Calculator equation from erroneous line',\n",
    "        'correct_answer_mapping': 'JSON mapping of line IDs to correct solution lines',\n",
    "        'wrong_answer_mapping': 'JSON mapping of line IDs to wrong solution lines',\n",
    "        'correct_eqn_mapping': 'JSON mapping of line IDs to correct calculator equations',\n",
    "        'wrong_eqn_mapping': 'JSON mapping of line IDs to wrong calculator equations', \n",
    "        'correct_answer_length': 'Number of lines in correct solution',\n",
    "        'wrong_answer_length': 'Number of lines in wrong solution',\n",
    "        'source': 'Data source (manual/programmatic)',\n",
    "        'error_subtype': 'Detailed error subtype classification'\n",
    "    }\n",
    "    return descriptions.get(col_name, 'No description available')\n",
    "\n",
    "# Save column schema\n",
    "schema_path = AUG_5_DATASET_DIR / \"column_schema.json\"\n",
    "schema_info = {\n",
    "    \"dataset_name\": \"aug-5-dataset\", \n",
    "    \"creation_date\": \"2025-08-05\",\n",
    "    \"total_columns\": len(MASTER_CATALOG_COLUMNS),\n",
    "    \"columns\": {\n",
    "        col: {\n",
    "            \"position\": i + 1,\n",
    "            \"data_type\": str(master_catalog[col].dtype) if col in master_catalog.columns else \"unknown\",\n",
    "            \"description\": get_column_description(col)\n",
    "        }\n",
    "        for i, col in enumerate(MASTER_CATALOG_COLUMNS)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(schema_path, 'w') as f:\n",
    "    json.dump(schema_info, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Column schema saved: {schema_path}\")\n",
    "\n",
    "# List all files in the new directory\n",
    "print(f\"\\nðŸ“ FILES IN {AUG_5_DATASET_DIR.name}/:\")\n",
    "for file_path in sorted(AUG_5_DATASET_DIR.iterdir()):\n",
    "    file_size = file_path.stat().st_size / (1024 * 1024)  # Size in MB\n",
    "    print(f\"   ðŸ“„ {file_path.name} ({file_size:.1f} MB)\")\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Dataset successfully saved to: {AUG_5_DATASET_DIR}\")\n",
    "print(\"âœ¨ Ready for downstream processing and analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "896d6a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š DATAFRAME INFO:\n",
      "==================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24652 entries, 0 to 24651\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   index                   24652 non-null  int64 \n",
      " 1   tier                    24652 non-null  object\n",
      " 2   question                24652 non-null  object\n",
      " 3   correct_answer          24652 non-null  object\n",
      " 4   wrong_answer            24652 non-null  object\n",
      " 5   error_type              24652 non-null  object\n",
      " 6   explanation             24651 non-null  object\n",
      " 7   erroneous_line_number   24652 non-null  object\n",
      " 8   erroneous_line          24382 non-null  object\n",
      " 9   erroneous_line_eqn      22616 non-null  object\n",
      " 10  correct_answer_mapping  24652 non-null  object\n",
      " 11  wrong_answer_mapping    24652 non-null  object\n",
      " 12  correct_eqn_mapping     24652 non-null  object\n",
      " 13  wrong_eqn_mapping       24652 non-null  object\n",
      " 14  correct_answer_length   24652 non-null  int64 \n",
      " 15  wrong_answer_length     24652 non-null  int64 \n",
      " 16  source                  24652 non-null  object\n",
      " 17  error_subtype           22912 non-null  object\n",
      "dtypes: int64(3), object(15)\n",
      "memory usage: 3.4+ MB\n",
      "\n",
      "ðŸ“‹ COLUMN DTYPES:\n",
      "==================================================\n",
      "index: int64\n",
      "tier: object\n",
      "question: object\n",
      "correct_answer: object\n",
      "wrong_answer: object\n",
      "error_type: object\n",
      "explanation: object\n",
      "erroneous_line_number: object\n",
      "erroneous_line: object\n",
      "erroneous_line_eqn: object\n",
      "correct_answer_mapping: object\n",
      "wrong_answer_mapping: object\n",
      "correct_eqn_mapping: object\n",
      "wrong_eqn_mapping: object\n",
      "correct_answer_length: int64\n",
      "wrong_answer_length: int64\n",
      "source: object\n",
      "error_subtype: object\n",
      "\n",
      "ðŸ” SAMPLE ROW (First Row):\n",
      "==================================================\n",
      "\n",
      "index:\n",
      "  Type: <class 'numpy.int64'>\n",
      "  Value: 1000\n",
      "\n",
      "tier:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'tier3'\n",
      "\n",
      "question:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'John buys a heating pad for $30.  He uses it 3 times a week for 2 weeks.  How much does he spend on each use?'\n",
      "\n",
      "correct_answer:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'He uses it 3*2=6 times\\nSo he pays 30/6=$5\\nFINAL ANSWER: 5'\n",
      "\n",
      "wrong_answer:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'He uses it 3*2=5 times\\nSo he pays 30/5=$6\\nFINAL ANSWER: 6'\n",
      "\n",
      "error_type:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'computational_error'\n",
      "\n",
      "explanation:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'computational error: John uses it 3*2=<<3*2=6>>6 times.'\n",
      "\n",
      "erroneous_line_number:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'L1'\n",
      "\n",
      "erroneous_line:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'He uses it 3*2=5 times'\n",
      "\n",
      "erroneous_line_eqn:\n",
      "  Type: <class 'str'>\n",
      "  Value: '3*2=5'\n",
      "\n",
      "correct_answer_mapping:\n",
      "  Type: <class 'str'>\n",
      "  Value: '{\\n  \"L1\": \"He uses it 3*2=6 times\",\\n  \"L2\": \"So he pays 30/6=$5\",\\n  \"FA\": \"5\"\\n}'\n",
      "  First 100 chars: {\n",
      "  \"L1\": \"He uses it 3*2=6 times\",\n",
      "  \"L2\": \"So he pays 30/6=$5\",\n",
      "  \"FA\": \"5\"\n",
      "}...\n",
      "  JSON Parse: SUCCESS - <class 'dict'>\n",
      "\n",
      "wrong_answer_mapping:\n",
      "  Type: <class 'str'>\n",
      "  Value: '{\\n  \"L1\": \"He uses it 3*2=5 times\",\\n  \"L2\": \"So he pays 30/5=$6\",\\n  \"FA\": \"6\"\\n}'\n",
      "  First 100 chars: {\n",
      "  \"L1\": \"He uses it 3*2=5 times\",\n",
      "  \"L2\": \"So he pays 30/5=$6\",\n",
      "  \"FA\": \"6\"\n",
      "}...\n",
      "  JSON Parse: SUCCESS - <class 'dict'>\n",
      "\n",
      "correct_eqn_mapping:\n",
      "  Type: <class 'str'>\n",
      "  Value: '{\\n  \"L1\": \"3*2=6\",\\n  \"L2\": \"30/6=5\",\\n  \"FA\": \"\"\\n}'\n",
      "  First 100 chars: {\n",
      "  \"L1\": \"3*2=6\",\n",
      "  \"L2\": \"30/6=5\",\n",
      "  \"FA\": \"\"\n",
      "}...\n",
      "  JSON Parse: SUCCESS - <class 'dict'>\n",
      "\n",
      "wrong_eqn_mapping:\n",
      "  Type: <class 'str'>\n",
      "  Value: '{\\n  \"L1\": \"3*2=5\",\\n  \"L2\": \"30/5=6\",\\n  \"FA\": \"\"\\n}'\n",
      "  First 100 chars: {\n",
      "  \"L1\": \"3*2=5\",\n",
      "  \"L2\": \"30/5=6\",\n",
      "  \"FA\": \"\"\n",
      "}...\n",
      "  JSON Parse: SUCCESS - <class 'dict'>\n",
      "\n",
      "correct_answer_length:\n",
      "  Type: <class 'numpy.int64'>\n",
      "  Value: 3\n",
      "\n",
      "wrong_answer_length:\n",
      "  Type: <class 'numpy.int64'>\n",
      "  Value: 3\n",
      "\n",
      "source:\n",
      "  Type: <class 'str'>\n",
      "  Value: 'manual'\n",
      "\n",
      "error_subtype:\n",
      "  Type: <class 'float'>\n",
      "  Value: nan\n",
      "\n",
      "ðŸ§ª JSON PARSING TEST:\n",
      "==================================================\n",
      "\n",
      "Testing correct_answer_mapping:\n",
      "Raw value: '{\\n  \"L1\": \"He uses it 3*2=6 times\",\\n  \"L2\": \"So he pays 30/6=$5\",\\n  \"FA\": \"5\"\\n}'\n",
      "âœ… Parsed successfully: <class 'dict'>\n",
      "   Sample content: ['L1', 'L2', 'FA']\n",
      "\n",
      "Testing wrong_answer_mapping:\n",
      "Raw value: '{\\n  \"L1\": \"He uses it 3*2=5 times\",\\n  \"L2\": \"So he pays 30/5=$6\",\\n  \"FA\": \"6\"\\n}'\n",
      "âœ… Parsed successfully: <class 'dict'>\n",
      "   Sample content: ['L1', 'L2', 'FA']\n",
      "\n",
      "Testing correct_eqn_mapping:\n",
      "Raw value: '{\\n  \"L1\": \"3*2=6\",\\n  \"L2\": \"30/6=5\",\\n  \"FA\": \"\"\\n}'\n",
      "âœ… Parsed successfully: <class 'dict'>\n",
      "   Sample content: ['L1', 'L2', 'FA']\n",
      "\n",
      "Testing wrong_eqn_mapping:\n",
      "Raw value: '{\\n  \"L1\": \"3*2=5\",\\n  \"L2\": \"30/5=6\",\\n  \"FA\": \"\"\\n}'\n",
      "âœ… Parsed successfully: <class 'dict'>\n",
      "   Sample content: ['L1', 'L2', 'FA']\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV and examine the data types and a sample row\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Read the saved master catalog\n",
    "df = pd.read_csv(master_catalog_path)\n",
    "\n",
    "print(\"ðŸ“Š DATAFRAME INFO:\")\n",
    "print(\"=\" * 50)\n",
    "df.info()\n",
    "\n",
    "print(\"\\nðŸ“‹ COLUMN DTYPES:\")\n",
    "print(\"=\" * 50)\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].dtype}\")\n",
    "\n",
    "print(\"\\nðŸ” SAMPLE ROW (First Row):\")\n",
    "print(\"=\" * 50)\n",
    "sample_row = df.iloc[0]\n",
    "for col, value in sample_row.items():\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Type: {type(value)}\")\n",
    "    print(f\"  Value: {repr(value)}\")  # repr shows the actual string representation\n",
    "    \n",
    "    # Special handling for JSON columns\n",
    "    if col.endswith('_mapping'):\n",
    "        print(f\"  First 100 chars: {str(value)[:100]}...\")\n",
    "        try:\n",
    "            parsed = json.loads(value)\n",
    "            print(f\"  JSON Parse: SUCCESS - {type(parsed)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  JSON Parse: FAILED - {str(e)}\")\n",
    "\n",
    "print(\"\\nðŸ§ª JSON PARSING TEST:\")\n",
    "print(\"=\" * 50)\n",
    "# Test parsing the JSON columns\n",
    "json_columns = ['correct_answer_mapping', 'wrong_answer_mapping', 'correct_eqn_mapping', 'wrong_eqn_mapping']\n",
    "\n",
    "for col in json_columns:\n",
    "    print(f\"\\nTesting {col}:\")\n",
    "    test_value = df.iloc[0][col]\n",
    "    print(f\"Raw value: {repr(test_value)}\")\n",
    "    \n",
    "    try:\n",
    "        parsed = json.loads(test_value)\n",
    "        print(f\"âœ… Parsed successfully: {type(parsed)}\")\n",
    "        print(f\"   Sample content: {list(parsed.keys())[:3]}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"âŒ JSON parsing failed: {e}\")\n",
    "        \n",
    "        # Try to fix the escaping issue\n",
    "        try:\n",
    "            fixed_value = test_value.replace('\"\"', '\"')\n",
    "            parsed = json.loads(fixed_value)\n",
    "            print(f\"âœ… Fixed and parsed: {type(parsed)}\")\n",
    "        except Exception as e2:\n",
    "            print(f\"âŒ Still failed after fixing: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3958000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” COMPREHENSIVE JSON VALIDATION\n",
      "============================================================\n",
      "ðŸ“Š Checking 98,608 JSON cells across 24,652 rows...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad721c5cc9e84a359b8f644ba422d6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating JSON cells:   0%|          | 0/24652 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… VALIDATION SUCCESSFUL!\n",
      "   ðŸ“Š 98,608 JSON cells parsed successfully\n",
      "   ðŸ“Š 0 parsing errors found\n",
      "   ðŸŽ‰ All JSON data is properly formatted and parseable!\n",
      "\n",
      "ðŸŽ¯ DATASET QUALITY SUMMARY:\n",
      "   ðŸ“‚ File: master_catalog.csv\n",
      "   ðŸ“Š Rows: 24,652\n",
      "   ðŸ“‹ Columns: 18\n",
      "   âœ… JSON Format: All valid\n",
      "   ðŸš€ Ready for downstream processing!\n"
     ]
    }
   ],
   "source": [
    "# Enhanced comprehensive JSON validation across the entire dataset\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def comprehensive_json_validation(df):\n",
    "    \"\"\"\n",
    "    Check all JSON columns across the entire dataset for parsing errors.\n",
    "    Only prints output if errors are found.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ” COMPREHENSIVE JSON VALIDATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    json_columns = ['correct_answer_mapping', 'wrong_answer_mapping', 'correct_eqn_mapping', 'wrong_eqn_mapping']\n",
    "    total_rows = len(df)\n",
    "    total_cells = total_rows * len(json_columns)\n",
    "    \n",
    "    print(f\"ðŸ“Š Checking {total_cells:,} JSON cells across {total_rows:,} rows...\")\n",
    "    \n",
    "    error_summary = {col: [] for col in json_columns}\n",
    "    successful_parses = 0\n",
    "    \n",
    "    for idx in tqdm(range(len(df)), desc=\"Validating JSON cells\"):\n",
    "        row = df.iloc[idx]\n",
    "        \n",
    "        for col in json_columns:\n",
    "            cell_value = row[col]\n",
    "            \n",
    "            # Skip if NaN or empty\n",
    "            if pd.isna(cell_value) or cell_value == \"\":\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                parsed = json.loads(cell_value)\n",
    "                successful_parses += 1\n",
    "                \n",
    "                # Basic validation - should be a dict with expected keys\n",
    "                if not isinstance(parsed, dict):\n",
    "                    error_summary[col].append({\n",
    "                        'row_idx': idx, \n",
    "                        'gsm8k_idx': row['index'],\n",
    "                        'error': 'Not a dictionary',\n",
    "                        'preview': str(cell_value)[:100]\n",
    "                    })\n",
    "                elif not any(key.startswith(('L', 'FA')) for key in parsed.keys()):\n",
    "                    error_summary[col].append({\n",
    "                        'row_idx': idx, \n",
    "                        'gsm8k_idx': row['index'],\n",
    "                        'error': 'Missing expected keys (L1, L2, FA, etc.)',\n",
    "                        'keys_found': list(parsed.keys())[:5]\n",
    "                    })\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                error_summary[col].append({\n",
    "                    'row_idx': idx, \n",
    "                    'gsm8k_idx': row['index'],\n",
    "                    'error': f'JSON decode error: {str(e)}',\n",
    "                    'preview': str(cell_value)[:100]\n",
    "                })\n",
    "            except Exception as e:\n",
    "                error_summary[col].append({\n",
    "                    'row_idx': idx, \n",
    "                    'gsm8k_idx': row['index'],\n",
    "                    'error': f'Unexpected error: {str(e)}',\n",
    "                    'preview': str(cell_value)[:100]\n",
    "                })\n",
    "    \n",
    "    # Report results\n",
    "    total_errors = sum(len(errors) for errors in error_summary.values())\n",
    "    \n",
    "    if total_errors == 0:\n",
    "        print(f\"âœ… VALIDATION SUCCESSFUL!\")\n",
    "        print(f\"   ðŸ“Š {successful_parses:,} JSON cells parsed successfully\")\n",
    "        print(f\"   ðŸ“Š 0 parsing errors found\")\n",
    "        print(f\"   ðŸŽ‰ All JSON data is properly formatted and parseable!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"âŒ VALIDATION FAILED!\")\n",
    "        print(f\"   ðŸ“Š {successful_parses:,} successful parses\")\n",
    "        print(f\"   ðŸ“Š {total_errors:,} parsing errors found\")\n",
    "        \n",
    "        for col, errors in error_summary.items():\n",
    "            if errors:\n",
    "                print(f\"\\nðŸ”´ {col} - {len(errors)} errors:\")\n",
    "                for i, error in enumerate(errors[:3]):  # Show first 3 errors\n",
    "                    print(f\"   {i+1}. Row {error['row_idx']} (GSM8K {error['gsm8k_idx']}): {error['error']}\")\n",
    "                    if 'preview' in error:\n",
    "                        print(f\"      Preview: {error['preview']}...\")\n",
    "                if len(errors) > 3:\n",
    "                    print(f\"   ... and {len(errors) - 3} more errors\")\n",
    "        \n",
    "        return False\n",
    "\n",
    "# Run the comprehensive validation\n",
    "validation_passed = comprehensive_json_validation(df)\n",
    "\n",
    "if validation_passed:\n",
    "    print(f\"\\nðŸŽ¯ DATASET QUALITY SUMMARY:\")\n",
    "    print(f\"   ðŸ“‚ File: {master_catalog_path.name}\")\n",
    "    print(f\"   ðŸ“Š Rows: {len(df):,}\")\n",
    "    print(f\"   ðŸ“‹ Columns: {len(df.columns)}\")\n",
    "    print(f\"   âœ… JSON Format: All valid\")\n",
    "    print(f\"   ðŸš€ Ready for downstream processing!\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  DATASET NEEDS ATTENTION:\")\n",
    "    print(f\"   ðŸ“‚ File: {master_catalog_path.name}\")\n",
    "    print(f\"   ðŸ“Š JSON parsing errors detected\")\n",
    "    print(f\"   ðŸ”§ Consider regenerating or fixing the problematic entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2467aa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š ENHANCED DATA QUALITY ANALYSIS (FIXED)\n",
      "================================================================================\n",
      "ðŸ“‹ Total rows: 24,652\n",
      "ðŸ“‹ Sources: manual, programmatic\n",
      "ðŸ“‹ Error types: computational_error, conceptual_error\n",
      "ðŸ“‹ Source distribution: {'programmatic': 22912, 'manual': 1740}\n",
      "ðŸ“‹ Error type distribution: {'computational_error': 22542, 'conceptual_error': 2110}\n",
      "\n",
      "ðŸ” Analyzing 24,652 rows...\n",
      "\n",
      "ðŸ“Š QUALITY METRICS SUMMARY (BY SOURCE AND ERROR TYPE)\n",
      "================================================================================\n",
      "\n",
      "ðŸ” 1. Missing Erroneous Line:\n",
      "------------------------------------------------------------\n",
      "   âš ï¸  Total issues: 270\n",
      "\n",
      "      ðŸ“Œ MANUAL: 34 / 1,740 (2.0%)\n",
      "         â””â”€ conceptual_error: 34 / 966 (3.5%)\n",
      "\n",
      "      ðŸ“Œ PROGRAMMATIC: 236 / 22,912 (1.0%)\n",
      "         â””â”€ computational_error: 232 / 21,768 (1.1%)\n",
      "         â””â”€ conceptual_error: 4 / 1,144 (0.3%)\n",
      "\n",
      "ðŸ” 2. Missing Explanation:\n",
      "------------------------------------------------------------\n",
      "   âš ï¸  Total issues: 1\n",
      "\n",
      "      ðŸ“Œ MANUAL: 1 / 1,740 (0.1%)\n",
      "         â””â”€ computational_error: 1 / 774 (0.1%)\n",
      "\n",
      "      âœ… PROGRAMMATIC: 0 / 22,912 (0.0%)\n",
      "\n",
      "ðŸ” 3. Length Mismatch (Non-FA):\n",
      "------------------------------------------------------------\n",
      "   âš ï¸  Total issues: 1,137\n",
      "\n",
      "      ðŸ“Œ MANUAL: 201 / 1,740 (11.6%)\n",
      "         â””â”€ computational_error: 3 / 774 (0.4%)\n",
      "         â””â”€ conceptual_error: 198 / 966 (20.5%)\n",
      "\n",
      "      ðŸ“Œ PROGRAMMATIC: 936 / 22,912 (4.1%)\n",
      "         â””â”€ computational_error: 914 / 21,768 (4.2%)\n",
      "         â””â”€ conceptual_error: 22 / 1,144 (1.9%)\n",
      "\n",
      "ðŸ” 4. Missing Correct Equations:\n",
      "------------------------------------------------------------\n",
      "   âš ï¸  Total issues: 4,828\n",
      "\n",
      "      ðŸ“Œ MANUAL: 375 / 1,740 (21.6%)\n",
      "         â””â”€ computational_error: 171 / 774 (22.1%)\n",
      "         â””â”€ conceptual_error: 204 / 966 (21.1%)\n",
      "\n",
      "      ðŸ“Œ PROGRAMMATIC: 4,453 / 22,912 (19.4%)\n",
      "         â””â”€ computational_error: 4,238 / 21,768 (19.5%)\n",
      "         â””â”€ conceptual_error: 215 / 1,144 (18.8%)\n",
      "\n",
      "ðŸ” 5. Missing Wrong Equations:\n",
      "------------------------------------------------------------\n",
      "   âš ï¸  Total issues: 4,305\n",
      "\n",
      "      ðŸ“Œ MANUAL: 478 / 1,740 (27.5%)\n",
      "         â””â”€ computational_error: 172 / 774 (22.2%)\n",
      "         â””â”€ conceptual_error: 306 / 966 (31.7%)\n",
      "\n",
      "      ðŸ“Œ PROGRAMMATIC: 3,827 / 22,912 (16.7%)\n",
      "         â””â”€ computational_error: 3,650 / 21,768 (16.8%)\n",
      "         â””â”€ conceptual_error: 177 / 1,144 (15.5%)\n",
      "\n",
      "ðŸ“‹ SUMMARY TABLE\n",
      "================================================================================\n",
      "Metric                         Total Issues    % of Dataset   \n",
      "--------------------------------------------------------------------------------\n",
      "Missing Erroneous Line         270             1.1            %\n",
      "Missing Explanation            1               0.0            %\n",
      "Length Mismatch (Non-FA)       1,137           4.6            %\n",
      "Missing Correct Equations      4,828           19.6           %\n",
      "Missing Wrong Equations        4,305           17.5           %\n",
      "\n",
      "ðŸ“‹ SOURCE Ã— ERROR TYPE BREAKDOWN (UNIQUE ROWS WITH ANY ISSUES)\n",
      "================================================================================\n",
      "Source          Error Type           Total Rows   Rows w/Issues  Quality %   \n",
      "--------------------------------------------------------------------------------\n",
      "manual          computational_error  774          173            77.6        %\n",
      "manual          conceptual_error     966          443            54.1        %\n",
      "programmatic    computational_error  21,768       4,387          79.8        %\n",
      "programmatic    conceptual_error     1,144        215            81.2        %\n",
      "\n",
      "ðŸ”¬ ADDITIONAL INSIGHTS (BASED ON UNIQUE ROWS)\n",
      "================================================================================\n",
      "ðŸš¨ Most problematic combinations (by % of rows with ANY issues):\n",
      "   1. manual Ã— conceptual_error: 443 problematic rows out of 966 total (45.9% have issues)\n",
      "   2. manual Ã— computational_error: 173 problematic rows out of 774 total (22.4% have issues)\n",
      "   3. programmatic Ã— computational_error: 4,387 problematic rows out of 21,768 total (20.2% have issues)\n",
      "   4. programmatic Ã— conceptual_error: 215 problematic rows out of 1,144 total (18.8% have issues)\n",
      "\n",
      "ðŸ“Š ISSUE DISTRIBUTION BREAKDOWN\n",
      "================================================================================\n",
      "ðŸ“‹ Total unique rows with any issues: 5,218\n",
      "ðŸ“‹ Rows with perfect quality: 19,434 (78.8%)\n",
      "\n",
      "ðŸŽ¯ FIXED ENHANCED ANALYSIS COMPLETE\n",
      "ðŸ’¡ Now shows correct unique row counts without overcounting.\n"
     ]
    }
   ],
   "source": [
    "# Fixed Enhanced Data Quality Analysis with Correct Counting\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_data_quality_enhanced_fixed(df):\n",
    "    \"\"\"\n",
    "    Comprehensive data quality analysis with breakdowns by source and error_type.\n",
    "    Fixed to avoid overcounting rows with multiple issues.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ“Š ENHANCED DATA QUALITY ANALYSIS (FIXED)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    sources = df['source'].unique()\n",
    "    error_types = df['error_type'].unique()\n",
    "    total_rows = len(df)\n",
    "    \n",
    "    print(f\"ðŸ“‹ Total rows: {total_rows:,}\")\n",
    "    print(f\"ðŸ“‹ Sources: {', '.join(sources)}\")\n",
    "    print(f\"ðŸ“‹ Error types: {', '.join(error_types)}\")\n",
    "    print(f\"ðŸ“‹ Source distribution: {dict(df['source'].value_counts())}\")\n",
    "    print(f\"ðŸ“‹ Error type distribution: {dict(df['error_type'].value_counts())}\")\n",
    "    \n",
    "    # Initialize results with nested dictionaries for source -> error_type -> count\n",
    "    quality_metrics = {\n",
    "        'missing_erroneous_line': defaultdict(lambda: defaultdict(int)),\n",
    "        'missing_explanation': defaultdict(lambda: defaultdict(int)), \n",
    "        'length_mismatch_non_fa': defaultdict(lambda: defaultdict(int)),\n",
    "        'correct_missing_equations': defaultdict(lambda: defaultdict(int)),\n",
    "        'wrong_missing_equations': defaultdict(lambda: defaultdict(int))\n",
    "    }\n",
    "    \n",
    "    # Track rows with ANY issues for proper summary calculations\n",
    "    rows_with_any_issues = defaultdict(lambda: defaultdict(set))  # source -> error_type -> set of row indices\n",
    "    \n",
    "    print(f\"\\nðŸ” Analyzing {total_rows:,} rows...\")\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        source = row['source']\n",
    "        error_type = row['error_type']\n",
    "        has_any_issue = False\n",
    "        \n",
    "        # 1. Check for missing erroneous_line\n",
    "        if pd.isna(row['erroneous_line']) or str(row['erroneous_line']).strip() == '' or str(row['erroneous_line']) == 'nan':\n",
    "            quality_metrics['missing_erroneous_line'][source][error_type] += 1\n",
    "            has_any_issue = True\n",
    "        \n",
    "        # 2. Check for missing explanation\n",
    "        if pd.isna(row['explanation']) or str(row['explanation']).strip() == '' or str(row['explanation']) == 'nan':\n",
    "            quality_metrics['missing_explanation'][source][error_type] += 1\n",
    "            has_any_issue = True\n",
    "        \n",
    "        # 3. Check length mismatch for non-FA erroneous lines\n",
    "        if row['erroneous_line_number'] != 'FA':\n",
    "            if row['correct_answer_length'] != row['wrong_answer_length']:\n",
    "                quality_metrics['length_mismatch_non_fa'][source][error_type] += 1\n",
    "                has_any_issue = True\n",
    "        \n",
    "        # 4. & 5. Check for missing calculator equations\n",
    "        try:\n",
    "            # Parse the equation mappings\n",
    "            correct_eqn_mapping = json.loads(row['correct_eqn_mapping'])\n",
    "            wrong_eqn_mapping = json.loads(row['wrong_eqn_mapping'])\n",
    "            \n",
    "            correct_length = row['correct_answer_length']\n",
    "            wrong_length = row['wrong_answer_length']\n",
    "            \n",
    "            # Count non-empty equations in correct mapping\n",
    "            correct_non_empty_eqns = sum(1 for v in correct_eqn_mapping.values() if v and str(v).strip())\n",
    "            \n",
    "            # Count non-empty equations in wrong mapping  \n",
    "            wrong_non_empty_eqns = sum(1 for v in wrong_eqn_mapping.values() if v and str(v).strip())\n",
    "            \n",
    "            # Check if correct equations are missing (should have at least length-1 non-empty equations)\n",
    "            if correct_non_empty_eqns < (correct_length - 1):\n",
    "                quality_metrics['correct_missing_equations'][source][error_type] += 1\n",
    "                has_any_issue = True\n",
    "            \n",
    "            # Check if wrong equations are missing\n",
    "            if wrong_non_empty_eqns < (wrong_length - 1):\n",
    "                quality_metrics['wrong_missing_equations'][source][error_type] += 1\n",
    "                has_any_issue = True\n",
    "                \n",
    "        except (json.JSONDecodeError, KeyError, TypeError) as e:\n",
    "            # If we can't parse the JSON, count as missing equations\n",
    "            quality_metrics['correct_missing_equations'][source][error_type] += 1\n",
    "            quality_metrics['wrong_missing_equations'][source][error_type] += 1\n",
    "            has_any_issue = True\n",
    "        \n",
    "        # Track this row if it has any issues\n",
    "        if has_any_issue:\n",
    "            rows_with_any_issues[source][error_type].add(idx)\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(f\"\\nðŸ“Š QUALITY METRICS SUMMARY (BY SOURCE AND ERROR TYPE)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    metrics_descriptions = {\n",
    "        'missing_erroneous_line': '1. Missing Erroneous Line',\n",
    "        'missing_explanation': '2. Missing Explanation', \n",
    "        'length_mismatch_non_fa': '3. Length Mismatch (Non-FA)',\n",
    "        'correct_missing_equations': '4. Missing Correct Equations',\n",
    "        'wrong_missing_equations': '5. Missing Wrong Equations'\n",
    "    }\n",
    "    \n",
    "    for metric_key, description in metrics_descriptions.items():\n",
    "        print(f\"\\nðŸ” {description}:\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        metric_data = quality_metrics[metric_key]\n",
    "        \n",
    "        # Calculate total issues for this metric\n",
    "        total_issues = sum(sum(error_counts.values()) for error_counts in metric_data.values())\n",
    "        \n",
    "        if total_issues == 0:\n",
    "            print(\"   âœ… No issues found!\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸  Total issues: {total_issues:,}\")\n",
    "            \n",
    "            # Show breakdown by source and error type\n",
    "            for source in sources:\n",
    "                source_total = len(df[df['source'] == source])\n",
    "                source_issues = sum(metric_data[source].values())\n",
    "                \n",
    "                if source_issues > 0:\n",
    "                    source_pct = (source_issues / source_total) * 100\n",
    "                    print(f\"\\n      ðŸ“Œ {source.upper()}: {source_issues:,} / {source_total:,} ({source_pct:.1f}%)\")\n",
    "                    \n",
    "                    for error_type in error_types:\n",
    "                        count = metric_data[source][error_type]\n",
    "                        if count > 0:\n",
    "                            error_type_total = len(df[(df['source'] == source) & (df['error_type'] == error_type)])\n",
    "                            if error_type_total > 0:\n",
    "                                error_type_pct = (count / error_type_total) * 100\n",
    "                                print(f\"         â””â”€ {error_type}: {count:,} / {error_type_total:,} ({error_type_pct:.1f}%)\")\n",
    "                else:\n",
    "                    print(f\"\\n      âœ… {source.upper()}: 0 / {source_total:,} (0.0%)\")\n",
    "    \n",
    "    # Overall summary table\n",
    "    print(f\"\\nðŸ“‹ SUMMARY TABLE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Metric':<30} {'Total Issues':<15} {'% of Dataset':<15}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for metric_key, description in metrics_descriptions.items():\n",
    "        short_desc = description.split('. ')[1]  # Remove number prefix\n",
    "        total_issues = sum(sum(error_counts.values()) for error_counts in quality_metrics[metric_key].values())\n",
    "        pct = (total_issues / total_rows) * 100\n",
    "        print(f\"{short_desc:<30} {total_issues:<15,} {pct:<15.1f}%\")\n",
    "    \n",
    "    # FIXED: Enhanced source breakdown summary using unique row counts\n",
    "    print(f\"\\nðŸ“‹ SOURCE Ã— ERROR TYPE BREAKDOWN (UNIQUE ROWS WITH ANY ISSUES)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Source':<15} {'Error Type':<20} {'Total Rows':<12} {'Rows w/Issues':<14} {'Quality %':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for source in sources:\n",
    "        for error_type in error_types:\n",
    "            subset_df = df[(df['source'] == source) & (df['error_type'] == error_type)]\n",
    "            subset_total = len(subset_df)\n",
    "            \n",
    "            if subset_total > 0:\n",
    "                # Count UNIQUE rows with any issues (not sum of individual issue counts)\n",
    "                unique_rows_with_issues = len(rows_with_any_issues[source][error_type])\n",
    "                \n",
    "                # Calculate quality percentage based on unique problematic rows\n",
    "                issue_pct = (unique_rows_with_issues / subset_total) * 100 if subset_total > 0 else 0\n",
    "                quality_pct = max(0, 100 - issue_pct)\n",
    "                \n",
    "                print(f\"{source:<15} {error_type:<20} {subset_total:<12,} {unique_rows_with_issues:<14,} {quality_pct:<12.1f}%\")\n",
    "    \n",
    "    # FIXED: Additional insights using unique row counts\n",
    "    print(f\"\\nðŸ”¬ ADDITIONAL INSIGHTS (BASED ON UNIQUE ROWS)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Find the most problematic sourceÃ—error_type combinations based on unique rows with issues\n",
    "    problematic_combinations = []\n",
    "    for source in sources:\n",
    "        for error_type in error_types:\n",
    "            subset_df = df[(df['source'] == source) & (df['error_type'] == error_type)]\n",
    "            subset_total = len(subset_df)\n",
    "            \n",
    "            if subset_total > 0:\n",
    "                unique_rows_with_issues = len(rows_with_any_issues[source][error_type])\n",
    "                issue_rate = (unique_rows_with_issues / subset_total) * 100\n",
    "                \n",
    "                if issue_rate > 0:\n",
    "                    problematic_combinations.append({\n",
    "                        'source': source,\n",
    "                        'error_type': error_type,\n",
    "                        'total_rows': subset_total,\n",
    "                        'unique_problematic_rows': unique_rows_with_issues,\n",
    "                        'issue_rate': issue_rate\n",
    "                    })\n",
    "    \n",
    "    # Sort by issue rate\n",
    "    problematic_combinations.sort(key=lambda x: x['issue_rate'], reverse=True)\n",
    "    \n",
    "    if problematic_combinations:\n",
    "        print(\"ðŸš¨ Most problematic combinations (by % of rows with ANY issues):\")\n",
    "        for i, combo in enumerate(problematic_combinations[:5], 1):\n",
    "            print(f\"   {i}. {combo['source']} Ã— {combo['error_type']}: \"\n",
    "                  f\"{combo['unique_problematic_rows']:,} problematic rows out of {combo['total_rows']:,} total \"\n",
    "                  f\"({combo['issue_rate']:.1f}% have issues)\")\n",
    "    else:\n",
    "        print(\"âœ… No problematic combinations found!\")\n",
    "    \n",
    "    # Additional breakdown showing issue distribution\n",
    "    print(f\"\\nðŸ“Š ISSUE DISTRIBUTION BREAKDOWN\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    total_unique_issues = sum(len(error_type_sets) for source_dict in rows_with_any_issues.values() \n",
    "                             for error_type_sets in source_dict.values())\n",
    "    \n",
    "    print(f\"ðŸ“‹ Total unique rows with any issues: {total_unique_issues:,}\")\n",
    "    print(f\"ðŸ“‹ Rows with perfect quality: {total_rows - total_unique_issues:,} ({((total_rows - total_unique_issues) / total_rows * 100):.1f}%)\")\n",
    "    \n",
    "    return quality_metrics, rows_with_any_issues\n",
    "\n",
    "# Run the fixed enhanced analysis\n",
    "quality_results, issue_tracking = analyze_data_quality_enhanced_fixed(df)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ FIXED ENHANCED ANALYSIS COMPLETE\")\n",
    "print(f\"ðŸ’¡ Now shows correct unique row counts without overcounting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3afa5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['erroneous_line', 'explanation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "554b5a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š MANUAL SOURCE + MISSING ERRONEOUS LINE\n",
      "============================================================\n",
      "Total rows found: 0\n",
      "âœ… No rows found with this combination\n",
      "\n",
      "ðŸ“Š MANUAL SOURCE + NON-FA LENGTH MISMATCH\n",
      "============================================================\n",
      "Total rows found: 167\n",
      "Sample GSM8K indices: [1087, 1003, 1004, 1007, 1008, 1016, 1019, 1020, 1023, 1024]\n",
      "Error types: {'conceptual_error': 164, 'computational_error': 3}\n",
      "Tiers: {'tier1': 65, 'tier3': 59, 'tier2': 22, 'tier4': 12, 'tier5': 9}\n",
      "Erroneous line numbers: {'L1': 82, 'L2': 45, 'L3': 28, 'L4': 10, 'L5': 1, 'L6': 1}\n",
      "Length differences: {1: 115, -1: 24, 2: 13, 3: 10, -2: 4, 4: 1}\n",
      "\n",
      "ðŸ” SAMPLE ROW:\n",
      "----------------------------------------\n",
      "Index: 1087\n",
      "Tier: tier5\n",
      "Error Type: computational_error\n",
      "Erroneous Line Number: L5\n",
      "Correct Answer Length: 7\n",
      "Wrong Answer Length: 8\n",
      "Length Difference: -1\n",
      "Explanation: computational error: In the equation 100 - x + 40 - 30 = 60, the calculation of 40 - 30 was incorrec...\n",
      "\n",
      "ðŸ“‹ SUMMARY\n",
      "============================================================\n",
      "Manual source total rows: 1,705\n",
      "Rows with missing erroneous line: 0\n",
      "Rows with non-FA length mismatch: 167\n"
     ]
    }
   ],
   "source": [
    "# 1. All rows with manual source and missing erroneous line\n",
    "manual_missing_erroneous_line = df[\n",
    "    (df['source'] == 'manual') & \n",
    "    (\n",
    "        pd.isna(df['erroneous_line']) | \n",
    "        (df['erroneous_line'].astype(str).str.strip() == '') |\n",
    "        (df['erroneous_line'].astype(str) == 'nan')\n",
    "    )\n",
    "].copy()\n",
    "\n",
    "print(\"ðŸ“Š MANUAL SOURCE + MISSING ERRONEOUS LINE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total rows found: {len(manual_missing_erroneous_line):,}\")\n",
    "\n",
    "if len(manual_missing_erroneous_line) > 0:\n",
    "    print(f\"Sample GSM8K indices: {manual_missing_erroneous_line['index'].head(10).tolist()}\")\n",
    "    print(f\"Error types: {manual_missing_erroneous_line['error_type'].value_counts().to_dict()}\")\n",
    "    print(f\"Tiers: {manual_missing_erroneous_line['tier'].value_counts().to_dict()}\")\n",
    "    \n",
    "    # Show a sample row\n",
    "    print(f\"\\nðŸ” SAMPLE ROW:\")\n",
    "    print(\"-\" * 40)\n",
    "    sample_row = manual_missing_erroneous_line.iloc[0]\n",
    "    print(f\"Index: {sample_row['index']}\")\n",
    "    print(f\"Tier: {sample_row['tier']}\")\n",
    "    print(f\"Error Type: {sample_row['error_type']}\")\n",
    "    print(f\"Erroneous Line Number: {sample_row['erroneous_line_number']}\")\n",
    "    print(f\"Erroneous Line: {repr(sample_row['erroneous_line'])}\")\n",
    "    print(f\"Explanation: {sample_row['explanation'][:100]}...\")\n",
    "else:\n",
    "    print(\"âœ… No rows found with this combination\")\n",
    "\n",
    "# 2. All rows with manual source and non-FA length mismatch\n",
    "manual_length_mismatch = df[\n",
    "    (df['source'] == 'manual') & \n",
    "    (df['erroneous_line_number'] != 'FA') &\n",
    "    (df['correct_answer_length'] != df['wrong_answer_length'])\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nðŸ“Š MANUAL SOURCE + NON-FA LENGTH MISMATCH\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total rows found: {len(manual_length_mismatch):,}\")\n",
    "\n",
    "if len(manual_length_mismatch) > 0:\n",
    "    print(f\"Sample GSM8K indices: {manual_length_mismatch['index'].head(10).tolist()}\")\n",
    "    print(f\"Error types: {manual_length_mismatch['error_type'].value_counts().to_dict()}\")\n",
    "    print(f\"Tiers: {manual_length_mismatch['tier'].value_counts().to_dict()}\")\n",
    "    print(f\"Erroneous line numbers: {manual_length_mismatch['erroneous_line_number'].value_counts().to_dict()}\")\n",
    "    \n",
    "    # Show length difference statistics\n",
    "    manual_length_mismatch['length_diff'] = manual_length_mismatch['correct_answer_length'] - manual_length_mismatch['wrong_answer_length']\n",
    "    print(f\"Length differences: {manual_length_mismatch['length_diff'].value_counts().to_dict()}\")\n",
    "    \n",
    "    # Show a sample row\n",
    "    print(f\"\\nðŸ” SAMPLE ROW:\")\n",
    "    print(\"-\" * 40)\n",
    "    sample_row = manual_length_mismatch.iloc[0]\n",
    "    print(f\"Index: {sample_row['index']}\")\n",
    "    print(f\"Tier: {sample_row['tier']}\")\n",
    "    print(f\"Error Type: {sample_row['error_type']}\")\n",
    "    print(f\"Erroneous Line Number: {sample_row['erroneous_line_number']}\")\n",
    "    print(f\"Correct Answer Length: {sample_row['correct_answer_length']}\")\n",
    "    print(f\"Wrong Answer Length: {sample_row['wrong_answer_length']}\")\n",
    "    print(f\"Length Difference: {sample_row['length_diff']}\")\n",
    "    print(f\"Explanation: {sample_row['explanation'][:100]}...\")\n",
    "else:\n",
    "    print(\"âœ… No rows found with this combination\")\n",
    "\n",
    "# Summary of both dataframes\n",
    "print(f\"\\nðŸ“‹ SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Manual source total rows: {len(df[df['source'] == 'manual']):,}\")\n",
    "print(f\"Rows with missing erroneous line: {len(manual_missing_erroneous_line):,}\")\n",
    "print(f\"Rows with non-FA length mismatch: {len(manual_length_mismatch):,}\")\n",
    "\n",
    "# Check for overlap between the two issues\n",
    "if len(manual_missing_erroneous_line) > 0 and len(manual_length_mismatch) > 0:\n",
    "    overlap_indices = set(manual_missing_erroneous_line['index']) & set(manual_length_mismatch['index'])\n",
    "    print(f\"Rows with BOTH issues: {len(overlap_indices):,}\")\n",
    "    if len(overlap_indices) > 0:\n",
    "        print(f\"Overlapping GSM8K indices: {list(overlap_indices)[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "37fa2e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tier</th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>wrong_answer</th>\n",
       "      <th>error_type</th>\n",
       "      <th>explanation</th>\n",
       "      <th>erroneous_line_number</th>\n",
       "      <th>erroneous_line</th>\n",
       "      <th>erroneous_line_eqn</th>\n",
       "      <th>correct_answer_mapping</th>\n",
       "      <th>wrong_answer_mapping</th>\n",
       "      <th>correct_eqn_mapping</th>\n",
       "      <th>wrong_eqn_mapping</th>\n",
       "      <th>correct_answer_length</th>\n",
       "      <th>wrong_answer_length</th>\n",
       "      <th>source</th>\n",
       "      <th>error_subtype</th>\n",
       "      <th>length_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1087</td>\n",
       "      <td>tier5</td>\n",
       "      <td>Hadley loves to do volunteer work at the local...</td>\n",
       "      <td>Let x be the number of books borrowed by lunch...</td>\n",
       "      <td>Let x be the number of books borrowed by lunch...</td>\n",
       "      <td>computational_error</td>\n",
       "      <td>computational error: In the equation 100 - x +...</td>\n",
       "      <td>L5</td>\n",
       "      <td>Thus 100 - x + 20 = 60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\\n  \"L1\": \"Let x be the number of books borro...</td>\n",
       "      <td>{\\n  \"L1\": \"Let x be the number of books borro...</td>\n",
       "      <td>{\\n  \"L1\": \"\",\\n  \"L2\": \"\",\\n  \"L3\": \"\",\\n  \"L...</td>\n",
       "      <td>{\\n  \"L1\": \"\",\\n  \"L2\": \"\",\\n  \"L3\": \"\",\\n  \"L...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>manual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1003</td>\n",
       "      <td>tier3</td>\n",
       "      <td>Cheryl is signing up for a golf tournament tha...</td>\n",
       "      <td>If the electricity bill costs $800, and Cheryl...</td>\n",
       "      <td>If the electricity bill costs $800, and Cheryl...</td>\n",
       "      <td>conceptual_error</td>\n",
       "      <td>misunderstanding of problem: The student calcu...</td>\n",
       "      <td>L2</td>\n",
       "      <td>Since the cost to enter the tournament is 20% ...</td>\n",
       "      <td>20/100*1200=240</td>\n",
       "      <td>{\\n  \"L1\": \"If the electricity bill costs $800...</td>\n",
       "      <td>{\\n  \"L1\": \"If the electricity bill costs $800...</td>\n",
       "      <td>{\\n  \"L1\": \"800+400=1200\",\\n  \"L2\": \"20/100*12...</td>\n",
       "      <td>{\\n  \"L1\": \"800+400=1200\",\\n  \"L2\": \"20/100*12...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>manual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1004</td>\n",
       "      <td>tier1</td>\n",
       "      <td>Kamil wants to renovate his kitchen at home. F...</td>\n",
       "      <td>Two professionals work together 6 * 2 = 12 hou...</td>\n",
       "      <td>One professional works 6 hours a day for 7 day...</td>\n",
       "      <td>conceptual_error</td>\n",
       "      <td>misunderstanding of problem: The calculation f...</td>\n",
       "      <td>L1</td>\n",
       "      <td>One professional works 6 hours a day for 7 day...</td>\n",
       "      <td>6*7=42</td>\n",
       "      <td>{\\n  \"L1\": \"Two professionals work together 6 ...</td>\n",
       "      <td>{\\n  \"L1\": \"One professional works 6 hours a d...</td>\n",
       "      <td>{\\n  \"L1\": \"6*2=12\",\\n  \"L2\": \"7*12=84\",\\n  \"L...</td>\n",
       "      <td>{\\n  \"L1\": \"6*7=42\",\\n  \"L2\": \"42*15=630\",\\n  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>manual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1007</td>\n",
       "      <td>tier5</td>\n",
       "      <td>Rajesh walked 10 kilometers less than 4 times ...</td>\n",
       "      <td>Let H = distance Hiro walked\\n4H - 10 = distan...</td>\n",
       "      <td>Let H = distance Hiro walked\\n4(H - 10) = dist...</td>\n",
       "      <td>conceptual_error</td>\n",
       "      <td>misinterpretation of phrase: The phrase \"10 ki...</td>\n",
       "      <td>L2</td>\n",
       "      <td>4(H - 10) = distance Rajesh walked</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\\n  \"L1\": \"Let H = distance Hiro walked\",\\n  ...</td>\n",
       "      <td>{\\n  \"L1\": \"Let H = distance Hiro walked\",\\n  ...</td>\n",
       "      <td>{\\n  \"L1\": \"\",\\n  \"L2\": \"\",\\n  \"L3\": \"\",\\n  \"L...</td>\n",
       "      <td>{\\n  \"L1\": \"\",\\n  \"L2\": \"\",\\n  \"L3\": \"\",\\n  \"L...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>manual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1008</td>\n",
       "      <td>tier1</td>\n",
       "      <td>Lana aims to sell 20 muffins at the bake sale....</td>\n",
       "      <td>Lana sold 12 muffins and has to sell 20 - 12 =...</td>\n",
       "      <td>Lana sold another 4 in the afternoon. So Lana ...</td>\n",
       "      <td>conceptual_error</td>\n",
       "      <td>skipped step: The step where the 12 muffins so...</td>\n",
       "      <td>L1</td>\n",
       "      <td>Lana sold another 4 in the afternoon. So Lana ...</td>\n",
       "      <td>20-4=16</td>\n",
       "      <td>{\\n  \"L1\": \"Lana sold 12 muffins and has to se...</td>\n",
       "      <td>{\\n  \"L1\": \"Lana sold another 4 in the afterno...</td>\n",
       "      <td>{\\n  \"L1\": \"\",\\n  \"L2\": \"8-4=4\",\\n  \"FA\": \"\"\\n}</td>\n",
       "      <td>{\\n  \"L1\": \"20-4=16\",\\n  \"FA\": \"\"\\n}</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>manual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index   tier                                           question  \\\n",
       "69   1087  tier5  Hadley loves to do volunteer work at the local...   \n",
       "83   1003  tier3  Cheryl is signing up for a golf tournament tha...   \n",
       "84   1004  tier1  Kamil wants to renovate his kitchen at home. F...   \n",
       "87   1007  tier5  Rajesh walked 10 kilometers less than 4 times ...   \n",
       "88   1008  tier1  Lana aims to sell 20 muffins at the bake sale....   \n",
       "\n",
       "                                       correct_answer  \\\n",
       "69  Let x be the number of books borrowed by lunch...   \n",
       "83  If the electricity bill costs $800, and Cheryl...   \n",
       "84  Two professionals work together 6 * 2 = 12 hou...   \n",
       "87  Let H = distance Hiro walked\\n4H - 10 = distan...   \n",
       "88  Lana sold 12 muffins and has to sell 20 - 12 =...   \n",
       "\n",
       "                                         wrong_answer           error_type  \\\n",
       "69  Let x be the number of books borrowed by lunch...  computational_error   \n",
       "83  If the electricity bill costs $800, and Cheryl...     conceptual_error   \n",
       "84  One professional works 6 hours a day for 7 day...     conceptual_error   \n",
       "87  Let H = distance Hiro walked\\n4(H - 10) = dist...     conceptual_error   \n",
       "88  Lana sold another 4 in the afternoon. So Lana ...     conceptual_error   \n",
       "\n",
       "                                          explanation erroneous_line_number  \\\n",
       "69  computational error: In the equation 100 - x +...                    L5   \n",
       "83  misunderstanding of problem: The student calcu...                    L2   \n",
       "84  misunderstanding of problem: The calculation f...                    L1   \n",
       "87  misinterpretation of phrase: The phrase \"10 ki...                    L2   \n",
       "88  skipped step: The step where the 12 muffins so...                    L1   \n",
       "\n",
       "                                       erroneous_line erroneous_line_eqn  \\\n",
       "69                             Thus 100 - x + 20 = 60                NaN   \n",
       "83  Since the cost to enter the tournament is 20% ...    20/100*1200=240   \n",
       "84  One professional works 6 hours a day for 7 day...             6*7=42   \n",
       "87                 4(H - 10) = distance Rajesh walked                NaN   \n",
       "88  Lana sold another 4 in the afternoon. So Lana ...            20-4=16   \n",
       "\n",
       "                               correct_answer_mapping  \\\n",
       "69  {\\n  \"L1\": \"Let x be the number of books borro...   \n",
       "83  {\\n  \"L1\": \"If the electricity bill costs $800...   \n",
       "84  {\\n  \"L1\": \"Two professionals work together 6 ...   \n",
       "87  {\\n  \"L1\": \"Let H = distance Hiro walked\",\\n  ...   \n",
       "88  {\\n  \"L1\": \"Lana sold 12 muffins and has to se...   \n",
       "\n",
       "                                 wrong_answer_mapping  \\\n",
       "69  {\\n  \"L1\": \"Let x be the number of books borro...   \n",
       "83  {\\n  \"L1\": \"If the electricity bill costs $800...   \n",
       "84  {\\n  \"L1\": \"One professional works 6 hours a d...   \n",
       "87  {\\n  \"L1\": \"Let H = distance Hiro walked\",\\n  ...   \n",
       "88  {\\n  \"L1\": \"Lana sold another 4 in the afterno...   \n",
       "\n",
       "                                  correct_eqn_mapping  \\\n",
       "69  {\\n  \"L1\": \"\",\\n  \"L2\": \"\",\\n  \"L3\": \"\",\\n  \"L...   \n",
       "83  {\\n  \"L1\": \"800+400=1200\",\\n  \"L2\": \"20/100*12...   \n",
       "84  {\\n  \"L1\": \"6*2=12\",\\n  \"L2\": \"7*12=84\",\\n  \"L...   \n",
       "87  {\\n  \"L1\": \"\",\\n  \"L2\": \"\",\\n  \"L3\": \"\",\\n  \"L...   \n",
       "88    {\\n  \"L1\": \"\",\\n  \"L2\": \"8-4=4\",\\n  \"FA\": \"\"\\n}   \n",
       "\n",
       "                                    wrong_eqn_mapping  correct_answer_length  \\\n",
       "69  {\\n  \"L1\": \"\",\\n  \"L2\": \"\",\\n  \"L3\": \"\",\\n  \"L...                      7   \n",
       "83  {\\n  \"L1\": \"800+400=1200\",\\n  \"L2\": \"20/100*12...                      4   \n",
       "84  {\\n  \"L1\": \"6*7=42\",\\n  \"L2\": \"42*15=630\",\\n  ...                      4   \n",
       "87  {\\n  \"L1\": \"\",\\n  \"L2\": \"\",\\n  \"L3\": \"\",\\n  \"L...                      8   \n",
       "88               {\\n  \"L1\": \"20-4=16\",\\n  \"FA\": \"\"\\n}                      3   \n",
       "\n",
       "    wrong_answer_length  source error_subtype  length_diff  \n",
       "69                    8  manual           NaN           -1  \n",
       "83                    3  manual           NaN            1  \n",
       "84                    3  manual           NaN            1  \n",
       "87                    9  manual           NaN           -1  \n",
       "88                    2  manual           NaN            1  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_length_mismatch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1ffdc27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_length_mismatch.to_csv(AUG_5_DATASET_DIR / \"manual_length_mismatch.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "183ab9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ SIMPLE MERGE: MANUALLY EDITED DATA BACK TO MASTER CATALOG\n",
      "======================================================================\n",
      "ðŸ“Š Initial master catalog rows: 24,376\n",
      "ðŸ“Š Manual edits to merge: 167\n",
      "\n",
      "ðŸ“Š MERGE RESULTS:\n",
      "   Rows successfully updated: 167\n",
      "   Rows not found/problematic: 0\n",
      "âœ… All edited rows were successfully merged!\n",
      "\n",
      "ðŸ“‹ VERIFICATION:\n",
      "   Total rows in master catalog: 24,376\n",
      "   Manual source rows: 1,700\n",
      "\n",
      "ðŸ” SAMPLE OF UPDATED ROWS:\n",
      "   Index 1087: conceptual_error | Tier: tier5\n",
      "   Index 1003: computational_error | Tier: tier3\n",
      "   Index 1004: computational_error | Tier: tier1\n",
      "\n",
      "ðŸŽ‰ SIMPLE MERGE COMPLETE!\n",
      "âœ… 167 rows updated in master catalog\n",
      "\n",
      "ðŸ“‹ VERIFICATION:\n",
      "   Total rows in master catalog: 24,376\n",
      "   Manual source rows: 1,700\n",
      "\n",
      "ðŸ” SAMPLE OF UPDATED ROWS:\n",
      "   Index 1087: conceptual_error | Tier: tier5\n",
      "   Index 1003: computational_error | Tier: tier3\n",
      "   Index 1004: computational_error | Tier: tier1\n",
      "\n",
      "ðŸŽ‰ SIMPLE MERGE COMPLETE!\n",
      "âœ… 167 rows updated in master catalog\n"
     ]
    }
   ],
   "source": [
    "# Load the manually edited CSV\n",
    "manual_edited = pd.read_csv(AUG_5_DATASET_DIR / \"manual_length_mismatch.csv\")\n",
    "\n",
    "print(\"ðŸ”„ SIMPLE MERGE: MANUALLY EDITED DATA BACK TO MASTER CATALOG\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Display initial state\n",
    "print(f\"ðŸ“Š Initial master catalog rows: {len(df):,}\")\n",
    "print(f\"ðŸ“Š Manual edits to merge: {len(manual_edited):,}\")\n",
    "\n",
    "# Track changes\n",
    "rows_updated = 0\n",
    "rows_not_found = 0\n",
    "not_found_details = []\n",
    "\n",
    "# Loop over each manually edited row\n",
    "for _, edited_row in manual_edited.iterrows():\n",
    "    edit_index = edited_row['index']\n",
    "    edit_error_type = edited_row['error_type']\n",
    "    \n",
    "    # Find the matching row in df (same index, error_type, and manual source)\n",
    "    mask = (df['index'] == edit_index) & \\\n",
    "           (df['error_type'] == edit_error_type) & \\\n",
    "           (df['source'] == 'manual')\n",
    "    \n",
    "    matching_rows = df[mask]\n",
    "    \n",
    "    if len(matching_rows) == 1:\n",
    "        # Found exactly one match - replace it\n",
    "        row_idx = matching_rows.index[0]\n",
    "        \n",
    "        # Replace the entire row with the edited version\n",
    "        for col in df.columns:\n",
    "            if col in edited_row:\n",
    "                df.at[row_idx, col] = edited_row[col]\n",
    "        \n",
    "        rows_updated += 1\n",
    "        \n",
    "    elif len(matching_rows) == 0:\n",
    "        # No match found\n",
    "        rows_not_found += 1\n",
    "        not_found_details.append({\n",
    "            'index': edit_index,\n",
    "            'error_type': edit_error_type\n",
    "        })\n",
    "        \n",
    "    else:\n",
    "        # Multiple matches found (shouldn't happen)\n",
    "        print(f\"âš ï¸  WARNING: Multiple matches found for index={edit_index}, error_type={edit_error_type}\")\n",
    "        rows_not_found += 1\n",
    "        not_found_details.append({\n",
    "            'index': edit_index,\n",
    "            'error_type': edit_error_type,\n",
    "            'issue': f'Multiple matches ({len(matching_rows)})'\n",
    "        })\n",
    "\n",
    "# Report results\n",
    "print(f\"\\nðŸ“Š MERGE RESULTS:\")\n",
    "print(f\"   Rows successfully updated: {rows_updated:,}\")\n",
    "print(f\"   Rows not found/problematic: {rows_not_found:,}\")\n",
    "\n",
    "if rows_not_found > 0:\n",
    "    print(f\"\\nâŒ PROBLEMATIC ROWS:\")\n",
    "    for detail in not_found_details[:5]:  # Show first 5\n",
    "        issue = detail.get('issue', 'Not found')\n",
    "        print(f\"   Index {detail['index']}, Error Type {detail['error_type']}: {issue}\")\n",
    "    if len(not_found_details) > 5:\n",
    "        print(f\"   ... and {len(not_found_details) - 5} more\")\n",
    "else:\n",
    "    print(\"âœ… All edited rows were successfully merged!\")\n",
    "\n",
    "# Verification\n",
    "manual_rows_in_df = len(df[df['source'] == 'manual'])\n",
    "print(f\"\\nðŸ“‹ VERIFICATION:\")\n",
    "print(f\"   Total rows in master catalog: {len(df):,}\")\n",
    "print(f\"   Manual source rows: {manual_rows_in_df:,}\")\n",
    "\n",
    "# Show sample of updated data\n",
    "if rows_updated > 0:\n",
    "    print(f\"\\nðŸ” SAMPLE OF UPDATED ROWS:\")\n",
    "    sample_indices = manual_edited['index'].head(3).tolist()\n",
    "    for idx in sample_indices:\n",
    "        sample_row = df[(df['index'] == idx) & (df['source'] == 'manual')]\n",
    "        if not sample_row.empty:\n",
    "            row = sample_row.iloc[0]\n",
    "            print(f\"   Index {idx}: {row['error_type']} | Tier: {row['tier']}\")\n",
    "\n",
    "print(f\"\\nðŸŽ‰ SIMPLE MERGE COMPLETE!\")\n",
    "print(f\"âœ… {rows_updated:,} rows updated in master catalog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "55870024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(AUG_5_DATASET_DIR / \"master_catalog.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7cd03cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” CHECKING ERRONEOUS LINE NUMBER vs WRONG ANSWER MAPPING\n",
      "======================================================================\n",
      "ðŸ“Š RESULTS:\n",
      "   Total rows checked: 24,376\n",
      "   Problematic rows found: 0\n",
      "\n",
      "âœ… All erroneous line numbers are properly found in their wrong answer mappings!\n"
     ]
    }
   ],
   "source": [
    "# Check for rows where erroneous_line_number is not in wrong_answer_mapping\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def check_erroneous_line_in_mapping(df):\n",
    "    \"\"\"\n",
    "    Check for rows where the erroneous_line_number is not found in the wrong_answer_mapping.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ” CHECKING ERRONEOUS LINE NUMBER vs WRONG ANSWER MAPPING\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    problematic_rows = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            erroneous_line_number = row['erroneous_line_number']\n",
    "            wrong_mapping_json = row['wrong_answer_mapping']\n",
    "            \n",
    "            # Skip if either field is missing\n",
    "            if pd.isna(erroneous_line_number) or pd.isna(wrong_mapping_json):\n",
    "                continue\n",
    "            \n",
    "            # Parse the wrong answer mapping\n",
    "            wrong_mapping = json.loads(wrong_mapping_json)\n",
    "            \n",
    "            # Check if erroneous line number exists in the mapping\n",
    "            if erroneous_line_number not in wrong_mapping:\n",
    "                problematic_rows.append({\n",
    "                    'row_index': idx,\n",
    "                    'gsm8k_index': row['index'],\n",
    "                    'source': row['source'],\n",
    "                    'error_type': row['error_type'],\n",
    "                    'tier': row['tier'],\n",
    "                    'erroneous_line_number': erroneous_line_number,\n",
    "                    'available_line_numbers': list(wrong_mapping.keys()),\n",
    "                    'wrong_answer_length': row['wrong_answer_length'],\n",
    "                    'explanation': row['explanation'][:100] + \"...\" if len(str(row['explanation'])) > 100 else row['explanation']\n",
    "                })\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            # JSON parsing error\n",
    "            problematic_rows.append({\n",
    "                'row_index': idx,\n",
    "                'gsm8k_index': row['index'],\n",
    "                'source': row['source'],\n",
    "                'error_type': row['error_type'],\n",
    "                'tier': row['tier'],\n",
    "                'erroneous_line_number': erroneous_line_number,\n",
    "                'available_line_numbers': 'JSON_PARSE_ERROR',\n",
    "                'wrong_answer_length': row['wrong_answer_length'],\n",
    "                'explanation': f\"JSON Error: {str(e)}\"\n",
    "            })\n",
    "        except Exception as e:\n",
    "            # Other errors\n",
    "            problematic_rows.append({\n",
    "                'row_index': idx,\n",
    "                'gsm8k_index': row['index'],\n",
    "                'source': row['source'],\n",
    "                'error_type': row['error_type'],\n",
    "                'tier': row['tier'],\n",
    "                'erroneous_line_number': erroneous_line_number,\n",
    "                'available_line_numbers': 'OTHER_ERROR',\n",
    "                'wrong_answer_length': row['wrong_answer_length'],\n",
    "                'explanation': f\"Error: {str(e)}\"\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    problematic_df = pd.DataFrame(problematic_rows)\n",
    "    \n",
    "    print(f\"ðŸ“Š RESULTS:\")\n",
    "    print(f\"   Total rows checked: {len(df):,}\")\n",
    "    print(f\"   Problematic rows found: {len(problematic_rows):,}\")\n",
    "    \n",
    "    if len(problematic_rows) > 0:\n",
    "        print(f\"\\nðŸ“‹ BREAKDOWN BY SOURCE:\")\n",
    "        source_counts = problematic_df['source'].value_counts()\n",
    "        for source, count in source_counts.items():\n",
    "            total_source_rows = len(df[df['source'] == source])\n",
    "            pct = (count / total_source_rows) * 100\n",
    "            print(f\"   {source}: {count:,} / {total_source_rows:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nðŸ“‹ BREAKDOWN BY ERROR TYPE:\")\n",
    "        error_type_counts = problematic_df['error_type'].value_counts()\n",
    "        for error_type, count in error_type_counts.items():\n",
    "            total_error_type_rows = len(df[df['error_type'] == error_type])\n",
    "            pct = (count / total_error_type_rows) * 100\n",
    "            print(f\"   {error_type}: {count:,} / {total_error_type_rows:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nðŸ” SAMPLE PROBLEMATIC ROWS:\")\n",
    "        print(\"-\" * 70)\n",
    "        for i, row in enumerate(problematic_df.head(5).itertuples(), 1):\n",
    "            print(f\"\\n{i}. GSM8K Index {row.gsm8k_index} (Source: {row.source}, Type: {row.error_type})\")\n",
    "            print(f\"   Erroneous Line Number: {row.erroneous_line_number}\")\n",
    "            print(f\"   Available Line Numbers: {row.available_line_numbers}\")\n",
    "            print(f\"   Wrong Answer Length: {row.wrong_answer_length}\")\n",
    "            print(f\"   Explanation: {row.explanation}\")\n",
    "        \n",
    "        if len(problematic_rows) > 5:\n",
    "            print(f\"\\n   ... and {len(problematic_rows) - 5} more problematic rows\")\n",
    "    else:\n",
    "        print(\"\\nâœ… All erroneous line numbers are properly found in their wrong answer mappings!\")\n",
    "    \n",
    "    return problematic_df\n",
    "\n",
    "# Run the check\n",
    "problematic_mappings = check_erroneous_line_in_mapping(df)\n",
    "\n",
    "# Save problematic rows if any found\n",
    "if len(problematic_mappings) > 0:\n",
    "    output_path = AUG_5_DATASET_DIR / \"problematic_line_mappings.csv\"\n",
    "    problematic_mappings.to_csv(output_path, index=False)\n",
    "    print(f\"\\nðŸ’¾ Problematic rows saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "08ad06e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ CREATING EQUATION EXTRACTION DATASET (REFINED)\n",
      "======================================================================\n",
      "\n",
      "ðŸ“‹ Processing COMPUTATIONAL_ERROR samples...\n",
      "   Initial candidates: 22,309\n",
      "   With complete annotation coverage: 18,576\n",
      "   tier4: 100 selected (available: 969, target: 100)\n",
      "   tier2: 50 selected (available: 2,617, target: 50)\n",
      "   tier3: 100 selected (available: 5,983, target: 100)\n",
      "   tier1: 50 selected (available: 9,007, target: 50)\n",
      "   âœ… Final selection: 300 samples\n",
      "      Train: 240\n",
      "      Test: 60\n",
      "      Tier distribution: {'tier1': 50, 'tier2': 50, 'tier3': 100, 'tier4': 100}\n",
      "\n",
      "ðŸ“‹ Processing CONCEPTUAL_ERROR samples...\n",
      "   Initial candidates: 2,067\n",
      "   With complete annotation coverage: 1,591\n",
      "   tier4: 100 selected (available: 169, target: 100)\n",
      "   tier2: 50 selected (available: 261, target: 50)\n",
      "   tier3: 100 selected (available: 605, target: 100)\n",
      "   tier1: 50 selected (available: 556, target: 50)\n",
      "   âœ… Final selection: 300 samples\n",
      "      Train: 240\n",
      "      Test: 60\n",
      "      Tier distribution: {'tier1': 50, 'tier2': 50, 'tier3': 100, 'tier4': 100}\n",
      "\n",
      "ðŸ“‹ Processing CORRECT samples...\n",
      "   Excluding 538 indices already used in error samples\n",
      "   Initial distinct candidates: 21,953\n",
      "   With complete annotation coverage: 17,424\n",
      "   tier4: 100 selected (available: 534, target: 100)\n",
      "   tier2: 50 selected (available: 2,307, target: 50)\n",
      "   tier3: 100 selected (available: 5,762, target: 100)\n",
      "   tier1: 50 selected (available: 8,821, target: 50)\n",
      "   âœ… Final selection: 300 samples\n",
      "      Train: 240\n",
      "      Test: 60\n",
      "      Tier distribution: {'tier1': 50, 'tier2': 50, 'tier3': 100, 'tier4': 100}\n",
      "\n",
      "ðŸŽ¯ FINAL DATASET SUMMARY\n",
      "==================================================\n",
      "Total samples: 900\n",
      "Unique GSM8K indices: 815 (should equal total samples: 900)\n",
      "âŒ WARNING: 85 duplicate indices found!\n",
      "\n",
      "By Error Type:\n",
      "  correct: 300 (train: 240, test: 60)\n",
      "  computational_error: 300 (train: 240, test: 60)\n",
      "  conceptual_error: 300 (train: 240, test: 60)\n",
      "\n",
      "By Split:\n",
      "  train: 720 (80.0%)\n",
      "  test: 180 (20.0%)\n",
      "\n",
      "By Tier:\n",
      "  tier1: 150 (16.7%)\n",
      "  tier2: 150 (16.7%)\n",
      "  tier3: 300 (33.3%)\n",
      "  tier4: 300 (33.3%)\n",
      "\n",
      "By Source:\n",
      "  programmatic: 783 (87.0%)\n",
      "  manual: 117 (13.0%)\n",
      "\n",
      "ðŸ’¾ Dataset saved to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/aug-5-dataset/equation_extraction_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_equation_extraction_dataset_refined(df):\n",
    "    \"\"\"\n",
    "    Create equation extraction dataset with distinct samples and unified error_type column.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”§ CREATING EQUATION EXTRACTION DATASET (REFINED)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Define sample types and their criteria\n",
    "    sample_configs = {\n",
    "        'computational_error': {\n",
    "            'criteria': lambda row: row['error_type'] == 'computational_error',\n",
    "            'answer_mapping_col': 'wrong_answer_mapping', \n",
    "            'eqn_mapping_col': 'wrong_eqn_mapping'\n",
    "        },\n",
    "        'conceptual_error': {\n",
    "            'criteria': lambda row: row['error_type'] == 'conceptual_error',\n",
    "            'answer_mapping_col': 'wrong_answer_mapping',\n",
    "            'eqn_mapping_col': 'wrong_eqn_mapping'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Tier priorities: tier4 (100), tier2 (50), tier3 (100), tier1 (remaining)\n",
    "    tier_priorities = [\n",
    "        ('tier4', 100),\n",
    "        ('tier2', 50), \n",
    "        ('tier3', 100),\n",
    "        ('tier1', None)  # Fill remaining slots\n",
    "    ]\n",
    "    \n",
    "    target_samples_per_type = 300\n",
    "    \n",
    "    def has_complete_annotation_coverage(row, eqn_mapping_col):\n",
    "        \"\"\"Check if all solution lines except FA have calculator annotations.\"\"\"\n",
    "        try:\n",
    "            eqn_mapping = json.loads(row[eqn_mapping_col])\n",
    "            \n",
    "            # Count total lines (excluding FA)\n",
    "            answer_length = row['correct_answer_length'] if 'correct' in eqn_mapping_col else row['wrong_answer_length']\n",
    "            expected_lines = answer_length - 1 if 'FA' in eqn_mapping else answer_length\n",
    "            \n",
    "            # Count non-empty equations (excluding FA)\n",
    "            non_empty_equations = sum(1 for key, value in eqn_mapping.items() \n",
    "                                    if key != 'FA' and value and str(value).strip())\n",
    "            \n",
    "            return non_empty_equations == expected_lines\n",
    "            \n",
    "        except (json.JSONDecodeError, KeyError, TypeError):\n",
    "            return False\n",
    "    \n",
    "    selected_samples = []\n",
    "    used_indices = set()  # Track used GSM8K indices to ensure distinctness\n",
    "    \n",
    "    # First, process error samples (computational and conceptual)\n",
    "    for sample_type, config in sample_configs.items():\n",
    "        print(f\"\\nðŸ“‹ Processing {sample_type.upper()} samples...\")\n",
    "        \n",
    "        # Filter candidates based on criteria\n",
    "        candidates = df[df.apply(config['criteria'], axis=1)].copy()\n",
    "        \n",
    "        print(f\"   Initial candidates: {len(candidates):,}\")\n",
    "        \n",
    "        # Filter for complete annotation coverage\n",
    "        candidates = candidates[\n",
    "            candidates.apply(lambda row: has_complete_annotation_coverage(row, config['eqn_mapping_col']), axis=1)\n",
    "        ].copy()\n",
    "        \n",
    "        print(f\"   With complete annotation coverage: {len(candidates):,}\")\n",
    "        \n",
    "        if len(candidates) == 0:\n",
    "            print(f\"   âŒ No candidates found for {sample_type}\")\n",
    "            continue\n",
    "        \n",
    "        # Select samples by tier priority\n",
    "        selected_for_type = []\n",
    "        remaining_slots = target_samples_per_type\n",
    "        \n",
    "        for tier, target_count in tier_priorities:\n",
    "            if remaining_slots <= 0:\n",
    "                break\n",
    "                \n",
    "            tier_candidates = candidates[candidates['tier'] == tier]\n",
    "            \n",
    "            if target_count is None:  # tier1 - fill remaining slots\n",
    "                target_count = remaining_slots\n",
    "            \n",
    "            available_count = len(tier_candidates)\n",
    "            actual_count = min(target_count, available_count, remaining_slots)\n",
    "            \n",
    "            if actual_count > 0:\n",
    "                # Randomly sample from this tier\n",
    "                tier_selected = tier_candidates.sample(n=actual_count, random_state=42).copy()\n",
    "                selected_for_type.append(tier_selected)\n",
    "                remaining_slots -= actual_count\n",
    "                \n",
    "                # Track used indices\n",
    "                used_indices.update(tier_selected['index'].tolist())\n",
    "                \n",
    "                print(f\"   {tier}: {actual_count:,} selected (available: {available_count:,}, target: {target_count})\")\n",
    "        \n",
    "        # Combine all selected samples for this type\n",
    "        if selected_for_type:\n",
    "            type_samples = pd.concat(selected_for_type, ignore_index=True)\n",
    "            \n",
    "            # Add train/test split (4:1 ratio)\n",
    "            np.random.seed(42 + len(selected_samples))  # Different seed per type\n",
    "            n_samples = len(type_samples)\n",
    "            n_train = int(0.8 * n_samples)  # 4:1 ratio\n",
    "            \n",
    "            indices = np.random.permutation(n_samples)\n",
    "            train_indices = indices[:n_train]\n",
    "            test_indices = indices[n_train:]\n",
    "            \n",
    "            type_samples['split'] = 'test'  # Default to test\n",
    "            type_samples.iloc[train_indices, type_samples.columns.get_loc('split')] = 'train'\n",
    "            \n",
    "            selected_samples.append(type_samples)\n",
    "            \n",
    "            print(f\"   âœ… Final selection: {len(type_samples):,} samples\")\n",
    "            print(f\"      Train: {len(type_samples[type_samples['split'] == 'train']):,}\")\n",
    "            print(f\"      Test: {len(type_samples[type_samples['split'] == 'test']):,}\")\n",
    "            \n",
    "            # Show tier distribution\n",
    "            tier_dist = type_samples['tier'].value_counts().sort_index()\n",
    "            print(f\"      Tier distribution: {dict(tier_dist)}\")\n",
    "    \n",
    "    # Now process correct samples, excluding used indices\n",
    "    print(f\"\\nðŸ“‹ Processing CORRECT samples...\")\n",
    "    print(f\"   Excluding {len(used_indices):,} indices already used in error samples\")\n",
    "    \n",
    "    # Filter out used indices to ensure distinctness\n",
    "    correct_candidates = df[~df['index'].isin(used_indices)].copy()\n",
    "    \n",
    "    print(f\"   Initial distinct candidates: {len(correct_candidates):,}\")\n",
    "    \n",
    "    # Filter for complete annotation coverage using correct mappings\n",
    "    correct_candidates = correct_candidates[\n",
    "        correct_candidates.apply(lambda row: has_complete_annotation_coverage(row, 'correct_eqn_mapping'), axis=1)\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"   With complete annotation coverage: {len(correct_candidates):,}\")\n",
    "    \n",
    "    if len(correct_candidates) > 0:\n",
    "        # Select correct samples by tier priority\n",
    "        selected_correct = []\n",
    "        remaining_slots = target_samples_per_type\n",
    "        \n",
    "        for tier, target_count in tier_priorities:\n",
    "            if remaining_slots <= 0:\n",
    "                break\n",
    "                \n",
    "            tier_candidates = correct_candidates[correct_candidates['tier'] == tier]\n",
    "            \n",
    "            if target_count is None:  # tier1 - fill remaining slots\n",
    "                target_count = remaining_slots\n",
    "            \n",
    "            available_count = len(tier_candidates)\n",
    "            actual_count = min(target_count, available_count, remaining_slots)\n",
    "            \n",
    "            if actual_count > 0:\n",
    "                # Randomly sample from this tier\n",
    "                tier_selected = tier_candidates.sample(n=actual_count, random_state=43).copy()\n",
    "                selected_correct.append(tier_selected)\n",
    "                remaining_slots -= actual_count\n",
    "                \n",
    "                print(f\"   {tier}: {actual_count:,} selected (available: {available_count:,}, target: {target_count})\")\n",
    "        \n",
    "        # Combine all selected correct samples\n",
    "        if selected_correct:\n",
    "            correct_samples = pd.concat(selected_correct, ignore_index=True)\n",
    "            \n",
    "            # Set error_type to \"correct\" for these samples\n",
    "            correct_samples['error_type'] = 'correct'\n",
    "            \n",
    "            # Add train/test split (4:1 ratio)\n",
    "            np.random.seed(44)  # Different seed for correct samples\n",
    "            n_samples = len(correct_samples)\n",
    "            n_train = int(0.8 * n_samples)  # 4:1 ratio\n",
    "            \n",
    "            indices = np.random.permutation(n_samples)\n",
    "            train_indices = indices[:n_train]\n",
    "            test_indices = indices[n_train:]\n",
    "            \n",
    "            correct_samples['split'] = 'test'  # Default to test\n",
    "            correct_samples.iloc[train_indices, correct_samples.columns.get_loc('split')] = 'train'\n",
    "            \n",
    "            selected_samples.append(correct_samples)\n",
    "            \n",
    "            print(f\"   âœ… Final selection: {len(correct_samples):,} samples\")\n",
    "            print(f\"      Train: {len(correct_samples[correct_samples['split'] == 'train']):,}\")\n",
    "            print(f\"      Test: {len(correct_samples[correct_samples['split'] == 'test']):,}\")\n",
    "            \n",
    "            # Show tier distribution\n",
    "            tier_dist = correct_samples['tier'].value_counts().sort_index()\n",
    "            print(f\"      Tier distribution: {dict(tier_dist)}\")\n",
    "    else:\n",
    "        print(f\"   âŒ No distinct correct samples found\")\n",
    "    \n",
    "    # Combine all sample types\n",
    "    if selected_samples:\n",
    "        final_dataset = pd.concat(selected_samples, ignore_index=True)\n",
    "        \n",
    "        print(f\"\\nðŸŽ¯ FINAL DATASET SUMMARY\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Total samples: {len(final_dataset):,}\")\n",
    "        \n",
    "        # Verify distinctness\n",
    "        unique_indices = final_dataset['index'].nunique()\n",
    "        total_samples = len(final_dataset)\n",
    "        print(f\"Unique GSM8K indices: {unique_indices:,} (should equal total samples: {total_samples:,})\")\n",
    "        if unique_indices == total_samples:\n",
    "            print(\"âœ… All samples are distinct!\")\n",
    "        else:\n",
    "            print(f\"âŒ WARNING: {total_samples - unique_indices} duplicate indices found!\")\n",
    "        \n",
    "        # Summary by error type (now unified)\n",
    "        print(f\"\\nBy Error Type:\")\n",
    "        for error_type in ['correct', 'computational_error', 'conceptual_error']:\n",
    "            type_data = final_dataset[final_dataset['error_type'] == error_type]\n",
    "            if len(type_data) > 0:\n",
    "                train_count = len(type_data[type_data['split'] == 'train'])\n",
    "                test_count = len(type_data[type_data['split'] == 'test'])\n",
    "                print(f\"  {error_type}: {len(type_data):,} (train: {train_count:,}, test: {test_count:,})\")\n",
    "        \n",
    "        # Summary by split\n",
    "        print(f\"\\nBy Split:\")\n",
    "        split_counts = final_dataset['split'].value_counts()\n",
    "        for split, count in split_counts.items():\n",
    "            pct = (count / len(final_dataset)) * 100\n",
    "            print(f\"  {split}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        # Summary by tier\n",
    "        print(f\"\\nBy Tier:\")\n",
    "        tier_counts = final_dataset['tier'].value_counts().sort_index()\n",
    "        for tier, count in tier_counts.items():\n",
    "            pct = (count / len(final_dataset)) * 100\n",
    "            print(f\"  {tier}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        # Summary by source\n",
    "        print(f\"\\nBy Source:\")\n",
    "        source_counts = final_dataset['source'].value_counts()\n",
    "        for source, count in source_counts.items():\n",
    "            pct = (count / len(final_dataset)) * 100\n",
    "            print(f\"  {source}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        return final_dataset\n",
    "    else:\n",
    "        print(\"\\nâŒ No samples could be selected!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Create the refined equation extraction dataset\n",
    "equation_extraction_dataset = create_equation_extraction_dataset_refined(df)\n",
    "\n",
    "# Save the dataset\n",
    "if not equation_extraction_dataset.empty:\n",
    "    output_path = AUG_5_DATASET_DIR / \"equation_extraction_dataset.csv\"\n",
    "    equation_extraction_dataset.to_csv(output_path, index=False)\n",
    "    print(f\"\\nðŸ’¾ Dataset saved to: {output_path}\")\n",
    "    \n",
    "    # # Save metadata\n",
    "    # metadata = {\n",
    "    #     \"dataset_name\": \"equation_extraction_dataset\",\n",
    "    #     \"creation_date\": \"2025-08-05\",\n",
    "    #     \"total_samples\": len(equation_extraction_dataset),\n",
    "    #     \"error_type_distribution\": dict(equation_extraction_dataset['error_type'].value_counts()),\n",
    "    #     \"split_distribution\": dict(equation_extraction_dataset['split'].value_counts()),\n",
    "    #     \"tier_distribution\": dict(equation_extraction_dataset['tier'].value_counts()),\n",
    "    #     \"source_distribution\": dict(equation_extraction_dataset['source'].value_counts()),\n",
    "    #     \"columns\": list(equation_extraction_dataset.columns),\n",
    "    #     \"distinctness_verified\": equation_extraction_dataset['index'].nunique() == len(equation_extraction_dataset),\n",
    "    #     \"description\": \"Dataset for fine-tuning equation extraction task with distinct samples and complete annotation coverage\"\n",
    "    # }\n",
    "    \n",
    "    # metadata_path = AUG_5_DATASET_DIR / \"equation_extraction_metadata.json\"\n",
    "    # with open(metadata_path, 'w') as f:\n",
    "    #     json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    # print(f\"ðŸ’¾ Metadata saved to: {metadata_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Dataset creation failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cdbfdef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ CREATING ERROR DETECTION DATASET\n",
      "======================================================================\n",
      "\n",
      "ðŸ“‹ Step 1: Processing CONCEPTUAL ERROR samples...\n",
      "   Found N = 2,067 conceptual error samples\n",
      "   âœ… Added 2,067 conceptual error samples\n",
      "\n",
      "ðŸ“‹ Step 2: Processing COMPUTATIONAL ERROR samples...\n",
      "   Target: 2,067 samples with distinct indices from conceptual samples\n",
      "   Available distinct computational candidates: 16,204\n",
      "   tier4: 500 selected (available: 787, limit: 500)\n",
      "   tier2: 500 selected (available: 2,051, limit: 500)\n",
      "   tier3: 500 selected (available: 5,505, limit: 500)\n",
      "   tier1: 500 selected (available: 7,851, limit: 500)\n",
      "   âœ… Added 2,000 computational error samples\n",
      "      Tier distribution: {'tier1': 500, 'tier2': 500, 'tier3': 500, 'tier4': 500}\n",
      "\n",
      "ðŸ“‹ Step 3: Processing CORRESPONDING CORRECT samples...\n",
      "   Target: 516 corresponding correct samples each for conceptual and computational\n",
      "   âœ… Added 2,238 correct samples corresponding to conceptual errors\n",
      "   âœ… Added 2,010 correct samples corresponding to computational errors\n",
      "\n",
      "ðŸ“‹ Step 4: Processing SEPARATE CORRECT samples...\n",
      "   Target: 1,033 entirely separate correct samples\n",
      "   Excluding 3,271 indices already used\n",
      "   Available distinct correct candidates: 10,287\n",
      "   tier4: 58 selected (available: 58, limit: 500)\n",
      "   tier2: 500 selected (available: 627, limit: 500)\n",
      "   tier3: 475 selected (available: 3,835, limit: 500)\n",
      "   âœ… Added 1,033 separate correct samples\n",
      "      Tier distribution: {'tier2': 500, 'tier3': 475, 'tier4': 58}\n",
      "\n",
      "ðŸ“‹ Adding train/test splits...\n",
      "\n",
      "ðŸŽ¯ FINAL DATASET SUMMARY\n",
      "==================================================\n",
      "Total samples: 9,348\n",
      "Expected total (3N): 6,201\n",
      "Unique GSM8K indices: 3,941\n",
      "\n",
      "By Error Type:\n",
      "  correct: 5,281 (train: 4,224, test: 1,057, unique indices: 1,637)\n",
      "  conceptual_error: 2,067 (train: 1,653, test: 414, unique indices: 1,847)\n",
      "  computational_error: 2,000 (train: 1,600, test: 400, unique indices: 1,424)\n",
      "\n",
      "By Split:\n",
      "  train: 7,477 (80.0%)\n",
      "  test: 1,871 (20.0%)\n",
      "\n",
      "By Tier:\n",
      "  tier1: 2,658 (28.4%)\n",
      "  tier2: 2,274 (24.3%)\n",
      "  tier3: 2,914 (31.2%)\n",
      "  tier4: 1,461 (15.6%)\n",
      "  tier5: 41 (0.4%)\n",
      "\n",
      "By Source:\n",
      "  programmatic: 7,955 (85.1%)\n",
      "  manual: 1,393 (14.9%)\n",
      "\n",
      "ðŸ’¾ Dataset saved to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/aug-5-dataset/error_detection_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_error_detection_dataset(df):\n",
    "    \"\"\"\n",
    "    Create error detection dataset with specified design requirements.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”§ CREATING ERROR DETECTION DATASET\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Tier priorities: tier4 (500), tier2 (500), tier3 (500), tier1 (500)\n",
    "    tier_priorities = [\n",
    "        ('tier4', 500),\n",
    "        ('tier2', 500), \n",
    "        ('tier3', 500),\n",
    "        ('tier1', 500)\n",
    "    ]\n",
    "    \n",
    "    used_indices = set()  # Track used GSM8K indices to ensure distinctness\n",
    "    selected_samples = []\n",
    "    \n",
    "    # Step 1: Get all conceptual error samples\n",
    "    print(f\"\\nðŸ“‹ Step 1: Processing CONCEPTUAL ERROR samples...\")\n",
    "    conceptual_samples = df[df['error_type'] == 'conceptual_error'].copy()\n",
    "    N = len(conceptual_samples)\n",
    "    \n",
    "    print(f\"   Found N = {N:,} conceptual error samples\")\n",
    "    \n",
    "    # Track conceptual indices\n",
    "    conceptual_indices = set(conceptual_samples['index'].tolist())\n",
    "    used_indices.update(conceptual_indices)\n",
    "    \n",
    "    # Add split column (will assign later)\n",
    "    conceptual_samples['split'] = 'train'  # Default, will be reassigned\n",
    "    selected_samples.append(conceptual_samples)\n",
    "    \n",
    "    print(f\"   âœ… Added {len(conceptual_samples):,} conceptual error samples\")\n",
    "    \n",
    "    # Step 2: Add N computational error samples (distinct problem indices)\n",
    "    print(f\"\\nðŸ“‹ Step 2: Processing COMPUTATIONAL ERROR samples...\")\n",
    "    print(f\"   Target: {N:,} samples with distinct indices from conceptual samples\")\n",
    "    \n",
    "    # Get computational candidates excluding conceptual indices\n",
    "    computational_candidates = df[\n",
    "        (df['error_type'] == 'computational_error') & \n",
    "        (~df['index'].isin(used_indices))\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"   Available distinct computational candidates: {len(computational_candidates):,}\")\n",
    "    \n",
    "    # Select computational samples by tier priority\n",
    "    selected_computational = []\n",
    "    remaining_slots = N\n",
    "    \n",
    "    for tier, tier_limit in tier_priorities:\n",
    "        if remaining_slots <= 0:\n",
    "            break\n",
    "            \n",
    "        tier_candidates = computational_candidates[computational_candidates['tier'] == tier]\n",
    "        available_count = len(tier_candidates)\n",
    "        actual_count = min(tier_limit, available_count, remaining_slots)\n",
    "        \n",
    "        if actual_count > 0:\n",
    "            # Randomly sample from this tier\n",
    "            tier_selected = tier_candidates.sample(n=actual_count, random_state=42).copy()\n",
    "            selected_computational.append(tier_selected)\n",
    "            remaining_slots -= actual_count\n",
    "            \n",
    "            # Track used indices\n",
    "            used_indices.update(tier_selected['index'].tolist())\n",
    "            \n",
    "            print(f\"   {tier}: {actual_count:,} selected (available: {available_count:,}, limit: {tier_limit:,})\")\n",
    "    \n",
    "    # Combine computational samples\n",
    "    if selected_computational:\n",
    "        computational_samples = pd.concat(selected_computational, ignore_index=True)\n",
    "        computational_samples['split'] = 'train'  # Default, will be reassigned\n",
    "        selected_samples.append(computational_samples)\n",
    "        \n",
    "        print(f\"   âœ… Added {len(computational_samples):,} computational error samples\")\n",
    "        \n",
    "        # Show tier distribution\n",
    "        tier_dist = computational_samples['tier'].value_counts().sort_index()\n",
    "        print(f\"      Tier distribution: {dict(tier_dist)}\")\n",
    "    else:\n",
    "        print(f\"   âŒ Could not select enough computational samples\")\n",
    "        computational_samples = pd.DataFrame()\n",
    "    \n",
    "    # Step 3: Add N//4 correct samples corresponding to random conceptual/computational samples\n",
    "    print(f\"\\nðŸ“‹ Step 3: Processing CORRESPONDING CORRECT samples...\")\n",
    "    \n",
    "    target_corresponding = N // 4\n",
    "    print(f\"   Target: {target_corresponding:,} corresponding correct samples each for conceptual and computational\")\n",
    "    \n",
    "    # Randomly select N//4 conceptual and computational samples\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Get corresponding correct samples for random conceptual samples\n",
    "    if len(conceptual_samples) >= target_corresponding:\n",
    "        random_conceptual_indices = np.random.choice(\n",
    "            conceptual_samples['index'].values, \n",
    "            size=target_corresponding, \n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        # Find corresponding correct samples\n",
    "        conceptual_correct_samples = df[df['index'].isin(random_conceptual_indices)].copy()\n",
    "        conceptual_correct_samples['error_type'] = 'correct'\n",
    "        conceptual_correct_samples['split'] = 'train'\n",
    "        selected_samples.append(conceptual_correct_samples)\n",
    "        \n",
    "        print(f\"   âœ… Added {len(conceptual_correct_samples):,} correct samples corresponding to conceptual errors\")\n",
    "    \n",
    "    # Get corresponding correct samples for random computational samples  \n",
    "    if len(computational_samples) >= target_corresponding:\n",
    "        random_computational_indices = np.random.choice(\n",
    "            computational_samples['index'].values,\n",
    "            size=target_corresponding,\n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        # Find corresponding correct samples\n",
    "        computational_correct_samples = df[df['index'].isin(random_computational_indices)].copy()\n",
    "        computational_correct_samples['error_type'] = 'correct'\n",
    "        computational_correct_samples['split'] = 'train'\n",
    "        selected_samples.append(computational_correct_samples)\n",
    "        \n",
    "        print(f\"   âœ… Added {len(computational_correct_samples):,} correct samples corresponding to computational errors\")\n",
    "    \n",
    "    # Step 4: Add N//2 entirely separate correct samples\n",
    "    print(f\"\\nðŸ“‹ Step 4: Processing SEPARATE CORRECT samples...\")\n",
    "    \n",
    "    target_separate = N // 2\n",
    "    print(f\"   Target: {target_separate:,} entirely separate correct samples\")\n",
    "    print(f\"   Excluding {len(used_indices):,} indices already used\")\n",
    "    \n",
    "    # Get correct candidates excluding all used indices\n",
    "    separate_correct_candidates = df[~df['index'].isin(used_indices)].copy()\n",
    "    \n",
    "    print(f\"   Available distinct correct candidates: {len(separate_correct_candidates):,}\")\n",
    "    \n",
    "    # Select separate correct samples by tier priority\n",
    "    selected_separate_correct = []\n",
    "    remaining_slots = target_separate\n",
    "    \n",
    "    for tier, tier_limit in tier_priorities:\n",
    "        if remaining_slots <= 0:\n",
    "            break\n",
    "            \n",
    "        tier_candidates = separate_correct_candidates[separate_correct_candidates['tier'] == tier]\n",
    "        available_count = len(tier_candidates)\n",
    "        actual_count = min(tier_limit, available_count, remaining_slots)\n",
    "        \n",
    "        if actual_count > 0:\n",
    "            # Randomly sample from this tier\n",
    "            tier_selected = tier_candidates.sample(n=actual_count, random_state=43).copy()\n",
    "            selected_separate_correct.append(tier_selected)\n",
    "            remaining_slots -= actual_count\n",
    "            \n",
    "            print(f\"   {tier}: {actual_count:,} selected (available: {available_count:,}, limit: {tier_limit:,})\")\n",
    "    \n",
    "    # Combine separate correct samples\n",
    "    if selected_separate_correct:\n",
    "        separate_correct_samples = pd.concat(selected_separate_correct, ignore_index=True)\n",
    "        separate_correct_samples['error_type'] = 'correct'\n",
    "        separate_correct_samples['split'] = 'train'  # Default, will be reassigned\n",
    "        selected_samples.append(separate_correct_samples)\n",
    "        \n",
    "        print(f\"   âœ… Added {len(separate_correct_samples):,} separate correct samples\")\n",
    "        \n",
    "        # Show tier distribution\n",
    "        tier_dist = separate_correct_samples['tier'].value_counts().sort_index()\n",
    "        print(f\"      Tier distribution: {dict(tier_dist)}\")\n",
    "    else:\n",
    "        print(f\"   âŒ Could not select enough separate correct samples\")\n",
    "    \n",
    "    # Combine all samples\n",
    "    if selected_samples:\n",
    "        final_dataset = pd.concat(selected_samples, ignore_index=True)\n",
    "        \n",
    "        # Add proper train/test split (4:1 ratio within each error type)\n",
    "        print(f\"\\nðŸ“‹ Adding train/test splits...\")\n",
    "        \n",
    "        for error_type in ['correct', 'conceptual_error', 'computational_error']:\n",
    "            type_mask = final_dataset['error_type'] == error_type\n",
    "            type_indices = final_dataset[type_mask].index.tolist()\n",
    "            \n",
    "            if len(type_indices) > 0:\n",
    "                np.random.seed(44 + hash(error_type) % 100)  # Different seed per type\n",
    "                n_samples = len(type_indices)\n",
    "                n_train = int(0.8 * n_samples)  # 4:1 ratio\n",
    "                \n",
    "                shuffled_indices = np.random.permutation(type_indices)\n",
    "                train_indices = shuffled_indices[:n_train]\n",
    "                test_indices = shuffled_indices[n_train:]\n",
    "                \n",
    "                final_dataset.loc[train_indices, 'split'] = 'train'\n",
    "                final_dataset.loc[test_indices, 'split'] = 'test'\n",
    "        \n",
    "        print(f\"\\nðŸŽ¯ FINAL DATASET SUMMARY\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Total samples: {len(final_dataset):,}\")\n",
    "        print(f\"Expected total (3N): {3 * N:,}\")\n",
    "        \n",
    "        # Verify distinctness within error types where expected\n",
    "        total_unique = final_dataset['index'].nunique()\n",
    "        print(f\"Unique GSM8K indices: {total_unique:,}\")\n",
    "        \n",
    "        # Summary by error type\n",
    "        print(f\"\\nBy Error Type:\")\n",
    "        for error_type in ['correct', 'conceptual_error', 'computational_error']:\n",
    "            type_data = final_dataset[final_dataset['error_type'] == error_type]\n",
    "            if len(type_data) > 0:\n",
    "                train_count = len(type_data[type_data['split'] == 'train'])\n",
    "                test_count = len(type_data[type_data['split'] == 'test'])\n",
    "                unique_indices = type_data['index'].nunique()\n",
    "                print(f\"  {error_type}: {len(type_data):,} (train: {train_count:,}, test: {test_count:,}, unique indices: {unique_indices:,})\")\n",
    "        \n",
    "        # Summary by split\n",
    "        print(f\"\\nBy Split:\")\n",
    "        split_counts = final_dataset['split'].value_counts()\n",
    "        for split, count in split_counts.items():\n",
    "            pct = (count / len(final_dataset)) * 100\n",
    "            print(f\"  {split}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        # Summary by tier\n",
    "        print(f\"\\nBy Tier:\")\n",
    "        tier_counts = final_dataset['tier'].value_counts().sort_index()\n",
    "        for tier, count in tier_counts.items():\n",
    "            pct = (count / len(final_dataset)) * 100\n",
    "            print(f\"  {tier}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        # Summary by source\n",
    "        print(f\"\\nBy Source:\")\n",
    "        source_counts = final_dataset['source'].value_counts()\n",
    "        for source, count in source_counts.items():\n",
    "            pct = (count / len(final_dataset)) * 100\n",
    "            print(f\"  {source}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        return final_dataset\n",
    "    else:\n",
    "        print(\"\\nâŒ No samples could be selected!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Create the error detection dataset\n",
    "error_detection_dataset = create_error_detection_dataset(df)\n",
    "\n",
    "# Save the dataset\n",
    "if not error_detection_dataset.empty:\n",
    "    output_path = AUG_5_DATASET_DIR / \"error_detection_dataset.csv\"\n",
    "    error_detection_dataset.to_csv(output_path, index=False)\n",
    "    print(f\"\\nðŸ’¾ Dataset saved to: {output_path}\")\n",
    "    \n",
    "    # # Save metadata\n",
    "    # metadata = {\n",
    "    #     \"dataset_name\": \"error_detection_dataset\",\n",
    "    #     \"creation_date\": \"2025-08-05\",\n",
    "    #     \"total_samples\": len(error_detection_dataset),\n",
    "    #     \"N_conceptual\": len(error_detection_dataset[error_detection_dataset['error_type'] == 'conceptual_error']),\n",
    "    #     \"error_type_distribution\": dict(error_detection_dataset['error_type'].value_counts()),\n",
    "    #     \"split_distribution\": dict(error_detection_dataset['split'].value_counts()),\n",
    "    #     \"tier_distribution\": dict(error_detection_dataset['tier'].value_counts()),\n",
    "    #     \"source_distribution\": dict(error_detection_dataset['source'].value_counts()),\n",
    "    #     \"columns\": list(error_detection_dataset.columns),\n",
    "    #     \"unique_indices\": error_detection_dataset['index'].nunique(),\n",
    "    #     \"description\": \"Dataset for fine-tuning error detection task with structure: N conceptual + N computational + N correct (3N total)\"\n",
    "    # }\n",
    "    \n",
    "    # metadata_path = AUG_5_DATASET_DIR / \"error_detection_metadata.json\"\n",
    "    # with open(metadata_path, 'w') as f:\n",
    "    #     json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    # print(f\"ðŸ’¾ Metadata saved to: {metadata_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Dataset creation failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5639699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ CREATING ERROR DETECTION DATASET (SIMPLIFIED)\n",
      "======================================================================\n",
      "\n",
      "ðŸ“‹ Step 1: Processing CONCEPTUAL ERROR samples...\n",
      "   Found N = 2,067 conceptual error samples\n",
      "   âœ… Added 2,067 conceptual error samples\n",
      "\n",
      "ðŸ“‹ Step 2: Processing COMPUTATIONAL ERROR samples...\n",
      "   Target: 2,067 samples with distinct indices from conceptual samples\n",
      "   Available distinct computational candidates: 16,204\n",
      "   tier4: 500 selected (available: 787, limit: 500)\n",
      "   tier2: 500 selected (available: 2,051, limit: 500)\n",
      "   tier3: 500 selected (available: 5,505, limit: 500)\n",
      "   tier1: 500 selected (available: 7,851, limit: 500)\n",
      "   âœ… Added 2,000 computational error samples\n",
      "      Tier distribution: {'tier1': 500, 'tier2': 500, 'tier3': 500, 'tier4': 500}\n",
      "\n",
      "ðŸ“‹ Step 3: Processing CORRECT samples...\n",
      "   Target: 2000 randomly chosen correct samples (following tier priority)\n",
      "   Available correct candidates: 24,376\n",
      "   tier4: 500 selected (available: 1,637, limit: 500)\n",
      "   tier2: 500 selected (available: 3,436, limit: 500)\n",
      "   tier3: 500 selected (available: 8,198, limit: 500)\n",
      "   tier1: 500 selected (available: 11,050, limit: 500)\n",
      "   âœ… Added 2,000 correct samples\n",
      "      Tier distribution: {'tier1': 500, 'tier2': 500, 'tier3': 500, 'tier4': 500}\n",
      "      Unique indices in correct samples: 1,607 / 2,000\n",
      "      âš ï¸  393 duplicate indices in correct samples\n",
      "\n",
      "ðŸ“‹ Adding train/test splits...\n",
      "\n",
      "ðŸŽ¯ FINAL DATASET SUMMARY\n",
      "==================================================\n",
      "Total samples: 6,067\n",
      "\n",
      "By Error Type:\n",
      "  correct: 2,000 (train: 1,600, test: 400, unique indices: 1,607)\n",
      "  conceptual_error: 2,067 (train: 1,653, test: 414, unique indices: 1,847)\n",
      "  computational_error: 2,000 (train: 1,600, test: 400, unique indices: 1,424)\n",
      "\n",
      "By Split:\n",
      "  train: 4,853 (80.0%)\n",
      "  test: 1,214 (20.0%)\n",
      "\n",
      "By Tier:\n",
      "  tier1: 1,690 (27.9%)\n",
      "  tier2: 1,321 (21.8%)\n",
      "  tier3: 1,794 (29.6%)\n",
      "  tier4: 1,234 (20.3%)\n",
      "  tier5: 28 (0.5%)\n",
      "\n",
      "By Source:\n",
      "  programmatic: 4,948 (81.6%)\n",
      "  manual: 1,119 (18.4%)\n",
      "\n",
      "Index Overlap Analysis:\n",
      "  Conceptual âˆ© Computational: 0 indices\n",
      "  Conceptual âˆ© Correct: 577 indices\n",
      "  Computational âˆ© Correct: 467 indices\n",
      "\n",
      "ðŸ’¾ Dataset saved to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/aug-5-dataset/error_detection_dataset.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type int64 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[110]\u001b[39m\u001b[32m, line 249\u001b[39m\n\u001b[32m    247\u001b[39m     metadata_path = AUG_5_DATASET_DIR / \u001b[33m\"\u001b[39m\u001b[33merror_detection_metadata.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(metadata_path, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m         \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸ’¾ Metadata saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos-dl/lib/python3.12/json/__init__.py:179\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    173\u001b[39m     iterable = \u001b[38;5;28mcls\u001b[39m(skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n\u001b[32m    174\u001b[39m         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n\u001b[32m    175\u001b[39m         separators=separators,\n\u001b[32m    176\u001b[39m         default=default, sort_keys=sort_keys, **kw).iterencode(obj)\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos-dl/lib/python3.12/json/encoder.py:432\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    430\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos-dl/lib/python3.12/json/encoder.py:406\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    405\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    408\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos-dl/lib/python3.12/json/encoder.py:406\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    405\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    408\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos-dl/lib/python3.12/json/encoder.py:439\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    437\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCircular reference detected\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    438\u001b[39m     markers[markerid] = o\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m o = \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos-dl/lib/python3.12/json/encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type int64 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_error_detection_dataset_simplified(df):\n",
    "    \"\"\"\n",
    "    Create error detection dataset with simplified correct sample logic.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”§ CREATING ERROR DETECTION DATASET (SIMPLIFIED)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Tier priorities: tier4 (500), tier2 (500), tier3 (500), tier1 (500)\n",
    "    tier_priorities = [\n",
    "        ('tier4', 500),\n",
    "        ('tier2', 500), \n",
    "        ('tier3', 500),\n",
    "        ('tier1', 500)\n",
    "    ]\n",
    "    \n",
    "    used_indices = set()  # Track used GSM8K indices for conceptual/computational\n",
    "    selected_samples = []\n",
    "    \n",
    "    # Step 1: Get all conceptual error samples\n",
    "    print(f\"\\nðŸ“‹ Step 1: Processing CONCEPTUAL ERROR samples...\")\n",
    "    conceptual_samples = df[df['error_type'] == 'conceptual_error'].copy()\n",
    "    N = len(conceptual_samples)\n",
    "    \n",
    "    print(f\"   Found N = {N:,} conceptual error samples\")\n",
    "    \n",
    "    # Track conceptual indices\n",
    "    conceptual_indices = set(conceptual_samples['index'].tolist())\n",
    "    used_indices.update(conceptual_indices)\n",
    "    \n",
    "    # Add split column (will assign later)\n",
    "    conceptual_samples['split'] = 'train'  # Default, will be reassigned\n",
    "    selected_samples.append(conceptual_samples)\n",
    "    \n",
    "    print(f\"   âœ… Added {len(conceptual_samples):,} conceptual error samples\")\n",
    "    \n",
    "    # Step 2: Add N computational error samples (distinct problem indices)\n",
    "    print(f\"\\nðŸ“‹ Step 2: Processing COMPUTATIONAL ERROR samples...\")\n",
    "    print(f\"   Target: {N:,} samples with distinct indices from conceptual samples\")\n",
    "    \n",
    "    # Get computational candidates excluding conceptual indices\n",
    "    computational_candidates = df[\n",
    "        (df['error_type'] == 'computational_error') & \n",
    "        (~df['index'].isin(used_indices))\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"   Available distinct computational candidates: {len(computational_candidates):,}\")\n",
    "    \n",
    "    # Select computational samples by tier priority\n",
    "    selected_computational = []\n",
    "    remaining_slots = N\n",
    "    \n",
    "    for tier, tier_limit in tier_priorities:\n",
    "        if remaining_slots <= 0:\n",
    "            break\n",
    "            \n",
    "        tier_candidates = computational_candidates[computational_candidates['tier'] == tier]\n",
    "        available_count = len(tier_candidates)\n",
    "        actual_count = min(tier_limit, available_count, remaining_slots)\n",
    "        \n",
    "        if actual_count > 0:\n",
    "            # Randomly sample from this tier\n",
    "            tier_selected = tier_candidates.sample(n=actual_count, random_state=42).copy()\n",
    "            selected_computational.append(tier_selected)\n",
    "            remaining_slots -= actual_count\n",
    "            \n",
    "            # Track used indices\n",
    "            used_indices.update(tier_selected['index'].tolist())\n",
    "            \n",
    "            print(f\"   {tier}: {actual_count:,} selected (available: {available_count:,}, limit: {tier_limit:,})\")\n",
    "    \n",
    "    # Combine computational samples\n",
    "    if selected_computational:\n",
    "        computational_samples = pd.concat(selected_computational, ignore_index=True)\n",
    "        computational_samples['split'] = 'train'  # Default, will be reassigned\n",
    "        selected_samples.append(computational_samples)\n",
    "        \n",
    "        print(f\"   âœ… Added {len(computational_samples):,} computational error samples\")\n",
    "        \n",
    "        # Show tier distribution\n",
    "        tier_dist = computational_samples['tier'].value_counts().sort_index()\n",
    "        print(f\"      Tier distribution: {dict(tier_dist)}\")\n",
    "    else:\n",
    "        print(f\"   âŒ Could not select enough computational samples\")\n",
    "        computational_samples = pd.DataFrame()\n",
    "    \n",
    "    # Step 3: Add 2000 randomly chosen correct samples (following tier priority)\n",
    "    print(f\"\\nðŸ“‹ Step 3: Processing CORRECT samples...\")\n",
    "    print(f\"   Target: 2000 randomly chosen correct samples (following tier priority)\")\n",
    "    \n",
    "    # Get all available candidates (don't worry about used indices)\n",
    "    correct_candidates = df.copy()\n",
    "    \n",
    "    print(f\"   Available correct candidates: {len(correct_candidates):,}\")\n",
    "    \n",
    "    # Select correct samples by tier priority\n",
    "    selected_correct = []\n",
    "    remaining_slots = 2000\n",
    "    \n",
    "    for tier, tier_limit in tier_priorities:\n",
    "        if remaining_slots <= 0:\n",
    "            break\n",
    "            \n",
    "        tier_candidates = correct_candidates[correct_candidates['tier'] == tier]\n",
    "        available_count = len(tier_candidates)\n",
    "        actual_count = min(tier_limit, available_count, remaining_slots)\n",
    "        \n",
    "        if actual_count > 0:\n",
    "            # Randomly sample from this tier\n",
    "            tier_selected = tier_candidates.sample(n=actual_count, random_state=45).copy()\n",
    "            selected_correct.append(tier_selected)\n",
    "            remaining_slots -= actual_count\n",
    "            \n",
    "            print(f\"   {tier}: {actual_count:,} selected (available: {available_count:,}, limit: {tier_limit:,})\")\n",
    "    \n",
    "    # Combine correct samples\n",
    "    if selected_correct:\n",
    "        correct_samples = pd.concat(selected_correct, ignore_index=True)\n",
    "        correct_samples['error_type'] = 'correct'\n",
    "        correct_samples['split'] = 'train'  # Default, will be reassigned\n",
    "        selected_samples.append(correct_samples)\n",
    "        \n",
    "        print(f\"   âœ… Added {len(correct_samples):,} correct samples\")\n",
    "        \n",
    "        # Show tier distribution\n",
    "        tier_dist = correct_samples['tier'].value_counts().sort_index()\n",
    "        print(f\"      Tier distribution: {dict(tier_dist)}\")\n",
    "        \n",
    "        # Check for distinctness within correct samples\n",
    "        unique_correct_indices = correct_samples['index'].nunique()\n",
    "        total_correct_samples = len(correct_samples)\n",
    "        print(f\"      Unique indices in correct samples: {unique_correct_indices:,} / {total_correct_samples:,}\")\n",
    "        if unique_correct_indices == total_correct_samples:\n",
    "            print(\"      âœ… All correct samples have distinct indices\")\n",
    "        else:\n",
    "            print(f\"      âš ï¸  {total_correct_samples - unique_correct_indices} duplicate indices in correct samples\")\n",
    "    else:\n",
    "        print(f\"   âŒ Could not select correct samples\")\n",
    "    \n",
    "    # Combine all samples\n",
    "    if selected_samples:\n",
    "        final_dataset = pd.concat(selected_samples, ignore_index=True)\n",
    "        \n",
    "        # Add proper train/test split (4:1 ratio within each error type)\n",
    "        print(f\"\\nðŸ“‹ Adding train/test splits...\")\n",
    "        \n",
    "        for error_type in ['correct', 'conceptual_error', 'computational_error']:\n",
    "            type_mask = final_dataset['error_type'] == error_type\n",
    "            type_indices = final_dataset[type_mask].index.tolist()\n",
    "            \n",
    "            if len(type_indices) > 0:\n",
    "                np.random.seed(44 + hash(error_type) % 100)  # Different seed per type\n",
    "                n_samples = len(type_indices)\n",
    "                n_train = int(0.8 * n_samples)  # 4:1 ratio\n",
    "                \n",
    "                shuffled_indices = np.random.permutation(type_indices)\n",
    "                train_indices = shuffled_indices[:n_train]\n",
    "                test_indices = shuffled_indices[n_train:]\n",
    "                \n",
    "                final_dataset.loc[train_indices, 'split'] = 'train'\n",
    "                final_dataset.loc[test_indices, 'split'] = 'test'\n",
    "        \n",
    "        print(f\"\\nðŸŽ¯ FINAL DATASET SUMMARY\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Total samples: {len(final_dataset):,}\")\n",
    "        \n",
    "        # Summary by error type\n",
    "        print(f\"\\nBy Error Type:\")\n",
    "        for error_type in ['correct', 'conceptual_error', 'computational_error']:\n",
    "            type_data = final_dataset[final_dataset['error_type'] == error_type]\n",
    "            if len(type_data) > 0:\n",
    "                train_count = len(type_data[type_data['split'] == 'train'])\n",
    "                test_count = len(type_data[type_data['split'] == 'test'])\n",
    "                unique_indices = type_data['index'].nunique()\n",
    "                print(f\"  {error_type}: {len(type_data):,} (train: {train_count:,}, test: {test_count:,}, unique indices: {unique_indices:,})\")\n",
    "        \n",
    "        # Summary by split\n",
    "        print(f\"\\nBy Split:\")\n",
    "        split_counts = final_dataset['split'].value_counts()\n",
    "        for split, count in split_counts.items():\n",
    "            pct = (count / len(final_dataset)) * 100\n",
    "            print(f\"  {split}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        # Summary by tier\n",
    "        print(f\"\\nBy Tier:\")\n",
    "        tier_counts = final_dataset['tier'].value_counts().sort_index()\n",
    "        for tier, count in tier_counts.items():\n",
    "            pct = (count / len(final_dataset)) * 100\n",
    "            print(f\"  {tier}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        # Summary by source\n",
    "        print(f\"\\nBy Source:\")\n",
    "        source_counts = final_dataset['source'].value_counts()\n",
    "        for source, count in source_counts.items():\n",
    "            pct = (count / len(final_dataset)) * 100\n",
    "            print(f\"  {source}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        # Check overlap between error types\n",
    "        conceptual_idx = set(final_dataset[final_dataset['error_type'] == 'conceptual_error']['index'])\n",
    "        computational_idx = set(final_dataset[final_dataset['error_type'] == 'computational_error']['index'])\n",
    "        correct_idx = set(final_dataset[final_dataset['error_type'] == 'correct']['index'])\n",
    "        \n",
    "        print(f\"\\nIndex Overlap Analysis:\")\n",
    "        conceptual_computational_overlap = len(conceptual_idx & computational_idx)\n",
    "        conceptual_correct_overlap = len(conceptual_idx & correct_idx)\n",
    "        computational_correct_overlap = len(computational_idx & correct_idx)\n",
    "        \n",
    "        print(f\"  Conceptual âˆ© Computational: {conceptual_computational_overlap:,} indices\")\n",
    "        print(f\"  Conceptual âˆ© Correct: {conceptual_correct_overlap:,} indices\")\n",
    "        print(f\"  Computational âˆ© Correct: {computational_correct_overlap:,} indices\")\n",
    "        \n",
    "        return final_dataset\n",
    "    else:\n",
    "        print(\"\\nâŒ No samples could be selected!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Create the simplified error detection dataset\n",
    "error_detection_dataset = create_error_detection_dataset_simplified(df)\n",
    "\n",
    "# Save the dataset\n",
    "if not error_detection_dataset.empty:\n",
    "    output_path = AUG_5_DATASET_DIR / \"error_detection_dataset.csv\"\n",
    "    error_detection_dataset.to_csv(output_path, index=False)\n",
    "    print(f\"\\nðŸ’¾ Dataset saved to: {output_path}\")\n",
    "    \n",
    "    # # Save metadata\n",
    "    # metadata = {\n",
    "    #     \"dataset_name\": \"error_detection_dataset_simplified\",\n",
    "    #     \"creation_date\": \"2025-08-05\",\n",
    "    #     \"total_samples\": len(error_detection_dataset),\n",
    "    #     \"N_conceptual\": len(error_detection_dataset[error_detection_dataset['error_type'] == 'conceptual_error']),\n",
    "    #     \"N_computational\": len(error_detection_dataset[error_detection_dataset['error_type'] == 'computational_error']),\n",
    "    #     \"N_correct\": len(error_detection_dataset[error_detection_dataset['error_type'] == 'correct']),\n",
    "    #     \"error_type_distribution\": dict(error_detection_dataset['error_type'].value_counts()),\n",
    "    #     \"split_distribution\": dict(error_detection_dataset['split'].value_counts()),\n",
    "    #     \"tier_distribution\": dict(error_detection_dataset['tier'].value_counts()),\n",
    "    #     \"source_distribution\": dict(error_detection_dataset['source'].value_counts()),\n",
    "    #     \"columns\": list(error_detection_dataset.columns),\n",
    "    #     \"total_unique_indices\": error_detection_dataset['index'].nunique(),\n",
    "    #     \"description\": \"Simplified dataset for error detection: all conceptual + equal computational (distinct) + 2000 correct (following tier priority)\"\n",
    "    # }\n",
    "    \n",
    "    # metadata_path = AUG_5_DATASET_DIR / \"error_detection_metadata.json\"\n",
    "    # with open(metadata_path, 'w') as f:\n",
    "    #     json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    # print(f\"ðŸ’¾ Metadata saved to: {metadata_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Dataset creation failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e6496214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Calculator Annotation Coverage Analysis\n",
      "==================================================\n",
      "Total samples in dataset: 6,067\n",
      "Total samples missing coverage: 1,297\n",
      "Overall coverage rate: 78.6%\n",
      "\n",
      "By Error Type:\n",
      "  conceptual_error:\n",
      "    Total samples: 2,067\n",
      "    With complete coverage: 1,591\n",
      "    Missing coverage: 476\n",
      "    Coverage rate: 77.0%\n",
      "\n",
      "  computational_error:\n",
      "    Total samples: 2,000\n",
      "    With complete coverage: 1,571\n",
      "    Missing coverage: 429\n",
      "    Coverage rate: 78.5%\n",
      "\n",
      "  correct:\n",
      "    Total samples: 2,000\n",
      "    With complete coverage: 1,608\n",
      "    Missing coverage: 392\n",
      "    Coverage rate: 80.4%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_annotation_coverage(dataset_df, verbose=True):\n",
    "    \"\"\"\n",
    "    Check how many samples in the dataset are missing complete calculator annotation coverage.\n",
    "    \n",
    "    Args:\n",
    "        dataset_df: DataFrame containing the dataset to check\n",
    "        verbose: Whether to print detailed breakdown\n",
    "    \n",
    "    Returns:\n",
    "        dict: Summary of annotation coverage statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    def has_complete_annotation_coverage(row, eqn_mapping_col):\n",
    "        \"\"\"Check if all solution lines except FA have calculator annotations.\"\"\"\n",
    "        try:\n",
    "            eqn_mapping = json.loads(row[eqn_mapping_col])\n",
    "            \n",
    "            # Count total lines (excluding FA)\n",
    "            answer_length = row['correct_answer_length'] if 'correct' in eqn_mapping_col else row['wrong_answer_length']\n",
    "            expected_lines = answer_length - 1 if 'FA' in eqn_mapping else answer_length\n",
    "            \n",
    "            # Count non-empty equations (excluding FA)\n",
    "            non_empty_equations = sum(1 for key, value in eqn_mapping.items() \n",
    "                                    if key != 'FA' and value and str(value).strip())\n",
    "            \n",
    "            return non_empty_equations == expected_lines\n",
    "            \n",
    "        except (json.JSONDecodeError, KeyError, TypeError):\n",
    "            return False\n",
    "    \n",
    "    # Initialize results\n",
    "    results = {\n",
    "        'total_samples': len(dataset_df),\n",
    "        'by_error_type': {},\n",
    "        'missing_coverage': {\n",
    "            'total': 0,\n",
    "            'by_error_type': {}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Group by error_type for analysis\n",
    "    for error_type in dataset_df['error_type'].unique():\n",
    "        type_data = dataset_df[dataset_df['error_type'] == error_type]\n",
    "        \n",
    "        # Determine which equation mapping column to use\n",
    "        if error_type == 'correct':\n",
    "            eqn_col = 'correct_eqn_mapping'\n",
    "        else:\n",
    "            eqn_col = 'wrong_eqn_mapping'\n",
    "        \n",
    "        # Check coverage for this error type\n",
    "        has_coverage = type_data.apply(\n",
    "            lambda row: has_complete_annotation_coverage(row, eqn_col), axis=1\n",
    "        )\n",
    "        \n",
    "        # Count missing coverage\n",
    "        missing_count = (~has_coverage).sum()\n",
    "        total_count = len(type_data)\n",
    "        \n",
    "        results['by_error_type'][error_type] = {\n",
    "            'total': total_count,\n",
    "            'with_coverage': has_coverage.sum(),\n",
    "            'missing_coverage': missing_count,\n",
    "            'coverage_rate': has_coverage.sum() / total_count if total_count > 0 else 0\n",
    "        }\n",
    "        \n",
    "        results['missing_coverage']['by_error_type'][error_type] = missing_count\n",
    "        results['missing_coverage']['total'] += missing_count\n",
    "    \n",
    "    # Print results if verbose\n",
    "    if verbose:\n",
    "        print(\"ðŸ” Calculator Annotation Coverage Analysis\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Total samples in dataset: {results['total_samples']:,}\")\n",
    "        print(f\"Total samples missing coverage: {results['missing_coverage']['total']:,}\")\n",
    "        print(f\"Overall coverage rate: {((results['total_samples'] - results['missing_coverage']['total']) / results['total_samples'] * 100):.1f}%\")\n",
    "        print()\n",
    "        \n",
    "        print(\"By Error Type:\")\n",
    "        for error_type, stats in results['by_error_type'].items():\n",
    "            print(f\"  {error_type}:\")\n",
    "            print(f\"    Total samples: {stats['total']:,}\")\n",
    "            print(f\"    With complete coverage: {stats['with_coverage']:,}\")\n",
    "            print(f\"    Missing coverage: {stats['missing_coverage']:,}\")\n",
    "            print(f\"    Coverage rate: {stats['coverage_rate']:.1%}\")\n",
    "            print()\n",
    "    \n",
    "    return results\n",
    "\n",
    "coverage_results = check_annotation_coverage(error_detection_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "037d97dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Filtering error detection dataset for complete annotation coverage...\n",
      "Original dataset size: 6,067 samples\n",
      "  conceptual_error: 1,591 / 2,067 samples have complete coverage (77.0%)\n",
      "  computational_error: 1,571 / 2,000 samples have complete coverage (78.5%)\n",
      "  correct: 1,608 / 2,000 samples have complete coverage (80.4%)\n",
      "\n",
      "Filtered dataset size: 4,770 samples\n",
      "Removed 1,297 samples without complete coverage\n",
      "\n",
      "Final dataset composition:\n",
      "  correct: 1,608 samples\n",
      "  conceptual_error: 1,591 samples\n",
      "  computational_error: 1,571 samples\n"
     ]
    }
   ],
   "source": [
    "def filter_error_detection_dataset_for_coverage(dataset_df):\n",
    "    \"\"\"\n",
    "    Filter error detection dataset to keep only rows with complete calculator annotation coverage.\n",
    "    \n",
    "    Args:\n",
    "        dataset_df: The error detection dataset DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Filtered dataset with only complete coverage samples\n",
    "    \"\"\"\n",
    "    \n",
    "    def has_complete_annotation_coverage(row, eqn_mapping_col):\n",
    "        \"\"\"Check if all solution lines except FA have calculator annotations.\"\"\"\n",
    "        try:\n",
    "            eqn_mapping = json.loads(row[eqn_mapping_col])\n",
    "            \n",
    "            # Count total lines (excluding FA)\n",
    "            answer_length = row['correct_answer_length'] if 'correct' in eqn_mapping_col else row['wrong_answer_length']\n",
    "            expected_lines = answer_length - 1 if 'FA' in eqn_mapping else answer_length\n",
    "            \n",
    "            # Count non-empty equations (excluding FA)\n",
    "            non_empty_equations = sum(1 for key, value in eqn_mapping.items() \n",
    "                                    if key != 'FA' and value and str(value).strip())\n",
    "            \n",
    "            return non_empty_equations == expected_lines\n",
    "            \n",
    "        except (json.JSONDecodeError, KeyError, TypeError):\n",
    "            return False\n",
    "    \n",
    "    print(\"ðŸ” Filtering error detection dataset for complete annotation coverage...\")\n",
    "    print(f\"Original dataset size: {len(dataset_df):,} samples\")\n",
    "    \n",
    "    # Create coverage mask for each error type\n",
    "    coverage_masks = []\n",
    "    \n",
    "    for error_type in dataset_df['error_type'].unique():\n",
    "        type_mask = dataset_df['error_type'] == error_type\n",
    "        type_data = dataset_df[type_mask]\n",
    "        \n",
    "        # Determine which equation mapping column to use\n",
    "        if error_type == 'correct':\n",
    "            eqn_col = 'correct_eqn_mapping'\n",
    "        else:\n",
    "            eqn_col = 'wrong_eqn_mapping'\n",
    "        \n",
    "        # Check coverage for this error type\n",
    "        type_coverage = type_data.apply(\n",
    "            lambda row: has_complete_annotation_coverage(row, eqn_col), axis=1\n",
    "        )\n",
    "        \n",
    "        # Count and report\n",
    "        with_coverage = type_coverage.sum()\n",
    "        total_type = len(type_data)\n",
    "        print(f\"  {error_type}: {with_coverage:,} / {total_type:,} samples have complete coverage ({with_coverage/total_type:.1%})\")\n",
    "        \n",
    "        # Add to overall mask\n",
    "        coverage_masks.append(type_coverage)\n",
    "    \n",
    "    # Combine all coverage masks\n",
    "    full_coverage_mask = pd.concat(coverage_masks, ignore_index=False)\n",
    "    \n",
    "    # Filter the dataset\n",
    "    filtered_dataset = dataset_df[full_coverage_mask].copy()\n",
    "    \n",
    "    print(f\"\\nFiltered dataset size: {len(filtered_dataset):,} samples\")\n",
    "    print(f\"Removed {len(dataset_df) - len(filtered_dataset):,} samples without complete coverage\")\n",
    "    \n",
    "    # Show final composition\n",
    "    print(\"\\nFinal dataset composition:\")\n",
    "    final_counts = filtered_dataset['error_type'].value_counts()\n",
    "    for error_type, count in final_counts.items():\n",
    "        print(f\"  {error_type}: {count:,} samples\")\n",
    "    \n",
    "    return filtered_dataset\n",
    "\n",
    "# Apply the filter to your error detection dataset\n",
    "# Replace 'error_detection_dataset' with your actual variable name\n",
    "error_detection_dataset_filtered = filter_error_detection_dataset_for_coverage(error_detection_dataset)\n",
    "\n",
    "# Optionally, update the original variable\n",
    "# error_detection_dataset = error_detection_dataset_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6ea9ca4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'tier', 'question', 'correct_answer', 'wrong_answer',\n",
       "       'error_type', 'explanation', 'erroneous_line_number', 'erroneous_line',\n",
       "       'erroneous_line_eqn', 'correct_answer_mapping', 'wrong_answer_mapping',\n",
       "       'correct_eqn_mapping', 'wrong_eqn_mapping', 'correct_answer_length',\n",
       "       'wrong_answer_length', 'source', 'error_subtype', 'split'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_detection_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7633987f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Cleaning correct samples...\n",
      "Found 2000 correct samples to clean\n",
      "  Cleaned explanation: 2000 non-null values set to null\n",
      "  Cleaned erroneous_line: 2000 non-null values set to null\n",
      "  Cleaned wrong_answer_mapping: 2000 non-null values set to null\n",
      "  Cleaned wrong_eqn_mapping: 2000 non-null values set to null\n",
      "âœ… Correct samples cleaned\n",
      "\n",
      "ðŸ” Sample correct row after cleanup:\n",
      "explanation: None\n",
      "erroneous_line: None\n",
      "error_line_numeric: None\n"
     ]
    }
   ],
   "source": [
    "# Clean up correct samples - set error-related fields to null\n",
    "print(\"ðŸ§¹ Cleaning correct samples...\")\n",
    "\n",
    "# Identify error-related columns that should be null for correct samples\n",
    "error_columns = [\n",
    "    'explanation', \n",
    "    'erroneous_line', \n",
    "    'error_line_numeric',\n",
    "    'mutation_type',  # if this exists\n",
    "    'wrong_answer_mapping',\n",
    "    'wrong_eqn_mapping'\n",
    "]\n",
    "\n",
    "# Clean correct samples\n",
    "correct_mask = error_detection_dataset['error_type'] == 'correct'\n",
    "print(f\"Found {correct_mask.sum()} correct samples to clean\")\n",
    "\n",
    "for col in error_columns:\n",
    "    if col in error_detection_dataset.columns:\n",
    "        before_count = error_detection_dataset.loc[correct_mask, col].notna().sum()\n",
    "        error_detection_dataset.loc[correct_mask, col] = None\n",
    "        print(f\"  Cleaned {col}: {before_count} non-null values set to null\")\n",
    "\n",
    "print(\"âœ… Correct samples cleaned\")\n",
    "\n",
    "# Verify the cleanup\n",
    "sample_correct = error_detection_dataset[error_detection_dataset['error_type'] == 'correct'].iloc[0]\n",
    "print(\"\\nðŸ” Sample correct row after cleanup:\")\n",
    "print(f\"explanation: {sample_correct.get('explanation')}\")\n",
    "print(f\"erroneous_line: {sample_correct.get('erroneous_line')}\")\n",
    "print(f\"error_line_numeric: {sample_correct.get('error_line_numeric')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
