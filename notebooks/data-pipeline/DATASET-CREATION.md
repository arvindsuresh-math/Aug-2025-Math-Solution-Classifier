# Final Dataset Creation

This document outlines the final phase of our data pipeline, where we aggregate all our error sources into a unified catalog and then sample from it to construct the two specialized datasets used for model fine-tuning.

## 1. The Master Catalog: A Unified Data Source

The first step is to combine our various sources of flawed solutions into a single, standardized **Master Catalog**. This process ensures that all data, regardless of its origin, conforms to a consistent schema, making it easy to sample from.

The master catalog is built by ingesting, cleaning, and standardizing data from the following sources:

* **Programmatic Computational Errors:**
  * **Source:** [`computational_error_catalog.csv`](../../data/error-catalogs/computational_error_catalog.csv)
  * **Description:** This is the largest source, containing over 20,000 fully-automated, high-precision computational errors generated by the pipeline described in `ERROR-INJECTION.md`.

* **Programmatic & Human-Validated Conceptual Errors:**
  * **Source:** The "accepted" entries from the five validator-specific catalogs:
    * [`validation_catalog_ali.csv`](../../data/error-catalogs/validation_catalog_ali.csv)
    * [`validation_catalog_arvind.csv`](../../data/error-catalogs/validation_catalog_arvind.csv)
    * [`validation_catalog_ling.csv`](../../data/error-catalogs/validation_catalog_ling.csv)
    * [`validation_catalog_mauro.csv`](../../data/error-catalogs/validation_catalog_mauro.csv)
    * [`validation_catalog_yewei.csv`](../../data/error-catalogs/validation_catalog_yewei.csv)
  * **Description:** This dataset contains the conceptual error candidates that were approved by our human validation team via the Streamlit application. These are high-quality examples of logical flaws.

* **Manually Generated Errors:**
  * **Source:** [`manually_generated_errors_final.csv`](../../data/error-catalogs/manually_generated_errors_final.csv)
  * **Description:** A smaller, high-quality set of errors that were created manually by team members to cover specific edge cases or error types.

The final, aggregated dataset is saved as the [`master_catalog.csv`](../../data/final-datasets/master_catalog.csv). This catalog serves as the single source of truth for all subsequent dataset creation steps.

## 2. Creating the Error Detection Dataset

The primary goal of the project is to classify solutions. The `error-detection` dataset is built to train the `Phi-4` model for this task. We sample from the `master_catalog` to create a balanced dataset that exposes the model to an equal number of correct, computationally flawed, and conceptually flawed solutions.

The sampling logic is as follows:

1. **Conceptual Errors:** First, we include **all** of the human-validated conceptual errors. These are the most valuable and difficult-to-obtain samples.
2. **Computational Errors:** Next, we sample an **equal number** of computational errors. To maximize the diversity of problems the model sees, we ensure these samples come from GSM8K problems that were *not* used for the conceptual errors.
3. **Correct Solutions:** Finally, we add a balanced number of **correct** solutions, again prioritizing problems that have not yet been used.
4. **Train/Test Split:** The resulting collection of ~6,000 samples is then split into a final training and testing set with an 80/20 ratio, stratified by error type.

This process results in the final [`error_detection_dataset.csv`](../../data/final-datasets/error_detection_dataset.csv), which is used to fine-tune the classification model.

## 3. Creating the Equation Extraction Dataset

The second model in our pipeline, `Gemma-3`, has a much simpler task: to read a single line of text and extract any equation it contains. The dataset for this task is correspondingly simpler and is focused on line-level examples.

It is constructed by sampling three types of lines from our `error_detection_dataset`:

1. **Flawed Lines:** The specific lines containing calculation mistakes from the `computational_error` samples. This teaches the model to transcribe equations literally, even if they are mathematically incorrect (e.g., `2+2=5`).
2. **Correct Lines:** A random selection of lines containing correct calculations, drawn from the `conceptual_error` and `correct` samples.
3. **Lines without Equations (Negative Examples):** Thousands of lines of text from the GSM8K solutions that do not contain any calculations. This is crucial for teaching the model to output nothing (`<eq></eq>`) when no equation is present.

This collection of individual lines is saved as the [`aug_10_eqn_extraction_dataset.csv`](../../data/final-datasets/aug_10_eqn_extraction_dataset.csv) and is used to fine-tune the highly specialized equation extraction model.
