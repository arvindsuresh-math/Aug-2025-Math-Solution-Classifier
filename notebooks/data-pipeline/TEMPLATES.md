# Data Formalization: The Template System

This document explains the "Formalization Template" system, which is the cornerstone of our data generation pipeline. The core idea is to convert unstructured math word problems and their natural language solutions into a highly structured, machine-readable format. This allows us to programmatically analyze, modify, and reconstruct solutions with high precision.

## The Purpose of Templates

Our goal is to create a large dataset of correct and flawed math solutions for training our models. Manually writing thousands of flawed examples is slow, mundane, and boring. A purely automated approach using a single LLM to generate flawed solutions proved unreliable; from our experimentation, it appeared that frontier LLM's like Gemini 2.5 Pro and GPT 4.1 are excellent at generating *correct* solutions, but are not very skilled at generating *realistic and plausibly flawed solutions*.

The template system solves this problem. By first converting a correct solution into a structured template, we create a "scaffold" that separates the solution's logic from its numerical values. Once we have this scaffold, we can programmatically introduce a wide variety of realistic errors by manipulating either the logic or the numbers, and then use the template to reconstruct a new, flawed solution in natural language.

This hybrid approach combines the strengths of LLMs (for the initial, complex task of creating the template) and programmatic logic (for the task of error injection).

### The Tier System: Tailoring Prompts for Precision

Generating a perfect `Formalization Template` is a complex task for an LLM. A simple problem involving only whole numbers requires a different kind of formalization than one involving decimals, fractions, or symbolic algebra.

To improve the quality and consistency of the templates generated by the LLM, we first categorize every problem from the GSM8K dataset into one of five **tiers** based on its mathematical content. This allows us to use more relevant few-shot examples in our prompts. For example, when asking the LLM to formalize a simple integer-based problem, we show it examples of other integer-based problems, not complex algebraic ones.

The five mutually exclusive tiers are defined as follows:

* **Tier 1: Simple Integer Arithmetic**
  * Solutions that use only integers and `+`, `-`, and `*`.

* **Tier 2: Decimal Arithmetic**
  * Solutions that use decimal numbers (floats) but do not contain division.

* **Tier 3: Division with Integers**
  * Solutions that use the division operator but do not involve decimals (so, they may include fractions).

* **Tier 4: Complex Arithmetic**
  * Solutions that involve both decimal numbers and division operations.

* **Tier 5: Symbolic Algebra**
  * Solutions that explicitly use algebraic variables (e.g., "Let x be...").

By grouping problems this way, we ensure that the LLM is guided by examples that closely match the structure of the task it is being asked to perform, leading to more reliable and accurate templates across the entire dataset.

## Anatomy of a Formalization Template

Each template is generated by the `gemini-2.5-flash` model, guided by a detailed prompt and few-shot examples. It consists of two main components: a Python function (`.py`) and a set of logical steps (`.json`).

To illustrate, let's look at how a raw problem is converted into a template.

---

### **Example: From Raw Input to Formalized Template**

#### **Step 1: Original Input (from GSM8K Dataset)**

The process starts with a math problem and its correct, step-by-step solution.

**Question:**
> Lucy plans to purchase potato chips for a party. Ten people will be at the party, including Lucy. The potato chips cost 25 cents per pound. How much will Lucy pay (in dollars) for the potato chips if she wants each person to get 1.2 pounds?

**Original Solution:**
> Lucy needs to purchase 10 x 1.2 = <<10\*1.2=12>>12 pounds of potato chips.\
> So, Lucy will pay 12 x 25 = <<12\*25=300>>300 cents for it.\
> Since there are 100 cents in $1, thus, Lucy will pay 300/100 = <<300/100=3>>3 dollars.\
> \#\#\#\# 3

---

#### **Step 2: Solution Mapping (Intermediate Dictionary)**

The raw solution text is first parsed into a line-numbered dictionary. This structured format is what is actually provided to the LLM as input, making it clear which line corresponds to `L1`, `L2`, etc.

```json
{
  "L1": "Lucy needs to purchase 10 x 1.2 = <<10*1.2=12>>12 pounds of potato chips.",
  "L2": "So, Lucy will pay 12 x 25 = <<12*25=300>>300 cents for it.",
  "L3": "Since there are 100 cents in $1, thus, Lucy will pay 300/100 = <<300/100=3>>3 dollars.",
  "FA": "3"
}
```

---

#### **Step 3: Generated Template**

The LLM processes the question and the solution mapping dictionary from Step 2 to generate the final, two-part template.

**Component A: The `function_code` (`.py` file)**

This is a self-contained Python function, always named `solve()`, that represents the mathematical "computation graph" of the solution. It captures the logic, variables, and calculations.

```python
def solve():
    """Index: 4847.
    Returns: the amount Lucy will pay in dollars.
    """
    # L1
    num_people = 10 # Ten people will be at the party
    chips_per_person = 1.2 # each person to get 1.2 pounds
    total_pounds = num_people * chips_per_person

    # L2
    cents_per_pound = 25 # 25 cents per pound
    total_cents = total_pounds * cents_per_pound

    # L3
    cents_per_dollar = 100 # WK
    total_dollars = total_cents / cents_per_dollar

    # FA
    answer = total_dollars
    return answer
```

**Component B: The `logical_steps` (`.json` file)**

This is a JSON array that connects the `function_code` back to the natural language solution. It contains `solution_line_template`s where all numbers involved in calculations have been replaced by their corresponding `{variable_name}` placeholders. Moreover, each line is associated with two kinds of inputs- `question_inputs` represent variables with values sourced from the question, and which appear in the solution for the first time, and `WK_inputs` represent "world knowledge inputs" (e.g. `cents_per_dollar = 100`).

```json
[
  {
    "line_number": "L1",
    "question_inputs": ["num_people", "chips_per_person"],
    "WK_inputs": [],
    "output_variable": "total_pounds",
    "solution_line_template": "Lucy needs to purchase {num_people} x {chips_per_person} = <<{num_people}*{chips_per_person}={total_pounds}>>{total_pounds} pounds of potato chips."
  },
  {
    "line_number": "L2",
    "question_inputs": ["cents_per_pound"],
    "WK_inputs": [],
    "output_variable": "total_cents",
    "solution_line_template": "So, Lucy will pay {total_pounds} x {cents_per_pound} = <<{total_pounds}*{cents_per_pound}={total_cents}>>{total_cents} cents for it."
  },
  {
    "line_number": "L3",
    "question_inputs": [],
    "WK_inputs": ["cents_per_dollar"],
    "output_variable": "total_dollars",
    "solution_line_template": "Since there are 100 cents in $1, thus, Lucy will pay {total_cents}/{cents_per_dollar} = <<{total_cents}/{cents_per_dollar}={total_dollars}>>{total_dollars} dollars."
  }
]
```

**Template:**
> Lucy needs to purchase `num_people` x `chips_per_person` = <<`num_people`\*`chips_per_person`=`total_pounds`>>`total_pounds` pounds of potato chips.\
> So, Lucy will pay `total_pounds` x `cents_per_pound` = <<`total_pounds`\*`cents_per_pound`=`total_cents`>>`total_cents` cents for it.\
> Since there are `cents_per_dollar` cents in $1, thus, Lucy will pay `total_cents`/`cents_per_dollar` = <<`total_cents`/`cents_per_dollar`=`total_dollars`>>`total_dollars` dollars.\
> \#\#\#\# `total_dollars`

## How Templates Power the Pipeline

The two-part structure of the template is what enables our entire data generation strategy.

1. **Error Injection:** We introduce errors by modifying the `function_code`.
    * For **computational errors**, we might change a `+` to a `-` in the code, or modify a constant value.
    * For **conceptual errors**, we might swap one variable for another (e.g., use `total_pounds` where `total_cents` should have been used).
2. **Trace Generation:** We execute the *modified* `function_code` to generate a new, "flawed trace" of variable values.
3. **Reconstruction:** We then use the *original* `logical_steps` templates and this new flawed trace to perfectly reconstruct a flawed natural language solution. Because we are just filling in the blanks, the resulting text is grammatically correct and flows logically, but contains the subtle error we introduced.

---

## Navigating the Template-Related Directories

The various files and artifacts related to the template generation process are organized within the [`data/`](../data/) directory. The structure is designed to separate the hand-crafted few-shot examples from the LLM-generated templates, and to keep raw source files distinct from processed outputs.

Here is an overview of the key directories:

* **[`data/templates/template-examples-processed/`](../../data/templates/template-examples-processed/)**
    This directory contains the final, hand-curated "gold standard" `Formalization Templates` that are used as few-shot examples in the prompts sent to the LLM. They are organized by tier and then by the problem's original index from the GSM8K dataset. Each folder contains the canonical `solve.py` and `logical_steps.json` files for a given example.

* **[`data/templates/template-examples-raw/`](../../data/templates/template-examples-raw/)**
    This holds the raw source materials used to construct the prompts for each tier.
  * `tier{n}_user_prompt_prefix.txt`: This file contains the detailed instructions and rules that are prepended to every prompt for that tier.
  * `_{index}.json`: The raw, unprocessed JSON for each few-shot example.

* **[`data/template-generated-processed/`](../../data/template-generated-processed/)**
    This is the output directory for the template generation pipeline. It contains the templates generated by the LLM, which have been processed and validated. The structure mirrors the examples, organized by `tier/` -> `{index}/`, with the final files named after the model that generated them (e.g., `google_gemini-2.5-flash.py`).
