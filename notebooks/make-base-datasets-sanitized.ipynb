{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54104716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math\n",
      "Data directory: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data\n",
      "Output directory: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/sft-datasets\n",
      "Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Set, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- Path and Directory Definitions ---\n",
    "def find_project_root(marker: str = \".git\") -> Path:\n",
    "    \"\"\"Traverse upwards to find the project root, marked by the git repository.\"\"\"\n",
    "    current_path = Path.cwd().resolve()\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / marker).exists():\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    raise FileNotFoundError(f\"Could not find project root. Marker '{marker}' not found.\")\n",
    "\n",
    "# --- Global Constants and Paths ---\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "OUTPUT_DIR = DATA_DIR / \"sft-datasets\"\n",
    "\n",
    "# --- Ensure output directory exists ---\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Configuration ---\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Random seed set to: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18f540b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded master catalog with 24,652 records\n",
      "Columns: ['index', 'tier', 'question', 'correct_answer', 'wrong_answer', 'error_type', 'erroneous_line_number', 'explanation', 'error_subtype', 'source', 'solution_length', 'relative_line_position']\n",
      "\n",
      "=== Master Catalog Overview ===\n",
      "Total samples: 24,652\n",
      "Unique indices: 6,777\n",
      "\n",
      "--- Error Type Distribution ---\n",
      "error_type\n",
      "computational_error    22542\n",
      "conceptual_error        2110\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Source Distribution ---\n",
      "source\n",
      "programmatic    22912\n",
      "manual           1740\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Tier Distribution ---\n",
      "tier\n",
      "tier1    11188\n",
      "tier2     3458\n",
      "tier3     8288\n",
      "tier4     1662\n",
      "tier5       56\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Missing Values Check ---\n",
      "index: 0 missing (0.0%)\n",
      "tier: 0 missing (0.0%)\n",
      "question: 0 missing (0.0%)\n",
      "correct_answer: 0 missing (0.0%)\n",
      "wrong_answer: 0 missing (0.0%)\n",
      "error_type: 0 missing (0.0%)\n",
      "source: 0 missing (0.0%)\n",
      "\n",
      "--- Sample Records ---\n",
      "   index   tier                                           question  \\\n",
      "0   1000  tier3  John buys a heating pad for $30.  He uses it 3...   \n",
      "1   1002  tier3  Carmen needs $7 more to have twice the amount ...   \n",
      "2   1003  tier3  Cheryl is signing up for a golf tournament tha...   \n",
      "\n",
      "                                      correct_answer  \\\n",
      "0  He uses it 3*2=6 times\\nSo he pays 30/6=$5\\n##...   \n",
      "1  Jethro has 60/3 = $20.\\nTwice of what Jethro h...   \n",
      "2  If the electricity bill costs $800, and Cheryl...   \n",
      "\n",
      "                                        wrong_answer           error_type  \\\n",
      "0  He uses it 3*2=5 times\\nSo he pays 30/5=$6\\n##...  computational_error   \n",
      "1  Jethro has 60/3 = $20.\\nTwice of what Jethro h...  computational_error   \n",
      "2  If the electricity bill costs $800, and Cheryl...  computational_error   \n",
      "\n",
      "  erroneous_line_number                                        explanation  \\\n",
      "0                    L1  computational error: John uses it 3*2=<<3*2=6>...   \n",
      "1                    L3     computational error: Carmen has $40 - 7 = $33.   \n",
      "2                    L1  computational error: Cheryl pays $800 + $400 =...   \n",
      "\n",
      "  error_subtype  source  solution_length  relative_line_position  \n",
      "0           NaN  manual                3                     0.0  \n",
      "1           NaN  manual                5                     0.5  \n",
      "2           NaN  manual                4                     0.0  \n"
     ]
    }
   ],
   "source": [
    "# Load the master catalog\n",
    "master_catalog_path = DATA_DIR / \"master_catalog_sanitized.csv\"\n",
    "if not master_catalog_path.exists():\n",
    "    raise FileNotFoundError(f\"Master catalog not found: {master_catalog_path}\")\n",
    "\n",
    "master_df = pd.read_csv(master_catalog_path)\n",
    "print(f\"Loaded master catalog with {len(master_df):,} records\")\n",
    "print(f\"Columns: {list(master_df.columns)}\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\n=== Master Catalog Overview ===\")\n",
    "print(f\"Total samples: {len(master_df):,}\")\n",
    "print(f\"Unique indices: {master_df['index'].nunique():,}\")\n",
    "\n",
    "print(\"\\n--- Error Type Distribution ---\")\n",
    "error_type_counts = master_df['error_type'].value_counts()\n",
    "print(error_type_counts)\n",
    "\n",
    "print(\"\\n--- Source Distribution ---\") \n",
    "source_counts = master_df['source'].value_counts()\n",
    "print(source_counts)\n",
    "\n",
    "print(\"\\n--- Tier Distribution ---\")\n",
    "tier_counts = master_df['tier'].value_counts().sort_index()\n",
    "print(tier_counts)\n",
    "\n",
    "# Check for missing values in critical columns\n",
    "critical_columns = ['index', 'tier', 'question', 'correct_answer', 'wrong_answer', 'error_type', 'source']\n",
    "print(\"\\n--- Missing Values Check ---\")\n",
    "for col in critical_columns:\n",
    "    if col in master_df.columns:\n",
    "        missing_count = master_df[col].isna().sum()\n",
    "        print(f\"{col}: {missing_count} missing ({missing_count/len(master_df)*100:.1f}%)\")\n",
    "\n",
    "# Display first few rows to understand structure\n",
    "print(\"\\n--- Sample Records ---\")\n",
    "print(master_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd1195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1881 anchor indices with conceptual errors\n",
      "\n",
      "--- Anchor Indices by Tier ---\n",
      "tier1: 635 problems\n",
      "tier2: 279 problems\n",
      "tier3: 722 problems\n",
      "tier4: 217 problems\n",
      "tier5: 28 problems\n"
     ]
    }
   ],
   "source": [
    "def get_anchor_indices(master_df):\n",
    "    \"\"\"\n",
    "    Get the anchor indices (set A) - problems that have conceptual errors.\n",
    "    These will be the core problems used in both 3N and 4N datasets.\n",
    "    \"\"\"\n",
    "    # Get all indices that have conceptual errors\n",
    "    conceptual_indices = master_df[\n",
    "        master_df['error_type'] == 'conceptual_error'\n",
    "    ]['index'].unique()\n",
    "    \n",
    "    anchor_indices = sorted(conceptual_indices)\n",
    "    print(f\"Found {len(anchor_indices)} anchor indices with conceptual errors\")\n",
    "    \n",
    "    # Verify we have sufficient coverage across tiers\n",
    "    anchor_df = master_df[master_df['index'].isin(anchor_indices)]\n",
    "    anchor_tier_dist = anchor_df.groupby('index')['tier'].first().value_counts().sort_index()\n",
    "    \n",
    "    print(\"\\n--- Anchor Indices by Tier ---\")\n",
    "    for tier, count in anchor_tier_dist.items():\n",
    "        print(f\"{tier}: {count} problems\")\n",
    "    \n",
    "    return anchor_indices\n",
    "\n",
    "anchor_indices = get_anchor_indices(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d48c5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Coverage Analysis for Anchor Indices ===\n",
      "Total anchor indices: 1881\n",
      "Indices with correct samples: 1881 (all indices have correct answers)\n",
      "Indices with conceptual errors: 1881\n",
      "Indices with computational errors: 1773\n",
      "Indices with complete triplets: 1773\n",
      "Indices missing computational errors: 108\n",
      "\n",
      "--- Missing Computational Errors by Tier ---\n",
      "tier1: 13\n",
      "tier2: 6\n",
      "tier3: 58\n",
      "tier4: 20\n",
      "tier5: 11\n"
     ]
    }
   ],
   "source": [
    "def analyze_anchor_coverage(master_df, anchor_indices):\n",
    "    \"\"\"\n",
    "    Analyze what types of samples we have for each anchor index.\n",
    "    Note: Every index has a correct answer available via the correct_answer column,\n",
    "    so we only need to check for error types.\n",
    "    \"\"\"\n",
    "    coverage_analysis = []\n",
    "    \n",
    "    for idx in anchor_indices:\n",
    "        idx_samples = master_df[master_df['index'] == idx]\n",
    "        \n",
    "        # Check what error types we have for this index\n",
    "        available_types = set(idx_samples['error_type'].unique())\n",
    "        \n",
    "        # Get tier (should be consistent for same index)\n",
    "        tier = idx_samples['tier'].iloc[0]\n",
    "        \n",
    "        analysis = {\n",
    "            'index': idx,\n",
    "            'tier': tier,\n",
    "            'total_samples': len(idx_samples),\n",
    "            'has_correct': True,  # Every index has correct answer via correct_answer column\n",
    "            'has_conceptual': 'conceptual_error' in available_types,\n",
    "            'has_computational': 'computational_error' in available_types,\n",
    "            'available_types': available_types,\n",
    "            'manual_sources': len(idx_samples[idx_samples['source'] == 'manual']),\n",
    "            'programmatic_sources': len(idx_samples[idx_samples['source'] == 'programmatic'])\n",
    "        }\n",
    "        \n",
    "        coverage_analysis.append(analysis)\n",
    "    \n",
    "    coverage_df = pd.DataFrame(coverage_analysis)\n",
    "    \n",
    "    print(\"=== Coverage Analysis for Anchor Indices ===\")\n",
    "    print(f\"Total anchor indices: {len(coverage_df)}\")\n",
    "    print(f\"Indices with correct samples: {coverage_df['has_correct'].sum()} (all indices have correct answers)\")\n",
    "    print(f\"Indices with conceptual errors: {coverage_df['has_conceptual'].sum()}\")\n",
    "    print(f\"Indices with computational errors: {coverage_df['has_computational'].sum()}\")\n",
    "    \n",
    "    # Indices that can form complete triplets (correct + conceptual + computational)\n",
    "    complete_triplets = coverage_df[\n",
    "        coverage_df['has_correct'] & \n",
    "        coverage_df['has_conceptual'] & \n",
    "        coverage_df['has_computational']\n",
    "    ]\n",
    "    print(f\"Indices with complete triplets: {len(complete_triplets)}\")\n",
    "    \n",
    "    # Indices missing computational errors\n",
    "    missing_computational = coverage_df[\n",
    "        coverage_df['has_correct'] & \n",
    "        coverage_df['has_conceptual'] & \n",
    "        ~coverage_df['has_computational']\n",
    "    ]\n",
    "    print(f\"Indices missing computational errors: {len(missing_computational)}\")\n",
    "    \n",
    "    if len(missing_computational) > 0:\n",
    "        print(\"\\n--- Missing Computational Errors by Tier ---\")\n",
    "        missing_by_tier = missing_computational['tier'].value_counts().sort_index()\n",
    "        for tier, count in missing_by_tier.items():\n",
    "            print(f\"{tier}: {count}\")\n",
    "    \n",
    "    return coverage_df\n",
    "\n",
    "coverage_df = analyze_anchor_coverage(master_df, anchor_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cd72fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Creating 3N Dataset (Requires Complete Triplets) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a7cebb25ff42dcbd4963382daf2ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing anchor indices:   0%|          | 0/1881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed: 1773 indices\n",
      "Failed to process: 108 indices (missing computational errors)\n",
      "Total samples in 3N dataset: 5319\n",
      "\n",
      "--- 3N Dataset Composition ---\n",
      "computational_error: 1773\n",
      "conceptual_error: 1773\n",
      "correct: 1773\n",
      "✓ Perfect balance: True (expected 1773 per type)\n",
      "\n",
      "--- 3N Dataset by Source ---\n",
      "programmatic: 2226\n",
      "gsm8k: 1773\n",
      "manual: 1320\n",
      "\n",
      "--- 3N Dataset by Tier ---\n",
      "tier1: 1866\n",
      "tier2: 819\n",
      "tier3: 1992\n",
      "tier4: 591\n",
      "tier5: 51\n"
     ]
    }
   ],
   "source": [
    "def create_3N_dataset_simplified(master_df, anchor_indices, coverage_df):\n",
    "    \"\"\"\n",
    "    Create the 3N dataset using only anchor indices that have BOTH conceptual and computational errors.\n",
    "    For each qualifying anchor index, include: correct (from correct_answer), conceptual_error, computational_error\n",
    "    \"\"\"\n",
    "    print(\"=== Creating 3N Dataset (Requires Complete Triplets) ===\")\n",
    "    \n",
    "    dataset_3N = []\n",
    "    successful_indices = []\n",
    "    failed_indices = []\n",
    "    \n",
    "    for idx in tqdm(anchor_indices, desc=\"Processing anchor indices\"):\n",
    "        idx_samples = master_df[master_df['index'] == idx]\n",
    "        \n",
    "        # Get the coverage info for this index\n",
    "        idx_coverage = coverage_df[coverage_df['index'] == idx].iloc[0]\n",
    "        \n",
    "        # Skip if we don't have both conceptual and computational errors\n",
    "        if not (idx_coverage['has_conceptual'] and idx_coverage['has_computational']):\n",
    "            failed_indices.append(idx)\n",
    "            continue\n",
    "        \n",
    "        # Get a representative sample for basic info (question, tier, etc.)\n",
    "        base_sample = idx_samples.iloc[0]\n",
    "        \n",
    "        # 1. Create correct sample using correct_answer column\n",
    "        correct_sample = base_sample.copy()\n",
    "        correct_sample['wrong_answer'] = correct_sample['correct_answer']\n",
    "        correct_sample['error_type'] = 'correct'\n",
    "        correct_sample['erroneous_line_number'] = None\n",
    "        correct_sample['explanation'] = None\n",
    "        correct_sample['error_subtype'] = None\n",
    "        correct_sample['source'] = 'gsm8k'\n",
    "        dataset_3N.append(correct_sample)\n",
    "        \n",
    "        # 2. Add conceptual error sample (exclude any with error_type='correct')\n",
    "        conceptual_samples = idx_samples[\n",
    "            (idx_samples['error_type'] == 'conceptual_error') & \n",
    "            (idx_samples['error_type'] != 'correct')\n",
    "        ]\n",
    "        manual_conceptual = conceptual_samples[conceptual_samples['source'] == 'manual']\n",
    "        if len(manual_conceptual) > 0:\n",
    "            conceptual_sample = manual_conceptual.iloc[0].copy()\n",
    "        else:\n",
    "            conceptual_sample = conceptual_samples.iloc[0].copy()\n",
    "        dataset_3N.append(conceptual_sample)\n",
    "        \n",
    "        # 3. Add computational error sample (exclude any with error_type='correct')\n",
    "        computational_samples = idx_samples[\n",
    "            (idx_samples['error_type'] == 'computational_error') & \n",
    "            (idx_samples['error_type'] != 'correct')\n",
    "        ]\n",
    "        manual_computational = computational_samples[computational_samples['source'] == 'manual']\n",
    "        if len(manual_computational) > 0:\n",
    "            computational_sample = manual_computational.iloc[0].copy()\n",
    "        else:\n",
    "            computational_sample = computational_samples.iloc[0].copy()\n",
    "        dataset_3N.append(computational_sample)\n",
    "        \n",
    "        successful_indices.append(idx)\n",
    "    \n",
    "    dataset_3N_df = pd.DataFrame(dataset_3N)\n",
    "    \n",
    "    # Sort by index first, then by error_type\n",
    "    dataset_3N_df = dataset_3N_df.sort_values(['index', 'error_type']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Successfully processed: {len(successful_indices)} indices\")\n",
    "    print(f\"Failed to process: {len(failed_indices)} indices (missing computational errors)\")\n",
    "    print(f\"Total samples in 3N dataset: {len(dataset_3N_df)}\")\n",
    "    \n",
    "    # Verify perfect balance\n",
    "    if len(dataset_3N_df) > 0:\n",
    "        print(\"\\n--- 3N Dataset Composition ---\")\n",
    "        error_type_dist = dataset_3N_df['error_type'].value_counts()\n",
    "        for error_type, count in error_type_dist.items():\n",
    "            print(f\"{error_type}: {count}\")\n",
    "        \n",
    "        # Check if perfectly balanced\n",
    "        n_indices = len(successful_indices)\n",
    "        expected_per_type = n_indices\n",
    "        counts_list = list(error_type_dist.values)\n",
    "        is_balanced = all(count == expected_per_type for count in counts_list)\n",
    "        print(f\"✓ Perfect balance: {is_balanced} (expected {expected_per_type} per type)\")\n",
    "        \n",
    "        print(\"\\n--- 3N Dataset by Source ---\")\n",
    "        source_dist = dataset_3N_df['source'].value_counts()\n",
    "        for source, count in source_dist.items():\n",
    "            print(f\"{source}: {count}\")\n",
    "        \n",
    "        print(\"\\n--- 3N Dataset by Tier ---\")\n",
    "        tier_dist = dataset_3N_df['tier'].value_counts().sort_index()\n",
    "        for tier, count in tier_dist.items():\n",
    "            print(f\"{tier}: {count}\")\n",
    "    \n",
    "    return dataset_3N_df, successful_indices, failed_indices\n",
    "\n",
    "dataset_3N_df, successful_3N_indices, failed_3N_indices = create_3N_dataset_simplified(\n",
    "    master_df, anchor_indices, coverage_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c71c2169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Creating 4N Dataset (Larger Version) ===\n",
      "Set A size: 1881 (all anchor indices)\n",
      "=== Selecting Disjoint Set B (target size: 1881) ===\n",
      "Candidate B indices with computational errors: 4896\n",
      "Valid B candidates: 4896\n",
      "Selected 722 from tier3 (target: 722, available: 2046)\n",
      "Selected 635 from tier1 (target: 635, available: 2036)\n",
      "Selected 279 from tier2 (target: 279, available: 535)\n",
      "Selected 217 from tier4 (target: 217, available: 269)\n",
      "Selected 10 from tier5 (target: 28, available: 10)\n",
      "Added 18 additional indices to reach target size\n",
      "Final set B size: 1881\n",
      "\n",
      "Processing Set A (1881 indices)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff79d450c6942eabbb8badb3b25a673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Set A:   0%|          | 0/1881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Set B (1881 indices)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5681f0083db4bee9b5d4ee95de1d00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Set B:   0%|          | 0/1881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples in 4N dataset: 7524\n",
      "\n",
      "--- 4N Dataset Composition ---\n",
      "correct: 3762\n",
      "conceptual_error: 1881\n",
      "computational_error: 1881\n",
      "\n",
      "--- 4N Dataset by Source ---\n",
      "gsm8k: 3762\n",
      "programmatic: 2680\n",
      "manual: 1082\n",
      "\n",
      "--- 4N Dataset by Tier ---\n",
      "tier1: 2562\n",
      "tier2: 1120\n",
      "tier3: 2898\n",
      "tier4: 868\n",
      "tier5: 76\n",
      "\n",
      "--- Set Distribution ---\n",
      "Set A samples: 3762\n",
      "Set B samples: 3762\n",
      "\n",
      "--- Expected vs Actual ---\n",
      "Expected: correct=3762, conceptual=1881, computational=1881\n",
      "Actual: correct=3762, conceptual=1881, computational=1881\n"
     ]
    }
   ],
   "source": [
    "def select_disjoint_set_B(master_df, anchor_indices, target_size):\n",
    "    \"\"\"\n",
    "    Select a disjoint set B of indices that:\n",
    "    1. Are not in anchor_indices (set A)\n",
    "    2. Have computational errors available\n",
    "    3. Have the same size as the successful anchor indices\n",
    "    \"\"\"\n",
    "    print(f\"=== Selecting Disjoint Set B (target size: {target_size}) ===\")\n",
    "    \n",
    "    # Get all indices that are NOT in anchor_indices and have computational errors\n",
    "    all_computational_indices = master_df[\n",
    "        master_df['error_type'] == 'computational_error'\n",
    "    ]['index'].unique()\n",
    "    \n",
    "    candidate_B_indices = [\n",
    "        idx for idx in all_computational_indices \n",
    "        if idx not in anchor_indices\n",
    "    ]\n",
    "    \n",
    "    print(f\"Candidate B indices with computational errors: {len(candidate_B_indices)}\")\n",
    "    \n",
    "    # Check coverage for candidate B indices\n",
    "    B_coverage = []\n",
    "    for idx in candidate_B_indices:\n",
    "        idx_samples = master_df[master_df['index'] == idx]\n",
    "        available_types = set(idx_samples['error_type'].unique())\n",
    "        tier = idx_samples['tier'].iloc[0]\n",
    "        \n",
    "        # For set B, we need: correct answer (from GSM8K) + computational error\n",
    "        # The correct answer is always available from GSM8K, so just check computational\n",
    "        has_computational = 'computational_error' in available_types\n",
    "        \n",
    "        if has_computational:\n",
    "            B_coverage.append({\n",
    "                'index': idx,\n",
    "                'tier': tier,\n",
    "                'has_computational': has_computational\n",
    "            })\n",
    "    \n",
    "    B_coverage_df = pd.DataFrame(B_coverage)\n",
    "    \n",
    "    print(f\"Valid B candidates: {len(B_coverage_df)}\")\n",
    "    \n",
    "    if len(B_coverage_df) < target_size:\n",
    "        print(f\"WARNING: Only {len(B_coverage_df)} valid B candidates, but need {target_size}\")\n",
    "        target_size = len(B_coverage_df)\n",
    "    \n",
    "    # Sample to maintain tier distribution similar to set A\n",
    "    A_tier_dist = master_df[master_df['index'].isin(anchor_indices)].groupby('index')['tier'].first().value_counts(normalize=True)\n",
    "    \n",
    "    selected_B_indices = []\n",
    "    \n",
    "    # Try to maintain proportional tier distribution\n",
    "    for tier in A_tier_dist.index:\n",
    "        tier_candidates = B_coverage_df[B_coverage_df['tier'] == tier]['index'].tolist()\n",
    "        tier_target = int(A_tier_dist[tier] * target_size)\n",
    "        tier_selected = min(tier_target, len(tier_candidates))\n",
    "        \n",
    "        if tier_selected > 0:\n",
    "            tier_sample = random.sample(tier_candidates, tier_selected)\n",
    "            selected_B_indices.extend(tier_sample)\n",
    "            print(f\"Selected {tier_selected} from {tier} (target: {tier_target}, available: {len(tier_candidates)})\")\n",
    "    \n",
    "    # Fill remaining slots if needed\n",
    "    remaining_needed = target_size - len(selected_B_indices)\n",
    "    if remaining_needed > 0:\n",
    "        remaining_candidates = [\n",
    "            idx for idx in B_coverage_df['index'].tolist() \n",
    "            if idx not in selected_B_indices\n",
    "        ]\n",
    "        if len(remaining_candidates) >= remaining_needed:\n",
    "            additional_selected = random.sample(remaining_candidates, remaining_needed)\n",
    "            selected_B_indices.extend(additional_selected)\n",
    "            print(f\"Added {remaining_needed} additional indices to reach target size\")\n",
    "    \n",
    "    print(f\"Final set B size: {len(selected_B_indices)}\")\n",
    "    return selected_B_indices[:target_size]\n",
    "\n",
    "def create_4N_dataset_larger(master_df, anchor_indices):\n",
    "    \"\"\"\n",
    "    Create the 4N dataset using:\n",
    "    - Set A (all anchor indices with conceptual errors): correct + conceptual_error samples  \n",
    "    - Set B (disjoint set with computational errors): correct + computational_error samples\n",
    "    \"\"\"\n",
    "    print(\"=== Creating 4N Dataset (Larger Version) ===\")\n",
    "    \n",
    "    # Set A: ALL anchor indices (since they all have conceptual errors by definition)\n",
    "    set_A_indices = anchor_indices.copy()\n",
    "    print(f\"Set A size: {len(set_A_indices)} (all anchor indices)\")\n",
    "    \n",
    "    # Select disjoint set B with same size as set A\n",
    "    set_B_indices = select_disjoint_set_B(master_df, anchor_indices, len(set_A_indices))\n",
    "    \n",
    "    dataset_4N = []\n",
    "    \n",
    "    # Add samples from Set A (correct + conceptual_error)\n",
    "    print(f\"\\nProcessing Set A ({len(set_A_indices)} indices)...\")\n",
    "    for idx in tqdm(set_A_indices, desc=\"Set A\"):\n",
    "        idx_samples = master_df[master_df['index'] == idx]\n",
    "        base_sample = idx_samples.iloc[0]\n",
    "        \n",
    "        # Add correct sample (created from correct_answer column)\n",
    "        correct_sample = base_sample.copy()\n",
    "        correct_sample['wrong_answer'] = correct_sample['correct_answer']\n",
    "        correct_sample['error_type'] = 'correct'\n",
    "        correct_sample['erroneous_line_number'] = None\n",
    "        correct_sample['explanation'] = None\n",
    "        correct_sample['error_subtype'] = None\n",
    "        correct_sample['source'] = 'gsm8k'\n",
    "        dataset_4N.append(correct_sample)\n",
    "        \n",
    "        # Add conceptual error sample (exclude any with error_type='correct')\n",
    "        conceptual_samples = idx_samples[\n",
    "            (idx_samples['error_type'] == 'conceptual_error') & \n",
    "            (idx_samples['error_type'] != 'correct')\n",
    "        ]\n",
    "        if len(conceptual_samples) > 0:\n",
    "            manual_conceptual = conceptual_samples[conceptual_samples['source'] == 'manual']\n",
    "            if len(manual_conceptual) > 0:\n",
    "                conceptual_sample = manual_conceptual.iloc[0].copy()\n",
    "            else:\n",
    "                conceptual_sample = conceptual_samples.iloc[0].copy()\n",
    "            dataset_4N.append(conceptual_sample)\n",
    "        else:\n",
    "            print(f\"WARNING: No conceptual error found for anchor index {idx}\")\n",
    "    \n",
    "    # Add samples from Set B (correct + computational_error)\n",
    "    print(f\"\\nProcessing Set B ({len(set_B_indices)} indices)...\")\n",
    "    for idx in tqdm(set_B_indices, desc=\"Set B\"):\n",
    "        idx_samples = master_df[master_df['index'] == idx]\n",
    "        base_sample = idx_samples.iloc[0]\n",
    "        \n",
    "        # Add correct sample (created from correct_answer column)\n",
    "        correct_sample = base_sample.copy()\n",
    "        correct_sample['wrong_answer'] = correct_sample['correct_answer']\n",
    "        correct_sample['error_type'] = 'correct'\n",
    "        correct_sample['erroneous_line_number'] = None\n",
    "        correct_sample['explanation'] = None\n",
    "        correct_sample['error_subtype'] = None\n",
    "        correct_sample['source'] = 'gsm8k'\n",
    "        dataset_4N.append(correct_sample)\n",
    "        \n",
    "        # Add computational error sample (exclude any with error_type='correct')\n",
    "        computational_samples = idx_samples[\n",
    "            (idx_samples['error_type'] == 'computational_error') & \n",
    "            (idx_samples['error_type'] != 'correct')\n",
    "        ]\n",
    "        if len(computational_samples) > 0:\n",
    "            manual_computational = computational_samples[computational_samples['source'] == 'manual']\n",
    "            if len(manual_computational) > 0:\n",
    "                computational_sample = manual_computational.iloc[0].copy()\n",
    "            else:\n",
    "                computational_sample = computational_samples.iloc[0].copy()\n",
    "            dataset_4N.append(computational_sample)\n",
    "        else:\n",
    "            print(f\"WARNING: No computational error found for set B index {idx}\")\n",
    "    \n",
    "    dataset_4N_df = pd.DataFrame(dataset_4N)\n",
    "    \n",
    "    # Sort by index first, then by error_type\n",
    "    dataset_4N_df = dataset_4N_df.sort_values(['index', 'error_type']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\nTotal samples in 4N dataset: {len(dataset_4N_df)}\")\n",
    "    \n",
    "    # Verify composition\n",
    "    if len(dataset_4N_df) > 0:\n",
    "        print(\"\\n--- 4N Dataset Composition ---\")\n",
    "        error_type_dist = dataset_4N_df['error_type'].value_counts()\n",
    "        for error_type, count in error_type_dist.items():\n",
    "            print(f\"{error_type}: {count}\")\n",
    "        \n",
    "        print(\"\\n--- 4N Dataset by Source ---\")\n",
    "        source_dist = dataset_4N_df['source'].value_counts()\n",
    "        for source, count in source_dist.items():\n",
    "            print(f\"{source}: {count}\")\n",
    "        \n",
    "        print(\"\\n--- 4N Dataset by Tier ---\")\n",
    "        tier_dist = dataset_4N_df['tier'].value_counts().sort_index()\n",
    "        for tier, count in tier_dist.items():\n",
    "            print(f\"{tier}: {count}\")\n",
    "        \n",
    "        # Check balance between sets\n",
    "        print(f\"\\n--- Set Distribution ---\")\n",
    "        set_A_samples = dataset_4N_df[dataset_4N_df['index'].isin(set_A_indices)]\n",
    "        set_B_samples = dataset_4N_df[dataset_4N_df['index'].isin(set_B_indices)]\n",
    "        print(f\"Set A samples: {len(set_A_samples)}\")\n",
    "        print(f\"Set B samples: {len(set_B_samples)}\")\n",
    "        \n",
    "        # Expected composition\n",
    "        expected_correct = len(set_A_indices) + len(set_B_indices)\n",
    "        expected_conceptual = len(set_A_indices)\n",
    "        expected_computational = len(set_B_indices)\n",
    "        \n",
    "        print(f\"\\n--- Expected vs Actual ---\")\n",
    "        print(f\"Expected: correct={expected_correct}, conceptual={expected_conceptual}, computational={expected_computational}\")\n",
    "        print(f\"Actual: correct={error_type_dist.get('correct', 0)}, conceptual={error_type_dist.get('conceptual_error', 0)}, computational={error_type_dist.get('computational_error', 0)}\")\n",
    "    \n",
    "    return dataset_4N_df, set_A_indices, set_B_indices\n",
    "\n",
    "dataset_4N_df, set_A_indices, set_B_indices = create_4N_dataset_larger(master_df, anchor_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "896640a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Saving Base Datasets ===\n",
      "✓ 3N dataset saved to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/base-datasets-sanitized/base_3N_dataset_sanitized.csv\n",
      "  Size: 5,319 samples\n",
      "  Unique indices: 1,773\n",
      "✓ 4N dataset saved to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/base-datasets-sanitized/base_4N_dataset_sanitized.csv\n",
      "  Size: 7,524 samples\n",
      "  Unique indices: 3,762\n",
      "✓ Metadata saved to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/base-datasets-sanitized/base_datasets_sanitized_metadata.json\n",
      "✓ README saved to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/base-datasets-sanitized/README.md\n",
      "\n",
      "📁 All files saved to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/base-datasets-sanitized\n"
     ]
    }
   ],
   "source": [
    "def save_base_datasets(dataset_3N_df, dataset_4N_df, output_dir):\n",
    "    \"\"\"\n",
    "    Save the 3N and 4N base datasets to CSV files with metadata.\n",
    "    \"\"\"\n",
    "    print(\"=== Saving Base Datasets ===\")\n",
    "    \n",
    "    # Create base-datasets directory\n",
    "    base_datasets_dir = output_dir / \"base-datasets-sanitized\"\n",
    "    base_datasets_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save 3N dataset\n",
    "    output_3N_path = base_datasets_dir / \"base_3N_dataset_sanitized.csv\"\n",
    "    dataset_3N_df.to_csv(output_3N_path, index=False)\n",
    "    print(f\"✓ 3N dataset saved to: {output_3N_path}\")\n",
    "    print(f\"  Size: {len(dataset_3N_df):,} samples\")\n",
    "    print(f\"  Unique indices: {dataset_3N_df['index'].nunique():,}\")\n",
    "    \n",
    "    # Save 4N dataset  \n",
    "    output_4N_path = base_datasets_dir / \"base_4N_dataset_sanitized.csv\"\n",
    "    dataset_4N_df.to_csv(output_4N_path, index=False)\n",
    "    print(f\"✓ 4N dataset saved to: {output_4N_path}\")\n",
    "    print(f\"  Size: {len(dataset_4N_df):,} samples\")\n",
    "    print(f\"  Unique indices: {dataset_4N_df['index'].nunique():,}\")\n",
    "    \n",
    "    # Create comprehensive metadata\n",
    "    metadata = {\n",
    "        \"creation_info\": {\n",
    "            \"creation_date\": pd.Timestamp.now().isoformat(),\n",
    "            \"random_seed\": RANDOM_SEED,\n",
    "            \"source_catalog\": \"master_catalog.csv\",\n",
    "            \"creator\": \"make-base-datasets.ipynb\"\n",
    "        },\n",
    "        \"datasets\": {\n",
    "            \"base_3N_dataset.csv\": {\n",
    "                \"description\": \"3N strategy: Requires complete triplets (correct + conceptual_error + computational_error) for each problem\",\n",
    "                \"strategy\": \"ternary_balanced\",\n",
    "                \"total_samples\": len(dataset_3N_df),\n",
    "                \"unique_problems\": dataset_3N_df['index'].nunique(),\n",
    "                \"samples_per_problem\": 3,\n",
    "                \"composition\": dict(dataset_3N_df['error_type'].value_counts()),\n",
    "                \"source_distribution\": dict(dataset_3N_df['source'].value_counts()),\n",
    "                \"tier_distribution\": dict(dataset_3N_df['tier'].value_counts()),\n",
    "                \"anchor_indices_used\": len(successful_3N_indices),\n",
    "                \"anchor_indices_failed\": len(failed_3N_indices)\n",
    "            },\n",
    "            \"base_4N_dataset.csv\": {\n",
    "                \"description\": \"4N strategy: Set A (conceptual errors) + Set B (computational errors), each with correct samples\",\n",
    "                \"strategy\": \"binary_balanced\", \n",
    "                \"total_samples\": len(dataset_4N_df),\n",
    "                \"unique_problems\": dataset_4N_df['index'].nunique(),\n",
    "                \"samples_per_problem\": 2,\n",
    "                \"composition\": dict(dataset_4N_df['error_type'].value_counts()),\n",
    "                \"source_distribution\": dict(dataset_4N_df['source'].value_counts()),\n",
    "                \"tier_distribution\": dict(dataset_4N_df['tier'].value_counts()),\n",
    "                \"set_A_size\": len(set_A_indices),\n",
    "                \"set_B_size\": len(set_B_indices),\n",
    "                \"sets_disjoint\": len(set(set_A_indices) & set(set_B_indices)) == 0\n",
    "            }\n",
    "        },\n",
    "        \"usage_notes\": {\n",
    "            \"for_colab\": \"These datasets are designed for Google Colab experiments\",\n",
    "            \"columns\": list(dataset_3N_df.columns),\n",
    "            \"correct_samples\": \"Created from correct_answer column, marked with source='gsm8k'\",\n",
    "            \"error_samples\": \"From master catalog, prioritizing manual > programmatic sources\",\n",
    "            \"formatting\": \"Ready for direct use in experiment pipeline notebooks\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata_path = base_datasets_dir / \"base_datasets_sanitized_metadata.json\"\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2, default=str)\n",
    "    print(f\"✓ Metadata saved to: {metadata_path}\")\n",
    "    \n",
    "    # Create a README file for the datasets\n",
    "    readme_content = f\"\"\"# Base Datasets for SFT Experiments\n",
    "\n",
    "Created on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Random seed: {RANDOM_SEED}\n",
    "\n",
    "## Dataset Files\n",
    "\n",
    "### base_3N_dataset_sanitized.csv\n",
    "- **Strategy**: Ternary classification (3N)\n",
    "- **Samples**: {len(dataset_3N_df):,} total ({dataset_3N_df['index'].nunique():,} unique problems × 3 samples each)\n",
    "- **Structure**: Each problem has exactly 3 samples: correct, conceptual_error, computational_error\n",
    "- **Use case**: Ternary classification experiments (correct vs conceptual_error vs computational_error)\n",
    "\n",
    "### base_4N_dataset_sanitized.csv\n",
    "- **Strategy**: Binary classification (4N)\n",
    "- **Samples**: {len(dataset_4N_df):,} total ({dataset_4N_df['index'].nunique():,} unique problems × 2 samples each)\n",
    "- **Structure**: \n",
    "  - Set A ({len(set_A_indices):,} problems): correct + conceptual_error\n",
    "  - Set B ({len(set_B_indices):,} problems): correct + computational_error\n",
    "- **Use case**: Binary classification experiments (correct vs flawed)\n",
    "\n",
    "## Column Descriptions\n",
    "\n",
    "- `index`: GSM8K problem index\n",
    "- `tier`: Problem difficulty tier (tier1-tier4)\n",
    "- `question`: Problem statement\n",
    "- `correct_answer`: Correct solution from GSM8K\n",
    "- `wrong_answer`: Solution text (correct for 'correct' samples, flawed for error samples)\n",
    "- `error_type`: 'correct', 'conceptual_error', or 'computational_error'\n",
    "- `erroneous_line_number`: Line number where error occurs (null for correct samples)\n",
    "- `explanation`: Error explanation (null for correct samples)\n",
    "- `error_subtype`: Specific error subtype (null for correct samples)\n",
    "- `source`: 'gsm8k' (correct samples), 'manual', or 'programmatic'\n",
    "- `solution_length`: Number of solution lines\n",
    "- `relative_line_position`: Position of error relative to solution length\n",
    "\n",
    "## Usage in Colab\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "df_3N = pd.read_csv('base_3N_dataset_sanitized.csv')\n",
    "df_4N = pd.read_csv('base_4N_dataset_sanitized.csv')\n",
    "\n",
    "# Verify structure\n",
    "print(\"3N dataset composition:\")\n",
    "print(df_3N['error_type'].value_counts())\n",
    "\n",
    "print(\"4N dataset composition:\")  \n",
    "print(df_4N['error_type'].value_counts())\n",
    "```\n",
    "\"\"\"\n",
    "    \n",
    "    readme_path = base_datasets_dir / \"README.md\"\n",
    "    with open(readme_path, 'w') as f:\n",
    "        f.write(readme_content)\n",
    "    print(f\"✓ README saved to: {readme_path}\")\n",
    "    \n",
    "    return base_datasets_dir\n",
    "\n",
    "# Call the function\n",
    "base_datasets_dir = save_base_datasets(dataset_3N_df, dataset_4N_df, DATA_DIR)\n",
    "print(f\"\\n📁 All files saved to: {base_datasets_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
