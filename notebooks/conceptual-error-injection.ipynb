{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c68369f",
   "metadata": {},
   "source": [
    "# Conceptual Error Candidate Generation\n",
    "\n",
    "This notebook contains the end-to-end pipeline for generating conceptual error \"candidates\" from validated `Formalization Templates`. The process involves programmatically applying logical mutations to the Abstract Syntax Tree (AST) of the correct `function_code`, executing the mutated code to generate a flawed numerical trace, and then packaging all relevant information for a human-in-the-loop validation and annotation stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e26a2ad",
   "metadata": {},
   "source": [
    "#### **Cell 1: Imports and Setup**\n",
    "*   **Functionality:** Standard project setup.\n",
    "*   **Logic:**\n",
    "    *   Imports necessary libraries (`json`, `ast`, `pathlib`, etc.).\n",
    "    *   Defines a robust `find_project_root` function to make path definitions portable.\n",
    "    *   Sets up key `Path` objects for input (`PROCESSED_TEMPLATE_DIR`) and output (`CONCEPTUAL_CANDIDATES_DIR`).\n",
    "    *   Ensures the output directory exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a17d40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math\n",
      "Input (Processed Templates): /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/template-generated-processed\n",
      "Output (Conceptual Candidates): /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates\n"
     ]
    }
   ],
   "source": [
    "# --- Imports and Path Definitions ---\n",
    "\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "import inspect\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "from types import ModuleType\n",
    "from typing import Callable, Any, Dict, List, Set\n",
    "from fractions import Fraction as BuiltinFraction\n",
    "import copy\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset, Dataset\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def find_project_root(marker: str = \".git\"):\n",
    "    \"\"\"\n",
    "    Traverses the directory structure upwards from the current working directory\n",
    "    to locate the project's root, which is identified by the presence of a\n",
    "    specific marker file or directory (e.g., '.git').\n",
    "\n",
    "    Args:\n",
    "        marker: The filename or directory name that marks the project root.\n",
    "\n",
    "    Returns:\n",
    "        A Path object to the project root directory.\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: If the project root cannot be found.\n",
    "    \"\"\"\n",
    "    current_path = Path.cwd().resolve()\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / marker).exists():\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    raise FileNotFoundError(f\"Could not find project root. Marker '{marker}' not found.\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "\n",
    "# --- Directory Paths ---\n",
    "PROCESSED_TEMPLATE_DIR = DATA_DIR / \"template-generated-processed\"\n",
    "CONCEPTUAL_CANDIDATES_DIR = DATA_DIR / \"conceptual-error-candidates\"\n",
    "\n",
    "# --- Models ---\n",
    "MODELS = ['google_gemini-2.5-flash', 'openai_gpt-4.1']\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Input (Processed Templates): {PROCESSED_TEMPLATE_DIR}\")\n",
    "print(f\"Output (Conceptual Candidates): {CONCEPTUAL_CANDIDATES_DIR}\")\n",
    "\n",
    "# --- Ensure Directories Exist ---\n",
    "PROCESSED_TEMPLATE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CONCEPTUAL_CANDIDATES_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715b8d8",
   "metadata": {},
   "source": [
    "#### **Cell 2: Load Dataset and Tiers**\n",
    "*   **Functionality:** Loads the ground-truth dataset and categorizes problems into tiers.\n",
    "*   **Logic:**\n",
    "    *   Loads the `gsm8k` training set.\n",
    "    *   Defines several helper functions (`has_computational_division`, `has_float`, `is_symbolic`) that use regular expressions to classify the solution text of each problem.\n",
    "    *   `mutually_disjoint_tiers` uses these helpers to partition all problem indices into distinct tiers (e.g., `tier1` for simple integer arithmetic, `tier5` for symbolic algebra). This organizes the data generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "902dd185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier definitions loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Load GSM8K Dataset ---\n",
    "GSM8K_TRAIN: Dataset = load_dataset(\"gsm8k\", \"main\")[\"train\"]\n",
    "\n",
    "# --- Tier Definition Functions ---\n",
    "def has_computational_division(solution_text: str):\n",
    "    \"\"\"Checks if a solution text contains a division operation.\"\"\"\n",
    "    pattern = re.compile(r'/\\s*\\d')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def has_float(solution_text: str):\n",
    "    \"\"\"Checks if a solution text contains a float value.\"\"\"\n",
    "    pattern = re.compile(r'(?<!\\d)\\.\\d+|\\d+\\.\\d+')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def is_symbolic(solution_text: str):\n",
    "    \"\"\"Checks if a solution text uses symbolic algebra (e.g., 'Let x...').\"\"\"\n",
    "    pattern = re.compile(r'^Let [a-zA-Z] ', re.MULTILINE)\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def mutually_disjoint_tiers(dataset: Dataset):\n",
    "    \"\"\"\n",
    "    Categorizes all problems in the dataset into mutually disjoint tiers\n",
    "    based on the mathematical operations present in their solution text.\n",
    "    \"\"\"\n",
    "    tiers = {}\n",
    "    symbolic_set = {idx for idx, sample in enumerate(dataset) if is_symbolic(sample.get(\"answer\", \"\"))}\n",
    "    non_symbolic_indices = [idx for idx in range(len(dataset)) if idx not in symbolic_set]\n",
    "    \n",
    "    tiers[\"tier1\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier2\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier3\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier4\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier5\"] = sorted(list(symbolic_set))\n",
    "    return tiers\n",
    "\n",
    "TIER_LISTS = mutually_disjoint_tiers(GSM8K_TRAIN)\n",
    "print(\"Tier definitions loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b24eaef",
   "metadata": {},
   "source": [
    "#### **Cell 3: Template Loading Utilities**\n",
    "*   **Functionality:** Provides helper functions to load the validated `Formalization Template` components.\n",
    "*   **Logic:**\n",
    "    *   `load_function_module`: Takes a tier, index, and model name. It constructs the path to the `.py` file and uses `importlib.util` to dynamically load the file as a Python module, making its `solve` function accessible.\n",
    "    *   `load_logical_steps`: Takes the same inputs, constructs the path to the `.json` file, and returns the parsed list of dictionaries representing the solution's logical steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa7f309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template loading functions defined.\n"
     ]
    }
   ],
   "source": [
    "def load_function_module(\n",
    "    tier: str,\n",
    "    index: int,\n",
    "    model_name: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Dynamically loads the 'solve.py' module for a given template using its\n",
    "    path, which is constructed from the tier, index, and model name.\n",
    "    \"\"\"\n",
    "    py_file_path = PROCESSED_TEMPLATE_DIR / tier / str(index) / f\"{model_name}.py\"\n",
    "    if not py_file_path.exists():\n",
    "        return None\n",
    "        \n",
    "    module_name = f\"templates.t{tier}.i{index}.m_{model_name.replace('.', '_')}.solve\"\n",
    "    spec = importlib.util.spec_from_file_location(module_name, py_file_path)\n",
    "    if spec and spec.loader:\n",
    "        module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(module)\n",
    "        return module\n",
    "        \n",
    "    return None\n",
    "\n",
    "def load_logical_steps(\n",
    "    tier: str,\n",
    "    index: int,\n",
    "    model_name: str\n",
    "):\n",
    "    \"\"\"Loads the 'logical_steps.json' for a given template.\"\"\"\n",
    "    json_file_path = PROCESSED_TEMPLATE_DIR / tier / str(index) / f\"{model_name}.json\"\n",
    "    try:\n",
    "        return json.loads(json_file_path.read_text(encoding='utf-8'))\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        return None\n",
    "\n",
    "print(\"Template loading functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd7b6d3",
   "metadata": {},
   "source": [
    "#### **Cell 4: Sanitization and solution mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca8cb33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanitization and Solution Mapping utilities defined.\n"
     ]
    }
   ],
   "source": [
    "def sanitize_text(text: str):\n",
    "    \"\"\"\n",
    "    Replaces a comprehensive set of problematic Unicode characters with their\n",
    "    ASCII equivalents to prevent model generation and string parsing errors.\n",
    "    \"\"\"\n",
    "    replacements = {\n",
    "        \"\\u2212\": \"-\", \"\\u00d7\": \"*\", \"\\u00f7\": \"/\", \"\\u22c5\": \"*\",\n",
    "        \"\\u201c\": '\"', \"\\u201d\": '\"', \"\\u2018\": \"'\", \"\\u2019\": \"'\",\n",
    "        \"\\u2014\": \"-\", \"\\u2013\": \"-\", \"\\u2026\": \"...\", \"\\u00a0\": \" \",\n",
    "    }\n",
    "    for uni, ascii_char in replacements.items():\n",
    "        text = text.replace(uni, ascii_char)\n",
    "    return text\n",
    "\n",
    "def build_solution_mapping(index: int):\n",
    "    \"\"\"\n",
    "    Extracts the original natural language solution from the dataset, sanitizes\n",
    "    it, and structures it into a line-numbered dictionary including the 'FA'\n",
    "    (Final Answer) line.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        solution_text = GSM8K_TRAIN[index][\"answer\"]\n",
    "        sanitized_text = sanitize_text(solution_text)\n",
    "        lines = [ln.strip() for ln in sanitized_text.splitlines() if ln.strip()]\n",
    "\n",
    "        solution_mapping = {}\n",
    "        if lines and re.match(r\"^####\\s*[\\d\\.,]+$\", lines[-1]):\n",
    "            solution_mapping[\"FA\"] = lines.pop(-1).strip()\n",
    "        \n",
    "        for i, line in enumerate(lines, 1):\n",
    "            solution_mapping[f\"L{i}\"] = line\n",
    "            \n",
    "        return solution_mapping\n",
    "    except IndexError:\n",
    "        return {}\n",
    "\n",
    "print(\"Sanitization and Solution Mapping utilities defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c2b877",
   "metadata": {},
   "source": [
    "#### **Cell 5: Core AST and Trace Utilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a961c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core AST and Trace Utilities defined.\n"
     ]
    }
   ],
   "source": [
    "class NonSimplifyingFraction(BuiltinFraction):\n",
    "    \"\"\"A subclass of fractions.Fraction that preserves original representation for printing.\"\"\"\n",
    "    def __new__(cls, numerator=0, denominator=None):\n",
    "        self = super().__new__(cls, numerator, denominator)\n",
    "        if denominator is not None:\n",
    "            self._original_denominator = denominator\n",
    "            self._original_numerator = numerator\n",
    "        else:\n",
    "            self._original_numerator, self._original_denominator = self.as_integer_ratio()\n",
    "        return self\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self._original_numerator}/{self._original_denominator}\"\n",
    "\n",
    "def _execute_ast_statements(stmts: List[ast.stmt]):\n",
    "    \"\"\"Executes a list of AST assignment statements and returns the final local environment.\"\"\"\n",
    "    try:\n",
    "        global_namespace = {'Fraction': NonSimplifyingFraction}\n",
    "        local_env = {}\n",
    "        for stmt in stmts:\n",
    "            if isinstance(stmt, ast.Assign):\n",
    "                module_node = ast.Module([stmt], type_ignores=[])\n",
    "                code_obj = compile(module_node, '<string>', 'exec')\n",
    "                exec(code_obj, global_namespace, local_env)\n",
    "        return local_env\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def execution_trace(func: Callable[[], Any]):\n",
    "    \"\"\"Executes a function's source code line by line to build a full variable trace.\"\"\"\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "        func_def = tree.body[0]\n",
    "        if isinstance(func_def, ast.FunctionDef):\n",
    "            return _execute_ast_statements(func_def.body)\n",
    "        return None\n",
    "    except (FileNotFoundError, TypeError, IndexError):\n",
    "        return None\n",
    "\n",
    "def get_scope_at_node(\n",
    "    func: Callable,\n",
    "    target_assign_node: ast.Assign\n",
    "):\n",
    "    \"\"\"Executes a function's AST up to a specific node to get the current variable scope.\"\"\"\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "        func_def = tree.body[0]\n",
    "        if not isinstance(func_def, ast.FunctionDef):\n",
    "            return None\n",
    "\n",
    "        statements_before = []\n",
    "        for stmt in func_def.body:\n",
    "            if isinstance(stmt, ast.Assign) and stmt.lineno == target_assign_node.lineno:\n",
    "                return _execute_ast_statements(statements_before)\n",
    "            statements_before.append(stmt)\n",
    "        return None\n",
    "    except (FileNotFoundError, TypeError, IndexError):\n",
    "        return None\n",
    "\n",
    "def is_plausible_trace(\n",
    "    correct_trace: dict,\n",
    "    flawed_trace: dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Validates a flawed trace against a correct one for type and value integrity.\n",
    "    A trace is considered implausible if any numeric variable becomes non-numeric,\n",
    "    flips its sign, or incorrectly becomes zero.\n",
    "    \"\"\"\n",
    "    for key, correct_val in correct_trace.items():\n",
    "        if not isinstance(correct_val, (int, float, BuiltinFraction)):\n",
    "            continue\n",
    "\n",
    "        flawed_val = flawed_trace.get(key)\n",
    "        if not isinstance(flawed_val, (int, float, BuiltinFraction)):\n",
    "            return False\n",
    "\n",
    "        is_correct_int_like = isinstance(correct_val, int) or (isinstance(correct_val, float) and correct_val.is_integer())\n",
    "        is_flawed_int_like = isinstance(flawed_val, int) or (isinstance(flawed_val, float) and flawed_val.is_integer())\n",
    "        if is_correct_int_like and not is_flawed_int_like:\n",
    "            return False\n",
    "\n",
    "        correct_sign = (correct_val > 0) - (correct_val < 0)\n",
    "        flawed_sign = (flawed_val > 0) - (flawed_val < 0)\n",
    "        if correct_val != 0 and correct_sign != flawed_sign:\n",
    "            return False\n",
    "        if correct_val != 0 and flawed_val == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def apply_mutation(\n",
    "    func: Callable,\n",
    "    mutation_details: Dict[str, Any]\n",
    "):\n",
    "    \"\"\"\n",
    "    Applies a single logical mutation to a function's AST and returns the\n",
    "    mutated code and resulting flawed trace.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "\n",
    "        class ASTMutator(ast.NodeTransformer):\n",
    "            def __init__(self, details):\n",
    "                self.details = details\n",
    "                self.mutation_applied = False\n",
    "\n",
    "            def visit_Assign(self, node):\n",
    "                if not (isinstance(node.targets[0], ast.Name) and node.targets[0].id == self.details['target_variable']):\n",
    "                    return node\n",
    "\n",
    "                mutation_type = self.details['type']\n",
    "                if mutation_type == 'incomplete_calculation' and isinstance(node.value, ast.BinOp):\n",
    "                    unrolled = _unroll_binop(node.value)\n",
    "                    if unrolled:\n",
    "                        operands, op_type = unrolled\n",
    "                        operand_to_remove = self.details['operand_to_remove']\n",
    "                        new_operands = [op for op in operands if not (isinstance(op, ast.Name) and op.id == operand_to_remove)]\n",
    "                        if len(new_operands) >= 2:\n",
    "                            node.value = _build_binop_tree_from_list(new_operands, op_type)\n",
    "                            self.mutation_applied = True\n",
    "                elif mutation_type == 'operator_swap' and isinstance(node.value, ast.BinOp):\n",
    "                    node.value.op = self.details['new_op']\n",
    "                    self.mutation_applied = True\n",
    "                elif mutation_type in ['incorrect_operand', 'input_misrepresentation', 'incorrect_final_answer_selection']:\n",
    "                    class OperandSwapper(ast.NodeTransformer):\n",
    "                        def __init__(self, to_replace, new_name):\n",
    "                            self.to_replace = to_replace\n",
    "                            self.new_name = new_name\n",
    "                        def visit_Name(self, name_node):\n",
    "                            if name_node.id == self.to_replace:\n",
    "                                return ast.Name(id=self.new_name, ctx=name_node.ctx)\n",
    "                            return name_node\n",
    "                    swapper = OperandSwapper(self.details['operand_to_replace'], self.details['replacement_variable'])\n",
    "                    node.value = swapper.visit(node.value)\n",
    "                    self.mutation_applied = True\n",
    "                return node\n",
    "\n",
    "        mutator = ASTMutator(mutation_details)\n",
    "        mutated_tree = mutator.visit(copy.deepcopy(tree))\n",
    "        if not mutator.mutation_applied:\n",
    "            return None, None\n",
    "\n",
    "        ast.fix_missing_locations(mutated_tree)\n",
    "        mutated_code_str = ast.unparse(mutated_tree)\n",
    "        func_def = mutated_tree.body[0]\n",
    "        flawed_trace = _execute_ast_statements(func_def.body) if isinstance(func_def, ast.FunctionDef) else None\n",
    "        return mutated_code_str, flawed_trace\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "print(\"Core AST and Trace Utilities defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2799ac",
   "metadata": {},
   "source": [
    "#### **Cell 6: Mutation Discovery**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73327a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutation Discovery functions defined.\n"
     ]
    }
   ],
   "source": [
    "def get_variable_dependencies(node: ast.Assign):\n",
    "    \"\"\"Extracts the names of variables used as operands in an assignment's value.\"\"\"\n",
    "    return sorted([n.id for n in ast.walk(node.value) if isinstance(n, ast.Name) and n.id != 'int'])\n",
    "\n",
    "def _unroll_binop(node: ast.BinOp):\n",
    "    \"\"\"\n",
    "    Recursively unrolls a nested ast.BinOp structure into a flat list of operands.\n",
    "    Returns None if operators are inconsistent (e.g., A + B * C).\n",
    "    \"\"\"\n",
    "    op_type = type(node.op)\n",
    "    def recurse(n):\n",
    "        if isinstance(n, ast.BinOp) and type(n.op) == op_type:\n",
    "            yield from recurse(n.left)\n",
    "            yield from recurse(n.right)\n",
    "        else:\n",
    "            yield n\n",
    "    operands = list(recurse(node))\n",
    "    return operands, op_type\n",
    "\n",
    "def _build_binop_tree_from_list(\n",
    "    operands: list[ast.AST],\n",
    "    op_constructor: type[ast.operator]\n",
    "):\n",
    "    \"\"\"Reconstructs a left-associative ast.BinOp tree from a list of operand nodes.\"\"\"\n",
    "    if len(operands) < 2:\n",
    "        raise ValueError(\"Cannot build a BinOp tree with fewer than 2 operands.\")\n",
    "    tree = ast.BinOp(left=operands[0], op=op_constructor(), right=operands[1])\n",
    "    for i in range(2, len(operands)):\n",
    "        tree = ast.BinOp(left=tree, op=op_constructor(), right=operands[i])\n",
    "    return tree\n",
    "\n",
    "def _discover_operator_swaps(node: ast.Assign):\n",
    "    \"\"\"Finds all valid OperatorSwap mutations for a given assignment node.\"\"\"\n",
    "    if not (isinstance(node.value, ast.BinOp) and hasattr(node.targets[0], 'id') and\n",
    "            isinstance(node.value.left, (ast.Name, ast.Constant)) and isinstance(node.value.right, (ast.Name, ast.Constant))):\n",
    "        return []\n",
    "\n",
    "    target_variable, original_op_node = node.targets[0].id, node.value.op\n",
    "    swap_map = {\n",
    "        ast.Add: [ast.Sub, ast.Mult], ast.Sub: [ast.Add, ast.Div],\n",
    "        ast.Mult: [ast.Div, ast.Add], ast.Div: [ast.Mult, ast.Sub]\n",
    "    }\n",
    "    mutations = []\n",
    "    if type(original_op_node) in swap_map:\n",
    "        for new_op_constructor in swap_map[type(original_op_node)]:\n",
    "            mutations.append({\"type\": \"operator_swap\", \"target_variable\": target_variable, \"original_op_type\": type(original_op_node),\n",
    "                              \"new_op\": new_op_constructor()})\n",
    "    return mutations\n",
    "\n",
    "def _discover_plausible_wrong_references(\n",
    "    func: Callable,\n",
    "    node: ast.Assign,\n",
    "    all_input_vars: Set[str],\n",
    "    debug: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Discovers plausible operand substitution mutations, excluding the 'answer' variable.\n",
    "    \"\"\"\n",
    "    mutations = []\n",
    "    if not hasattr(node.targets[0], 'id'):\n",
    "        return []\n",
    "    target_variable = node.targets[0].id\n",
    "    if target_variable == 'answer':\n",
    "        return []\n",
    "\n",
    "    scope = get_scope_at_node(func, node)\n",
    "    if scope is None:\n",
    "        return []\n",
    "\n",
    "    operands = [n.id for n in ast.walk(node.value) if isinstance(n, ast.Name) and n.id != 'int']\n",
    "    for operand_to_replace in set(operands):\n",
    "        if operand_to_replace not in scope:\n",
    "            continue\n",
    "        for replacement_candidate in scope:\n",
    "            if replacement_candidate in (operand_to_replace, 'Fraction'):\n",
    "                continue\n",
    "            if isinstance(scope.get(operand_to_replace), (int, float, BuiltinFraction)) and isinstance(scope.get(replacement_candidate), (int, float, BuiltinFraction)):\n",
    "                mutation_type = \"input_misrepresentation\" if operand_to_replace in all_input_vars else \"incorrect_operand\"\n",
    "                mutations.append({\"type\": mutation_type, \"target_variable\": target_variable, \"operand_to_replace\": operand_to_replace, \"replacement_variable\": replacement_candidate})\n",
    "    return [dict(t) for t in {tuple(d.items()) for d in mutations}]\n",
    "\n",
    "def _discover_incomplete_calculations(node: ast.Assign):\n",
    "    \"\"\"Discovers opportunities for an Incomplete Calculation error by omitting one operand.\"\"\"\n",
    "    if not (isinstance(node.value, ast.BinOp) and hasattr(node.targets[0], 'id')):\n",
    "        return []\n",
    "    target_variable = node.targets[0].id\n",
    "    unrolled = _unroll_binop(node.value)\n",
    "    if not unrolled:\n",
    "        return []\n",
    "    operands, op_type = unrolled\n",
    "    if len(operands) < 3 or op_type not in [ast.Add, ast.Mult]:\n",
    "        return []\n",
    "        \n",
    "    mutations = []\n",
    "    operand_names = [op.id for op in operands if isinstance(op, ast.Name)]\n",
    "    for operand_node in operands:\n",
    "        if isinstance(operand_node, ast.Name):\n",
    "            mutations.append({\"type\": \"incomplete_calculation\", \"target_variable\": target_variable, \"operand_to_remove\": operand_node.id, \"original_operands\": tuple(sorted(operand_names))})\n",
    "    return mutations\n",
    "\n",
    "def _discover_incorrect_final_answer_selections(\n",
    "    node: ast.Assign,\n",
    "    logical_steps: List[Dict],\n",
    "    all_output_vars: Set[str],\n",
    "    debug: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Discovers opportunities to select an incorrect final answer from recently\n",
    "    computed intermediate variables.\n",
    "    \"\"\"\n",
    "    if not hasattr(node.targets[0], 'id') or node.targets[0].id != 'answer':\n",
    "        return []\n",
    "\n",
    "    correct_operands = [n.id for n in ast.walk(node.value) if isinstance(n, ast.Name)]\n",
    "    if not correct_operands:\n",
    "        return []\n",
    "    correct_final_var = correct_operands[0]\n",
    "\n",
    "    mutations = []\n",
    "    num_steps = len(logical_steps)\n",
    "    line_threshold = max(1, num_steps - 2)\n",
    "\n",
    "    for var_name in all_output_vars:\n",
    "        if var_name == correct_final_var:\n",
    "            continue\n",
    "        step_info = next((s for s in logical_steps if s.get('output_variable') == var_name), None)\n",
    "        if step_info and step_info.get('line_number'):\n",
    "            line_num = int(step_info['line_number'][1:])\n",
    "            if line_num >= line_threshold:\n",
    "                mutations.append({\"type\": \"incorrect_final_answer_selection\", \"target_variable\": \"answer\", \"operand_to_replace\": correct_final_var, \"replacement_variable\": var_name})\n",
    "    return mutations\n",
    "\n",
    "def discover_mutation_opportunities(\n",
    "    func: Callable,\n",
    "    logical_steps: list,\n",
    "    correct_trace: dict,\n",
    "    debug_mode: bool = False\n",
    "):\n",
    "    \"\"\"Analyzes a function's AST to find all possible conceptual error mutations.\"\"\"\n",
    "    all_mutations = []\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "        func_def = tree.body[0]\n",
    "        if not isinstance(func_def, ast.FunctionDef):\n",
    "            return []\n",
    "    except (FileNotFoundError, TypeError, IndexError):\n",
    "        return []\n",
    "\n",
    "    assign_nodes = [node for node in func_def.body if isinstance(node, ast.Assign)]\n",
    "    all_input_vars = {v for s in logical_steps for k in ('question_inputs', 'WK_inputs') for v in s.get(k, [])}\n",
    "    all_output_vars = {s['output_variable'] for s in logical_steps if 'output_variable' in s}\n",
    "\n",
    "    for node in assign_nodes:\n",
    "        all_mutations.extend(_discover_operator_swaps(node))\n",
    "        all_mutations.extend(_discover_plausible_wrong_references(func, node, all_input_vars, debug=debug_mode))\n",
    "        all_mutations.extend(_discover_incomplete_calculations(node))\n",
    "        all_mutations.extend(_discover_incorrect_final_answer_selections(node, logical_steps, all_output_vars, debug=debug_mode))\n",
    "    return [dict(t) for t in {tuple(d.items()) for d in all_mutations}]\n",
    "\n",
    "print(\"Mutation Discovery functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa8c43a",
   "metadata": {},
   "source": [
    "#### **Cell 7: Candidate Generation and Reconstruction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b0c7989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate Generation and Reconstruction functions defined.\n"
     ]
    }
   ],
   "source": [
    "class FormattingTrace(dict):\n",
    "    \"\"\"A dictionary subclass that formats numbers for clean reconstruction.\"\"\"\n",
    "    def __getitem__(self, key):\n",
    "        val = super().__getitem__(key)\n",
    "        if isinstance(val, float) and val.is_integer():\n",
    "            return str(int(val))\n",
    "        if isinstance(val, float):\n",
    "            return str(round(val, 2))\n",
    "        return str(val)\n",
    "        \n",
    "def _cap_candidates(\n",
    "    candidates: List[Dict],\n",
    "    repro_seed: int\n",
    "):\n",
    "    \"\"\"Applies constraints to the list of generated candidates to ensure variety.\"\"\"\n",
    "    from collections import Counter\n",
    "    import random\n",
    "\n",
    "    type_counts, line_counts = Counter(), Counter()\n",
    "    filtered_candidates = []\n",
    "    for cand in candidates:\n",
    "        m_type, err_line = cand['mutation_details']['type'], cand['erroneous_line_number']\n",
    "        type_counts[m_type] += 1\n",
    "        line_counts[err_line] += 1\n",
    "        if type_counts[m_type] <= 2 and line_counts[err_line] <= 2:\n",
    "            filtered_candidates.append(cand)\n",
    "\n",
    "    if len(filtered_candidates) > 5:\n",
    "        random.seed(repro_seed)\n",
    "        random.shuffle(filtered_candidates)\n",
    "        return filtered_candidates[:5]\n",
    "    return filtered_candidates\n",
    "\n",
    "def _get_mutated_template(\n",
    "    original_template: str,\n",
    "    mutation: dict\n",
    "):\n",
    "    \"\"\"Modifies a template string to reflect a variable swap or operator swap.\"\"\"\n",
    "    mutation_type = mutation['type']\n",
    "    if mutation_type == 'operator_swap':\n",
    "        # This part of the function is not currently used by the active discovery\n",
    "        # functions but is kept for potential future use.\n",
    "        return original_template\n",
    "    elif mutation_type in ['incorrect_operand', 'input_misrepresentation', 'incorrect_final_answer_selection']:\n",
    "        to_replace_ph, new_name_ph = f\"{{{mutation['operand_to_replace']}}}\", f\"{{{mutation['replacement_variable']}}}\"\n",
    "        return original_template.replace(to_replace_ph, new_name_ph)\n",
    "    return original_template\n",
    "\n",
    "def _reconstruct_incomplete_calc_template(\n",
    "    original_template: str,\n",
    "    mutation: dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Reconstructs the solution line template for an 'incomplete_calculation' error,\n",
    "    modifying both the outer text and the inner calculator annotation.\n",
    "    \"\"\"\n",
    "    placeholder_to_remove = f\"{{{mutation['operand_to_remove']}}}\"\n",
    "    target_variable = mutation['target_variable']\n",
    "    pattern_after = re.compile(re.escape(placeholder_to_remove) + r'\\s*[x*×+]\\s*')\n",
    "    pattern_before = re.compile(r'\\s*[x*×+]\\s*' + re.escape(placeholder_to_remove))\n",
    "\n",
    "    mutated_template = original_template\n",
    "    annotation_match = re.search(r'<<(.*?)>>', mutated_template)\n",
    "    if annotation_match:\n",
    "        full_annotation_str, inner_expr_str = annotation_match.group(0), annotation_match.group(1)\n",
    "        modified_inner_expr = pattern_after.sub('', inner_expr_str, count=1)\n",
    "        if modified_inner_expr == inner_expr_str:\n",
    "            modified_inner_expr = pattern_before.sub('', modified_inner_expr, count=1)\n",
    "        new_annotation_str = f\"<<{modified_inner_expr}>>\"\n",
    "        mutated_template = mutated_template.replace(full_annotation_str, new_annotation_str)\n",
    "\n",
    "    final_template = pattern_after.sub('', mutated_template, count=1)\n",
    "    if final_template == mutated_template:\n",
    "        final_template = pattern_before.sub('', final_template, count=1)\n",
    "    return final_template\n",
    "\n",
    "def _generate_explanation(\n",
    "    mutation: dict,\n",
    "    correct_trace: dict\n",
    "):\n",
    "    \"\"\"Generates a human-readable explanation with values for a given mutation.\"\"\"\n",
    "    m_type = mutation['type']\n",
    "    def get_val(var_name): return correct_trace.get(var_name, 'N/A')\n",
    "\n",
    "    if m_type == 'incomplete_calculation':\n",
    "        return f\"Incomplete calculation. The term '{mutation['operand_to_remove']}' (value: {get_val(mutation['operand_to_remove'])}) was omitted from the operation.\"\n",
    "    elif m_type == 'operator_swap':\n",
    "        op_map = {ast.Add: '+', ast.Sub: '-', ast.Mult: '*', ast.Div: '/'}\n",
    "        original_op_str, new_op_str = op_map.get(mutation['original_op_type'], '?'), op_map.get(type(mutation['new_op']), '?')\n",
    "        return f\"Incorrect operation. The calculation should use '{original_op_str}' but used '{new_op_str}' instead.\"\n",
    "    elif m_type == 'incorrect_operand':\n",
    "        original, replacement = mutation['operand_to_replace'], mutation['replacement_variable']\n",
    "        return f\"Incorrect operand. The variable '{replacement}' (value: {get_val(replacement)}) was used instead of '{original}' (value: {get_val(original)}).\"\n",
    "    elif m_type == 'input_misrepresentation':\n",
    "        original, replacement = mutation['operand_to_replace'], mutation['replacement_variable']\n",
    "        return f\"Input misrepresentation. The value for '{replacement}' ({get_val(replacement)}) was used instead of '{original}' ({get_val(original)}).\"\n",
    "    elif m_type == 'incorrect_final_answer_selection':\n",
    "        original, replacement = mutation['operand_to_replace'], mutation['replacement_variable']\n",
    "        return f\"Incorrect final answer. An intermediate value '{replacement}' (value: {get_val(replacement)}) was reported instead of '{original}' (value: {get_val(original)}).\"\n",
    "    return \"An unknown conceptual error occurred.\"\n",
    "\n",
    "def reconstruct_solution_from_trace(\n",
    "    logical_steps: list[dict],\n",
    "    eval_trace: dict[str, Any],\n",
    "    candidate_mutation: dict | None = None\n",
    "):\n",
    "    \"\"\"Reconstructs NL solution lines, truncates if necessary, and adds the FA line.\"\"\"\n",
    "    formatted_trace, reconstructed_mapping = FormattingTrace(eval_trace), {}\n",
    "    cutoff_line = None\n",
    "    if candidate_mutation and candidate_mutation['type'] == 'incorrect_final_answer_selection':\n",
    "        incorrect_answer_var = candidate_mutation['replacement_variable']\n",
    "        cutoff_line_info = next((s for s in logical_steps if s.get('output_variable') == incorrect_answer_var), None)\n",
    "        if cutoff_line_info:\n",
    "            cutoff_line = cutoff_line_info['line_number']\n",
    "\n",
    "    for step in logical_steps:\n",
    "        ln, template = step.get(\"line_number\"), step.get(\"solution_line_template\")\n",
    "        if not (ln and template):\n",
    "            continue\n",
    "\n",
    "        if candidate_mutation and candidate_mutation['type'] != 'incorrect_final_answer_selection':\n",
    "            if step.get(\"output_variable\") == candidate_mutation['target_variable']:\n",
    "                if candidate_mutation['type'] == 'incomplete_calculation':\n",
    "                    template = _reconstruct_incomplete_calc_template(template, candidate_mutation)\n",
    "                else:\n",
    "                    template = _get_mutated_template(template, candidate_mutation)\n",
    "        try:\n",
    "            reconstructed_mapping[ln] = template.format_map(formatted_trace)\n",
    "        except (KeyError, ValueError):\n",
    "            return None\n",
    "        if ln == cutoff_line:\n",
    "            break\n",
    "\n",
    "    flawed_final_answer = eval_trace.get('answer')\n",
    "    if flawed_final_answer is not None:\n",
    "        if isinstance(flawed_final_answer, float) and flawed_final_answer.is_integer():\n",
    "            formatted_answer = int(flawed_final_answer)\n",
    "        else:\n",
    "            formatted_answer = round(flawed_final_answer, 2) if isinstance(flawed_final_answer, float) else flawed_final_answer\n",
    "        reconstructed_mapping['FA'] = f\"#### {formatted_answer}\"\n",
    "    return reconstructed_mapping\n",
    "\n",
    "def generate_candidates_for_template(\n",
    "    func: Callable,\n",
    "    logical_steps: list,\n",
    "    correct_trace: dict,\n",
    "    original_solution_mapping: dict,\n",
    "    index: int,\n",
    "    debug_mode: bool = False\n",
    "):\n",
    "    \"\"\"Orchestrates the generation of all possible conceptual error candidates for a single template.\"\"\"\n",
    "    mutations = discover_mutation_opportunities(func, logical_steps, correct_trace, debug_mode=debug_mode)\n",
    "    candidates, original_code = [], inspect.getsource(func)\n",
    "    repro_seed = hash(f\"conceptual_{index}\")\n",
    "\n",
    "    for mutation in mutations:\n",
    "        mutated_code, flawed_trace = apply_mutation(func, mutation)\n",
    "        if not flawed_trace or not is_plausible_trace(correct_trace, flawed_trace):\n",
    "            continue\n",
    "        correct_answer, flawed_answer = correct_trace.get('answer'), flawed_trace.get('answer')\n",
    "        norm_correct = str(float(correct_answer)) if isinstance(correct_answer, (int, float)) else str(correct_answer)\n",
    "        norm_flawed = str(float(flawed_answer)) if isinstance(flawed_answer, (int, float)) else str(flawed_answer)\n",
    "        if correct_answer is None or flawed_answer is None or norm_correct == norm_flawed:\n",
    "            continue\n",
    "        try:\n",
    "            flawed_nl_reconstruction = reconstruct_solution_from_trace(logical_steps, flawed_trace, candidate_mutation=mutation)\n",
    "            if not flawed_nl_reconstruction:\n",
    "                continue\n",
    "        except AttributeError as e:\n",
    "            if \"'str' object has no attribute 'numerator'\" in str(e):\n",
    "                print(f\"\\n[DEBUG] Caught AttributeError on index {index}. Skipping mutation: {mutation}\")\n",
    "                continue\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "        if mutation['type'] == 'incorrect_final_answer_selection':\n",
    "            erroneous_line_number = \"FA\"\n",
    "        else:\n",
    "            erroneous_line_number = next((s['line_number'] for s in logical_steps if s.get('output_variable') == mutation['target_variable']), None)\n",
    "        target_var = mutation['target_variable']\n",
    "        \n",
    "        candidate_package = {\n",
    "            \"index\": index, \"original_solution_mapping\": original_solution_mapping,\n",
    "            \"original_function_code\": original_code, \"mutation_details\": mutation,\n",
    "            \"correct_trace\": correct_trace, \"flawed_trace\": flawed_trace,\n",
    "            \"correct_value\": correct_trace.get(target_var), \"flawed_value\": flawed_trace.get(target_var),\n",
    "            \"logical_steps\": logical_steps, \"flawed_nl_reconstruction\": flawed_nl_reconstruction,\n",
    "            \"erroneous_line_number\": erroneous_line_number,\n",
    "            \"explanation\": _generate_explanation(mutation, correct_trace)\n",
    "        }\n",
    "        candidates.append(candidate_package)\n",
    "        \n",
    "    capped_candidates = _cap_candidates(candidates, repro_seed)\n",
    "    for cand in capped_candidates:\n",
    "        cand['repro_seed'] = repro_seed\n",
    "    return capped_candidates\n",
    "\n",
    "print(\"Candidate Generation and Reconstruction functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75712cf",
   "metadata": {},
   "source": [
    "#### **Cell 7: Main Driver**\n",
    "*   **Functionality:** Executes the entire pipeline in parallel for a specified range of problem indices.\n",
    "*   **Logic:**\n",
    "    *   `run_candidate_generation_pipeline_parallel`: The entry point. It defines a list of tasks (indices to process) and uses the `joblib` library to run them in parallel across all available CPU cores.\n",
    "    *   `process_single_index`: The worker function executed by each parallel job. It contains the model fallback logic: it tries to load a template from the preferred model (`gemini-2.5-flash`), and if that fails or produces no candidates, it tries the next model (`gpt-4.1`).\n",
    "    *   `save_candidates_and_get_metadata`: A utility to save the generated candidate packages to disk as individual JSON files and compile their metadata into a list for the final CSV catalog. The logic for generating a unique filename is a good safeguard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be9b6c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Driver and supporting functions defined.\n"
     ]
    }
   ],
   "source": [
    "def process_single_index(\n",
    "    index_info: tuple,\n",
    "    model_preference: list\n",
    "):\n",
    "    \"\"\"\n",
    "    Worker function to process a single problem index for candidate generation.\n",
    "    It loads a template, validates it, and orchestrates the generation of\n",
    "    conceptual error candidates.\n",
    "    \"\"\"\n",
    "    tier, index = index_info\n",
    "    original_solution_mapping = build_solution_mapping(index)\n",
    "    if not original_solution_mapping:\n",
    "        return []\n",
    "\n",
    "    for model_name in model_preference:\n",
    "        solve_module = load_function_module(tier, index, model_name)\n",
    "        logical_steps = load_logical_steps(tier, index, model_name)\n",
    "        if solve_module and logical_steps:\n",
    "            is_brittle = False\n",
    "            for step in logical_steps:\n",
    "                template = step.get('solution_line_template', '')\n",
    "                placeholders = re.findall(r'\\{([^}]+)\\}', template)\n",
    "                if any('.' in p for p in placeholders):\n",
    "                    print(f\"[INFO] Skipping brittle template for index {index} (model: {model_name}) due to attribute access in placeholder.\")\n",
    "                    is_brittle = True\n",
    "                    break\n",
    "            if is_brittle:\n",
    "                continue\n",
    "\n",
    "            solve_function, correct_trace = solve_module.solve, execution_trace(solve_module.solve)\n",
    "            if not correct_trace:\n",
    "                continue\n",
    "            \n",
    "            candidates = generate_candidates_for_template(\n",
    "                func=solve_function, logical_steps=logical_steps,\n",
    "                correct_trace=correct_trace, original_solution_mapping=original_solution_mapping,\n",
    "                index=index\n",
    "            )\n",
    "            \n",
    "            if candidates:\n",
    "                for cand in candidates:\n",
    "                    cand['model_name'] = model_name\n",
    "                return candidates\n",
    "    return []\n",
    "\n",
    "def run_candidate_generation_pipeline_parallel(indices_to_generate: List[int]):\n",
    "    \"\"\"Drives the conceptual error candidate generation pipeline in parallel using joblib.\"\"\"\n",
    "    print(\"--- Starting Conceptual Error Candidate Generation (PARALLEL MODE) ---\")\n",
    "    \n",
    "    tasks = []\n",
    "    for tier, indices in TIER_LISTS.items():\n",
    "        for index in indices:\n",
    "            if index in indices_to_generate:\n",
    "                tasks.append((tier, index))\n",
    "    \n",
    "    print(f\"Prepared {len(tasks)} indices for processing across all available CPU cores.\")\n",
    "\n",
    "    results_list = Parallel(n_jobs=-1)(\n",
    "        delayed(process_single_index)(task, MODELS) \n",
    "        for task in tqdm(tasks, desc=\"Processing Indices\")\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Parallel processing complete. Saving artifacts... ---\")\n",
    "    \n",
    "    all_candidates = [candidate for sublist in results_list if sublist for candidate in sublist]\n",
    "    all_candidate_metadata = []\n",
    "\n",
    "    if not all_candidates:\n",
    "        print(\"No valid conceptual error candidates were generated.\")\n",
    "        return\n",
    "\n",
    "    for cand in tqdm(all_candidates, desc=\"Saving Candidates\"):\n",
    "        mutation, index, model_name = cand['mutation_details'], cand['index'], cand['model_name']\n",
    "        m_type, target_var = mutation['type'], mutation['target_variable']\n",
    "        tier = next((t for t, ids in TIER_LISTS.items() if index in ids), 'unknown')\n",
    "        repro_seed = cand.get('repro_seed')\n",
    "        now_utc = datetime.datetime.now(datetime.timezone.utc)\n",
    "        \n",
    "        output_dir = CONCEPTUAL_CANDIDATES_DIR / tier / str(index)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        replacement_var = mutation.get('replacement_variable', '')\n",
    "        filename = f\"{model_name}_{m_type}_{target_var}_{replacement_var}.json\"\n",
    "        filepath = output_dir / filename\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(cand, f, indent=2, default=str)\n",
    "        \n",
    "        record = {\n",
    "            \"index\": index, \"tier\": tier, \"model\": model_name, \"mutation_type\": m_type, \n",
    "            \"target_variable\": target_var, \"correct_value\": str(cand.get('correct_value')), \n",
    "            \"flawed_value\": str(cand.get('flawed_value')), \"repro_seed\": repro_seed,\n",
    "            \"date_utc\": now_utc.strftime('%Y-%m-%d'), \"time_utc\": now_utc.strftime('%H:%M:%S'),\n",
    "            \"mutation_details\": json.dumps(mutation, default=str), \"filepath\": str(filepath.relative_to(PROJECT_ROOT))\n",
    "        }\n",
    "        all_candidate_metadata.append(record)\n",
    "\n",
    "    if all_candidate_metadata:\n",
    "        catalog_df = pd.DataFrame(all_candidate_metadata)\n",
    "        cols = ['index', 'tier', 'model', 'mutation_type', 'target_variable', 'correct_value', 'flawed_value', 'repro_seed', 'date_utc', 'time_utc', 'mutation_details', 'filepath']\n",
    "        catalog_df = catalog_df.reindex(columns=[c for c in cols if c in catalog_df.columns])\n",
    "        catalog_path = CONCEPTUAL_CANDIDATES_DIR / \"conceptual_candidate_catalog.csv\"\n",
    "        catalog_df.to_csv(catalog_path, index=False)\n",
    "        print(f\"\\n--- Pipeline Complete ---\")\n",
    "        print(f\"Generated and saved {len(all_candidate_metadata)} conceptual error candidates.\")\n",
    "        print(f\"Catalog saved to: {catalog_path}\")\n",
    "\n",
    "print(\"Main Driver and supporting functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae495b50",
   "metadata": {},
   "source": [
    "## Cell 8: Execute Pipeline\n",
    "\n",
    "This final cell executes the main driver function to run the entire test pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67b2fd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Conceptual Error Candidate Generation (PARALLEL MODE) ---\n",
      "Prepared 3000 indices for processing across all available CPU cores.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5f0b4682094320b6f6c48611a2cfa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Indices:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Skipping brittle template for index 1484 (model: google_gemini-2.5-flash) due to attribute access in placeholder.\n",
      "\n",
      "--- Parallel processing complete. Saving artifacts... ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5280bbc9896542f5b998795e0162b3d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving Candidates:   0%|          | 0/13499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pipeline Complete ---\n",
      "Generated and saved 13499 conceptual error candidates.\n",
      "Catalog saved to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/conceptual-error-candidates/conceptual_candidate_catalog.csv\n"
     ]
    }
   ],
   "source": [
    "run_candidate_generation_pipeline_parallel(indices_to_generate=list(range(3000)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
