{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdL76Y1pQEIL",
    "outputId": "ca1b083f-e8f3-4a62-d567-b02a5bb9d17c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.53.2\n",
      "  Downloading transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.53.2) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.2) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.2) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.2) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.53.2) (2025.8.3)\n",
      "Downloading transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.54.1\n",
      "    Uninstalling transformers-4.54.1:\n",
      "      Successfully uninstalled transformers-4.54.1\n",
      "Successfully installed transformers-4.53.2\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.53.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.9.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.34.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (1.1.5)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.13.0->peft)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.8.3)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
      "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n",
      "Collecting trl==0.20.0\n",
      "  Downloading trl-0.20.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.20.0) (1.9.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.20.0) (4.0.0)\n",
      "Requirement already satisfied: transformers>=4.53.2 in /usr/local/lib/python3.11/dist-packages (from trl==0.20.0) (4.53.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.20.0) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.20.0) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.20.0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.20.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.20.0) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.20.0) (0.34.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.20.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.20.0) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.20.0) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.20.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.20.0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.20.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.20.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.20.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.20.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.20.0) (2025.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.53.2->trl==0.20.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.53.2->trl==0.20.0) (0.21.4)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.20.0) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl==0.20.0) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl==0.20.0) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.20.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.20.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.20.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.20.0) (2025.8.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl==0.20.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl==0.20.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl==0.20.0) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.20.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.20.0) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.20.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.20.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.20.0) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.20.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.20.0) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl==0.20.0) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl==0.20.0) (3.0.2)\n",
      "Downloading trl-0.20.0-py3-none-any.whl (504 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.6/504.6 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: trl\n",
      "Successfully installed trl-0.20.0\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.34.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n",
      "Downloading accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.7/374.7 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.9.0\n",
      "    Uninstalling accelerate-1.9.0:\n",
      "      Successfully uninstalled accelerate-1.9.0\n",
      "Successfully installed accelerate-1.10.0\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.34.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
      "Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.46.1\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu124\n",
      "Collecting flash-attn==2.7.4.post1\n",
      "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.7.4.post1) (2.6.0+cu124)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.7.4.post1) (0.8.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (4.14.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn==2.7.4.post1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn==2.7.4.post1) (3.0.2)\n",
      "Building wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187831595 sha256=58853b28a5a926cae14402bfd8d4d93a45ebf8f9e79533f37ab09d0d77a99c05\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: flash-attn\n",
      "Successfully installed flash-attn-2.7.4.post1\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Installations\n",
    "!pip install -U transformers==4.53.2\n",
    "!pip install -U peft\n",
    "!pip install -U trl==0.20.0\n",
    "!pip install -U accelerate\n",
    "!pip install -U datasets\n",
    "!pip install -U bitsandbytes\n",
    "\n",
    "!pip install flash-attn==2.7.4.post1 \\\n",
    "  --extra-index-url https://download.pytorch.org/whl/cu124 \\\n",
    "  --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EE50oPibQHo2"
   },
   "outputs": [],
   "source": [
    "# Cell 2: Configuration\n",
    "class Config:\n",
    "    # Model ID from Hugging Face Hub\n",
    "    MODEL_ID = \"microsoft/Phi-4-mini-instruct\"\n",
    "\n",
    "    # Local path to the unzipped dataset\n",
    "    DATASET_PATH = '/content/error_detection_dataset.csv'\n",
    "\n",
    "    # Number of labels for the classification task\n",
    "    NUM_LABELS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TLcAlKbLQKQi",
    "outputId": "acc23f3b-8d0c-4ee1-e81b-68ffd2eb83e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Raw Dataset Structure ---\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['index', 'question', 'solution', 'label', '__index_level_0__'],\n",
      "        num_rows: 4853\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['index', 'question', 'solution', 'label', '__index_level_0__'],\n",
      "        num_rows: 1214\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 3: Data Loading and Preprocessing (Updated)\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# --- 3.1: Load Raw Data from CSV ---\n",
    "df = pd.read_csv(Config.DATASET_PATH)\n",
    "\n",
    "# --- 3.2: Create 'solution' and 'label' columns based on error_type ---\n",
    "# If error_type is 'correct', use the correct_answer, otherwise use wrong_answer.\n",
    "df['solution'] = np.where(df['error_type'] == 'correct', df['correct_answer'], df['wrong_answer'])\n",
    "\n",
    "# The label is 1 (flawed) if the error_type is NOT 'correct', otherwise 0.\n",
    "df['label'] = (df['error_type'] != 'correct').astype(int)\n",
    "\n",
    "# --- 3.3: Split DataFrame using the 'split' column ---\n",
    "train_df = df[df['split'] == 'train'].copy()\n",
    "test_df = df[df['split'] == 'test'].copy()\n",
    "\n",
    "# --- 3.4: Select final columns and convert to Hugging Face Dataset ---\n",
    "# We keep 'index' for final referencing.\n",
    "cols_to_keep = ['index', 'question', 'solution', 'label']\n",
    "raw_dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df[cols_to_keep]),\n",
    "    \"test\": Dataset.from_pandas(test_df[cols_to_keep])\n",
    "})\n",
    "\n",
    "print(\"--- Raw Dataset Structure ---\")\n",
    "print(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227,
     "referenced_widgets": [
      "c8018e2c1e0a4946af9859eada196555",
      "9d7522a2f533489eb6c7320f9ecfd430",
      "244ee8e8fbe344768cceb13d57dfe6f0",
      "3bfd4393050e42e5bb36e8bde56c9652",
      "0ce1ac360e9f4898b120bfa4d1b72d58",
      "50af573c59a746fc832ab4c0563dd7fd",
      "f8efa5c8dc7f43cfa5d9f392f776ec08",
      "a7cf961f87a8402a8942f460fa0c55df",
      "2d6987c7289e443f9999dc61185a6ffc",
      "f5bdaa09b5f44c8c9c80113d97973c48",
      "fe4ac378cad14222b011277aa1b2df91",
      "3730dc1941a24c7e9413811c0680d45d",
      "bffa5033b84a47bb95ba86269612b74e",
      "36b3471dc89b4364a0100e2eb2cf5cab",
      "37c3f306b62c4cc6a60de84c39bf3093",
      "d6791e12789e4433813221a1e6fedcdd",
      "e0570778658048f7ae4c95cb259d286b",
      "0050421b364d4147a27660875aa8c459",
      "d63265bb546640358aebcfcd17601151",
      "ae0405ef8a8c4430ab846c62c1c3cd7b",
      "a9ad1ccf89334a7f9d0c8a1045a6652f",
      "b30eec4c302e4f44a3c293bcd09eea60",
      "de0ce2429fbc4b59878f18d2bf1767bc",
      "b284aac41893470caa5f977a48e6cbb2",
      "8546b571681a48d7b01082a49bc8895f",
      "d7d5df30d39f412cbf6bbcc09d1bec21",
      "b827bb07873046408e958c76ebb0a794",
      "2545d2fc1b4d46e5803973d32b3a6b82",
      "5fbee26c24064877976c6e9e34d416bf",
      "f650d29d15a74330b76a9262d9bbde26",
      "9bad156a3c344476a8af65316e9a76f8",
      "a55bca1b118e45dcbabce229a5f2b9eb",
      "583305261724461cbc155c5bd95cecb9",
      "18c05501a0b04b8798a43e7d05e81c9d",
      "b388a3b2eb7049ee8908225d03b283ef",
      "609b3408ef9f450e82376abe10541e2e",
      "154a512b526e42c9862795c19d7ea639",
      "12ba1862c0334aef8be1471addd1afc4",
      "d36638ccb6d64b7fbe447c939eb75d3c",
      "d82f7b445232409ea275c49517e519bc",
      "882dd42ad2804ca4a3d2fdb1df8d203e",
      "846bdc2737004e5c82b179bfd3ac5c1e",
      "a88baef1e947423a965cc22e7c529aa8",
      "b3e5d79f548a463e9da695c4c09edf43",
      "760b2696561340e888d0bb478438bb8a",
      "81aa0cf6b5234645b3aeb3c2f94cc2a2",
      "657358b8c7fa4349bcfc05864a9e5301",
      "a92de68b051d43e3ab27b5222befa85b",
      "e022ada881934b1c94a6ed699b7ef39a",
      "f9611eecc4f44752b61b3b881a134ea7",
      "15957135d09b4d8f8c182659418a4964",
      "e7354c28bdfe4dc798c0c91687c1d5fa",
      "103b21f5764d46a78ae6eb36b950fc89",
      "7f60b8ca5425456f96abff2ba270d7d5",
      "77352d0357b2403e87711b1b81207be2",
      "7b98095df2684fc39f4c39c56fb5c701",
      "26144706165440de8580647530f19d66",
      "0e344b689f704799ba4d82f92e032889",
      "52b95df206f548d49f394dfcdf9f2079",
      "12d55ecc936648fbb129f64f0b22721f",
      "e6209cbb4a6146c3b61f54d5146bd345",
      "c6f0a330ad004383bf7235bb7322a3ee",
      "043a3890c16749a586dab4113928536a",
      "b9b9dec5ac404a05a47ce5178e1d348b",
      "d6c77aa6ae644868957e2048f27f8076",
      "e288be405cff42be83683bfc6278a278"
     ]
    },
    "id": "JxqjTpgQQLvE",
    "outputId": "e2ec4dda-cac6-4183-d7be-852f66b8ef08"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8018e2c1e0a4946af9859eada196555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3730dc1941a24c7e9413811c0680d45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0ce2429fbc4b59878f18d2bf1767bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c05501a0b04b8798a43e7d05e81c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/15.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760b2696561340e888d0bb478438bb8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/249 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b98095df2684fc39f4c39c56fb5c701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/587 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded and configured successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load and Configure Tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    Config.MODEL_ID,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Tokenizer loaded and configured successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "roJOkZlDQzAz"
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \\\n",
    "\"\"\"You are a mathematics tutor.\n",
    "You will be given a math word problem and a solution written by a student.\n",
    "Carefully analyze the problem and solution LINE-BY-LINE and determine whether there are any errors in the solution.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295,
     "referenced_widgets": [
      "a25dedf7d5584896a750a28abf1a9260",
      "24c855df799e42e08632b8753e410706",
      "8451877a75064d6c900a8d749b3c0127",
      "8b2190ead2274a7c8efef06bc0debe17",
      "c060bb8e8d4543b1840c2f86e3b23fe9",
      "fc4d80cdec4642ec85aa0be0bf0b6efd",
      "aeec4b450e57475d9867a5ba95ea8012",
      "91171f92d4714902a0ac5bcb183ddb06",
      "0bfe58002ea84cac854fb269e1be3a54",
      "228ffcd2ab124cb4800788e74816e5d5",
      "7552673b5e904d719e0c00c00ce7dd7a",
      "6769e22d7ee84e41aa6abeba30ae21cb",
      "dd1135a4b8b04c108de052e4e82fa3a0",
      "1fcddb45c8fa4858a9ca1f2a68f6a0e0",
      "2c6e4c1571524603a071ae48d50c9208",
      "22705bc21f7f45878c0a6069d5114223",
      "f2a078ae0ee2437cbb0df1b9dbd6f878",
      "9514c1a159a54e6984638d751ea0f5ee",
      "e21c660f943c4ddcbafd2f7cea0c873a",
      "4789ae454cbe471a9644000627091be8",
      "e23ba705ffad4cd38f4ef46c64b5087d",
      "8e2d54550f2543b99e1ba90ab70adade"
     ]
    },
    "id": "6VCl9ESiQNzG",
    "outputId": "0e64169e-85b2-4071-8214-9bb4d4ecc26f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25dedf7d5584896a750a28abf1a9260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4853 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6769e22d7ee84e41aa6abeba30ae21cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1214 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Tokenized Dataset ---\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['index', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 4853\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['index', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1214\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Define and Apply Preprocessing\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"Formats the input text and tokenizes it for sequence classification.\"\"\"\n",
    "    input_texts = [\n",
    "        f\"{SYSTEM_PROMPT}\\n\\n### Problem:\\n{q}\\n\\n### Solution:\\n{s}\"\n",
    "        for q, s in zip(examples[\"question\"], examples[\"solution\"])\n",
    "    ]\n",
    "    return tokenizer(\n",
    "        input_texts,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=False\n",
    "    )\n",
    "\n",
    "tokenized_dataset = raw_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"question\", \"solution\"] # Keep 'index' and 'label'\n",
    ")\n",
    "\n",
    "final_dataset = tokenized_dataset\n",
    "\n",
    "print(\"\\n--- Final Tokenized Dataset ---\")\n",
    "print(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PzPHireAQ2qb",
    "outputId": "8ad1e1b4-f2f4-4e0e-bf1a-a5f20b6e1870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Example of a Single Formatted Prompt ---\n",
      "You are a mathematics tutor. \n",
      "You will be given a math word problem and a solution written by a student. \n",
      "Carefully analyze the problem and solution LINE-BY-LINE and determine whether there are any errors in the solution.\n",
      "\n",
      "### Problem:\n",
      "Stephen has 110 ants in his ant farm.  Half of the ants are worker ants, 20 percent of the worker ants are male.  How many female worker ants are there?\n",
      "\n",
      "### Answer:\n",
      "Worker ants:110*2=220 ants\n",
      "Male worker ants:220(0.2)=44\n",
      "Female worker ants:220-44=176 ants\n",
      "FINAL ANSWER: 176\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Display a Complete Formatted Prompt for Inspection\n",
    "first_example_raw = raw_dataset[\"train\"][0]\n",
    "\n",
    "# Reconstruct the full prompt string\n",
    "full_prompt = f\"{SYSTEM_PROMPT}\\n\\n### Problem:\\n{first_example_raw['question']}\\n\\n### Answer:\\n{first_example_raw['solution']}\"\n",
    "\n",
    "print(\"--- Example of a Single Formatted Prompt ---\")\n",
    "print(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynYjeCKDQ6Oi"
   },
   "outputs": [],
   "source": [
    "# Cell 7: Define the Custom Classifier Class\n",
    "import torch.nn as nn\n",
    "\n",
    "class GPTSequenceClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    A custom wrapper class for sequence classification using an LLM backbone.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model, num_labels):\n",
    "        super().__init__()\n",
    "        self.base = base_model\n",
    "        hidden_size = base_model.config.hidden_size\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels, bias=True)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "        outputs = self.base(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            **kwargs,\n",
    "        )\n",
    "        last_hidden_state = outputs.hidden_states[-1]\n",
    "        pooled_output = last_hidden_state[:, -1, :]\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = nn.functional.cross_entropy(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        return {\"loss\": loss, \"logits\": logits} if loss is not None else {\"logits\": logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIerc7UORBAI",
    "outputId": "3827b9e2-5b57-49a9-d1f1-587c6d12b0fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced TrainingArguments configured with early stopping.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 8: Define Enhanced Training Arguments\n",
    "# ==============================================================================\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Define the arguments, now including frequent evaluation and early stopping logic.\n",
    "training_args = TrainingArguments(\n",
    "    # Base directory for outputs.\n",
    "    output_dir=\"/content/training_output\",\n",
    "\n",
    "    # --- Batching & Epochs ---\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "\n",
    "    # --- Optimizer & Learning Rate Schedule ---\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "\n",
    "    # --- Precision & Memory ---\n",
    "    bf16=True,\n",
    "    gradient_checkpointing=False,\n",
    "\n",
    "    # --- Logging, Evaluation & Checkpointing (ENHANCED) ---\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=25,\n",
    "    eval_strategy=\"steps\",        # ADDED: Evaluate every 25 steps\n",
    "    eval_steps=25,                # ADDED: Evaluation frequency\n",
    "    save_strategy=\"steps\",        # CHANGED: Save checkpoints at the same frequency as evaluation\n",
    "    save_steps=25,                # ADDED: Save frequency\n",
    "    save_total_limit=1,\n",
    "    report_to=\"none\",\n",
    "    save_safetensors=False,\n",
    "\n",
    "    # --- Early Stopping Configuration (ENHANCED) ---\n",
    "    load_best_model_at_end=True,         # ADDED: Load the best model found during training at the end\n",
    "    metric_for_best_model=\"accuracy\",    # ADDED: Use 'accuracy' to determine the best model\n",
    "    greater_is_better=True,              # ADDED: Higher accuracy is better\n",
    ")\n",
    "\n",
    "print(\"Enhanced TrainingArguments configured with early stopping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Hda6SLfReFj"
   },
   "outputs": [],
   "source": [
    "# Cell 9: Define the Evaluation Metric\n",
    "import numpy as np\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    \"\"\"\n",
    "    Computes accuracy for a sequence classification task.\n",
    "    \"\"\"\n",
    "    logits = p.predictions[0] if isinstance(p.predictions, (tuple, list)) else p.predictions\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    labels = p.label_ids\n",
    "    accuracy = (preds == labels).mean().item()\n",
    "    return {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468,
     "referenced_widgets": [
      "35e97108b9c247b19cfe10a9c970f921",
      "522bbe97078e4e609417301c8bd9d1a8",
      "2f61861f45654db2b7e750641e1d39ee",
      "f186664ecfe74cc6a707769b6ad38d06",
      "5b2ef527b74d4e09a2a44e5e50930b44",
      "41ae384071ac43f19e7ec71d9f3e4f8d",
      "0b31fd217f3747089efc7974fdcf6f6f",
      "ba134bf2119247e1870e0c5c892af48f",
      "e7425e2607f644e2a1829f6b365d5488",
      "35fa41d6a62345569c935cfe3a156cd4",
      "9e3dade0e4b04551a9838f840f577ca7",
      "b2aabc1fafec415083ac0ffa502e8449",
      "60f2661f90e24a87b262d3160f19cd56",
      "75b468e33e074bf8b653ce721be88e80",
      "6c0c1fb356164bdeb1e687098361a889",
      "cffcfe14325b4679a392fb1af8e8f3a7",
      "6b078c2999f24421b86a3f66fabb5af5",
      "bda63565f948486ca0bb5bf9c08364df",
      "b938afdb9e8c4d5ea5a88c4040704b48",
      "b8aad5637347482a86fe448cd7fd525f",
      "7cbbd09e1f6e441391296cce891007cb",
      "0aaf0bd855204140ae0cfe49cb22fac8",
      "a7ea5699d7114d98876d1c15339a6a32",
      "c60fcb0874db456ba75bcbd4fe81842c",
      "38a5f9afdf294f6bb20d172bb6a8591f",
      "4615fecf9e654d808003d5887f649ea7",
      "52608d3f4cb64ec3b0354aa7c3b9e200",
      "d6e11ab1fefb4800ae27f1db681cc28e",
      "2e56992ebfd74973904938a9f628f80e",
      "2451e68669f14a8ea20429a21ad0bf1a",
      "0d02272545be40dab963b49abb64bd6f",
      "a2e5a053bdbe43b39090e184551c8106",
      "bb5109f29ac64dd396c95c6c8823043b",
      "b1132eccf0e74d5ab74f02d06af43389",
      "de664939734d469c96c21251c3f58960",
      "872c384c0c2646038b768175c42086ae",
      "15b5684f00964987ba4a16af06e3c63e",
      "fefcff4df7514b9a82efcc6cb5e32ed2",
      "10f5dee1f85f4597afed6026f2c7f0ba",
      "3dea373b26a14bc5a618aacfc3cdfa0b",
      "04c69e65110c4b018b708cee36611746",
      "f2d23514a5864b6abd1397ecc4599ac0",
      "45fb7ce842ab4f79abc67f63fe883885",
      "20ee4bb5997b4bb3b4a59b8bc71867a1",
      "4fa1997ab283401ebfb218467122b5dd",
      "7c1a9ad61f724e82b3dfa430312a8c03",
      "a632ac8b5cca45e29095e61809171a64",
      "cc657fa4abe247f291a964a15f7a3781",
      "997751e7e6fa482a93036c4a91a3581c",
      "1da7c818d8464cd89a1c804fae3b8249",
      "172563a120e044248ddb216c45fc7682",
      "87d3ad1755a64ca09c81bb6410077509",
      "dcc8e6335db64eab977bc0128e141652",
      "fdc050568d1942ae9bf35d0d9acb76d0",
      "aeafc507f2f042e5b4c5f45719127721",
      "b60e614f9aaa435088d596b618de1fb1",
      "81710569ce61458a9df322f7e4fa2046",
      "a87d847173f2407e933703d037fca636",
      "b42c96aaa944471da759fa790375bb73",
      "364660d054a04422829f0881201011b7",
      "59368fafad344476b7c891f3e80aefbd",
      "2ff82d3fd3a2442baa9fbcbee09d3214",
      "84446e815a844a05ac2699bdec42b8d1",
      "b89e09eb71d24682969b6e8da14399f8",
      "8c1ddedcb3a745dd9f81dd28b0f209b0",
      "de6d0d5a5a7b49c38f6b69e710aa4f3d",
      "7ea947ea9e96424e886792d49c36f10f",
      "47c90249bec14d5b90e40e3255030b20",
      "a60a690178ef4e40b6d36a171e930bf6",
      "a7bcbcb274a5470182d7b2c68a35499b",
      "147cf0bb19924ca1afb105f223292745",
      "9a337406eab144c194ba00d496a5c271",
      "f831e04b0f6941adae9ef5b2ee0143cd",
      "17e929dd54dd41e3baef9cbbc1c377e7",
      "9a321b7a502a4d65b7380ca8b36d06d7",
      "21f4ab18413f4507aecc5d79967a158d",
      "f6aa1681ad6f41b6bfe13d474dd49d9d",
      "913d4ab79fba4949b4fa01ae094fe03a",
      "13015dabfb1041b08d05ffba0741d9e3",
      "1cb9436cbd6848f68330815dc51f00a6",
      "d91db7e4b03646cd93b700817bb8b514",
      "b46f9909588a43a6ad59b290df7a680e",
      "9346a3a0db874b54babdb02a4a077fe8",
      "bc0904de50574f65a6f27f12612f5716",
      "1fb55ef7e0f54adaa10291c78ee423b3",
      "3821721dafdb41aba1694052ff45a25e",
      "013346c2b54c4c378bce708687ace574",
      "9f32b3556b1b4dcc8667bb9787f47d75",
      "38be1a1087da420e974fa9559fe43d4c",
      "0ee9b98a6f7b465795de49dceca084f2",
      "61a584b00c86499f810db007b2d8f2dd",
      "dddbd018e0084e78a4e5fb1c9af8195a",
      "a9d37e5f87e64c58ae5e3e39d7377432",
      "7bad61e02de547ea8ebe2e4593abd7db",
      "7f0fc503d25d4057aa73d2522f65db2f",
      "97ef24db052c4e739c7e1b8c8d911e9b",
      "7c769d1bcbe948ffbc07220e76322c39",
      "10ac40d2ceca4d2a839a3849b28db4bd",
      "ea85e522edd04fb89d67f74a53156835"
     ]
    },
    "id": "EwutJ4e8RZYR",
    "outputId": "f1ac0211-314d-42a4-b684-ec555077ca71"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e97108b9c247b19cfe10a9c970f921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2aabc1fafec415083ac0ffa502e8449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-4-mini-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ea5699d7114d98876d1c15339a6a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-4-mini-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1132eccf0e74d5ab74f02d06af43389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa1997ab283401ebfb218467122b5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60e614f9aaa435088d596b618de1fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.77G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea947ea9e96424e886792d49c36f10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913d4ab79fba4949b4fa01ae094fe03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38be1a1087da420e974fa9559fe43d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trainable Status for LoRA Fine-Tuning Model ---\n",
      "trainable params: 23,068,672 || all params: 3,859,090,432 || trainable%: 0.5978\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Define and Initialize the LoRA-Enabled Model\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "DTYPE = torch.bfloat16\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=DTYPE,\n",
    ")\n",
    "\n",
    "backbone_lora = AutoModelForCausalLM.from_pretrained(\n",
    "    Config.MODEL_ID,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "backbone_lora.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=\"all-linear\",\n",
    ")\n",
    "\n",
    "lora_backbone = get_peft_model(backbone_lora, lora_config)\n",
    "model_lora = GPTSequenceClassifier(lora_backbone, Config.NUM_LABELS)\n",
    "\n",
    "print(\"--- Trainable Status for LoRA Fine-Tuning Model ---\")\n",
    "model_lora.base.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwUGvX2ARhiK",
    "outputId": "bace91c7-af8e-4518-80fd-abdda5360d08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer for full LoRA fine-tuning initialized with Early Stopping.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 11: Initialize the LoRA Trainer with Early Stopping\n",
    "# ==============================================================================\n",
    "import copy\n",
    "from transformers import Trainer, DataCollatorWithPadding, EarlyStoppingCallback\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Create a copy of the training args to set a specific output directory\n",
    "lora_training_args = copy.deepcopy(training_args)\n",
    "lora_training_args.output_dir = \"/content/training_output/lora_finetune\"\n",
    "\n",
    "# Initialize the early stopping callback\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=10,  # Stop if the 'accuracy' metric does not improve for 10 evaluations\n",
    "    early_stopping_threshold=0.0   # Any improvement is considered significant\n",
    ")\n",
    "\n",
    "# Instantiate a new Trainer for the fine-tuning experiment.\n",
    "trainer_lora = Trainer(\n",
    "    model=model_lora,\n",
    "    args=lora_training_args,\n",
    "    train_dataset=final_dataset[\"train\"],\n",
    "    eval_dataset=final_dataset[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stopping_callback]  # ADDED: Include the callback here\n",
    ")\n",
    "\n",
    "print(\"Trainer for full LoRA fine-tuning initialized with Early Stopping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "j1VhQEO0RmBm",
    "outputId": "04b75bba-2e6b-448f-946c-b166fec1a7ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting full LoRA fine-tuning ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='760' max='760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [760/760 1:05:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.592300</td>\n",
       "      <td>0.656590</td>\n",
       "      <td>0.670511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.544900</td>\n",
       "      <td>0.615223</td>\n",
       "      <td>0.668863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>2.501000</td>\n",
       "      <td>0.630228</td>\n",
       "      <td>0.584020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.378100</td>\n",
       "      <td>0.547597</td>\n",
       "      <td>0.687809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.990700</td>\n",
       "      <td>0.427423</td>\n",
       "      <td>0.817957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.469200</td>\n",
       "      <td>0.359185</td>\n",
       "      <td>0.850082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.995200</td>\n",
       "      <td>0.393971</td>\n",
       "      <td>0.870675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.253154</td>\n",
       "      <td>0.903624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.909000</td>\n",
       "      <td>0.307702</td>\n",
       "      <td>0.870675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.756500</td>\n",
       "      <td>0.264172</td>\n",
       "      <td>0.898682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.876700</td>\n",
       "      <td>0.242020</td>\n",
       "      <td>0.910214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.803000</td>\n",
       "      <td>0.237435</td>\n",
       "      <td>0.904448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.307100</td>\n",
       "      <td>0.325684</td>\n",
       "      <td>0.913509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.474200</td>\n",
       "      <td>0.356185</td>\n",
       "      <td>0.914333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.369100</td>\n",
       "      <td>0.432317</td>\n",
       "      <td>0.920099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.474100</td>\n",
       "      <td>0.331634</td>\n",
       "      <td>0.915157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.287010</td>\n",
       "      <td>0.920099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.274792</td>\n",
       "      <td>0.917628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.351322</td>\n",
       "      <td>0.922570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.406346</td>\n",
       "      <td>0.920923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.232100</td>\n",
       "      <td>0.411448</td>\n",
       "      <td>0.921746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.115700</td>\n",
       "      <td>0.487955</td>\n",
       "      <td>0.920099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.127100</td>\n",
       "      <td>0.461272</td>\n",
       "      <td>0.920099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.124600</td>\n",
       "      <td>0.484073</td>\n",
       "      <td>0.920099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.474683</td>\n",
       "      <td>0.923394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.464535</td>\n",
       "      <td>0.920923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.465737</td>\n",
       "      <td>0.923394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.461123</td>\n",
       "      <td>0.921746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>0.114100</td>\n",
       "      <td>0.465109</td>\n",
       "      <td>0.921746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.462874</td>\n",
       "      <td>0.921746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were unexpected keys in the checkpoint model loaded: ['base.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.0.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.0.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.0.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.0.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.0.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.0.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.1.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.1.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.1.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.1.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.1.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.1.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.2.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.2.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.2.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.2.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.2.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.2.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.3.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.3.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.3.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.3.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.3.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.3.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.4.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.4.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.4.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.4.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.4.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.4.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.5.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.5.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.5.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.5.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.5.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.5.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.6.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.6.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.6.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.6.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.6.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.6.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.7.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.7.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.7.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.7.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.7.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.7.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.8.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.8.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.8.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.8.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.8.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.8.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.9.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.9.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.9.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.9.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.9.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.9.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.10.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.10.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.10.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.10.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.10.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.10.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.11.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.11.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.11.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.11.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.11.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.11.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.12.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.12.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.12.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.12.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.12.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.12.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.13.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.13.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.13.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.13.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.13.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.13.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.14.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.14.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.14.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.14.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.14.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.14.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.15.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.15.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.15.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.15.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.15.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.15.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.16.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.16.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.16.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.16.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.16.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.16.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.16.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.16.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.16.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.17.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.17.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.17.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.17.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.17.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.17.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.17.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.17.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.17.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.18.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.18.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.18.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.18.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.18.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.18.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.18.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.18.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.18.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.19.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.19.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.19.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.19.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.19.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.19.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.19.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.19.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.19.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.20.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.20.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.20.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.20.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.20.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.20.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.20.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.20.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.20.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.21.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.21.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.21.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.21.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.21.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.21.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.21.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.21.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.21.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.22.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.22.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.22.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.22.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.22.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.22.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.22.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.22.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.22.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.23.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.23.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.23.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.23.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.23.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.23.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.23.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.23.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.23.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.24.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.24.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.24.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.24.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.24.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.24.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.24.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.24.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.24.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.25.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.25.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.25.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.25.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.25.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.25.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.25.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.25.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.25.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.26.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.26.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.26.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.26.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.26.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.26.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.26.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.26.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.26.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.27.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.27.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.27.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.27.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.27.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.27.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.27.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.27.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.27.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.28.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.28.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.28.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.28.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.28.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.28.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.28.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.28.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.28.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.29.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.29.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.29.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.29.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.29.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.29.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.29.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.29.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.29.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.30.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.30.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.30.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.30.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.30.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.30.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.30.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.30.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.30.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.31.self_attn.qkv_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.31.self_attn.qkv_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.31.self_attn.qkv_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.31.mlp.gate_up_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.31.mlp.gate_up_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.31.mlp.gate_up_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base.base_model.model.model.layers.31.mlp.down_proj.base_layer.weight.absmax', 'base.base_model.model.model.layers.31.mlp.down_proj.base_layer.weight.quant_map', 'base.base_model.model.model.layers.31.mlp.down_proj.base_layer.weight.quant_state.bitsandbytes__nf4'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full LoRA fine-tuning complete ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Fine-Tune the LoRA Model\n",
    "print(\"--- Starting full LoRA fine-tuning ---\")\n",
    "trainer_lora.train()\n",
    "print(\"\\n--- Full LoRA fine-tuning complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "_UlJai8DRngs",
    "outputId": "9b89be14-be55-4f1d-f489-e09ab53d4a6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating predictions for the test set to create a detailed results DataFrame ---\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final evaluation results saved to /content/final_evaluation_results.csv\n",
      "--- Final Evaluation DataFrame Head ---\n",
      "   index  true_label  predicted_label  predicted_proba  is_correct\n",
      "0   5091           1                1         0.999987        True\n",
      "1   1925           1                1         0.999960        True\n",
      "2   1193           1                1         0.999910        True\n",
      "3   6695           1                1         1.000000        True\n",
      "4   4633           1                1         0.999994        True\n",
      "\n",
      "Final Test Accuracy: 0.9234\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 13: Final Evaluation and Detailed Results Generation (Updated)\n",
    "# ==============================================================================\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"--- Generating predictions for the test set to create a detailed results DataFrame ---\")\n",
    "\n",
    "# 1. Run inference on the test set\n",
    "pred_outputs = trainer_lora.predict(final_dataset[\"test\"])\n",
    "\n",
    "# 2. Extract logits and true labels\n",
    "logits = pred_outputs.predictions[0] if isinstance(pred_outputs.predictions, (tuple, list)) else pred_outputs.predictions\n",
    "true_labels = pred_outputs.label_ids\n",
    "\n",
    "# 3. Calculate probabilities, predicted labels, and confidence scores\n",
    "probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "predicted_labels = np.argmax(probs, axis=1)\n",
    "predicted_probas = np.max(probs, axis=1)\n",
    "\n",
    "# 4. Determine if each prediction was correct\n",
    "is_correct = (predicted_labels == true_labels)\n",
    "\n",
    "# 5. Assemble the final DataFrame with the 'index' column included\n",
    "results_df = pd.DataFrame({\n",
    "    'index': final_dataset[\"test\"][\"index\"],  # UPDATED: Source index directly from the dataset\n",
    "    'true_label': true_labels,\n",
    "    'predicted_label': predicted_labels,\n",
    "    'predicted_proba': predicted_probas,\n",
    "    'is_correct': is_correct\n",
    "})\n",
    "\n",
    "# 6. Save the detailed results to a CSV file\n",
    "output_csv_path = \"/content/final_evaluation_results.csv\"\n",
    "results_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# 7. Print a summary for quick inspection\n",
    "print(f\"\\n✅ Final evaluation results saved to {output_csv_path}\")\n",
    "print(\"--- Final Evaluation DataFrame Head ---\")\n",
    "print(results_df.head())\n",
    "\n",
    "final_accuracy = results_df['is_correct'].mean()\n",
    "print(f\"\\nFinal Test Accuracy: {final_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286,
     "referenced_widgets": [
      "abc525c654ec4750a172e66d837b6cfc",
      "b3c8c606242a4082a904334c67324326",
      "cbd8239d920b40069552a73c2914da4a",
      "ca3bf70cf2d5444fb5ffda332e94100c",
      "a1cbaaf7a90a415887b866f38f28fa1e",
      "bdb11f0eb8b74ef289395465ff69804d",
      "821ec3ab757042219ee90e518b2afbaa",
      "0660c938a7ca453dae53ebf25ce97c15",
      "a6306a77bffc464da1b6e21a73388559",
      "d53b9505e6ef45e28f49307cd7ab2c25",
      "2549842f29dd4298bdf3afdd43b9c9e9",
      "2fab6e31b763487c8170b5eb653a45cc",
      "61296107968d491f94f73ddfff94dacf",
      "7dec6fa68b704361b4037d769c2c99ba",
      "481f7c4c6e4e4a25ba2ba52aeb47e1f4",
      "54b6fefc17e849f7864b017aab97c6bf",
      "c486fed1ecb340ae88358d48d0fc3026",
      "887e3c7e0c5142afa06228f9efe622eb",
      "dd504ba28cf147e6901220c0de94c059",
      "e6f00478eb1a458c83246c7843243e11",
      "4e7e75d1855743529bdac715aafdef52",
      "4cdff2bb2e5c4d38b4c92eafb4c2f607",
      "cf6835b6e317409fbfa1ecad8f142cc1",
      "191071ce23e14f1f8776a6720bb6eacd",
      "a164a2f25bcf49e6ac3f34df1afbb0a5",
      "53c89fbbc9584b4c838f32254dc8f7ee",
      "bb6907637bcd4c3fa0adfec2bf2886d2",
      "71fff4b4f18c43d0ae1dcc2f27810553",
      "268c2a07b9fc4727ad176c04d14de64b",
      "95db5185a2f445edacb4a7c32dc8816a",
      "afa665046efd44c29069e70c903b4797",
      "fc8ed4a9570c41f8983bd740bf47962c",
      "32a8b9674d0c4fa9b881abecdcf44c9a",
      "9e882a21e0ac4be18783502235a4035d",
      "6407c0287b1e4bcd923efbdcc588d6f1",
      "8cee85e1e76943e8b3cccb2cebe89b78",
      "cca800ba9e4647348f69c54a52155ed6",
      "f6070b665cf44582b4609b23bdd1d4ac",
      "19d1f943df1c41a7a24cbcf9200dbda6",
      "3b31f8a2fe4941db9b544f384246d8dd",
      "c2dc49835d064dc1ab03cffea9dc3709",
      "68ca342a05484791b5f0b0d015e5bd38",
      "78988f90fc4244399d3a86e17743eee9",
      "7351dfe5472048918ff11166922bd387",
      "b6fdcc73754a4185947dbff4c8894c61",
      "1e8552347ec14ab98eee55cf68f5dc4e",
      "9406fdf58e6e4e4dbc0df27be4cfac13",
      "8ef3a5c6cd304d6caeb1362a52d1f6b0",
      "bda7b21297e044f4bea6d9120fdbcf8f",
      "195dba13aa2d4dbdbfa757d5368bd90f",
      "db4b7bf40eaa4e3e868b3bcd02403730",
      "e8927b25dc6d4df7982a63d5a9eb05fb",
      "61a5e2031af34314b10395a684665db8",
      "e15e70c769d34bfaab3ebae9fd0a76e9",
      "793f78580f704f31abfb81b7f465b36c"
     ]
    },
    "id": "oYDHzC8YRpE9",
    "outputId": "c31fd54f-9a2d-484d-93b2-b168a38438e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving components to local directory: /content/phi-4-error-binary-classifier\n",
      "All components saved locally.\n",
      "Uploading files to HF Hub repository: arvindsuresh-math/phi-4-error-binary-classifier\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc525c654ec4750a172e66d837b6cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fab6e31b763487c8170b5eb653a45cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6835b6e317409fbfa1ecad8f142cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...or-binary-classifier/tokenizer.json: 100%|##########| 15.5MB / 15.5MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e882a21e0ac4be18783502235a4035d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...lassifier/adapter_model.safetensors:   1%|          |  557kB / 92.3MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fdcc73754a4185947dbff4c8894c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...nary-classifier/classifier_head.pth:   2%|2         |   577B / 26.1kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Successfully pushed all components to: https://huggingface.co/arvindsuresh-math/phi-4-error-binary-classifier\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Push Fine-Tuned Model and Classifier Head to Hugging Face Hub\n",
    "import torch\n",
    "from huggingface_hub import HfApi, HfFolder, create_repo\n",
    "\n",
    "# --- Configuration ---\n",
    "# IMPORTANT: Replace with your Hugging Face username and desired repo name\n",
    "hf_username = \"arvindsuresh-math\"\n",
    "hf_repo_name = \"phi-4-error-binary-classifier\"\n",
    "local_save_path = f\"/content/{hf_repo_name}\"\n",
    "\n",
    "# --- Save all necessary components locally ---\n",
    "print(f\"Saving components to local directory: {local_save_path}\")\n",
    "\n",
    "# 1. Save the LoRa adapter weights for the backbone model\n",
    "model_lora.base.save_pretrained(local_save_path)\n",
    "\n",
    "# 2. Save the state dictionary of the custom classifier head\n",
    "classifier_head_path = f\"{local_save_path}/classifier_head.pth\"\n",
    "torch.save(model_lora.classifier.state_dict(), classifier_head_path)\n",
    "\n",
    "# 3. Save the tokenizer to bundle it with the model\n",
    "tokenizer.save_pretrained(local_save_path)\n",
    "\n",
    "print(\"All components saved locally.\")\n",
    "\n",
    "# --- Push all files to the Hugging Face Hub ---\n",
    "print(f\"Uploading files to HF Hub repository: {hf_username}/{hf_repo_name}\")\n",
    "api = HfApi()\n",
    "\n",
    "# Create the repository on the Hub (if it doesn't already exist)\n",
    "create_repo(\n",
    "    repo_id=f\"{hf_username}/{hf_repo_name}\",\n",
    "    exist_ok=True,\n",
    "    token=HfFolder.get_token(),\n",
    ")\n",
    "\n",
    "# Upload the entire folder's contents\n",
    "api.upload_folder(\n",
    "    folder_path=local_save_path,\n",
    "    repo_id=f\"{hf_username}/{hf_repo_name}\",\n",
    "    commit_message=\"Upload fine-tuned LoRa adapters and classifier head\",\n",
    "    token=HfFolder.get_token(),\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Successfully pushed all components to: https://huggingface.co/{hf_username}/{hf_repo_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CusNKQyHsfo8",
    "outputId": "b8af75a6-b6b4-4d7b-b24f-f253509d511c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2932480192"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_lora.get_memory_footprint()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
