{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92cb78d",
   "metadata": {},
   "source": [
    "### Cell 1: Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75ca7c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math\n",
      "Input (Split Manifests): /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/tier-manifests-gen-processed\n",
      "Output (Generated Errors): /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/computational-errors-generated\n"
     ]
    }
   ],
   "source": [
    "# --- Python Standard Library Imports ---\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "import inspect\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "from types import ModuleType\n",
    "from typing import Callable, Any, Dict, List\n",
    "from fractions import Fraction\n",
    "import datetime\n",
    "import functools\n",
    "import random\n",
    "import copy\n",
    "\n",
    "# --- Third-Party Imports ---\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# --- MODIFIED: Path and Directory Definitions ---\n",
    "def find_project_root(marker: str = \".git\") -> Path:\n",
    "    current_path = Path.cwd().resolve()\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / marker).exists():\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    raise FileNotFoundError(f\"Could not find project root. Marker '{marker}' not found.\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "\n",
    "PROCESSED_MANIFEST_DIR = DATA_DIR / \"tier-manifests-gen-processed\"\n",
    "GENERATED_ERRORS_DIR = DATA_DIR / \"computational-errors-generated\"\n",
    "\n",
    "# --- NEW: Define the list of models we will process ---\n",
    "MODELS = ['openai_gpt-4.1', 'google_gemini-2.5-flash']\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Input (Split Manifests): {PROCESSED_MANIFEST_DIR}\")\n",
    "print(f\"Output (Generated Errors): {GENERATED_ERRORS_DIR}\")\n",
    "\n",
    "# --- Ensure Output Directory Exists ---\n",
    "PROCESSED_MANIFEST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "GENERATED_ERRORS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56474573",
   "metadata": {},
   "source": [
    "### Cell 2: Load dataset and define tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28ec494d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'main' at /Users/arvindsuresh/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu Jul 10 18:53:50 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier definitions loaded and samples categorized.\n",
      "tier1     : 2767 samples\n",
      "tier2     : 837 samples\n",
      "tier3     : 3113 samples\n",
      "tier4     : 544 samples\n",
      "tier5     : 212 samples\n"
     ]
    }
   ],
   "source": [
    "# --- Load GSM8K Dataset ---\n",
    "GSM8K_TRAIN: Dataset = load_dataset(\"gsm8k\", \"main\")[\"train\"]\n",
    "\n",
    "# --- Tier Definition Functions ---\n",
    "def has_computational_division(solution_text: str) -> bool:\n",
    "    pattern = re.compile(r'/\\s*\\d')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def has_float(solution_text: str) -> bool:\n",
    "    pattern = re.compile(r'(?<!\\d)\\.\\d+|\\d+\\.\\d+')\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def is_symbolic(solution_text: str) -> bool:\n",
    "    pattern = re.compile(r'^Let [a-zA-Z] ', re.MULTILINE)\n",
    "    return bool(pattern.search(solution_text))\n",
    "\n",
    "def mutually_disjoint_tiers(dataset: Dataset) -> dict[str, list[int]]:\n",
    "    # (Function content is unchanged)\n",
    "    tiers = {}\n",
    "    symbolic_set = set(idx for idx, sample in enumerate(dataset) if is_symbolic(sample.get(\"answer\", \"\")))\n",
    "    non_symbolic_indices = [idx for idx in range(len(dataset)) if idx not in symbolic_set]\n",
    "    tiers[\"tier1\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier2\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and not has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier3\"] = sorted([idx for idx in non_symbolic_indices if not has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier4\"] = sorted([idx for idx in non_symbolic_indices if has_float(dataset[idx].get(\"answer\", \"\")) and has_computational_division(dataset[idx].get(\"answer\", \"\"))])\n",
    "    tiers[\"tier5\"] = sorted(list(symbolic_set))\n",
    "    return tiers\n",
    "\n",
    "TIER_LISTS = mutually_disjoint_tiers(GSM8K_TRAIN)\n",
    "print(\"Tier definitions loaded and samples categorized.\")\n",
    "for tier, indices in TIER_LISTS.items():\n",
    "    print(f\"{tier:<10}: {len(indices)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fc6ad0",
   "metadata": {},
   "source": [
    "### Cell 3: Manifest loading and processing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f74917a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifest loading functions updated to read from the split-file directory.\n"
     ]
    }
   ],
   "source": [
    "def load_function_module(\n",
    "    tier: str,\n",
    "    index: int,\n",
    "    model_name: str, \n",
    "    base_dir: Path = PROCESSED_MANIFEST_DIR # \n",
    ") -> ModuleType | None:\n",
    "    \"\"\"\n",
    "    Dynamically loads the '{model_name}.py' file for a given tier, index, and model.\n",
    "    \"\"\"\n",
    "    py_file_path = base_dir / tier / str(index) / f\"{model_name}.py\"\n",
    "    if not py_file_path.exists():\n",
    "        return None\n",
    "\n",
    "    # Make module name unique to avoid import caching issues\n",
    "    module_name = f\"manifests.t{tier}.i{index}.m_{model_name.replace('.', '_')}.solve\"\n",
    "    spec = importlib.util.spec_from_file_location(module_name, py_file_path)\n",
    "    if spec and spec.loader:\n",
    "        module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(module)\n",
    "        return module\n",
    "    return None\n",
    "\n",
    "def load_logical_steps(\n",
    "    tier: str,\n",
    "    index: int,\n",
    "    model_name: str, \n",
    "    base_dir: Path = PROCESSED_MANIFEST_DIR\n",
    ") -> list[dict] | None:\n",
    "    \"\"\"\n",
    "    Loads the '{model_name}.json' file for a given tier, index, and model.\n",
    "    \"\"\"\n",
    "    json_file_path = base_dir / tier / str(index) / f\"{model_name}.json\"\n",
    "    try:\n",
    "        with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def build_solution_mapping(index: int, dataset: Dataset = GSM8K_TRAIN):\n",
    "    \"\"\"\n",
    "    (Function is unchanged)\n",
    "    Extracts the original NL solution for comparison. Not strictly needed for the\n",
    "    pipeline but useful for debugging.\n",
    "    \"\"\"\n",
    "    solution_mapping = {}\n",
    "    solution_text = dataset[index][\"answer\"]\n",
    "    lines = [ln.strip() for ln in solution_text.splitlines() if ln.strip()]\n",
    "    if lines and re.match(r\"^####\\s*[\\d\\.,]+$\", lines[-1]):\n",
    "        lines.pop(-1)\n",
    "    for i, line in enumerate(lines, 1):\n",
    "        solution_mapping[f\"L{i}\"] = line\n",
    "    return solution_mapping\n",
    "\n",
    "\n",
    "print(\"Manifest loading functions updated to read from the split-file directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc9976b",
   "metadata": {},
   "source": [
    "### Cell 4: General and core utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba31dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- General Numeric and String Helpers ---\n",
    "def normalize_value(value):\n",
    "    if isinstance(value, float) and value.is_integer(): return int(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "def get_sign(n) -> int:\n",
    "    if n > 0: return 1\n",
    "    if n < 0: return -1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def has_distinct_adjacent_digits(n: int) -> bool:\n",
    "    s = str(abs(n))\n",
    "    return len(s) >= 2 and any(s[i] != s[i+1] for i in range(len(s) - 1))\n",
    "\n",
    "\n",
    "# --- Core AST-based Trace and Solution Generation ---\n",
    "def execution_trace(func: Callable[[], Any]) -> Dict[str, Any] | None:\n",
    "    # (Function content is unchanged from old Cell 4)\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "        func_def = tree.body[0]\n",
    "        global_namespace = {'Fraction': Fraction}\n",
    "        local_env = {}\n",
    "        for stmt in func_def.body:\n",
    "            if isinstance(stmt, ast.Assign):\n",
    "                module_node = ast.Module([stmt], type_ignores=[])\n",
    "                code_obj = compile(module_node, '<string>', 'exec')\n",
    "                exec(code_obj, global_namespace, local_env)\n",
    "        return local_env\n",
    "    except Exception: return None\n",
    "\n",
    "\n",
    "def generate_flawed_trace(func: Callable, error_details: dict[str, Any]) -> dict[str, Any] | None:\n",
    "    # (Function content is unchanged from old Cell 4)\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "        func_def = tree.body[0]\n",
    "        variable_to_change = error_details[\"variable\"]\n",
    "        flawed_value = error_details[\"flawed_value\"]\n",
    "        modified_body = copy.deepcopy(func_def.body)\n",
    "        node_found_and_modified = False\n",
    "        for node in modified_body:\n",
    "            if isinstance(node, ast.Assign) and any(isinstance(t, ast.Name) and t.id == variable_to_change for t in node.targets):\n",
    "                if isinstance(flawed_value, Fraction): new_value_node = ast.Call(func=ast.Name(id='Fraction', ctx=ast.Load()), args=[ast.Constant(value=flawed_value.numerator), ast.Constant(value=flawed_value.denominator)], keywords=[])\n",
    "                else: new_value_node = ast.Constant(value=flawed_value)\n",
    "                ast.copy_location(new_value_node, node.value)\n",
    "                ast.fix_missing_locations(new_value_node)\n",
    "                node.value = new_value_node\n",
    "                node_found_and_modified = True\n",
    "                break\n",
    "        if not node_found_and_modified: return None\n",
    "        global_namespace = {'Fraction': Fraction}\n",
    "        env = {}\n",
    "        for stmt in modified_body:\n",
    "            if isinstance(stmt, ast.Assign):\n",
    "                code_obj = compile(ast.Module([stmt], type_ignores=[]), '<string>', 'exec')\n",
    "                exec(code_obj, global_namespace, env)\n",
    "        return env\n",
    "    except Exception: return None\n",
    "\n",
    "\n",
    "def reconstruct_solution_lines_enhanced(logical_steps: list[dict], eval_trace: dict[str, Any]) -> dict[str, str]:\n",
    "    # (Function content is unchanged from old Cell 4)\n",
    "    reconstructed_mapping = {}\n",
    "    placeholder_pattern = re.compile(r'\\{([a-zA-Z0-9_]+)\\}')\n",
    "    for step in logical_steps:\n",
    "        line_number = step.get(\"line_number\")\n",
    "        template = step.get(\"solution_line_template\")\n",
    "        if not line_number or not template: continue\n",
    "        def replacer(match):\n",
    "            variable_name = match.group(1)\n",
    "            value = eval_trace.get(variable_name)\n",
    "            if value is None: return f\"{{ERROR}}\"\n",
    "            if isinstance(value, Fraction):\n",
    "                if value.denominator == 1: return str(value.numerator)\n",
    "                return f\"{value.numerator}/{value.denominator}\"\n",
    "            return str(normalize_value(value))\n",
    "        reconstructed_mapping[line_number] = placeholder_pattern.sub(replacer, template)\n",
    "    return reconstructed_mapping\n",
    "\n",
    "\n",
    "def is_trace_valid(\n",
    "    flawed_trace: dict[str, Any],\n",
    "    correct_trace: dict[str, Any]\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Validates a flawed trace to ensure it adheres to project constraints.\n",
    "\n",
    "    Checks for two conditions:\n",
    "    1. Type Integrity: An integer-like value must remain integer-like.\n",
    "       (e.g., 15 students cannot become 15.5 students).\n",
    "    2. Sign Integrity: A value cannot change its sign\n",
    "       (e.g., a cost of $20 cannot become -$20).\n",
    "    \"\"\"\n",
    "    for var_name, correct_val in correct_trace.items():\n",
    "        if var_name not in flawed_trace:\n",
    "            continue\n",
    "\n",
    "        flawed_val = flawed_trace.get(var_name)\n",
    "        \n",
    "        # Rule 1: Type Integrity Check\n",
    "        is_correct_int_like = isinstance(normalize_value(correct_val), int)\n",
    "        is_flawed_int_like = isinstance(normalize_value(flawed_val), int)\n",
    "\n",
    "        if is_correct_int_like and not is_flawed_int_like:\n",
    "            return False\n",
    "\n",
    "        # Rule 2: Sign Integrity Check\n",
    "        processed_correct = normalize_value(correct_val)\n",
    "        processed_flawed = normalize_value(flawed_val)\n",
    "        \n",
    "        if isinstance(processed_correct, (int, float)) and processed_correct != 0:\n",
    "            if get_sign(processed_correct) != get_sign(processed_flawed):\n",
    "                return False\n",
    "                \n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07618b44",
   "metadata": {},
   "source": [
    "### Cell 5: Individual error generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ff50735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "\n",
    "def generate_off_by_n_error(\n",
    "    correct_value: int,\n",
    "    offset_range: tuple[int, int] = (1, 5)\n",
    "    ):\n",
    "    \"\"\"Generates a minor miscalculation error, preventing sign changes.\"\"\"\n",
    "    offset = random.randint(offset_range[0], offset_range[1])\n",
    "    if random.random() < 0.5:\n",
    "        offset = -offset\n",
    "\n",
    "    flawed_value = correct_value + offset\n",
    "    \n",
    "    # --- THIS IS THE FIX ---\n",
    "    # If the sign flips, either use a smaller offset or flip the offset's sign\n",
    "    if get_sign(correct_value) != get_sign(flawed_value) and correct_value != 0:\n",
    "        flawed_value = correct_value - offset # Try the opposite offset\n",
    "\n",
    "    # Ensure value actually changes, especially if the fix above reverted it\n",
    "    if flawed_value == correct_value:\n",
    "        flawed_value += 1 if correct_value >= 0 else -1\n",
    "    # --- END FIX ---\n",
    "    \n",
    "    return {\n",
    "        \"flawed_value\": flawed_value,\n",
    "        \"explanation_type\": \"This appears to be a minor miscalculation.\"\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_off_by_factor_of_10_error(correct_value: int):\n",
    "    \"\"\"Generates a dropped/added zero error. Assumes input is a multiple of 100.\"\"\"\n",
    "    options = [\"divide\", \"multiply\"]\n",
    "    choice = random.choice(options)\n",
    "    \n",
    "    if choice == \"divide\":\n",
    "        flawed_value = correct_value // 10\n",
    "        explanation = \"It appears a zero was dropped from the number.\"\n",
    "    else: # multiply\n",
    "        flawed_value = correct_value * 10\n",
    "        explanation = \"It appears an extra zero was added to the number.\"\n",
    "\n",
    "    return {\n",
    "        \"flawed_value\": flawed_value,\n",
    "        \"explanation_type\": explanation\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_digit_transposition_error(correct_value: int) -> dict[str, Any] | None:\n",
    "    \"\"\"\n",
    "    Swaps two adjacent digits. Now includes a check to prevent creating\n",
    "    a leading zero, which would alter the number's magnitude.\n",
    "    \"\"\"\n",
    "    # This check is important as this function should only ever receive integers\n",
    "    if not isinstance(correct_value, int):\n",
    "        return None\n",
    "\n",
    "    s_val = str(abs(correct_value))\n",
    "    \n",
    "    # Pre-condition: must have at least 2 digits to swap.\n",
    "    if len(s_val) < 2:\n",
    "        return None\n",
    "\n",
    "    # Find all indices where adjacent digits are different\n",
    "    possible_indices = [i for i in range(len(s_val) - 1) if s_val[i] != s_val[i+1]]\n",
    "    \n",
    "    # --- NEW VALIDATION LOGIC ---\n",
    "    # Filter out swaps that would create a leading zero.\n",
    "    # A swap at index i is invalid if i=0 and the digit at i+1 is '0'.\n",
    "    valid_indices = [\n",
    "        i for i in possible_indices\n",
    "        if not (i == 0 and s_val[i+1] == '0')\n",
    "    ]\n",
    "    \n",
    "    # If no valid swaps are possible, we cannot generate this error.\n",
    "    if not valid_indices:\n",
    "        return None\n",
    "    # --- END NEW LOGIC ---\n",
    "\n",
    "    idx_to_swap = random.choice(valid_indices)\n",
    "    \n",
    "    s_list = list(s_val)\n",
    "    s_list[idx_to_swap], s_list[idx_to_swap+1] = s_list[idx_to_swap+1], s_list[idx_to_swap]\n",
    "    \n",
    "    flawed_value = int(\"\".join(s_list))\n",
    "    if correct_value < 0:\n",
    "        flawed_value = -flawed_value\n",
    "\n",
    "    return {\n",
    "        \"flawed_value\": flawed_value,\n",
    "        \"explanation_type\": \"It appears two adjacent digits were swapped.\"\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_stem_off_by_n_error(\n",
    "    correct_value: int,\n",
    "    offset_range: tuple[int, int] = (1, 3)\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Applies a small offset to the 'stem' of a number (the part before the final zero).\n",
    "    Assumes the input is a non-zero multiple of 10.\n",
    "    \"\"\"\n",
    "    stem = correct_value // 10\n",
    "    \n",
    "    offset = random.randint(offset_range[0], offset_range[1])\n",
    "    if random.random() < 0.5:\n",
    "        offset = -offset\n",
    "\n",
    "    flawed_stem = stem + offset\n",
    "    if flawed_stem == stem:\n",
    "        flawed_stem += 1 # Ensure the value changes\n",
    "\n",
    "    flawed_value = flawed_stem * 10\n",
    "\n",
    "    return {\n",
    "        \"flawed_value\": flawed_value,\n",
    "        \"explanation_type\": \"It appears there was a miscalculation with the digits before the final zero.\"\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_decimal_shift_error(correct_value: float) -> dict[str, Any]:\n",
    "    \"\"\"Multiplies or divides a float by 10 to simulate a decimal shift.\"\"\"\n",
    "    choice = random.choice([\"multiply\", \"divide\"])\n",
    "    flawed_value = correct_value * 10 if choice == \"multiply\" else correct_value / 10\n",
    "    return {\n",
    "        \"flawed_value\": round(flawed_value, 10), # Round to avoid precision issues\n",
    "        \"explanation_type\": \"It appears the decimal point was misplaced.\"\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_float_off_by_n_error(correct_value: float) -> dict[str, Any]:\n",
    "    \"\"\"Applies a small offset to a general float.\"\"\"\n",
    "    # This creates an offset that is roughly 10-20% of the original value's magnitude\n",
    "    magnitude = abs(correct_value)\n",
    "    offset = random.uniform(magnitude * 0.1, magnitude * 0.2)\n",
    "    if random.random() < 0.5:\n",
    "        offset = -offset\n",
    "        \n",
    "    flawed_value = correct_value + offset\n",
    "    return {\n",
    "        \"flawed_value\": round(flawed_value, 10),\n",
    "        \"explanation_type\": \"This appears to be a minor miscalculation.\"\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_reciprocal_error(correct_value: Fraction) -> dict[str, Any] | None:\n",
    "    \"\"\"Swaps the numerator and denominator of a fraction.\"\"\"\n",
    "    if correct_value.denominator == 0: return None # Should not happen\n",
    "    \n",
    "    flawed_value = Fraction(correct_value.denominator, correct_value.numerator)\n",
    "    return {\n",
    "        \"flawed_value\": flawed_value,\n",
    "        \"explanation_type\": \"It appears the numerator and denominator were swapped.\"\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_off_by_one_in_fraction_part_error(correct_value: Fraction) -> dict[str, Any]:\n",
    "    \"\"\"Adds or subtracts 1 from either the numerator or the denominator.\"\"\"\n",
    "    part_to_change = random.choice([\"numerator\", \"denominator\"])\n",
    "    offset = random.choice([-1, 1])\n",
    "\n",
    "    if part_to_change == \"numerator\":\n",
    "        new_num = correct_value.numerator + offset\n",
    "        new_den = correct_value.denominator\n",
    "    else: # denominator\n",
    "        new_num = correct_value.numerator\n",
    "        new_den = correct_value.denominator + offset\n",
    "        # Avoid creating a zero denominator\n",
    "        if new_den == 0:\n",
    "            new_den = correct_value.denominator + (offset * 2)\n",
    "\n",
    "    return {\n",
    "        \"flawed_value\": Fraction(new_num, new_den),\n",
    "        \"explanation_type\": \"It appears there was an off-by-one error in the fraction.\"\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_multiplication_by_reciprocal_error(\n",
    "    numeric_val: 'Any',\n",
    "    fraction_val: 'Fraction'\n",
    ") -> dict[str, Any] | None:\n",
    "    \"\"\"\n",
    "    Simulates an error where a value is multiplied by the reciprocal of the\n",
    "    intended fraction (e.g., x * (b/a) instead of x * (a/b)).\n",
    "\n",
    "    Returns None if the original fraction's numerator is 0 to avoid DivisionByZero.\n",
    "    \"\"\"\n",
    "    # Edge Case: Prevent division by zero\n",
    "    if fraction_val.numerator == 0:\n",
    "        return None\n",
    "\n",
    "    reciprocal_fraction = Fraction(fraction_val.denominator, fraction_val.numerator)\n",
    "    flawed_value = numeric_val * reciprocal_fraction\n",
    "    \n",
    "    return {\n",
    "        \"flawed_value\": flawed_value,\n",
    "        \"explanation_type\": \"It appears the value was multiplied by the reciprocal of the intended fraction.\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f9aa6",
   "metadata": {},
   "source": [
    "### Cell 6: AST and Logical Step Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca578f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import random\n",
    "from typing import Callable, Any\n",
    "\n",
    "def get_target_variables(logical_steps: list[dict]) -> list[str]:\n",
    "    \"\"\"Extracts all 'output_variable' names from the logical steps.\"\"\"\n",
    "    return [step['output_variable'] for step in logical_steps if 'output_variable' in step]\n",
    "\n",
    "\n",
    "def get_operator_for_variable(func: Callable, variable_name: str) -> str | None:\n",
    "    \"\"\"Inspects the AST to find the operator used to compute a variable.\"\"\"\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "    except (TypeError, FileNotFoundError, SyntaxError):\n",
    "        return None\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Assign) and any(isinstance(t, ast.Name) and t.id == variable_name for t in node.targets):\n",
    "            if isinstance(node.value, ast.BinOp):\n",
    "                op = node.value.op\n",
    "                if isinstance(op, ast.Add): return \"add\"\n",
    "                if isinstance(op, ast.Sub): return \"sub\"\n",
    "                if isinstance(op, ast.Mult): return \"mult\"\n",
    "                if isinstance(op, ast.Div): return \"div\"\n",
    "            return \"other\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_operand_names_for_variable(func: Callable, variable_name: str) -> list[str]:\n",
    "    \"\"\"Finds the names of variables used as operands for a target variable.\"\"\"\n",
    "    operand_names = []\n",
    "    try:\n",
    "        src = inspect.getsource(func)\n",
    "        tree = ast.parse(src)\n",
    "    except (TypeError, FileNotFoundError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Assign) and any(isinstance(t, ast.Name) and t.id == variable_name for t in node.targets):\n",
    "            for sub_node in ast.walk(node.value):\n",
    "                if isinstance(sub_node, ast.Name):\n",
    "                    operand_names.append(sub_node.id)\n",
    "            return list(set(operand_names))\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d072a42",
   "metadata": {},
   "source": [
    "### Cell 7: Error applicability logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab6d7048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _get_applicable_integer_errors(\n",
    "    correct_value: int,\n",
    "    operator: str,\n",
    "    operand_values: list\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Returns a list of applicable error generator functions for an integer.\n",
    "    Refined to separate logic for addition/subtraction vs. other operations.\n",
    "    \"\"\"\n",
    "    applicable_generators = []\n",
    "    \n",
    "    # Rule 1: Off-by-n and stem errors are only for addition/subtraction.\n",
    "    if operator in [\"add\", \"sub\"]:\n",
    "        all_end_in_zero = all(isinstance(v, int) and v % 10 == 0 for v in operand_values) if operand_values else False\n",
    "        if all_end_in_zero and correct_value % 10 == 0 and correct_value != 0:\n",
    "            applicable_generators.append(generate_stem_off_by_n_error)\n",
    "        else:\n",
    "            applicable_generators.append(generate_off_by_n_error)\n",
    "\n",
    "    # Rule 2: Factor-of-10 error applies to any operation resulting in a multiple of 100.\n",
    "    if correct_value % 100 == 0 and correct_value != 0:\n",
    "        applicable_generators.append(generate_off_by_factor_of_10_error)\n",
    "    \n",
    "    # Rule 3: Digit transposition applies to any operation resulting in a suitable integer.\n",
    "    if has_distinct_adjacent_digits(correct_value):\n",
    "        applicable_generators.append(generate_digit_transposition_error)\n",
    "        \n",
    "    return applicable_generators\n",
    "\n",
    "\n",
    "def get_applicable_generators(\n",
    "    func: Callable,\n",
    "    correct_trace: dict[str, Any],\n",
    "    variable_name: str\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Identifies and partially instantiates all applicable error generators for a variable.\n",
    "    This version correctly handles integer multiplication.\n",
    "    \"\"\"\n",
    "    applicable_generators = []\n",
    "    correct_value = correct_trace.get(variable_name)\n",
    "    if not isinstance(correct_value, (int, float, Fraction)):\n",
    "        return []\n",
    "\n",
    "    def add_generator(gen_func, value_to_pass):\n",
    "        \"\"\"Creates a callable partial function with the correct value and name.\"\"\"\n",
    "        partial_gen = functools.partial(gen_func, value_to_pass)\n",
    "        partial_gen.__name__ = gen_func.__name__\n",
    "        applicable_generators.append(partial_gen)\n",
    "\n",
    "    # --- Part 1: Type-Based Error Selection ---\n",
    "    if isinstance(correct_value, int) or (isinstance(correct_value, float) and correct_value.is_integer()) or (isinstance(correct_value, Fraction) and correct_value.denominator == 1):\n",
    "        int_val = int(correct_value)\n",
    "        operator = get_operator_for_variable(func, variable_name)\n",
    "        op_names = get_operand_names_for_variable(func, variable_name)\n",
    "        op_vals = [correct_trace.get(name) for name in op_names if name in correct_trace]\n",
    "        \n",
    "        # This now correctly applies integer errors (including transposition) to multiplication results.\n",
    "        integer_gens = _get_applicable_integer_errors(int_val, operator, op_vals)\n",
    "        for gen_func in integer_gens:\n",
    "            add_generator(gen_func, int_val)\n",
    "\n",
    "    elif isinstance(correct_value, float):\n",
    "        add_generator(generate_float_off_by_n_error, correct_value)\n",
    "        if correct_value != 0:\n",
    "            add_generator(generate_decimal_shift_error, correct_value)\n",
    "\n",
    "    elif isinstance(correct_value, Fraction) and correct_value.denominator != 1:\n",
    "        add_generator(generate_off_by_one_in_fraction_part_error, correct_value)\n",
    "        if correct_value.numerator != 0:\n",
    "            add_generator(generate_reciprocal_error, correct_value)\n",
    "\n",
    "    # --- Part 2: Context-Based Error Selection (Multiplication by Reciprocal) ---\n",
    "    operator = get_operator_for_variable(func, variable_name)\n",
    "    if operator == \"mult\":\n",
    "        operand_names = get_operand_names_for_variable(func, variable_name)\n",
    "        operand_values = [correct_trace.get(name) for name in operand_names if name in correct_trace]\n",
    "        \n",
    "        if len(operand_values) == 2:\n",
    "            num_op = next((op for op in operand_values if isinstance(op, (int, float))), None)\n",
    "            frac_op = next((op for op in operand_values if isinstance(op, Fraction)), None)\n",
    "\n",
    "            if num_op is not None and frac_op is not None and frac_op.denominator != 1:\n",
    "                # This error is specific and does not use the standard `add_generator`\n",
    "                reciprocal_mult_gen = functools.partial(\n",
    "                    generate_multiplication_by_reciprocal_error,\n",
    "                    numeric_val=num_op,\n",
    "                    fraction_val=frac_op\n",
    "                )\n",
    "                reciprocal_mult_gen.__name__ = 'generate_multiplication_by_reciprocal_error'\n",
    "                applicable_generators.append(reciprocal_mult_gen)\n",
    "\n",
    "    # Return unique generators, as some rules might overlap\n",
    "    return list(dict.fromkeys(applicable_generators))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b32217",
   "metadata": {},
   "source": [
    "### Cell 8: Orchestrator and artifact generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f775eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_error_line_number(variable_name: str, logical_steps: list[dict]) -> str | None:\n",
    "    \"\"\"Finds the line number corresponding to a given output variable.\"\"\"\n",
    "    for step in logical_steps:\n",
    "        if step.get(\"output_variable\") == variable_name:\n",
    "            return step.get(\"line_number\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def generate_training_artifacts(\n",
    "    logical_steps: list[dict],\n",
    "    error_details: dict[str, Any],\n",
    "    flawed_trace: dict[str, Any]\n",
    ") -> tuple[str, dict] | None:\n",
    "    \"\"\"Generates the final training data: a flawed NL solution and a JSON label.\"\"\"\n",
    "    flawed_solution_map = reconstruct_solution_lines_enhanced(logical_steps, flawed_trace)\n",
    "    if not flawed_solution_map:\n",
    "        return None\n",
    "    \n",
    "    sorted_lines = sorted(flawed_solution_map.items(), key=lambda item: int(item[0][1:]))\n",
    "    flawed_nl_solution = \"\\n\".join([line for _, line in sorted_lines])\n",
    "\n",
    "    erroneous_line = find_error_line_number(error_details[\"variable\"], logical_steps)\n",
    "    if not erroneous_line:\n",
    "        return None\n",
    "\n",
    "    base_explanation = (\n",
    "        f\"The result of this computation should be {error_details['correct_value']}, \"\n",
    "        f\"not {error_details['flawed_value']}.\"\n",
    "    )\n",
    "    type_explanation = error_details[\"explanation_type\"]\n",
    "    final_explanation = f\"{base_explanation} {type_explanation}\"\n",
    "\n",
    "    target_json = {\n",
    "        \"verdict\": \"Flawed\",\n",
    "        \"error_details\": {\n",
    "            \"error_type\": \"computational_error\",\n",
    "            \"erroneous_line_number\": erroneous_line,\n",
    "            \"explanation\": final_explanation,\n",
    "        }\n",
    "    }\n",
    "    return flawed_nl_solution, target_json\n",
    "\n",
    "\n",
    "# def generate_all_valid_errors(\n",
    "#     func: Callable,\n",
    "#     logical_steps: list[dict],\n",
    "#     correct_trace: dict[str, Any]\n",
    "# ) -> list[dict]:\n",
    "#     \"\"\"\n",
    "#     Deterministically generates and validates all possible computational errors for a problem.\n",
    "\n",
    "#     This function iterates through every target variable and every applicable error type,\n",
    "#     producing a comprehensive list of valid flawed examples without retries.\n",
    "\n",
    "#     Returns:\n",
    "#         A list of dictionaries, where each dictionary represents a single valid\n",
    "#         flawed example and has the structure:\n",
    "#         {\n",
    "#             \"variable\": str,\n",
    "#             \"error_type\": str,\n",
    "#             \"flawed_nl_solution\": str,\n",
    "#             \"target_json\": dict\n",
    "#         }\n",
    "#     \"\"\"\n",
    "#     all_generated_examples = []\n",
    "#     target_variables = get_target_variables(logical_steps)\n",
    "\n",
    "#     for variable_name in target_variables:\n",
    "#         correct_value = correct_trace.get(variable_name)\n",
    "        \n",
    "#         # Use a consistent seed for each variable to ensure deterministic error generation\n",
    "#         seed = hash(f\"{variable_name}\")\n",
    "        \n",
    "#         applicable_generators = get_applicable_generators(func, correct_trace, variable_name)\n",
    "\n",
    "#         for generator_func in applicable_generators:\n",
    "#             # Seed based on variable and generator for reproducibility\n",
    "#             random.seed(seed + hash(generator_func.__name__))\n",
    "\n",
    "#             error_result = generator_func()\n",
    "#             if not error_result:\n",
    "#                 continue\n",
    "\n",
    "#             error_details = {\"variable\": variable_name, \"correct_value\": correct_value, **error_result}\n",
    "            \n",
    "#             # Ensure integer-like floats remain floats after error injection\n",
    "#             if isinstance(correct_value, float) and correct_value.is_integer():\n",
    "#                 error_details['flawed_value'] = float(error_details['flawed_value'])\n",
    "\n",
    "#             flawed_trace = generate_flawed_trace(func, error_details)\n",
    "#             if not flawed_trace or not is_trace_valid(flawed_trace, correct_trace):\n",
    "#                 continue\n",
    "            \n",
    "#             artifacts = generate_training_artifacts(logical_steps, error_details, flawed_trace)\n",
    "#             if artifacts:\n",
    "#                 flawed_nl_solution, target_json = artifacts\n",
    "#                 all_generated_examples.append({\n",
    "#                     \"variable\": variable_name,\n",
    "#                     \"error_type\": generator_func.__name__,\n",
    "#                     \"flawed_nl_solution\": flawed_nl_solution,\n",
    "#                     \"target_json\": target_json\n",
    "#                 })\n",
    "\n",
    "#     return all_generated_examples\n",
    "\n",
    "# In Cell 8\n",
    "\n",
    "def generate_all_valid_errors(\n",
    "    func: Callable,\n",
    "    logical_steps: list[dict],\n",
    "    correct_trace: dict[str, Any]\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Deterministically generates and validates all possible computational errors.\n",
    "    --- MODIFIED ---\n",
    "    Now includes correct/flawed values and the specific seed in its output\n",
    "    for enhanced metadata logging.\n",
    "    \"\"\"\n",
    "    all_generated_examples = []\n",
    "    target_variables = get_target_variables(logical_steps)\n",
    "\n",
    "    for variable_name in target_variables:\n",
    "        correct_value = correct_trace.get(variable_name)\n",
    "        base_seed = hash(f\"{variable_name}\")\n",
    "        \n",
    "        applicable_generators = get_applicable_generators(func, correct_trace, variable_name)\n",
    "\n",
    "        for generator_func in applicable_generators:\n",
    "            # --- MODIFIED: Create a reproducible seed specific to this generator ---\n",
    "            repro_seed = base_seed + hash(generator_func.__name__)\n",
    "            random.seed(repro_seed)\n",
    "\n",
    "            error_result = generator_func()\n",
    "            if not error_result:\n",
    "                continue\n",
    "\n",
    "            error_details = {\"variable\": variable_name, \"correct_value\": correct_value, **error_result}\n",
    "            \n",
    "            if isinstance(correct_value, float) and correct_value.is_integer():\n",
    "                error_details['flawed_value'] = float(error_details['flawed_value'])\n",
    "\n",
    "            flawed_trace = generate_flawed_trace(func, error_details)\n",
    "            if not flawed_trace or not is_trace_valid(flawed_trace, correct_trace):\n",
    "                continue\n",
    "            \n",
    "            artifacts = generate_training_artifacts(logical_steps, error_details, flawed_trace)\n",
    "            if artifacts:\n",
    "                flawed_nl_solution, target_json = artifacts\n",
    "                \n",
    "                # --- MODIFIED: Append a richer dictionary ---\n",
    "                all_generated_examples.append({\n",
    "                    \"variable\": variable_name,\n",
    "                    \"error_type\": generator_func.__name__,\n",
    "                    \"flawed_nl_solution\": flawed_nl_solution,\n",
    "                    \"target_json\": target_json,\n",
    "                    \"correct_value\": error_details['correct_value'],\n",
    "                    \"flawed_value\": error_details['flawed_value'],\n",
    "                    \"repro_seed\": repro_seed  # <-- Add the seed\n",
    "                })\n",
    "\n",
    "    return all_generated_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1cbc07",
   "metadata": {},
   "source": [
    "### Cell 9: Serialization Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae8c076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_error_artifacts(\n",
    "#     tier: str,\n",
    "#     index: int,\n",
    "#     model_name: str,\n",
    "#     valid_errors: list[dict],\n",
    "#     base_output_dir: Path = GENERATED_ERRORS_DIR\n",
    "# ) -> list[dict]:\n",
    "#     \"\"\"\n",
    "#     Saves all valid error artifacts to disk in a structured format and\n",
    "#     returns a list of metadata records for the catalog, now including a timestamp.\n",
    "#     \"\"\"\n",
    "#     output_dir = base_output_dir / tier / str(index)\n",
    "#     output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "#     metadata_records = []\n",
    "\n",
    "#     for error_example in valid_errors:\n",
    "#         variable = error_example['variable']\n",
    "#         error_type = error_example['error_type']\n",
    "        \n",
    "#         filename = f\"{model_name}_{variable}_{error_type}.json\"\n",
    "#         filepath = output_dir / filename\n",
    "        \n",
    "#         artifact_content = {\n",
    "#             \"flawed_nl_solution\": error_example[\"flawed_nl_solution\"],\n",
    "#             \"target_json\": error_example[\"target_json\"]\n",
    "#         }\n",
    "        \n",
    "#         with open(filepath, 'w', encoding='utf-8') as f:\n",
    "#             json.dump(artifact_content, f, indent=2)\n",
    "\n",
    "#         # Create a record for the metadata catalog\n",
    "#         record = {\n",
    "#             \"index\": index,\n",
    "#             \"tier\": tier,\n",
    "#             \"model\": model_name,\n",
    "#             \"target_variable\": variable,\n",
    "#             \"error_type\": error_type,\n",
    "#             \"filepath\": str(filepath.relative_to(PROJECT_ROOT)),\n",
    "#             # --- ADDED: Generate a timezone-aware ISO format timestamp ---\n",
    "#             \"utc_timestamp\": datetime.datetime.now(datetime.timezone.utc).isoformat(timespec='seconds')\n",
    "#         }\n",
    "#         metadata_records.append(record)\n",
    "        \n",
    "#     return metadata_records\n",
    "\n",
    "\n",
    "# In Cell 9\n",
    "\n",
    "def save_error_artifacts(\n",
    "    tier: str,\n",
    "    index: int,\n",
    "    model_name: str,\n",
    "    valid_errors: list[dict],\n",
    "    base_output_dir: Path = GENERATED_ERRORS_DIR\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Saves all valid error artifacts to disk and returns metadata records.\n",
    "    --- MODIFIED ---\n",
    "    - Extracts correct/flawed values and the seed.\n",
    "    - Formats the timestamp into separate date and time columns.\n",
    "    \"\"\"\n",
    "    output_dir = base_output_dir / tier / str(index)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    metadata_records = []\n",
    "    now_utc = datetime.datetime.now(datetime.timezone.utc)\n",
    "\n",
    "    for error_example in valid_errors:\n",
    "        variable = error_example['variable']\n",
    "        error_type = error_example['error_type']\n",
    "        \n",
    "        filename = f\"{model_name}_{variable}_{error_type}.json\"\n",
    "        filepath = output_dir / filename\n",
    "        \n",
    "        artifact_content = {\n",
    "            \"flawed_nl_solution\": error_example[\"flawed_nl_solution\"],\n",
    "            \"target_json\": error_example[\"target_json\"]\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(artifact_content, f, indent=2)\n",
    "\n",
    "        # --- MODIFIED: Create the enhanced metadata record ---\n",
    "        record = {\n",
    "            \"index\": index,\n",
    "            \"tier\": tier,\n",
    "            \"model\": model_name,\n",
    "            \"target_variable\": variable,\n",
    "            \"error_type\": error_type,\n",
    "            \"correct_value\": normalize_value(error_example['correct_value']),\n",
    "            \"flawed_value\": normalize_value(error_example['flawed_value']),\n",
    "            \"repro_seed\": error_example['repro_seed'],\n",
    "            \"date_utc\": now_utc.strftime('%Y-%m-%d'),\n",
    "            \"time_utc\": now_utc.strftime('%H:%M:%S'),\n",
    "            \"filepath\": str(filepath.relative_to(PROJECT_ROOT))\n",
    "        }\n",
    "        metadata_records.append(record)\n",
    "        \n",
    "    return metadata_records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfefc9e2",
   "metadata": {},
   "source": [
    "### Cell 10: Main function for error injection pipeline execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed158b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_errors_for_all_manifests(\n",
    "    manifest_dir: Path,\n",
    "    output_dir: Path,\n",
    "    models: list[str]\n",
    "):\n",
    "    \"\"\"\n",
    "    Main driver function to orchestrate error generation for all processed manifests.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Error Generation for All Processed Manifests ---\")\n",
    "    all_metadata = []\n",
    "    \n",
    "    tier_dirs = sorted([d for d in manifest_dir.iterdir() if d.is_dir() and d.name.startswith('tier')])\n",
    "\n",
    "    for tier_dir in tqdm(tier_dirs, desc=\"Tiers\"):\n",
    "        index_dirs = sorted([d for d in tier_dir.iterdir() if d.is_dir()], key=lambda p: int(p.name))\n",
    "        \n",
    "        for index_dir in tqdm(index_dirs, desc=f\"Processing {tier_dir.name}\", leave=False):\n",
    "            index = int(index_dir.name)\n",
    "            \n",
    "            for model_name in models:\n",
    "                # Load components using the modified loading functions\n",
    "                solve_module = load_function_module(tier_dir.name, index, model_name)\n",
    "                logical_steps = load_logical_steps(tier_dir.name, index, model_name)\n",
    "\n",
    "                if not (solve_module and logical_steps):\n",
    "                    continue\n",
    "                \n",
    "                # Generate correct trace (from Cell 4)\n",
    "                solve_function = solve_module.solve\n",
    "                correct_trace = execution_trace(solve_function)\n",
    "                if not correct_trace:\n",
    "                    continue\n",
    "                \n",
    "                # Generate all valid errors using the orchestrator (from Cell 8)\n",
    "                valid_errors = generate_all_valid_errors(solve_function, logical_steps, correct_trace)\n",
    "                \n",
    "                # Save artifacts and collect metadata (from Cell 9)\n",
    "                if valid_errors:\n",
    "                    records = save_error_artifacts(\n",
    "                        tier=tier_dir.name,\n",
    "                        index=index,\n",
    "                        model_name=model_name,\n",
    "                        valid_errors=valid_errors\n",
    "                    )\n",
    "                    all_metadata.extend(records)\n",
    "\n",
    "    # Create and Save the Final Metadata Catalog\n",
    "    if all_metadata:\n",
    "        catalog_df = pd.DataFrame(all_metadata)\n",
    "        catalog_path = output_dir / \"computational_error_catalog.csv\"\n",
    "        catalog_df.to_csv(catalog_path, index=False)\n",
    "        print(f\"\\nSuccessfully generated {len(catalog_df)} error examples.\")\n",
    "        print(f\"Metadata catalog saved to: {catalog_path}\")\n",
    "    else:\n",
    "        print(\"\\nNo error examples were generated.\")\n",
    "        \n",
    "    print(\"\\n--- Error Generation Pipeline Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0a02af",
   "metadata": {},
   "source": [
    "### Executing the whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98b8e0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Error Generation for All Processed Manifests ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0ac4f21f8b40b1a740befa84b93e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tiers:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c353e3bc0c74ee0b660b23c6401bfea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tier1:   0%|          | 0/1138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77015fa7d4d64ae9946fb52cfa9b3f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tier2:   0%|          | 0/332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2b525872304b2bb38a952e6e034564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tier3:   0%|          | 0/1262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585aa4a196084f82beaef6520d83be8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing tier4:   0%|          | 0/185 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully generated 15775 error examples.\n",
      "Metadata catalog saved to: /Users/arvindsuresh/Documents/Github/Erdos-DL-June25-Math/data/computational-errors-generated/computational_error_catalog.csv\n",
      "\n",
      "--- Error Generation Pipeline Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Execute the Pipeline ---\n",
    "generate_errors_for_all_manifests(\n",
    "    manifest_dir=PROCESSED_MANIFEST_DIR,\n",
    "    output_dir=GENERATED_ERRORS_DIR,\n",
    "    models=MODELS\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
