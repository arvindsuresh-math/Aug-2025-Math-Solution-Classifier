{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f64a70a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f64a70a",
        "outputId": "22a26995-b780-4d93-9e75-07a3f7712c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully.\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu124\n",
            "Requirement already satisfied: flash-attn==2.7.4.post1 in /usr/local/lib/python3.11/dist-packages (2.7.4.post1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.7.4.post1) (2.6.0+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.7.4.post1) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.7.4.post1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn==2.7.4.post1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn==2.7.4.post1) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup and Installations\n",
        "\n",
        "# 1.1 Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully.\")\n",
        "\n",
        "# 1.2 Install required libraries\n",
        "# Note: TRL is included for consistency with your original script, but is not\n",
        "# strictly required for this sequence classification task.\n",
        "!pip install -Uq transformers\n",
        "!pip install -Uq peft\n",
        "!pip install -Uq trl\n",
        "!pip install -Uq accelerate\n",
        "!pip install -Uq datasets\n",
        "!pip install -Uq bitsandbytes\n",
        "\n",
        "# Install Flash Attention 2\n",
        "!pip install flash-attn==2.7.4.post1 \\\n",
        "  --extra-index-url https://download.pytorch.org/whl/cu124 \\\n",
        "  --no-build-isolation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "heGM58MzMgM6"
      },
      "id": "heGM58MzMgM6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Replace 'path/to/your/key.txt' with the actual path to your key file in Google Drive\n",
        "key_file_path = '/content/drive/MyDrive/Erdos/huggingface_key.txt'\n",
        "\n",
        "try:\n",
        "    with open(key_file_path, 'r') as f:\n",
        "        key = f.read().strip()\n",
        "    print(\"Key loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Key file not found at {key_file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TY0HjwLLdv4",
        "outputId": "15c7e01a-cb67-4be4-fc2a-3c7825c65eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Key loaded successfully.\n"
          ]
        }
      ],
      "id": "2TY0HjwLLdv4"
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(key)"
      ],
      "metadata": {
        "id": "fQLBSKXiMcPJ"
      },
      "id": "fQLBSKXiMcPJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e27a641",
      "metadata": {
        "id": "3e27a641"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Project Configuration\n",
        "\n",
        "class Config:\n",
        "    # Model ID from Hugging Face Hub\n",
        "    MODEL_ID = \"meta-llama/Llama-3.2-3B\"\n",
        "\n",
        "    # Local path to the unzipped dataset\n",
        "    DATASET_PATH = \"/content/drive/MyDrive/Erdos/finetuning_data/level-1-binary/level-1-binary\"\n",
        "\n",
        "    # Directory for saving the final model adapter\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/Erdos/finetuning_data/llama3B_finetuning\"\n",
        "\n",
        "    # Number of labels for the classification task\n",
        "    NUM_LABELS = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5828e2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498,
          "referenced_widgets": [
            "3ea3746f1b5f401eb60ceb714d37add5",
            "66e3b4e49732401a889b46053d6c6daa",
            "7b08b6bd580846cda187c63ac19d2b9f",
            "0ef5abe40939410f85aa3b45b092e128",
            "957ac7f63720464eafe8eb5f69d0dd35",
            "12a8707916f74306a9c124dec3eb6bef",
            "aa4d51e0d29e4a49925c988c5dc1b638",
            "4dfc5bcb2c1c4ee087b585a8bec693ba",
            "1616efa5d8424055a37094190a153d94",
            "8e8ca166ce7c4858866720b38f232e78",
            "83351d36a7df494cb645b930a8713fb1"
          ]
        },
        "id": "b5828e2a",
        "outputId": "7e4cc9c3-9e97-4e91-db17-5098a240a22a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/412 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ea3746f1b5f401eb60ceb714d37add5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tokenized dataset ---\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['index', 'label', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 3296\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['index', 'label', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 412\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['index', 'label', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 412\n",
            "    })\n",
            "})\n",
            "\n",
            "Example record:\n",
            "{'index': 1325, 'label': 1, 'input_ids': [128000, 2127, 56956, 279, 2768, 37072, 3575, 323, 6425, 311, 8417, 422, 279, 6425, 374, 4495, 477, 48008, 382, 14711, 22854, 512, 50, 750, 15662, 400, 1041, 15, 520, 990, 1566, 2305, 13, 1115, 2305, 11, 1364, 4036, 264, 220, 605, 4, 4933, 13, 2650, 1790, 3300, 690, 1364, 1304, 304, 2860, 369, 279, 1403, 4038, 1980, 14711, 12761, 512, 2028, 2305, 1364, 690, 7380, 400, 1041, 15, 353, 320, 605, 14, 1041, 8, 284, 400, 2501, 1041, 15, 6737, 605, 14, 1041, 11992, 1041, 2511, 1041, 627, 644, 2860, 11, 1364, 690, 1304, 400, 1041, 15, 489, 400, 1041, 284, 400, 2501, 1041, 15, 10, 1041, 28, 5120, 15, 2511, 5120, 15, 627, 827, 220, 5120, 15], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Data Loading and Preprocessing\n",
        "\n",
        "from datasets import load_from_disk\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 3.1 Load the tokenizer needed for preprocessing\n",
        "# This will be the same tokenizer used for the model later.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    Config.MODEL_ID,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "tokenizer.padding_side = \"left\"      # Flash-Attn requires left padding\n",
        "# Set a padding token if one is not already defined\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# 3.2 Load the raw dataset from disk\n",
        "raw_dataset = load_from_disk(Config.DATASET_PATH)\n",
        "\n",
        "# 3.3 Define the preprocessing function\n",
        "def preprocess_function(examples):\n",
        "    \"\"\"\n",
        "    Formats the input text and tokenizes it for sequence classification.\n",
        "    The label is passed through untouched.\n",
        "    \"\"\"\n",
        "    # Create a single input string per example\n",
        "    # Note: We do not include the label (0 or 1) in the input text itself.\n",
        "    system_prompt = \"Analyze the following mathematical problem and solution to determine if the solution is correct or flawed.\"\n",
        "    input_texts = [\n",
        "        f\"{system_prompt}\\n\\n### Problem:\\n{q}\\n\\n### Solution:\\n{s}\"\n",
        "        for q, s in zip(examples[\"question\"], examples[\"solution\"])\n",
        "    ]\n",
        "\n",
        "    # Tokenize the texts\n",
        "    # The tokenizer will return 'input_ids' and 'attention_mask'.\n",
        "    return tokenizer(\n",
        "        input_texts,\n",
        "        truncation=True,\n",
        "        max_length=512,  # A reasonable max length for these problems\n",
        "        padding=False    # Padding will be handled by the data collator\n",
        "    )\n",
        "\n",
        "# 3.4 Apply the preprocessing function to the dataset\n",
        "# We use batched=True for efficiency and remove original text columns.\n",
        "tokenized_dataset = raw_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"question\", \"solution\"]\n",
        ")\n",
        "\n",
        "# 3.5 Verify the new dataset structure\n",
        "print(\"--- Tokenized dataset ---\")\n",
        "print(tokenized_dataset)\n",
        "print(\"\\nExample record:\")\n",
        "print(tokenized_dataset[\"train\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d83b4e68",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d83b4e68",
        "outputId": "552954d8-f3cc-48eb-a95e-6a9d6c20d98d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Merged dataset for training ---\n"
          ]
        }
      ],
      "source": [
        "# Cell 3.5: Merge Datasets for Training\n",
        "\n",
        "from datasets import concatenate_datasets, DatasetDict\n",
        "\n",
        "# 3.5.1 Combine the 'train' and 'validation' splits\n",
        "# This creates a larger training set for the model.\n",
        "full_train_dataset = concatenate_datasets(\n",
        "    [tokenized_dataset[\"train\"], tokenized_dataset[\"validation\"]]\n",
        ")\n",
        "\n",
        "# 3.5.2 Create a new DatasetDict with the merged training set and the original test set\n",
        "final_dataset = DatasetDict({\n",
        "    \"train\": full_train_dataset,\n",
        "    \"test\": tokenized_dataset[\"test\"]\n",
        "})\n",
        "\n",
        "print(\"--- Merged dataset for training ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6fe0346",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "1835331d64f34615ac650f3a8789c8f0",
            "3ba0242d175b461584f3b4e303d54705",
            "0246f61dbdfe4e198308814245c7e98e",
            "202889936fb34e949766811c92bdb8db",
            "0d61801a2b614343ae78644280f31218",
            "1baf3198cd0145af84119066077b5841",
            "0e5ba171a3884eebb24e4bf99747b349",
            "7cc049c200e14814988a3a7c435761c2",
            "2e6ee5da16364bae87053aad51331f4c",
            "15641acc8950468ca965c622425ad25c",
            "52306cc3cda1450683725a8bc74c1be9"
          ]
        },
        "id": "d6fe0346",
        "outputId": "92132728-b9be-40be-9fb3-3ad91442b10f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1835331d64f34615ac650f3a8789c8f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 24,313,856 || all params: 3,237,063,680 || trainable%: 0.7511\n",
            "--- LoRA+classifier model ready ---\n"
          ]
        }
      ],
      "source": [
        "# ────────────────────────────────────────────────────────────────\n",
        "# Cell 4-5 · Tokenizer, 4-bit backbone → LoRA + custom classifier\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "import torch, torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# ----- Config -----\n",
        "NUM_LABELS = Config.NUM_LABELS      # e.g. 2\n",
        "DTYPE       = torch.bfloat16        # A100 native\n",
        "\n",
        "quant_cfg = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=DTYPE,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_ID, trust_remote_code=True)\n",
        "tokenizer.padding_side = \"left\"      # Flash-Attn requires left padding\n",
        "tokenizer.pad_token = tokenizer.pad_token or tokenizer.eos_token\n",
        "\n",
        "# 1. load causal-LM in 4-bit\n",
        "backbone = AutoModelForCausalLM.from_pretrained(\n",
        "    Config.MODEL_ID,\n",
        "    quantization_config=quant_cfg,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        ")\n",
        "backbone.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "# 2. LoRA on all linear layers\n",
        "lora_cfg = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,   # still “SEQ_CLS” so PEFT knows to train a head\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    target_modules=\"all-linear\",\n",
        ")\n",
        "backbone = get_peft_model(backbone, lora_cfg)\n",
        "\n",
        "# 3. custom classification wrapper\n",
        "class GPTSequenceClassifier(nn.Module):\n",
        "    def __init__(self, base_model, num_labels):\n",
        "        super().__init__()\n",
        "        self.base = base_model                       # LoRA-augmented Φ-4-mini\n",
        "        hidden = base_model.config.hidden_size\n",
        "        self.classifier = nn.Linear(hidden, num_labels, bias=True)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kw):\n",
        "        outputs = self.base(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_hidden_states=True,\n",
        "            **kw,\n",
        "        )\n",
        "        last_hidden = outputs.hidden_states[-1]      # (B, L, H)\n",
        "        pooled      = last_hidden[:, -1, :]          # use last token\n",
        "        logits      = self.classifier(pooled)        # (B, num_labels)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = nn.functional.cross_entropy(logits, labels)\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits} if loss is not None else {\"logits\": logits}\n",
        "\n",
        "model = GPTSequenceClassifier(backbone, NUM_LABELS)\n",
        "# call on the LoRA-augmented backbone instead\n",
        "backbone.print_trainable_parameters()\n",
        "print(\"--- LoRA+classifier model ready ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Compute metrics for binary classification\n",
        "    \"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # Get the predicted class (argmax for multi-class, but for binary we can use > 0.5)\n",
        "    if predictions.ndim == 2:\n",
        "        # If logits are returned, take argmax\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "    else:\n",
        "        # If probabilities are returned, threshold at 0.5\n",
        "        predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall\n",
        "    }"
      ],
      "metadata": {
        "id": "isKgDMNANqXC"
      },
      "id": "isKgDMNANqXC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b14c14a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b14c14a",
        "outputId": "384834a9-ba83-40bf-fa1e-0e079a6db25a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Trainer initialised ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-9-1445400942.py:33: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=Config.OUTPUT_DIR,\n",
        "\n",
        "    # —— Batching ——\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,   # safe default on 4-bit + A100\n",
        "    gradient_accumulation_steps=4,   # effective 32\n",
        "\n",
        "    # —— Optimiser / sched ——\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    learning_rate=2e-4,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.1,\n",
        "\n",
        "    # —— Precision / memory ——\n",
        "    bf16=True,                       # A100 native bf16\n",
        "    gradient_checkpointing=False,\n",
        "\n",
        "    # —— Logging / ckpt ——\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=25,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        "    report_to=\"none\",\n",
        "    save_safetensors=False,\n",
        "\n",
        "    # —— Evaluation ——\n",
        "    # evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=final_dataset[\"train\"],\n",
        "    # eval_dataset=final_dataset[\"test\"],   # drop if you have no split\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,            # ↳ defined earlier\n",
        ")\n",
        "\n",
        "print(\"--- Trainer initialised ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c9bdd06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "2c9bdd06",
        "outputId": "aea7f935-9ad1-48ac-899e-35531ae6b19b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting model training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='348' max='348' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [348/348 11:38, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>3.422500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.399800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>2.985200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.902500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>2.789900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.746100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>2.654200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.263600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>2.312300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>2.088700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>1.915200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.689800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>1.762800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Execute Training\n",
        "\n",
        "print(\"Starting model training...\")\n",
        "trainer.train()\n",
        "print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70f17c5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "70f17c5b",
        "outputId": "0fd6a805-66ec-4b85-ce90-29068e0897bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating on the test set ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [52/52 00:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set performance:\n",
            "{'eval_loss': 0.47961145639419556, 'eval_accuracy': 0.7524271844660194, 'eval_runtime': 11.5439, 'eval_samples_per_second': 35.69, 'eval_steps_per_second': 4.505, 'epoch': 3.0}\n",
            "\n",
            "Saving final model adapter to /content/drive/MyDrive/Erdos/finetuning_data/llama3B_finetuning...\n",
            "Model saved successfully.\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Final Evaluation and Saving\n",
        "\n",
        "def compute_metrics_new(p):\n",
        "    # HF passes either a plain ndarray or a tuple; handle both robustly\n",
        "    logits = p.predictions[0] if isinstance(p.predictions, (tuple, list)) else p.predictions\n",
        "\n",
        "    preds  = np.argmax(logits, axis=1)\n",
        "    labels = p.label_ids\n",
        "    return {\"accuracy\": (preds == labels).mean().item()}\n",
        "\n",
        "trainer.compute_metrics = compute_metrics_new\n",
        "\n",
        "# 9.1 Evaluate the model on the test set\n",
        "print(\"\\n--- Evaluating on the test set ---\")\n",
        "test_results = trainer.evaluate(eval_dataset=final_dataset[\"test\"])\n",
        "\n",
        "# 9.2 Print the evaluation results\n",
        "print(\"Test set performance:\")\n",
        "print(test_results)\n",
        "\n",
        "# 9.3 Save the final trained LoRA adapter\n",
        "print(f\"\\nSaving final model adapter to {Config.OUTPUT_DIR}...\")\n",
        "trainer.save_model(Config.OUTPUT_DIR)\n",
        "print(\"Model saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kpiaq7jqBHxr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpiaq7jqBHxr",
        "outputId": "1f9f0825-0896-4701-d002-8d3cfbe67c2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'index': 1417, 'label': 0, 'input_ids': [128000, 2127, 56956, 279, 2768, 37072, 3575, 323, 6425, 311, 8417, 422, 279, 6425, 374, 4495, 477, 48008, 382, 14711, 22854, 512, 791, 2694, 315, 24270, 323, 23880, 596, 17051, 1457, 374, 220, 22, 13, 24270, 374, 220, 16, 1060, 9191, 1109, 23880, 13, 2650, 2362, 374, 24270, 1980, 14711, 12761, 512, 2746, 865, 374, 23880, 596, 4325, 11, 1243, 24270, 596, 4325, 374, 865, 489, 220, 16, 627, 791, 24524, 430, 11105, 279, 2694, 315, 872, 17051, 374, 865, 489, 865, 489, 220, 16, 284, 220, 22, 627, 1383, 35271, 1093, 3878, 11, 279, 24524, 9221, 220, 17, 87, 284, 220, 21, 627, 39, 768, 11, 279, 907, 315, 865, 902, 11105, 279, 4325, 315, 23880, 374, 220, 21, 14, 17, 28, 2501, 21, 14, 17, 28, 18, 2511, 18, 627, 4516, 29829, 84, 374, 220, 18, 489, 220, 16, 284, 1134, 18, 10, 16, 28, 19, 2511, 19, 1667, 2362, 627, 827, 220, 19], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "print(final_dataset['test'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FSUGEIDzCBy4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "FSUGEIDzCBy4",
        "outputId": "46b79a41-ca28-4e31-bda6-06414386e96e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   index  true_label  p(class=0)  p(class=1)\n",
            "0   1417           0    0.848094    0.151906\n",
            "1   1179           1    0.631594    0.368406\n",
            "2   1299           1    0.520496    0.479504\n",
            "3   2527           0    0.831827    0.168173\n",
            "4    880           0    0.674479    0.325521\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd   # only if you want a tidy table\n",
        "\n",
        "# 1. Forward pass (no grad) over the test set\n",
        "pred_outputs = trainer.predict(final_dataset[\"test\"])   # returns EvalPrediction\n",
        "\n",
        "# 2. Extract logits – shape: (num_samples, num_labels)\n",
        "logits = pred_outputs.predictions if not isinstance(pred_outputs.predictions, (tuple, list)) \\\n",
        "         else pred_outputs.predictions[0]\n",
        "\n",
        "# 3. Convert to probabilities\n",
        "probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()  # (N, C) NumPy array\n",
        "\n",
        "# 4. (optional) wrap in a DataFrame for easy inspection / CSV export\n",
        "df = pd.DataFrame(\n",
        "    probs,\n",
        "    columns=[f\"p(class={i})\" for i in range(probs.shape[1])],\n",
        ")\n",
        "\n",
        "# 5. add auxiliary fields from the dataset\n",
        "df[\"index\"]      = final_dataset[\"test\"][\"index\"]   # ← your original sample ID\n",
        "df[\"true_label\"] = final_dataset[\"test\"][\"label\"]\n",
        "\n",
        "# optional: move index to first column\n",
        "cols = [\"index\", \"true_label\"] + [c for c in df.columns if c.startswith(\"p(\")]\n",
        "df = df[cols]\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# 5. Save if you like\n",
        "df.to_csv(\"test_probs_llama3B_finetuned.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A-3ISKYvGsUd",
      "metadata": {
        "id": "A-3ISKYvGsUd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8664b049"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "PREDICTED_PROBAS_PATH = \"/content/drive/MyDrive/Erdos/finetuning_data/test_probs/test_probs_llama3B_finetuned.csv\"\n",
        "\n",
        "# ── 1 · load files ───────────────────────────────────────────────\n",
        "probs_df  = pd.read_csv(PREDICTED_PROBAS_PATH)                 # your earlier export\n",
        "meta_df   = pd.read_csv(\"/content/drive/MyDrive/Erdos/finetuning_data/level-1-binary/level-1-binary/sft_level1_catalog.csv\")  # the metadata file\n",
        "\n",
        "# ── 2 · merge on (index, true_label) ─────────────────────────────\n",
        "\n",
        "# Rename label to true_label for consistency\n",
        "meta_df.rename(columns={\"label\": \"true_label\"}, inplace=True)\n",
        "df = probs_df.merge(meta_df, on=[\"index\", \"true_label\"], how=\"inner\")\n",
        "\n",
        "# sanity-check\n",
        "assert len(df) == len(probs_df), \"some rows failed to merge\"\n",
        "\n",
        "# ── 3 · binary confusion matrix (correct = 0, incorrect = 1) ─────\n",
        "# 3.1 predicted class from probs\n",
        "prob_cols = [c for c in df.columns if c.startswith(\"p(class=\")]\n",
        "df[\"y_pred\"]  = df[prob_cols].values.argmax(axis=1)            # 0 or 1\n",
        "df[\"y_true\"]  = df[\"true_label\"]                               # 0 or 1\n",
        "\n",
        "cm_bin = confusion_matrix(df[\"y_true\"], df[\"y_pred\"], labels=[0, 1])\n",
        "print(\"Binary confusion-matrix (0=correct, 1=flawed):\\n\", cm_bin)\n",
        "\n",
        "# (optional) visual\n",
        "ConfusionMatrixDisplay(cm_bin, display_labels=[\"correct(0)\", \"flawed(1)\"]).plot()\n",
        "plt.show()\n",
        "\n",
        "# ── 4 · 3-class confusion matrix ────────────────────────────────\n",
        "# ── map ground-truth into three groups ───────────────────────────────────────\n",
        "def collapse_error_type(row):\n",
        "    if row[\"true_label\"] == 0:\n",
        "        return \"correct\"\n",
        "    return \"conceptual\" if row[\"error_type\"] == \"conceptual\" else \"computational\"\n",
        "\n",
        "df[\"y_true_3\"] = df.apply(collapse_error_type, axis=1)\n",
        "\n",
        "# ── binary model output: 0 → correct, 1 → **generic “incorrect”** ────────────\n",
        "df[\"y_pred_2\"] = df[\"y_pred\"].map({0: \"correct\", 1: \"flawed\"})\n",
        "\n",
        "# ── 3 × 2 confusion matrix via crosstab ───────────────────────────\n",
        "cm_3x2 = pd.crosstab(\n",
        "    df[\"y_true_3\"],\n",
        "    df[\"y_pred_2\"],\n",
        "    rownames=[\"true\"],\n",
        "    colnames=[\"pred\"],\n",
        "    dropna=False,\n",
        ").reindex(index=[\"correct\", \"conceptual\", \"computational\"],\n",
        "          columns=[\"correct\", \"flawed\"],\n",
        "          fill_value=0)\n",
        "\n",
        "print(\"3 × 2 confusion matrix:\")\n",
        "print(cm_3x2)"
      ],
      "id": "8664b049"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ea3746f1b5f401eb60ceb714d37add5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66e3b4e49732401a889b46053d6c6daa",
              "IPY_MODEL_7b08b6bd580846cda187c63ac19d2b9f",
              "IPY_MODEL_0ef5abe40939410f85aa3b45b092e128"
            ],
            "layout": "IPY_MODEL_957ac7f63720464eafe8eb5f69d0dd35"
          }
        },
        "66e3b4e49732401a889b46053d6c6daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12a8707916f74306a9c124dec3eb6bef",
            "placeholder": "​",
            "style": "IPY_MODEL_aa4d51e0d29e4a49925c988c5dc1b638",
            "value": "Map: 100%"
          }
        },
        "7b08b6bd580846cda187c63ac19d2b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dfc5bcb2c1c4ee087b585a8bec693ba",
            "max": 412,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1616efa5d8424055a37094190a153d94",
            "value": 412
          }
        },
        "0ef5abe40939410f85aa3b45b092e128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e8ca166ce7c4858866720b38f232e78",
            "placeholder": "​",
            "style": "IPY_MODEL_83351d36a7df494cb645b930a8713fb1",
            "value": " 412/412 [00:00&lt;00:00, 4355.09 examples/s]"
          }
        },
        "957ac7f63720464eafe8eb5f69d0dd35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12a8707916f74306a9c124dec3eb6bef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa4d51e0d29e4a49925c988c5dc1b638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dfc5bcb2c1c4ee087b585a8bec693ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1616efa5d8424055a37094190a153d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e8ca166ce7c4858866720b38f232e78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83351d36a7df494cb645b930a8713fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1835331d64f34615ac650f3a8789c8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ba0242d175b461584f3b4e303d54705",
              "IPY_MODEL_0246f61dbdfe4e198308814245c7e98e",
              "IPY_MODEL_202889936fb34e949766811c92bdb8db"
            ],
            "layout": "IPY_MODEL_0d61801a2b614343ae78644280f31218"
          }
        },
        "3ba0242d175b461584f3b4e303d54705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1baf3198cd0145af84119066077b5841",
            "placeholder": "​",
            "style": "IPY_MODEL_0e5ba171a3884eebb24e4bf99747b349",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0246f61dbdfe4e198308814245c7e98e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cc049c200e14814988a3a7c435761c2",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e6ee5da16364bae87053aad51331f4c",
            "value": 2
          }
        },
        "202889936fb34e949766811c92bdb8db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15641acc8950468ca965c622425ad25c",
            "placeholder": "​",
            "style": "IPY_MODEL_52306cc3cda1450683725a8bc74c1be9",
            "value": " 2/2 [00:07&lt;00:00,  3.49s/it]"
          }
        },
        "0d61801a2b614343ae78644280f31218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1baf3198cd0145af84119066077b5841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e5ba171a3884eebb24e4bf99747b349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cc049c200e14814988a3a7c435761c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e6ee5da16364bae87053aad51331f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15641acc8950468ca965c622425ad25c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52306cc3cda1450683725a8bc74c1be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}