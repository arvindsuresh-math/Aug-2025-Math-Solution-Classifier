{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee417ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from url_to_llm_text.get_llm_ready_text import url_to_llm_text\n",
    "import asyncio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a36f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_and_save(url: str, filename: str):\n",
    "    \"\"\"\n",
    "    Scrape the content from the given URL and save it in a format suitable for LLM processing.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL to scrape.\n",
    "    \n",
    "    Returns:\n",
    "        str: The processed text ready for LLM input.\n",
    "    \"\"\"\n",
    "    llm_text = await url_to_llm_text(url)\n",
    "    filepath = f\"scraped-webpages/{filename}.txt\"\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(\"scraped-webpages\", exist_ok=True)\n",
    "\n",
    "    with open(filepath, 'w') as file:\n",
    "        file.write(llm_text)\n",
    "    return llm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da00cafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/erdos-dl/lib/python3.12/site-packages/bs4/builder/_lxml.py:383: RuntimeWarning: coroutine 'url_to_llm_text' was never awaited\n",
      "  for attr, value in list(new_attrs.items()):\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "result = await scrape_and_save(\n",
    "    url=\"https://huggingface.co/docs/transformers/v4.53.1/en/main_classes/trainer\",\n",
    "    filename=\"huggingface_transformers_trainer_doc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9922548",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await scrape_and_save(\n",
    "    url=\"https://huggingface.co/docs/trl/v0.19.1/en/sft_trainer\",\n",
    "    filename=\"huggingface_transformers_sfttrainer_doc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52f94dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await scrape_and_save(\n",
    "    url=\"https://huggingface.co/docs/transformers/v4.53.1/en/main_classes/tokenizer\",\n",
    "    filename=\"huggingface_transformers_tokenizer_doc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db920732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from url_to_llm_text.get_llm_ready_text import url_to_llm_text\n",
    "from urllib.parse import urlparse\n",
    "import asyncio\n",
    "\n",
    "class HuggingFaceDocFormatter:\n",
    "    \"\"\"Integrated scraper and formatter for Hugging Face documentation.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.patterns = self._initialize_patterns()\n",
    "    \n",
    "    def _initialize_patterns(self):\n",
    "        \"\"\"Initialize regex patterns for formatting.\"\"\"\n",
    "        return {\n",
    "            'cleanup': [\n",
    "                (r'Hugging Face: https://huggingface\\.co/.*?Sign Up: https://huggingface\\.co/join', ''),\n",
    "                (r'üè° View all docs.*?timm\\s*Search documentation', ''),\n",
    "                (r'mainv\\d+\\.\\d+\\.\\d+.*?EN\\s*', ''),\n",
    "                (r'\\d+,?\\d*: https://github\\.com/huggingface/\\w+', ''),\n",
    "                (r'Join the Hugging Face community.*?to get started', ''),\n",
    "                (r'\\n{3,}', '\\n\\n'),\n",
    "                (r'[ \\t]+$', ''),\n",
    "            ],\n",
    "            'headers': [\n",
    "                (r'(\\w+) documentation\\s+([\\w\\s-]+?)(?:\\s+\\1|\\s*$)', r'# \\1 Documentation - \\2'),\n",
    "                (r': https://huggingface\\.co/docs/[\\w/.-]+#[\\w-]+ ([A-Z][A-Za-z\\s&-]+)(?=\\n|$)', r'## \\1'),\n",
    "                (r': https://huggingface\\.co/docs/[\\w/.-]+ ([A-Z][A-Za-z\\s&-]+)(?=\\n|$)', r'### \\1'),\n",
    "            ],\n",
    "            'code_blocks': [\n",
    "                (r'Copied\\s*(```\\w*\\n.*?```)', r'\\1'),\n",
    "                (r'Copied\\s*([^`\\n]+(?:\\n[^`\\n]+)*?)(?=\\n\\n|\\n[A-Z]|\\Z)', r'```python\\n\\1\\n```'),\n",
    "            ],\n",
    "            'classes': [\n",
    "                (r'class (trl|transformers)\\. (\\w+)', r'### `\\1.\\2`'),\n",
    "                (r'< source >: https://github\\.com/huggingface/[\\w/.-]+', ''),\n",
    "            ],\n",
    "            'lists': [\n",
    "                (r'^\\s*\\*\\s+', '- ', re.MULTILINE),\n",
    "                (r'Important attributes:\\s*\\*\\s*', '\\n**Important attributes:**\\n\\n- '),\n",
    "                (r'\\*\\s*(\\w+)\\s*‚Äî\\s*', r'- **\\1** ‚Äî '),\n",
    "            ],\n",
    "            'links': [\n",
    "                (r': https://huggingface\\.co/docs/[\\w/.-]+', ''),\n",
    "                (r'https://img\\.shields\\.io/badge/[^\\s]+', ''),\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def _apply_patterns(self, content, pattern_category):\n",
    "        \"\"\"Apply a category of regex patterns.\"\"\"\n",
    "        patterns = self.patterns.get(pattern_category, [])\n",
    "        for pattern_info in patterns:\n",
    "            if len(pattern_info) == 2:\n",
    "                pattern, replacement = pattern_info\n",
    "                flags = 0\n",
    "            else:\n",
    "                pattern, replacement, flags = pattern_info\n",
    "            content = re.sub(pattern, replacement, content, flags=flags)\n",
    "        return content\n",
    "    \n",
    "    def _extract_title_from_content(self, content):\n",
    "        \"\"\"Extract a suitable title from the documentation content.\"\"\"\n",
    "        # Try to find the main documentation title\n",
    "        title_patterns = [\n",
    "            r'(\\w+) documentation\\s+([\\w\\s-]+)',\n",
    "            r'# ([\\w\\s-]+)',\n",
    "            r'^([A-Z][A-Za-z\\s&-]+)(?=\\n|$)',\n",
    "        ]\n",
    "        \n",
    "        for pattern in title_patterns:\n",
    "            match = re.search(pattern, content, re.MULTILINE)\n",
    "            if match:\n",
    "                if len(match.groups()) == 2:\n",
    "                    return f\"{match.group(1)}_{match.group(2)}\"\n",
    "                else:\n",
    "                    return match.group(1)\n",
    "        \n",
    "        return \"huggingface_doc\"\n",
    "    \n",
    "    def _url_to_filename(self, url, content):\n",
    "        \"\"\"Generate a filename from URL and content.\"\"\"\n",
    "        # Extract title from content\n",
    "        title = self._extract_title_from_content(content)\n",
    "        \n",
    "        # Clean up title for filename\n",
    "        filename = re.sub(r'[^\\w\\s-]', '', title.lower())\n",
    "        filename = re.sub(r'[-\\s]+', '_', filename)\n",
    "        filename = filename.strip('_')\n",
    "        \n",
    "        # Add URL-based context if needed\n",
    "        parsed = urlparse(url)\n",
    "        path_parts = [p for p in parsed.path.split('/') if p and p not in ['docs', 'en']]\n",
    "        \n",
    "        if path_parts:\n",
    "            url_context = '_'.join(path_parts[-2:])  # Last 2 parts\n",
    "            url_context = re.sub(r'[^\\w]', '_', url_context)\n",
    "            if url_context not in filename:\n",
    "                filename = f\"{filename}_{url_context}\"\n",
    "        \n",
    "        return filename\n",
    "    \n",
    "    def format_documentation(self, content):\n",
    "        \"\"\"Format the raw documentation content.\"\"\"\n",
    "        # Apply all formatting patterns\n",
    "        for category in ['cleanup', 'headers', 'code_blocks', 'classes', 'lists', 'links']:\n",
    "            content = self._apply_patterns(content, category)\n",
    "        \n",
    "        # Format parameter lists\n",
    "        content = re.sub(r'\\( ([^)]+) \\)', self._format_parameters, content)\n",
    "        \n",
    "        # Wrap class definitions in code blocks\n",
    "        content = re.sub(\n",
    "            r'(### `\\w+\\.\\w+`.*?)(?=###|\\Z)', \n",
    "            self._format_class_block, \n",
    "            content, \n",
    "            flags=re.DOTALL\n",
    "        )\n",
    "        \n",
    "        # Add proper spacing around headers\n",
    "        content = re.sub(r'(#{1,6}[^\\n]+)', r'\\n\\1\\n', content)\n",
    "        content = re.sub(r'\\n{3,}', '\\n\\n', content)\n",
    "        \n",
    "        return content.strip()\n",
    "    \n",
    "    def _format_parameters(self, match):\n",
    "        \"\"\"Format parameter lists.\"\"\"\n",
    "        param_string = match.group(1)\n",
    "        if len(param_string) > 100:\n",
    "            params = [p.strip() for p in param_string.split(',') if p.strip()]\n",
    "            if len(params) > 3:\n",
    "                formatted_params = '\\n'.join([f\"    {param}\" for param in params])\n",
    "                return f\"(\\n{formatted_params}\\n)\"\n",
    "        return f\"({param_string})\"\n",
    "    \n",
    "    def _format_class_block(self, match):\n",
    "        \"\"\"Format class definition blocks.\"\"\"\n",
    "        block = match.group(1)\n",
    "        lines = block.split('\\n')\n",
    "        \n",
    "        # Find the class signature\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.strip().startswith('(') and ')' in line:\n",
    "                # This looks like a class signature, wrap it in code block\n",
    "                code_start = i\n",
    "                code_end = i\n",
    "                \n",
    "                # Find the end of the signature\n",
    "                paren_count = 0\n",
    "                for j in range(i, len(lines)):\n",
    "                    paren_count += lines[j].count('(') - lines[j].count(')')\n",
    "                    if paren_count <= 0:\n",
    "                        code_end = j\n",
    "                        break\n",
    "                \n",
    "                # Wrap the signature in code block\n",
    "                signature_lines = lines[code_start:code_end+1]\n",
    "                signature = '\\n'.join(signature_lines)\n",
    "                \n",
    "                new_lines = (\n",
    "                    lines[:code_start] + \n",
    "                    ['```python'] + \n",
    "                    signature_lines + \n",
    "                    ['```'] + \n",
    "                    lines[code_end+1:]\n",
    "                )\n",
    "                return '\\n'.join(new_lines)\n",
    "        \n",
    "        return block\n",
    "\n",
    "async def scrape_and_format_docs(urls, output_dir=\"scraped-webpages\"):\n",
    "    \"\"\"\n",
    "    Scrape and format multiple Hugging Face documentation URLs.\n",
    "    \n",
    "    Args:\n",
    "        urls (list): List of URLs to scrape\n",
    "        output_dir (str): Directory to save formatted files\n",
    "    \n",
    "    Returns:\n",
    "        dict: Mapping of URLs to saved filenames\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    formatter = HuggingFaceDocFormatter()\n",
    "    results = {}\n",
    "    \n",
    "    for url in urls:\n",
    "        print(f\"Processing: {url}\")\n",
    "        \n",
    "        try:\n",
    "            # Scrape the content\n",
    "            raw_content = await url_to_llm_text(url)\n",
    "            \n",
    "            # Generate filename from content\n",
    "            filename = formatter._url_to_filename(url, raw_content)\n",
    "            \n",
    "            # Format the content\n",
    "            formatted_content = formatter.format_documentation(raw_content)\n",
    "            \n",
    "            # Save formatted markdown\n",
    "            output_path = Path(output_dir) / f\"{filename}.md\"\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(formatted_content)\n",
    "            \n",
    "            results[url] = str(output_path)\n",
    "            print(f\"  ‚úÖ Saved to: {output_path.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error processing {url}: {e}\")\n",
    "            results[url] = None\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Convenience function for single URL\n",
    "async def scrape_and_format_single(url, output_dir=\"scraped-webpages\"):\n",
    "    \"\"\"Scrape and format a single URL.\"\"\"\n",
    "    results = await scrape_and_format_docs([url], output_dir)\n",
    "    return results[url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abeef723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from url_to_llm_text.get_llm_ready_text import url_to_llm_text\n",
    "from urllib.parse import urlparse\n",
    "import asyncio\n",
    "\n",
    "class HuggingFaceDocFormatter:\n",
    "    \"\"\"Improved formatter for Hugging Face documentation.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.patterns = self._initialize_patterns()\n",
    "    \n",
    "    def _initialize_patterns(self):\n",
    "        \"\"\"Initialize regex patterns for formatting.\"\"\"\n",
    "        return {\n",
    "            'cleanup': [\n",
    "                # Remove navigation and header clutter\n",
    "                (r'Hugging Face: https://huggingface\\.co/.*?Sign Up: https://huggingface\\.co/join', ''),\n",
    "                (r'üè° View all docs.*?timm\\s*Search documentation', ''),\n",
    "                (r'mainv\\d+\\.\\d+\\.\\d+.*?doc-builder-html[A-Z]+\\s*', ''),\n",
    "                (r'\\d+,?\\d*: https://github\\.com/huggingface/\\w+', ''),\n",
    "                (r'Join the Hugging Face community.*?to get started', ''),\n",
    "                (r'You are viewing v\\d+\\.\\d+\\.\\d+ version\\..*?is available\\.', ''),\n",
    "                # Clean up navigation breadcrumbs\n",
    "                (r'‚Üê[^‚Üí]*‚Üí', ''),\n",
    "                # Remove excessive whitespace\n",
    "                (r'\\n{3,}', '\\n\\n'),\n",
    "                (r'[ \\t]+$', ''),\n",
    "            ],\n",
    "            'main_headers': [\n",
    "                # Main documentation title\n",
    "                (r'(\\w+) documentation\\s+([\\w\\s-]+?)(?:\\s+\\1|\\s*$)', r'# \\1 Documentation - \\2'),\n",
    "                # Major section headers (only if they start a new paragraph)\n",
    "                (r'\\n\\s*([A-Z][A-Za-z\\s&-]+)\\n\\s*\\n', r'\\n## \\1\\n\\n'),\n",
    "            ],\n",
    "            'class_definitions': [\n",
    "                # Class definitions with proper formatting\n",
    "                (r'class (trl|transformers)\\. (\\w+)', r'## `\\1.\\2`'),\n",
    "                # Remove source links\n",
    "                (r'< source >: https://github\\.com/huggingface/[\\w/.-]+', ''),\n",
    "            ],\n",
    "            'code_formatting': [\n",
    "                # Handle \"Copied\" code blocks\n",
    "                (r'Copied\\s*```(\\w*)\\n(.*?)```', r'```\\1\\n\\2```'),\n",
    "                # Handle simple code examples with \"Copied\"\n",
    "                (r'Copied\\s*([^`\\n]+(?:\\n[^`\\n]*)*?)(?=\\n\\n|\\n[A-Z]|\\Z)', self._format_simple_code),\n",
    "            ],\n",
    "            'links_cleanup': [\n",
    "                # Remove link references that aren't useful\n",
    "                (r': https://huggingface\\.co/docs/[\\w/.-]+#[\\w-]+', ''),\n",
    "                (r': https://huggingface\\.co/docs/[\\w/.-]+', ''),\n",
    "                (r'https://img\\.shields\\.io/badge/[^\\s]+', ''),\n",
    "            ],\n",
    "            'lists': [\n",
    "                # Fix bullet points\n",
    "                (r'^\\s*\\*\\s+', '- ', re.MULTILINE),\n",
    "                # Format important attributes\n",
    "                (r'Important attributes:\\s*\\n\\s*-\\s*', '\\n**Important attributes:**\\n\\n- '),\n",
    "            ],\n",
    "        }\n",
    "    \n",
    "    def _format_simple_code(self, match):\n",
    "        \"\"\"Format simple code blocks that don't have triple backticks.\"\"\"\n",
    "        code = match.group(1).strip()\n",
    "        \n",
    "        # Check if it looks like Python code\n",
    "        if any(keyword in code for keyword in ['from ', 'import ', 'def ', 'class ', '=', '(', ')']):\n",
    "            return f'```python\\n{code}\\n```'\n",
    "        else:\n",
    "            return code\n",
    "    \n",
    "    def _apply_patterns(self, content, pattern_category):\n",
    "        \"\"\"Apply a category of regex patterns.\"\"\"\n",
    "        patterns = self.patterns.get(pattern_category, [])\n",
    "        for pattern_info in patterns:\n",
    "            if len(pattern_info) == 2:\n",
    "                pattern, replacement = pattern_info\n",
    "                flags = 0\n",
    "            elif len(pattern_info) == 3:\n",
    "                pattern, replacement, flags = pattern_info\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            if callable(replacement):\n",
    "                content = re.sub(pattern, replacement, content, flags=flags)\n",
    "            else:\n",
    "                content = re.sub(pattern, replacement, content, flags=flags)\n",
    "        return content\n",
    "    \n",
    "    def _extract_title_from_content(self, content):\n",
    "        \"\"\"Extract a suitable title from the documentation content.\"\"\"\n",
    "        title_patterns = [\n",
    "            r'(\\w+) documentation\\s+([\\w\\s-]+)',\n",
    "            r'# ([\\w\\s-]+)',\n",
    "            r'^([A-Z][A-Za-z\\s&-]+)(?=\\n|$)',\n",
    "        ]\n",
    "        \n",
    "        for pattern in title_patterns:\n",
    "            match = re.search(pattern, content, re.MULTILINE)\n",
    "            if match:\n",
    "                if len(match.groups()) == 2:\n",
    "                    return f\"{match.group(1)}_{match.group(2)}\"\n",
    "                else:\n",
    "                    return match.group(1)\n",
    "        \n",
    "        return \"huggingface_doc\"\n",
    "    \n",
    "    def _url_to_filename(self, url, content):\n",
    "        \"\"\"Generate a filename from URL and content.\"\"\"\n",
    "        title = self._extract_title_from_content(content)\n",
    "        filename = re.sub(r'[^\\w\\s-]', '', title.lower())\n",
    "        filename = re.sub(r'[-\\s]+', '_', filename)\n",
    "        filename = filename.strip('_')\n",
    "        \n",
    "        # Add URL context\n",
    "        parsed = urlparse(url)\n",
    "        path_parts = [p for p in parsed.path.split('/') if p and p not in ['docs', 'en']]\n",
    "        \n",
    "        if path_parts:\n",
    "            url_context = '_'.join(path_parts[-2:])\n",
    "            url_context = re.sub(r'[^\\w]', '_', url_context)\n",
    "            if url_context not in filename:\n",
    "                filename = f\"{filename}_{url_context}\"\n",
    "        \n",
    "        return filename\n",
    "    \n",
    "    def _format_class_signature(self, content):\n",
    "        \"\"\"Format class signatures with proper parameter formatting.\"\"\"\n",
    "        # Find class signatures with parameters\n",
    "        class_pattern = r'(## `\\w+\\.\\w+`.*?)\\(\\s*([^)]+)\\s*\\)'\n",
    "        \n",
    "        def format_signature(match):\n",
    "            class_header = match.group(1)\n",
    "            params = match.group(2)\n",
    "            \n",
    "            # Clean up parameters\n",
    "            params = re.sub(r'\\s+', ' ', params)\n",
    "            param_list = [p.strip() for p in params.split(',') if p.strip()]\n",
    "            \n",
    "            if len(param_list) > 3 or len(params) > 100:\n",
    "                # Format as multi-line\n",
    "                formatted_params = '\\n'.join([f'    {param},' for param in param_list])\n",
    "                signature = f'{class_header}\\n\\n```python\\nclass_name(\\n{formatted_params}\\n)\\n```'\n",
    "            else:\n",
    "                # Keep as single line\n",
    "                signature = f'{class_header}\\n\\n```python\\nclass_name({params})\\n```'\n",
    "            \n",
    "            return signature\n",
    "        \n",
    "        return re.sub(class_pattern, format_signature, content, flags=re.DOTALL)\n",
    "    \n",
    "    def _clean_parameter_descriptions(self, content):\n",
    "        \"\"\"Clean up parameter description formatting.\"\"\"\n",
    "        # Fix parameter list formatting\n",
    "        content = re.sub(\n",
    "            r'(\\w+)\\s+\\(([^)]+)\\)\\s*‚Äî\\s*(.+?)(?=\\n\\s*\\w+\\s+\\(|\\n\\n|\\Z)',\n",
    "            r'- **\\1** (`\\2`) ‚Äî \\3',\n",
    "            content,\n",
    "            flags=re.DOTALL\n",
    "        )\n",
    "        \n",
    "        # Clean up method descriptions that got mixed in\n",
    "        content = re.sub(r'- \\*\\*(\\w+)\\*\\* ‚Äî', r'- **\\1** ‚Äî', content)\n",
    "        \n",
    "        return content\n",
    "    \n",
    "    def _format_method_sections(self, content):\n",
    "        \"\"\"Format method sections without making them all headers.\"\"\"\n",
    "        # Only make actual method definitions into subsections, not every mention\n",
    "        method_pattern = r'\\n\\s*(\\w+)\\n\\s*\\n\\s*([A-Z].*?)\\n'\n",
    "        \n",
    "        def replace_method(match):\n",
    "            method_name = match.group(1)\n",
    "            description = match.group(2)\n",
    "            \n",
    "            # Only format as subsection if it looks like a method definition\n",
    "            if re.match(r'^[a-z_]+$', method_name) and len(description) > 20:\n",
    "                return f'\\n### {method_name}\\n\\n{description}\\n'\n",
    "            else:\n",
    "                return match.group(0)\n",
    "        \n",
    "        return re.sub(method_pattern, replace_method, content)\n",
    "    \n",
    "    def format_documentation(self, content):\n",
    "        \"\"\"Main formatting method.\"\"\"\n",
    "        # Apply basic cleanup\n",
    "        content = self._apply_patterns(content, 'cleanup')\n",
    "        \n",
    "        # Apply main headers\n",
    "        content = self._apply_patterns(content, 'main_headers')\n",
    "        \n",
    "        # Handle class definitions\n",
    "        content = self._apply_patterns(content, 'class_definitions')\n",
    "        \n",
    "        # Format code blocks\n",
    "        content = self._apply_patterns(content, 'code_formatting')\n",
    "        \n",
    "        # Clean up links\n",
    "        content = self._apply_patterns(content, 'links_cleanup')\n",
    "        \n",
    "        # Fix lists\n",
    "        content = self._apply_patterns(content, 'lists')\n",
    "        \n",
    "        # Format class signatures\n",
    "        content = self._format_class_signature(content)\n",
    "        \n",
    "        # Clean parameter descriptions\n",
    "        content = self._clean_parameter_descriptions(content)\n",
    "        \n",
    "        # Format method sections more carefully\n",
    "        content = self._format_method_sections(content)\n",
    "        \n",
    "        # Final cleanup\n",
    "        content = re.sub(r'\\n{3,}', '\\n\\n', content)\n",
    "        content = re.sub(r'#+\\s*#+', '##', content)  # Fix double headers\n",
    "        \n",
    "        # Add proper spacing around headers\n",
    "        content = re.sub(r'(#{1,3}[^\\n]+)', r'\\n\\1\\n', content)\n",
    "        content = re.sub(r'\\n{3,}', '\\n\\n', content)\n",
    "        \n",
    "        return content.strip()\n",
    "\n",
    "# Main functions remain the same\n",
    "async def scrape_and_format_docs(urls, output_dir=\"scraped-webpages\"):\n",
    "    \"\"\"Scrape and format multiple Hugging Face documentation URLs.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    formatter = HuggingFaceDocFormatter()\n",
    "    results = {}\n",
    "    \n",
    "    for url in urls:\n",
    "        print(f\"Processing: {url}\")\n",
    "        \n",
    "        try:\n",
    "            raw_content = await url_to_llm_text(url)\n",
    "            filename = formatter._url_to_filename(url, raw_content)\n",
    "            formatted_content = formatter.format_documentation(raw_content)\n",
    "            \n",
    "            output_path = Path(output_dir) / f\"{filename}.md\"\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(formatted_content)\n",
    "            \n",
    "            results[url] = str(output_path)\n",
    "            print(f\"  ‚úÖ Saved to: {output_path.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error processing {url}: {e}\")\n",
    "            results[url] = None\n",
    "    \n",
    "    return results\n",
    "\n",
    "async def scrape_and_format_single(url, output_dir=\"scraped-webpages\"):\n",
    "    \"\"\"Scrape and format a single URL.\"\"\"\n",
    "    results = await scrape_and_format_docs([url], output_dir)\n",
    "    return results[url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48b85414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: https://huggingface.co/docs/transformers/v4.53.1/en/main_classes/trainer\n",
      "  ‚úÖ Saved to: transformers_trainer_transformers_main_classes_trainer.md\n",
      "Processing: https://huggingface.co/docs/trl/v0.19.1/en/sft_trainer\n",
      "  ‚úÖ Saved to: trl_supervised_fine_tuning_trainer_trl_v0_19_1_sft_trainer.md\n",
      "Processing: https://huggingface.co/docs/transformers/v4.53.1/en/main_classes/tokenizer\n",
      "  ‚úÖ Saved to: transformers_tokenizer_transformers_main_classes_tokenizer.md\n",
      "‚úÖ https://huggingface.co/docs/transformers/v4.53.1/en/main_classes/trainer ‚Üí scraped-webpages/transformers_trainer_transformers_main_classes_trainer.md\n",
      "‚úÖ https://huggingface.co/docs/trl/v0.19.1/en/sft_trainer ‚Üí scraped-webpages/trl_supervised_fine_tuning_trainer_trl_v0_19_1_sft_trainer.md\n",
      "‚úÖ https://huggingface.co/docs/transformers/v4.53.1/en/main_classes/tokenizer ‚Üí scraped-webpages/transformers_tokenizer_transformers_main_classes_tokenizer.md\n"
     ]
    }
   ],
   "source": [
    "# Example usage - multiple URLs\n",
    "urls = [\n",
    "    \"https://huggingface.co/docs/transformers/v4.53.1/en/main_classes/trainer\",\n",
    "    \"https://huggingface.co/docs/trl/v0.19.1/en/sft_trainer\",\n",
    "    \"https://huggingface.co/docs/transformers/v4.53.1/en/main_classes/tokenizer\"\n",
    "]\n",
    "\n",
    "results = await scrape_and_format_docs(urls)\n",
    "\n",
    "# Check results\n",
    "for url, filepath in results.items():\n",
    "    if filepath:\n",
    "        print(f\"‚úÖ {url} ‚Üí {filepath}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbfdf9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
