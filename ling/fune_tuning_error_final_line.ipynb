{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c64d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25.2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute '_core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(numpy\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_core\u001b[49m\u001b[38;5;241m.\u001b[39mmultiarray\u001b[38;5;241m.\u001b[39m_reconstruct)  \u001b[38;5;66;03m# ‚Üê this line should succeed\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maccelerate\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccelerate version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accelerate\u001b[38;5;241m.\u001b[39m__version__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/numpy/__init__.py:328\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved in NumPy 1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTester was removed in NumPy 1.25.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    329\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute '_core'"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)\n",
    "print(numpy._core.multiarray._reconstruct)  # ‚Üê this line should succeed\n",
    "\n",
    "import accelerate\n",
    "print(\"Accelerate version:\", accelerate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d182ce30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.26.4\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy._core' has no attribute 'multiarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumpy version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, numpy\u001b[38;5;241m.\u001b[39m__version__)  \u001b[38;5;66;03m# should be 1.26.4\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maccelerate\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccelerate version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accelerate\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/accelerate/__init__.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.8.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccelerator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbig_modeling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     cpu_offload,\n\u001b[1;32m     19\u001b[0m     cpu_offload_with_hook,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     load_checkpoint_and_dispatch,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m skip_first_batches\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/accelerate/accelerator.py:36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhooks\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m split_torch_state_dict_into_shards\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpointing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoaderDispatcher, prepare_data_loader, skip_first_batches\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_logger\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/accelerate/checkpointing.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msafetensors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     MODEL_NAME,\n\u001b[1;32m     24\u001b[0m     OPTIMIZER_NAME,\n\u001b[1;32m     25\u001b[0m     RNG_STATE_NAME,\n\u001b[1;32m     26\u001b[0m     SAFE_MODEL_NAME,\n\u001b[1;32m     27\u001b[0m     SAFE_WEIGHTS_NAME,\n\u001b[1;32m     28\u001b[0m     SAMPLER_NAME,\n\u001b[1;32m     29\u001b[0m     SCALER_NAME,\n\u001b[1;32m     30\u001b[0m     SCHEDULER_NAME,\n\u001b[1;32m     31\u001b[0m     WEIGHTS_NAME,\n\u001b[1;32m     32\u001b[0m     get_pretty_name,\n\u001b[1;32m     33\u001b[0m     is_cuda_available,\n\u001b[1;32m     34\u001b[0m     is_hpu_available,\n\u001b[1;32m     35\u001b[0m     is_mlu_available,\n\u001b[1;32m     36\u001b[0m     is_musa_available,\n\u001b[1;32m     37\u001b[0m     is_sdaa_available,\n\u001b[1;32m     38\u001b[0m     is_torch_version,\n\u001b[1;32m     39\u001b[0m     is_torch_xla_available,\n\u001b[1;32m     40\u001b[0m     is_xpu_available,\n\u001b[1;32m     41\u001b[0m     load,\n\u001b[1;32m     42\u001b[0m     save,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.4.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GradScaler\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/accelerate/utils/__init__.py:219\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_deepspeed_available():\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeepspeed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    209\u001b[0m         DeepSpeedEngineWrapper,\n\u001b[1;32m    210\u001b[0m         DeepSpeedOptimizerWrapper,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m         map_pytorch_optim_to_deepspeed,\n\u001b[1;32m    217\u001b[0m     )\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbnb\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m has_4bit_bnb_layers, load_and_quantize_model\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    221\u001b[0m     disable_fsdp_ram_efficient_loading,\n\u001b[1;32m    222\u001b[0m     enable_fsdp_ram_efficient_loading,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     save_fsdp_optimizer,\n\u001b[1;32m    235\u001b[0m )\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlaunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    237\u001b[0m     PrepareForLaunch,\n\u001b[1;32m    238\u001b[0m     _filter_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m     prepare_tpu,\n\u001b[1;32m    244\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/accelerate/utils/bnb.py:29\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimports\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     is_4bit_bnb_available,\n\u001b[1;32m     26\u001b[0m     is_8bit_bnb_available,\n\u001b[1;32m     27\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbig_modeling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch_model, init_empty_weights\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BnbQuantizationConfig\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     find_tied_parameters,\n\u001b[1;32m     33\u001b[0m     get_balanced_memory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     set_module_tensor_to_device,\n\u001b[1;32m     38\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/accelerate/big_modeling.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     AlignDevicesHook,\n\u001b[1;32m     27\u001b[0m     CpuOffload,\n\u001b[1;32m     28\u001b[0m     LayerwiseCastingHook,\n\u001b[1;32m     29\u001b[0m     UserCpuOffloadHook,\n\u001b[1;32m     30\u001b[0m     add_hook_to_module,\n\u001b[1;32m     31\u001b[0m     attach_align_device_hook,\n\u001b[1;32m     32\u001b[0m     attach_align_device_hook_on_blocks,\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     35\u001b[0m     OffloadedWeightsLoader,\n\u001b[1;32m     36\u001b[0m     check_cuda_p2p_ib_support,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     retie_parameters,\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SUPPORTED_PYTORCH_LAYERS_FOR_UPCASTING\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/accelerate/hooks.py:37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clear_device_cache\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_non_persistent_buffers\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mother\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m recursive_getattr\n\u001b[1;32m     40\u001b[0m _accelerate_added_attributes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msdaa\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmusa\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mModelHook\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/accelerate/utils/other.py:369\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# The following are considered \"safe\" globals to reconstruct various types of objects when using `weights_only=True`\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# These should be added and then removed after loading in the file\u001b[39;00m\n\u001b[1;32m    366\u001b[0m np_core \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39m_core \u001b[38;5;28;01mif\u001b[39;00m is_numpy_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcore\n\u001b[1;32m    367\u001b[0m TORCH_SAFE_GLOBALS \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# numpy arrays are just numbers, not objects, so we can reconstruct them safely\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     \u001b[43mnp_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiarray\u001b[49m\u001b[38;5;241m.\u001b[39m_reconstruct,\n\u001b[1;32m    370\u001b[0m     np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# The following are needed for the RNG states\u001b[39;00m\n\u001b[1;32m    372\u001b[0m     encode,\n\u001b[1;32m    373\u001b[0m     np\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    374\u001b[0m ]\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_numpy_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    377\u001b[0m     TORCH_SAFE_GLOBALS\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mUInt32DType)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy._core' has no attribute 'multiarray'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy\n",
    "print(\"Numpy version:\", numpy.__version__)  # should be 1.26.4\n",
    "\n",
    "import accelerate\n",
    "print(\"Accelerate version:\", accelerate.__version__)\n",
    "\n",
    "import transformers\n",
    "print(\"Transformers version:\",transformers.__version__)  # Should be 4.53.0 or higher\n",
    "\n",
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675b2377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.7.1\n",
      "MPS available: True\n",
      "MPS built: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "print(\"MPS built:\", torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3c803b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maccelerate\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(accelerate\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(transformers\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "import accelerate\n",
    "import transformers\n",
    "print(accelerate.__version__)\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319ada7",
   "metadata": {},
   "source": [
    "# Start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50f22a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8b8988",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"openai/gsm8k\", \"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8331d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e551ab3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n",
      "#### 72\n"
     ]
    }
   ],
   "source": [
    "example = train_data[0]\n",
    "print(example[\"question\"])\n",
    "print(example[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66405c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 7473\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673435c2",
   "metadata": {},
   "source": [
    "## Error in the final answer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f79ef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå QUESTION:\n",
      " Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "\n",
      "‚úÖ ORIGINAL ANSWER:\n",
      " Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n",
      "#### 72\n",
      "\n",
      "‚ùå FLAWED ANSWER:\n",
      " Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n",
      "#### 73\n",
      "\n",
      "üßæ LABEL:\n",
      " {'verdict': 'Flawed', 'error_details': {'error_type': 'computational_error', 'erroneous_line_number': 'L3', 'explanation': 'The final answer is too high by 1. It should be 72, not 73.', 'error_in_text': '#### 72', 'correction_in_text': '#### 72'}}\n"
     ]
    }
   ],
   "source": [
    "question = example[\"question\"]\n",
    "original_answer = example[\"answer\"]\n",
    "\n",
    "# Split into lines for L1, L2, ...\n",
    "lines = original_answer.strip().splitlines()\n",
    "\n",
    "# Find the line that contains '#### <number>'\n",
    "for i, line in enumerate(lines):\n",
    "    match = re.match(r\"####\\s*(-?\\d+)\", line.strip())\n",
    "    if match:\n",
    "        correct = int(match.group(1))\n",
    "        flawed = correct + 1\n",
    "        error_line_index = i\n",
    "        break\n",
    "else:\n",
    "    print(\"‚ùå No final answer line found.\")\n",
    "    exit()\n",
    "\n",
    "# Create modified lines\n",
    "flawed_lines = lines.copy()\n",
    "flawed_lines[error_line_index] = re.sub(r\"####\\s*\\d+\", f\"#### {flawed}\", lines[error_line_index])\n",
    "\n",
    "# Recombine into modified answer\n",
    "flawed_answer = \"\\n\".join(flawed_lines)\n",
    "\n",
    "# Compute error location as \"L<N>\"\n",
    "error_location = f\"L{error_line_index + 1}\"\n",
    "\n",
    "# Create label\n",
    "label = {\n",
    "    \"verdict\": \"Flawed\",\n",
    "    \"error_details\": {\n",
    "        \"error_type\": \"computational_error\",\n",
    "        \"erroneous_line_number\": error_location,\n",
    "        \"explanation\": f\"The final answer is too high by 1. It should be {correct}, not {flawed}.\",\n",
    "        \"error_in_text\": lines[error_line_index],\n",
    "        \"correction_in_text\": f\"#### {correct}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Output\n",
    "print(\"üìå QUESTION:\\n\", question)\n",
    "print(\"\\n‚úÖ ORIGINAL ANSWER:\\n\", original_answer)\n",
    "print(\"\\n‚ùå FLAWED ANSWER:\\n\", flawed_answer)\n",
    "print(\"\\nüßæ LABEL:\\n\", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faaae799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished writing gsm8k_train_flawed_plus1_final_answer.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Output path\n",
    "output_path = Path(\"gsm8k_train_flawed_plus1_final_answer.jsonl\")\n",
    "\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as f_out:\n",
    "    for i, ex in enumerate(dataset[\"train\"]):\n",
    "        q = ex[\"question\"]\n",
    "        a = ex[\"answer\"]\n",
    "\n",
    "        # Split into lines for L1, L2, ...\n",
    "        lines = a.strip().splitlines()\n",
    "\n",
    "        # Find the line with the final answer\n",
    "        for idx, line in enumerate(lines):\n",
    "            match = re.match(r\"####\\s*(-?\\d+)\", line.strip())\n",
    "            if match:\n",
    "                correct = int(match.group(1))\n",
    "                flawed = correct + 1\n",
    "                error_line_index = idx\n",
    "                break\n",
    "        else:\n",
    "            print(i, \"‚ùå No final answer line found.\\n\")\n",
    "            print(a)\n",
    "            continue  # skip if no final answer found\n",
    "\n",
    "        # Copy and modify lines\n",
    "        flawed_lines = lines.copy()\n",
    "        flawed_lines[error_line_index] = re.sub(r\"####\\s*\\d+\", f\"#### {flawed}\", lines[error_line_index]) #f\"#### {flawed}\"\n",
    "\n",
    "        # # Replace the final display number in any inline computation\n",
    "        # flawed_lines = [\n",
    "        #     re.sub(r\"(>>)\" + str(correct) + r\"\\b\", r\"\\1\" + str(flawed), line)\n",
    "        #     for line in flawed_lines\n",
    "        # ]\n",
    "\n",
    "        flawed_answer = \"\\n\".join(flawed_lines)\n",
    "\n",
    "        error_location = f\"L{error_line_index + 1}\"\n",
    "\n",
    "        # Create label\n",
    "        label = {\n",
    "            \"verdict\": \"Flawed\",\n",
    "            \"error_details\": {\n",
    "                \"error_type\": \"computational_error\",\n",
    "                \"erroneous_line_number\": f\"L{error_line_index + 1}\",\n",
    "                \"explanation\": f\"The final answer is too high by 1. It should be {correct}, not {flawed}.\",\n",
    "                \"error_in_text\": lines[error_line_index],\n",
    "                \"correction_in_text\": f\"#### {correct}\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Final example\n",
    "        entry = {\n",
    "            \"id\": i,\n",
    "            \"question\": q,\n",
    "            \"flawed_answer\": flawed_answer,\n",
    "            \"label\": label\n",
    "        }\n",
    "        f_out.write(json.dumps(entry) + \"\\n\")\n",
    "        \n",
    "print(f\"‚úÖ Finished writing {output_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9201dd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7473\n"
     ]
    }
   ],
   "source": [
    "with open(\"gsm8k_train_flawed_plus1_final_answer.jsonl\") as f:\n",
    "    print(len(f.readlines()))  # Should be >0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "083e72cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished writing gsm8k_test_flawed_plus1_final_answer.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Output path\n",
    "output_path = Path(\"gsm8k_test_flawed_plus1_final_answer.jsonl\")\n",
    "\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as f_out:\n",
    "    for i, ex in enumerate(dataset[\"test\"]):\n",
    "        q = ex[\"question\"]\n",
    "        a = ex[\"answer\"]\n",
    "\n",
    "        # Split into lines for L1, L2, ...\n",
    "        lines = a.strip().splitlines()\n",
    "\n",
    "        # Find the line with the final answer\n",
    "        for idx, line in enumerate(lines):\n",
    "            match = re.match(r\"####\\s*(-?\\d+)\", line.strip())\n",
    "            if match:\n",
    "                correct = int(match.group(1))\n",
    "                flawed = correct + 1\n",
    "                error_line_index = idx\n",
    "                break\n",
    "        else:\n",
    "            print(i, \"‚ùå No final answer line found.\\n\")\n",
    "            print(a)\n",
    "            continue  # skip if no final answer found\n",
    "\n",
    "        # Copy and modify lines\n",
    "        flawed_lines = lines.copy()\n",
    "        flawed_lines[error_line_index] = re.sub(r\"####\\s*\\d+\", f\"#### {flawed}\", lines[error_line_index]) #f\"#### {flawed}\"\n",
    "\n",
    "        # # Replace the final display number in any inline computation\n",
    "        # flawed_lines = [\n",
    "        #     re.sub(r\"(>>)\" + str(correct) + r\"\\b\", r\"\\1\" + str(flawed), line)\n",
    "        #     for line in flawed_lines\n",
    "        # ]\n",
    "\n",
    "        flawed_answer = \"\\n\".join(flawed_lines)\n",
    "\n",
    "        error_location = f\"L{error_line_index + 1}\"\n",
    "\n",
    "        # Create label\n",
    "        label = {\n",
    "            \"verdict\": \"Flawed\",\n",
    "            \"error_details\": {\n",
    "                \"error_type\": \"computational_error\",\n",
    "                \"erroneous_line_number\": f\"L{error_line_index + 1}\",\n",
    "                \"explanation\": f\"The final answer is too high by 1. It should be {correct}, not {flawed}.\",\n",
    "                \"error_in_text\": lines[error_line_index],\n",
    "                \"correction_in_text\": f\"#### {correct}\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Final example\n",
    "        entry = {\n",
    "            \"id\": i,\n",
    "            \"question\": q,\n",
    "            \"flawed_answer\": flawed_answer,\n",
    "            \"label\": label\n",
    "        }\n",
    "        f_out.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Finished writing {output_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6532c71",
   "metadata": {},
   "source": [
    "## Error in the second last line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23f3abfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå QUESTION:\n",
      " Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "\n",
      "‚úÖ ORIGINAL ANSWER:\n",
      " Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n",
      "#### 72\n",
      "\n",
      "‚ùå FLAWED ANSWER:\n",
      " Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=73>>73 clips altogether in April and May.\n",
      "#### 73\n",
      "\n",
      "üßæ LABEL:\n",
      " {'verdict': 'Flawed', 'error_details': {'error_type': 'computational_error', 'erroneous_line_number': 'L2', 'explanation': 'The answer is too high by 1. It should be 72, not 73.', 'error_in_text': '#### 72', 'correction_in_text': '#### 72'}}\n"
     ]
    }
   ],
   "source": [
    "question = example[\"question\"]\n",
    "original_answer = example[\"answer\"]\n",
    "\n",
    "# Split into lines for L1, L2, ...\n",
    "lines = original_answer.strip().splitlines()\n",
    "\n",
    "# Find the line that contains '#### <number>'\n",
    "for i, line in enumerate(lines):\n",
    "    match = re.match(r\"####\\s*(-?\\d+)\", line.strip())\n",
    "    if match:\n",
    "        correct = int(match.group(1))\n",
    "        flawed = correct + 1\n",
    "        error_line_index = i\n",
    "        break\n",
    "else:\n",
    "    print(\"‚ùå No final answer line found.\")\n",
    "    exit()\n",
    "\n",
    "# Create modified lines\n",
    "flawed_lines = lines.copy()\n",
    "flawed_lines[error_line_index] = re.sub(r\"####\\s*\\d+\", f\"#### {flawed}\", lines[error_line_index])\n",
    "\n",
    "# Replace only the number after the final '>>' (the human-readable result)\n",
    "flawed_lines = [\n",
    "    re.sub(str(correct) + r\"(>>)\" + str(correct) + r\"\\b\", str(flawed) + r\">>\" + str(flawed), line)\n",
    "    for line in flawed_lines\n",
    "]\n",
    "\n",
    "# Recombine into modified answer\n",
    "flawed_answer = \"\\n\".join(flawed_lines)\n",
    "\n",
    "# Compute error location as \"L<N>\"\n",
    "error_location = f\"L{error_line_index}\"\n",
    "\n",
    "# Create label\n",
    "label = {\n",
    "    \"verdict\": \"Flawed\",\n",
    "    \"error_details\": {\n",
    "        \"error_type\": \"computational_error\",\n",
    "        \"erroneous_line_number\": error_location,\n",
    "        \"explanation\": f\"The answer is too high by 1. It should be {correct}, not {flawed}.\",\n",
    "        \"error_in_text\": lines[error_line_index],\n",
    "        \"correction_in_text\": f\"#### {correct}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Output\n",
    "print(\"üìå QUESTION:\\n\", question)\n",
    "print(\"\\n‚úÖ ORIGINAL ANSWER:\\n\", original_answer)\n",
    "print(\"\\n‚ùå FLAWED ANSWER:\\n\", flawed_answer)\n",
    "print(\"\\nüßæ LABEL:\\n\", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4b55ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished writing gsm8k_train_flawed_plus1_2nd_last.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Output path\n",
    "output_path = Path(\"gsm8k_train_flawed_plus1_2nd_last.jsonl\")\n",
    "\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as f_out:\n",
    "    for i, ex in enumerate(dataset[\"train\"]):\n",
    "        q = ex[\"question\"]\n",
    "        a = ex[\"answer\"]\n",
    "\n",
    "        # Split into lines for L1, L2, ...\n",
    "        lines = a.strip().splitlines()\n",
    "\n",
    "        # Find the line with the final answer\n",
    "        for idx, line in enumerate(lines):\n",
    "            match = re.match(r\"####\\s*(-?\\d+)\", line.strip())\n",
    "            if match:\n",
    "                correct = int(match.group(1))\n",
    "                flawed = correct + 1\n",
    "                error_line_index = idx\n",
    "                break\n",
    "        else:\n",
    "            print(i, \"‚ùå No final answer line found.\\n\")\n",
    "            print(a)\n",
    "            continue  # skip if no final answer found\n",
    "\n",
    "        # Copy and modify lines\n",
    "        flawed_lines = lines.copy()\n",
    "        flawed_lines[error_line_index] = re.sub(r\"####\\s*\\d+\", f\"#### {flawed}\", lines[error_line_index]) #f\"#### {flawed}\"\n",
    "\n",
    "        # Replace only the number after the final '>>' (the human-readable result)\n",
    "        flawed_lines = [\n",
    "            re.sub(str(correct) + r\"(>>)\" + str(correct) + r\"\\b\", str(flawed) + r\">>\" + str(flawed), line)\n",
    "            for line in flawed_lines\n",
    "        ]\n",
    "\n",
    "        flawed_answer = \"\\n\".join(flawed_lines)\n",
    "\n",
    "        error_location = f\"L{error_line_index}\"\n",
    "\n",
    "        # Create label\n",
    "        label = {\n",
    "            \"verdict\": \"Flawed\",\n",
    "            \"error_details\": {\n",
    "                \"error_type\": \"computational_error\",\n",
    "                \"erroneous_line_number\": f\"L{error_line_index}\",\n",
    "                \"explanation\": f\"The 2n last line value is too high by 1. It should be {correct}, not {flawed}.\",\n",
    "                \"error_in_text\": lines[error_line_index],\n",
    "                \"correction_in_text\": f\"#### {correct}\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Final example\n",
    "        entry = {\n",
    "            \"id\": i,\n",
    "            \"question\": q,\n",
    "            \"flawed_answer\": flawed_answer,\n",
    "            \"label\": label\n",
    "        }\n",
    "        f_out.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Finished writing {output_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aa32743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished writing gsm8k_test_flawed_plus1_2nd_last.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Output path\n",
    "output_path = Path(\"gsm8k_test_flawed_plus1_2nd_last.jsonl\")\n",
    "\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as f_out:\n",
    "    for i, ex in enumerate(dataset[\"test\"]):\n",
    "        q = ex[\"question\"]\n",
    "        a = ex[\"answer\"]\n",
    "\n",
    "        # Split into lines for L1, L2, ...\n",
    "        lines = a.strip().splitlines()\n",
    "\n",
    "        # Find the line with the final answer\n",
    "        for idx, line in enumerate(lines):\n",
    "            match = re.match(r\"####\\s*(-?\\d+)\", line.strip())\n",
    "            if match:\n",
    "                correct = int(match.group(1))\n",
    "                flawed = correct + 1\n",
    "                error_line_index = idx\n",
    "                break\n",
    "        else:\n",
    "            print(i, \"‚ùå No final answer line found.\\n\")\n",
    "            print(a)\n",
    "            continue  # skip if no final answer found\n",
    "\n",
    "        # Copy and modify lines\n",
    "        flawed_lines = lines.copy()\n",
    "        flawed_lines[error_line_index] = re.sub(r\"####\\s*\\d+\", f\"#### {flawed}\", lines[error_line_index]) #f\"#### {flawed}\"\n",
    "\n",
    "        # Replace only the number after the final '>>' (the human-readable result)\n",
    "        flawed_lines = [\n",
    "            re.sub(str(correct) + r\"(>>)\" + str(correct) + r\"\\b\", str(flawed) + r\">>\" + str(flawed), line)\n",
    "            for line in flawed_lines\n",
    "        ]\n",
    "\n",
    "        flawed_answer = \"\\n\".join(flawed_lines)\n",
    "\n",
    "        error_location = f\"L{error_line_index}\"\n",
    "\n",
    "        # Create label\n",
    "        label = {\n",
    "            \"verdict\": \"Flawed\",\n",
    "            \"error_details\": {\n",
    "                \"error_type\": \"computational_error\",\n",
    "                \"erroneous_line_number\": f\"L{error_line_index}\",\n",
    "                \"explanation\": f\"The 2n last line value is too high by 1. It should be {correct}, not {flawed}.\",\n",
    "                \"error_in_text\": lines[error_line_index],\n",
    "                \"correction_in_text\": f\"#### {correct}\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Final example\n",
    "        entry = {\n",
    "            \"id\": i,\n",
    "            \"question\": q,\n",
    "            \"flawed_answer\": flawed_answer,\n",
    "            \"label\": label\n",
    "        }\n",
    "        f_out.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Finished writing {output_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1484a1a",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ef736c",
   "metadata": {},
   "source": [
    "## Combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fe07740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 7473\n",
      "First line: {\"id\": 0, \"question\": \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\", \"flawed_answer\": \"Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 73\", \"label\": {\"verdict\": \"Flawed\", \"error_details\": {\"error_type\": \"computational_error\", \"erroneous_line_number\": \"L3\", \"explanation\": \"The final answer is too high by 1. It should be 72, not 73.\", \"error_in_text\": \"#### 72\", \"correction_in_text\": \"#### 72\"}}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"gsm8k_train_flawed_plus1_final_answer.jsonl\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    print(f\"Total lines: {len(lines)}\")\n",
    "    print(\"First line:\", lines[0] if lines else \"No data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c05357c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined training set size: 14946\n"
     ]
    }
   ],
   "source": [
    "original_dataset = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "\n",
    "def load_jsonl(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "flawed_train = load_jsonl(\"gsm8k_train_flawed_plus1_final_answer.jsonl\")\n",
    "flawed_test = load_jsonl(\"gsm8k_test_flawed_plus1_final_answer.jsonl\")\n",
    "\n",
    "combined_train = []\n",
    "\n",
    "# Add correct examples from original dataset\n",
    "for ex in original_dataset[\"train\"]:\n",
    "    combined_train.append({\n",
    "        \"question\": ex[\"question\"],\n",
    "        \"solution\": ex[\"answer\"],\n",
    "        \"label\": \"Correct\"\n",
    "    })\n",
    "\n",
    "# Add flawed examples\n",
    "for ex in flawed_train:\n",
    "    combined_train.append({\n",
    "        \"question\": ex[\"question\"],\n",
    "        \"solution\": ex[\"flawed_answer\"],\n",
    "        \"label\": \"Flawed\"\n",
    "    })\n",
    "\n",
    "print(f\"Combined training set size: {len(combined_train)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03a7e72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined test set size: 2638\n"
     ]
    }
   ],
   "source": [
    "combined_test = []\n",
    "\n",
    "# Add correct examples from original test split\n",
    "for ex in original_dataset[\"test\"]:\n",
    "    combined_test.append({\n",
    "        \"question\": ex[\"question\"],\n",
    "        \"solution\": ex[\"answer\"],\n",
    "        \"label\": \"Correct\"\n",
    "    })\n",
    "\n",
    "# Add flawed examples from test JSONL\n",
    "for ex in flawed_test:\n",
    "    combined_test.append({\n",
    "        \"question\": ex[\"question\"],\n",
    "        \"solution\": ex[\"flawed_answer\"],\n",
    "        \"label\": \"Flawed\"\n",
    "    })\n",
    "\n",
    "print(f\"Combined test set size: {len(combined_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52c0e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to HUgging Face Dataset\n",
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_list(combined_train)\n",
    "test_dataset = Dataset.from_list(combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e34fc74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1\n",
      "MPS available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50ba8256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e67532276f459aa09f3bf00362a6e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6fa062ae45452eafd86268d5d473a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocessing with tokenizer\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_fn(example):\n",
    "    full_input = f\"Question:\\n{example['question']}\\n\\nSolution:\\n{example['solution']}\"\n",
    "    return tokenizer(full_input, truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_fn)\n",
    "test_dataset = test_dataset.map(tokenize_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd9cc45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_TF_DATASET_REFS',\n",
       " '__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getitems__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_build_local_temp_path',\n",
       " '_check_index_is_initialized',\n",
       " '_data',\n",
       " '_estimate_nbytes',\n",
       " '_fingerprint',\n",
       " '_format_columns',\n",
       " '_format_kwargs',\n",
       " '_format_type',\n",
       " '_generate_tables_from_cache_file',\n",
       " '_generate_tables_from_shards',\n",
       " '_get_cache_file_path',\n",
       " '_get_output_signature',\n",
       " '_getitem',\n",
       " '_indexes',\n",
       " '_indices',\n",
       " '_info',\n",
       " '_map_single',\n",
       " '_new_dataset_with_indices',\n",
       " '_output_all_columns',\n",
       " '_push_parquet_shards_to_hub',\n",
       " '_save_to_disk_single',\n",
       " '_select_contiguous',\n",
       " '_select_with_indices_mapping',\n",
       " '_split',\n",
       " 'add_column',\n",
       " 'add_elasticsearch_index',\n",
       " 'add_faiss_index',\n",
       " 'add_faiss_index_from_external_arrays',\n",
       " 'add_item',\n",
       " 'align_labels_with_mapping',\n",
       " 'batch',\n",
       " 'builder_name',\n",
       " 'cache_files',\n",
       " 'cast',\n",
       " 'cast_column',\n",
       " 'citation',\n",
       " 'class_encode_column',\n",
       " 'cleanup_cache_files',\n",
       " 'column_names',\n",
       " 'config_name',\n",
       " 'data',\n",
       " 'dataset_size',\n",
       " 'description',\n",
       " 'download_checksums',\n",
       " 'download_size',\n",
       " 'drop_index',\n",
       " 'features',\n",
       " 'filter',\n",
       " 'flatten',\n",
       " 'flatten_indices',\n",
       " 'format',\n",
       " 'formatted_as',\n",
       " 'from_buffer',\n",
       " 'from_csv',\n",
       " 'from_dict',\n",
       " 'from_file',\n",
       " 'from_generator',\n",
       " 'from_json',\n",
       " 'from_list',\n",
       " 'from_pandas',\n",
       " 'from_parquet',\n",
       " 'from_polars',\n",
       " 'from_spark',\n",
       " 'from_sql',\n",
       " 'from_text',\n",
       " 'get_index',\n",
       " 'get_nearest_examples',\n",
       " 'get_nearest_examples_batch',\n",
       " 'homepage',\n",
       " 'info',\n",
       " 'is_index_initialized',\n",
       " 'iter',\n",
       " 'license',\n",
       " 'list_indexes',\n",
       " 'load_elasticsearch_index',\n",
       " 'load_faiss_index',\n",
       " 'load_from_disk',\n",
       " 'map',\n",
       " 'num_columns',\n",
       " 'num_rows',\n",
       " 'push_to_hub',\n",
       " 'remove_columns',\n",
       " 'rename_column',\n",
       " 'rename_columns',\n",
       " 'repeat',\n",
       " 'reset_format',\n",
       " 'save_faiss_index',\n",
       " 'save_to_disk',\n",
       " 'search',\n",
       " 'search_batch',\n",
       " 'select',\n",
       " 'select_columns',\n",
       " 'set_format',\n",
       " 'set_transform',\n",
       " 'shape',\n",
       " 'shard',\n",
       " 'shuffle',\n",
       " 'size_in_bytes',\n",
       " 'skip',\n",
       " 'sort',\n",
       " 'split',\n",
       " 'supervised_keys',\n",
       " 'take',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_iterable_dataset',\n",
       " 'to_json',\n",
       " 'to_list',\n",
       " 'to_pandas',\n",
       " 'to_parquet',\n",
       " 'to_polars',\n",
       " 'to_sql',\n",
       " 'to_tf_dataset',\n",
       " 'train_test_split',\n",
       " 'unique',\n",
       " 'version',\n",
       " 'with_format',\n",
       " 'with_transform']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dc075df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
       " 'solution': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72',\n",
       " 'label': 'Correct',\n",
       " 'input_ids': [101,\n",
       "  3160,\n",
       "  1024,\n",
       "  21521,\n",
       "  2853,\n",
       "  15281,\n",
       "  2000,\n",
       "  4466,\n",
       "  1997,\n",
       "  2014,\n",
       "  2814,\n",
       "  1999,\n",
       "  2258,\n",
       "  1010,\n",
       "  1998,\n",
       "  2059,\n",
       "  2016,\n",
       "  2853,\n",
       "  2431,\n",
       "  2004,\n",
       "  2116,\n",
       "  15281,\n",
       "  1999,\n",
       "  2089,\n",
       "  1012,\n",
       "  2129,\n",
       "  2116,\n",
       "  15281,\n",
       "  2106,\n",
       "  21521,\n",
       "  5271,\n",
       "  10462,\n",
       "  1999,\n",
       "  2258,\n",
       "  1998,\n",
       "  2089,\n",
       "  1029,\n",
       "  5576,\n",
       "  1024,\n",
       "  21521,\n",
       "  2853,\n",
       "  4466,\n",
       "  1013,\n",
       "  1016,\n",
       "  1027,\n",
       "  1026,\n",
       "  1026,\n",
       "  4466,\n",
       "  1013,\n",
       "  1016,\n",
       "  1027,\n",
       "  2484,\n",
       "  1028,\n",
       "  1028,\n",
       "  2484,\n",
       "  15281,\n",
       "  1999,\n",
       "  2089,\n",
       "  1012,\n",
       "  21521,\n",
       "  2853,\n",
       "  4466,\n",
       "  1009,\n",
       "  2484,\n",
       "  1027,\n",
       "  1026,\n",
       "  1026,\n",
       "  4466,\n",
       "  1009,\n",
       "  2484,\n",
       "  1027,\n",
       "  5824,\n",
       "  1028,\n",
       "  1028,\n",
       "  5824,\n",
       "  15281,\n",
       "  10462,\n",
       "  1999,\n",
       "  2258,\n",
       "  1998,\n",
       "  2089,\n",
       "  1012,\n",
       "  1001,\n",
       "  1001,\n",
       "  1001,\n",
       "  1001,\n",
       "  5824,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eabd6a",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0647094f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14946/14946 [00:01<00:00, 7501.45 examples/s] \n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2638/2638 [00:00<00:00, 24672.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Label encoding\n",
    "label_map = {\"Correct\": 0, \"Flawed\": 1}\n",
    "train_dataset = train_dataset.map(lambda e: {\"labels\": label_map[e[\"label\"]]})\n",
    "test_dataset = test_dataset.map(lambda e: {\"labels\": label_map[e[\"label\"]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cd635c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TransformGetItemToIndex' from 'torch._dynamo._trace_wrapped_higher_order_op' (/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/torch/_dynamo/_trace_wrapped_higher_order_op.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     AutoTokenizer,\n\u001b[1;32m      3\u001b[0m     AutoModelForSequenceClassification,\n\u001b[1;32m      4\u001b[0m     Trainer,\n\u001b[1;32m      5\u001b[0m     TrainingArguments\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Use a lightweight and stable model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/transformers/utils/import_utils.py:2154\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   2153\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2154\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2155\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2156\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/transformers/utils/import_utils.py:2184\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/transformers/utils/import_utils.py:2182\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2182\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2183\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2184\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:38\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     cached_file,\n\u001b[1;32m     31\u001b[0m     extract_commit_hash,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     logging,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoder_decoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EncoderDecoderConfig\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto_factory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LazyAutoMapping\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     40\u001b[0m     CONFIG_MAPPING_NAMES,\n\u001b[1;32m     41\u001b[0m     AutoConfig,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     replace_list_option_in_docstrings,\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available():\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:43\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoConfig, model_type_to_module_name, replace_list_option_in_docstrings\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GenerationMixin\n\u001b[1;32m     46\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     48\u001b[0m _T \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_T\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/transformers/utils/import_utils.py:2154\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   2153\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2154\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2155\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2156\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/transformers/utils/import_utils.py:2184\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/transformers/utils/import_utils.py:2182\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2182\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2183\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2184\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/transformers/generation/utils.py:49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeepspeed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_deepspeed_zero3_enabled\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_fsdp_managed_module\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmasking_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_masks_for_generate\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CausalLMOutputWithPast, Seq2SeqLMOutput\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m isin_mps_friendly\n",
      "File \u001b[0;32m/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/transformers/masking_utils.py:37\u001b[0m\n\u001b[1;32m     34\u001b[0m _is_torch_greater_or_equal_than_2_6 \u001b[38;5;241m=\u001b[39m is_torch_greater_or_equal(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.6\u001b[39m\u001b[38;5;124m\"\u001b[39m, accept_dev\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_greater_or_equal_than_2_6:\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_trace_wrapped_higher_order_op\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TransformGetItemToIndex\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mand_masks\u001b[39m(\u001b[38;5;241m*\u001b[39mmask_functions: \u001b[38;5;28mlist\u001b[39m[Callable]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable:\n\u001b[1;32m     41\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a mask function that is the intersection of provided mask functions\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'TransformGetItemToIndex' from 'torch._dynamo._trace_wrapped_higher_order_op' (/opt/anaconda3/envs/gsm8k-verifier/lib/python3.10/site-packages/torch/_dynamo/_trace_wrapped_higher_order_op.py)"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "# Use a lightweight and stable model\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./verifier_model\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de2b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.53.0\n",
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import accelerate\n",
    "\n",
    "print(transformers.__version__)  # should be >= 4.38\n",
    "print(accelerate.__version__)   # should be >= 0.26.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4760c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4907c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsm8k-verifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
